---
layout: default
author: muyalei
date: 2018-12-21
title: sqool使用
tags:
   - sqoop相关
---


***整理自[http://www.cnblogs.com/xuyou551/p/7991973.html](http://www.cnblogs.com/xuyou551/p/7991973.html)、[https://blog.csdn.net/u013850277/article/details/78808631](https://blog.csdn.net/u013850277/article/details/78808631)***

## 简介：

Sqoop可以在HDFS/Hive和关系型数据库之间进行数据的导入导出，其中主要使用了import和export这两个工具。这两个工具非常强大，提供了很多选项帮助我们完成数据的迁移和同步。比如，下面两个潜在的需求：
  1. 业务数据存放在关系数据库中，如果数据量达到一定规模后需要对其进行分析或同统计，单纯使用关系数据库可能会成为瓶颈，这时可以将数据从业务数据库数据导入（import）到Hadoop平台进行离线分析。
  2. 对大规模的数据在Hadoop平台上进行分析以后，可能需要将结果同步到关系数据库中作为业务的辅助数据，这时候需要将Hadoop平台分析后的数据导出（export）到关系数据库。


## 使用

1. 将mysql数据导入hdfs

命令：
```
sqoop import --connect jdbc:mysql://host:port/db --username xx --password xx --table xx --target-dir xx
```

2. 将mysql数据导入hive

命令：
```
sqoop import --connect jdbc:mysql://host:port/db --username xx --password xx --table --hive-import --hive-table xx
```
*注意：*
   * 如果这个表没有主键，需要加 `-m 1` 参数，将其运行在一个map中。
   * 关于-m参数更详细的解释：sqoop导入mysql表时，没有指定map数量时，会并行导入。并行导入时会根据表的主键类型选着不同的Splitter，参见DataDrivenDBInputFormat的getSplitter方法，TextSplitter会现将string转BigDecimal再转string ，这个过程可能会产生乱码和特殊字符，导致后期的sql语法错误。<br/>
   建议：
    * 导入中不要选用String类型的主键切分map个数 
    * 导入小表时指定-m 1，单map 即节省资源，又防止并行切分字符串主键问题
   *参考自[https://blog.csdn.net/MuQianHuanHuoZhe/article/details/80585672](https://blog.csdn.net/MuQianHuanHuoZhe/article/details/80585672)*

3. 执行导入Hive的命令（如果Hive中没有存在对应的hive表，则会依据mysql 的表来创建对应的表，字段属性也跟mysql的一致）
   * 这张表不存在的情况下（默认会自动创建对应的Hive表并全量将数据加载进去）
   * 这张表存在的情况下（默认往表中追加数据）

4. 复杂查询条件导入
  * where参数的使用<br/>
  举例：--where " SXQMC='广东省广州市萝岗区' and XZJDMC='九龙镇' and BMC='女' and S_LAST_UPDATED > '2018-01-04 03:10:13'  and  S_LAST_UPDATED < '2018-01-04 03:21:00' " <br/>
  * query参数的使用<br/>
  举例：--query " select * from test1  where SXQMC='广东省广州市番禺区' and BMC='女' and S_LAST_UPDATED > '2018-01-04 03:10:13'  and  S_LAST_UPDATED < '2018-01-04 03:21:00'  AND \$CONDITIONS" 


5. 常用参数
  * import和export工具有些通用的选项，如下所示<br/>
  选项	                                     含义说明<br/>
  --connect <jdbc-uri>	                 指定JDBC连接字符串<br/>
  --connection-manager <class-name>	     指定要使用的连接管理器类<br/>
  --driver <class-name>	                 指定要使用的JDBC驱动类<br/>
  --hadoop-mapred-home <dir>	         指定$HADOOP_MAPRED_HOME路径<br/>
  --help	                             打印用法帮助信息<br/>
  --password-file	                     设置用于存放认证的密码信息文件的路径<br/>
  -P	                                 从控制台读取输入的密码<br/>
  --password <password>	                 设置认证密码<br/>
  --username <username>	                 设置认证用户名<br/>
  --verbose	                             打印详细的运行信息<br/>
  --connection-param-file <filename>	 可选，指定存储数据库连接参数的属性文件<br/>
















