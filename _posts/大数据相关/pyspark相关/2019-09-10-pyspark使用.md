---
layout: default
author: muyalei
title: pyspark安装使用
date：2019-09-10
tags:
    - spark相关
---


***整理自[https://blog.csdn.net/u010793236/article/details/74388920](https://blog.csdn.net/u010793236/article/details/74388920)***

### 1、pyspark安装使用
使用`pip3 install pyspark`安装pyspark，使用过程中可能包如下错误：<br />
Exception: Python in worker has different version 2.7 than that in driver 3.6, PySpark cannot run with different minor versions.Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.<br />
解决方法： 
```
在 ~/.bash_profile 文件下增加：
export PYSPARK_PYTHON=/usr/local/bin/python3
export PYSPARK_DRIVER_PYTHON=/usr/local/bin/python3
```
或者，也可以在python代码中添加：
```
import os
os.environ['PYSPARK_PYTHON']='/usr/local/bin/pythonXXX' 
```
