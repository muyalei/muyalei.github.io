---
layout: default
author: muyalei
title: Ambari扩展第三方应用
date: 2019-11-27
tags:
    - 大数据
---


***鄙人原创，转载请注明出处***


***参考：***

[https://cwiki.apache.org/confluence/display/AMBARI/Defining+a+Custom+Service](https://cwiki.apache.org/confluence/display/AMBARI/Defining+a+Custom+Service)
[https://www.ibm.com/developerworks/cn/opensource/os-cn-ambari-metrics/index.html](https://www.ibm.com/developerworks/cn/opensource/os-cn-ambari-metrics/index.html)
[https://www.ibm.com/developerworks/cn/opensource/os-cn-bigdata-ambari/index.html](https://www.ibm.com/developerworks/cn/opensource/os-cn-bigdata-ambari/index.html)
[https://blog.csdn.net/qq_22796957/article/details/91038467](https://blog.csdn.net/qq_22796957/article/details/91038467)
[https://segmentfault.com/a/1190000019831651](https://segmentfault.com/a/1190000019831651)
[https://blog.csdn.net/WangPing1223/article/details/77499068](https://blog.csdn.net/WangPing1223/article/details/77499068)
[https://blog.csdn.net/BalaBalaYi/article/details/84139541](https://blog.csdn.net/BalaBalaYi/article/details/84139541)
[https://github.com/BalaBalaYi/Ambari-Elastic-Service/blob/master/ELASTICSEARCH-6.4.x/package/scripts/es_master.py](https://github.com/BalaBalaYi/Ambari-Elastic-Service/blob/master/ELASTICSEARCH-6.4.x/package/scripts/es_master.py)
[https://github.com/BalaBalaYi/Ambari-Redis-Service/tree/master/REDIS-5.0.0](https://github.com/BalaBalaYi/Ambari-Redis-Service/tree/master/REDIS-5.0.0)
[https://blog.csdn.net/BalaBalaYi/article/details/84134926](https://blog.csdn.net/BalaBalaYi/article/details/84134926)
[https://blog.csdn.net/BalaBalaYi/article/details/84140971](https://blog.csdn.net/BalaBalaYi/article/details/84140971)
[https://blog.csdn.net/high2011/article/details/90272331](https://blog.csdn.net/high2011/article/details/90272331)
[https://blog.csdn.net/qq_39429714/article/details/84328807](https://blog.csdn.net/qq_39429714/article/details/84328807)
[https://github.com/BalaBalaYi/Ambari-Redis-Service/blob/master/REDIS-5.0.0/configuration/redis-env.xml](https://github.com/BalaBalaYi/Ambari-Redis-Service/blob/master/REDIS-5.0.0/configuration/redis-env.xml)
[https://blog.csdn.net/u013595419/article/details/79139207#t6](https://blog.csdn.net/u013595419/article/details/79139207#t6)
[https://www.cnblogs.com/felixzh/p/10594952.html](https://www.cnblogs.com/felixzh/p/10594952.html)
[https://github.com/highfei2011/ambari-flink-service/tree/master/configuration](https://github.com/highfei2011/ambari-flink-service/tree/master/configuration)
[https://www.kgraph.cn/164.html](https://www.kgraph.cn/164.html)
[https://blog.csdn.net/xianzhen376/article/details/52485145](https://blog.csdn.net/xianzhen376/article/details/52485145)
[https://www.jianshu.com/p/96271bccb6bc](https://www.jianshu.com/p/96271bccb6bc)


## 简介

Ambari管理内置应用有一套标准的流程模版，只需要按照这个流程，将自己的第三方应用做相应配置，Ambari即可像管理内置应用一样管理添加的第三方应用。

将下载的ambari-server安装文件解压后，可以在下面路径找到Ambari所有的内置应用设置文件：`/var/www/html/ambari/centos7/2.7.0.0-897/tars/ambari/ambari-3.0.0.0.2.7.0.0-897/ambari-server/src/main/resources/stacks/HDP/2.6/services`(我是解压到了/var/www/html/ambari目录下)，每个应用下面都有很多设置文件，metainfo.xml、package、configuration这三个是一定存在的。

metainfo.xml是告诉Ambari服务，这个应用名字是什么，有哪些组件，部署每个组件对应的加载脚本名称、位置，部署这个应用前操作系统需要安装哪些东西，依赖的配置文件等描述信息；package/scripts目录下存放加载应用的脚本、读取配置文件的params.py等；configuration是配置文件，存放这个应用需要用户在web界面上配置的信息。 

下面会以扩展Flink作为实例。


##  一、metainfo.xml

实例：

```
<?xml version="1.0"?>
<metainfo> 
    <schemaVersion>2.0</schemaVersion>
    <services>
        <service> #要扩展的第三方服务描述信息，在web界面点击`add service`时，显示的服务信息就是这个标签设置的
            <name>FLINK</name> 
            <displayName>Flink</displayName>
            <comment>balabalamuyalei</comment>
            <version>1.9.1</version>
            <components>
                <component> #这个服务包含的组件
                    <name>FLINK_MASTER</name> 
                    <displayName>Flink Master</displayName>
                    <category>MASTER</category> #这个标签，只有MASTER、SLAVE、CLIENT三个值，一定要大写
                    <cardinality>1</cardinality> #组件数量
                    <timelineAppid>FLINK</timelineAppid>
                    <versionAdvertised>true</versionAdvertised>
                    <commandScript>
                        <script>scripts/flink_master.py</script> #Ambari管理这个服务的控制脚本（完成install、start、stop、status、configure这些生命周期）
                        <scriptType>PYTHON</scriptType>
                        <timeout>1200</timeout>
                    </commandScript>
                    <logs>
                        <log>
                            <logId>flink-master</logId>
                            <primary>true</primary>
                        </log>
                    </logs>
                </component>
                <component>
                    <name>FLINK_SLAVE</name>
                    <displayName>Flink Slave</displayName>
                    <category>SLAVE</category>
                    <cardinality>0+</cardinality>
                    <timelineAppid>FLINK</timelineAppid>
                    <versionAdvertised>true</versionAdvertised>
                    <commandScript>
                        <script>scripts/flink_slave.py</script>
                        <scriptType>PYTHON</scriptType>
                        <timeout>1200</timeout>
                    </commandScript>
                    <logs>
                        <log>
                            <logId>flink-slave</logId>
                            <primary>true</primary>
                        </log>
                    </logs>
                </component> 
            </components>
            <osSpecifics>
                <osSpecific>
                    <osFamily>any</osFamily> #所支持的操作系统
                    <packages>
                        <package> #这个服务的依赖，比如下面的wget，部署这个应用前，Ambari会通过yum或者apt-get安装所有这些依赖
                            <name>gcc</name>
                        </package>
                        <package>
                            <name>wget</name>
                        </package>
                    </packages>
                </osSpecific>
            </osSpecifics>
            <!--
            <commandScript> #服务检查的脚本实现
                <script>scripts/service_check.py</script> 
                <scriptType>PYTHON</scriptType>
                <timeout>300</timeout>
            </commandScript>
            -->            
           <!-- 
            <configuration-dependencies> #这个应用依赖的配置文件，写在这里后，当这些配置文件内容改变，web界面会提示重启该服务。这里空着也没事。
                <config-type>flink-env</config-type>
                <config-type>config-sh</config-type>  
                <config-type>flink-conf-yaml</config-type>  
            </configuration-dependencies>
            -->

            #这两个是Ambari提供的为扩展的第三方应用能使用`AMS`系统而提供的两个基础配置文件
            <!--<metricsFileName>metrics.json</metricsFileName>-->
            <!--<widgetsFileName>widgets.json</widgetsFileName>-->
           

            <restartRequiredAfterChange>true</restartRequiredAfterChange>  #修改配置后是否重启（一般都为true）

            <!--<quickLinksConfigurations>-->
                <!--<quickLinksConfiguration>-->
                    <!--<fileName>quicklinks.json</fileName>-->
                    <!--<default>true</default>-->
                <!--</quickLinksConfiguration>-->
            <!--</quickLinksConfigurations>-->

        </service>
    </services>
</metainfo>
```  


###  几个重要的标签及其参数：

1、category：描述组件是主服务、节点从服务或是客户端。

| category类别 | 默认生命周期命令实现 |
| :------: | :------: | 
| MASTER  | install, start, stop, configure, status |
| SLAVE  | install, start, stop, configure, status |
| CLIENT  | install, configure, status |

2、cardinality：描述组件的数量限制。

| cardinality格式 | 格式说明举例 |
| :------: | :------: | 
| 数字 | <cardinality>1</cardinality>：表示只能有一个 |
| 数字区间 | <cardinality>0-1</cardinality>：表示最少有零个，最多有一个 |
| 数字单增区间 | <cardinality>1+</cardinality>：表示最少有1个 |
| ALL | <cardinality>ALL</cardinality>：表示所有节点都需要 |

3、commandScript：组件生命周期命令的执行脚本实现。（除install、start、stop、status、configure这几个基本声明周期命令外的命令。）

其它参数请参考：[官方说明](https://cwiki.apache.org/confluence/display/AMBARI/Writing+metainfo.xml)（[中文翻译](https://blog.csdn.net/WangPing1223/article/details/77499098)）


## 二、configuration

实例：

```
...................

    <property>
        <name>flink.user</name>
        <value>flink</value>
        <property-type>USER</property-type>
        <display-name>Flink User</display-name>
        <description>flink unix user</description>
    </property>

    <property>
        <name>flink.group</name>
        <value>flink</value>
        <property-type>GROUP</property-type>
        <display-name>Flink Group</display-name>
        <description>flink unix group</description>
    </property>

    <property>
        <name>flink.base.dir</name>
        <value>ambari+HDP安装包所在路径前半部分(即httpd服务的路径)/hdp/HDP/centos7/3.0.0.0-1634/hualala/flink</value>
        <display-name>Location to install Flink</display-name>
        <description>flink安装源文件所在位置</description>
    </property>

    <property>                
        <name>flink.base.dir.slave</name>        
        <value>http://flink源码文件所在服务器ip/hdp/HDP/centos7/3.0.0.0-1634/hualala/flink</value>    
        <display-name>Location to install Flink</display-name>  
        <description>flink安装源文件所在位置</description>                           
    </property>

</configuration>
```

这个目录下存放这个应用的相关配置文件，可以简单分为两种类型的配置文件，即-env和其它，-env.xml 配置文件要求必须存在，主要描述安装包路径，用户，组，pid文件目录，根目录等。

配置文件添加参数的格式参照实例。

要添加其他配置文件，只需要将文件添加在这里即可，必须是 .xml 文件，如下面这个，要在安装应用后覆写flink_conf.yaml文件的flink-conf-yaml.xml文件，内容格式如下（注意，要将某些`<`标签注释掉，否则Ambari不能正确读取这个配置文件。可以使用`vim`打开配置文件，<value>...</value>标签内的内容有些带 `<` 的字符会高亮，需要注意将这些注释掉，这些会打乱xml文件的格式）：

```
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

........................

    <property>
        <name>flink_conf_yaml_content</name>
        <value>
.........................

jobmanager.rpc.address: localhost

# The RPC port where the JobManager is reachable.

jobmanager.rpc.port: 6123


# The heap size for the JobManager JVM

jobmanager.heap.size: 1024m
..........

        </value>
        <description>Template for flink-conf.yaml</description>
    </property>

</configuration>
```

### 部分参数详解

```
默认情况下，<value>值不能为空，如果想允许值为空，可在<value-attributes>下添加<empty-value-valid>为true：

<property>
    <name>server.basePath</name>
    <value>none</value>
    <value-attributes>
        <empty-value-valid>true</empty-value-valid>
    </value-attributes>
    <display-name>Server Base Path</display-name>
</property>

<value-attributes>还支持一些常见的格式，例如boolean：

此处要注意，xml中boolean值的内容请填写false或true，但是后续代码在获取参数时，获取的是boolean类型的False和True。

<property>
    <name>server.rewriteBasePath</name>
    <value>false</value>
    <value-attributes>
        <type>boolean</type>
        <overridable>false</overridable>
    </value-attributes>
    <display-name>Server Rewrite Base Path</display-name>
    <description>xxxx</description>
</property>

<value-attributes>针对密码类型的支持：

<property>
    <name>zeppelin.ssl.keystore.password</name>
    <value>change me</value>
    <value-attributes>
        <type>password</type>
    </value-attributes>
    <property-type>PASSWORD</property-type>
    <description>Keystore password. Can be obfuscated by the Jetty Password tool</description>
</property>

<value-attributes>针对数字类型的支持，其中type可以为int,long等，minimum和maximum为可选参数用于给定范围，unit为单位显示等，例如：

<property>
    <name>ops.interval</name>
    <value>5000</value>
    <value-attributes>
        <type>int</type>
        <minimum>100</minimum>
        <maximum>50000</maximum>
        <unit>Milliseconds</unit>
        <increment-step>100</increment-step>
        <overridable>false</overridable>
    </value-attributes>
    <display-name>Ops Interval</display-name>
    <description>Set the interval in milliseconds to sample system and process performance metrics. Minimum is 100ms. Defaults to 5000.</description>
\</property>
```

上述格式已然能满足大部分需求了。当然，Ambari对此xml文件的支持还包括很多其它参数，有兴趣的童鞋可参考Ambari下的通用服务目录下的配置：/var/lib/ambari-server/resources/common-services。


## 三、flink_master.py、flink_slave.py

以为flink_master.py举例：

```
#!/usr/bin/python
# -*- coding:utf-8 -*-#


from resource_management import *
import time,sys,os,glob,pwd,grp,signal
reload(sys)
sys.setdefaultencoding('utf-8') 


class FlinkMaster(Script):
    
    #安装flink
    def install(self,env):

        import params
        env.set_params(params) #这是Ambari服务实现的一个方法，像这样调用一下这个方法，下面可以使用params.key_name的方式获取params中的参数值
      
        #安装依赖文件（<osSpecific>标签下<packages>标签中列出的依赖，ambari会尝试通过yum或apt-get安装）        
        self.install_packages(env)
       
        #检查用户组flink是否存在
        try:
            grp.getgrnam(params.flink_group)
        except KeyError:
            for gid in range(10000,50000,5): #500以内是系统程序用户组使用的gid
                try:
                    grp.getgrgid(gid) #判断当前gid是否存在，不存在时进入错误处理流程 
                except KeyError:
                    cmd = 'groupadd -g {} {}'.format(gid,params.flink_group) #新建用户组
                    os.system(cmd)
                    break #成功新建用户组，则跳出循环
                       
        #检查用户flink是否存在，不存在就创建
        try:
            pwd.getpwnam(params.flink_user)
        except KeyError:
            for uid in range(10000,50000,5):
                try:
                    pwd.getpwuid(uid)
                except KeyError:
                    cmd = 'useradd -u {} -g {} -m {}'.format(uid,params.flink_group,params.flink_user) #新建用户
                    os.system(cmd)
                    cmd = 'echo "{}" |passwd --stdin {}'.format(params.flink_user,params.flink_user)
                    os.system(cmd)
                    break


        #下面这个是调用Ambari服务实现的方法检查或创建用户指定的安装用户
        """ 
        #检查用户组，不存在就创建
        try:
            grp.getgrnam(params.flink_group)
        except KeyError:
            Group(group_name=params.flink_group)

        #检查用户，不存在就创建
        try:
            pwd.getpwnam(params.flink_user)
        except KeyError:
            User(username=params.flink_user,
                 gid=params.flink_group,
                 groups=[params.flink_group],
                 ignore_failures=True
                 )
        #创建目录
        Directory([params.log_file_dir, params.pid_file_dir],
                  mode=0755,
                  cd_access='a',
                  owner=params.flink_user,
                  group=params.flink_group,
                  create_parents=True
                  )
        """
        #创建存放pid文件的目录
        Directory(params.pid_file_dir,mode=0755,cd_access='a',owner=params.flink_user,group=params.flink_group,create_parents=True)
        
        #安装flink 
        cmd = format("cd {flink_base_dir};rm -rf flink;tar -zxvf {flink_edition_name};mv flink-1.9.1 flink")
        Execute(cmd,user=params.flink_user)
      
        #将修改后的flink-conf.yaml文件内容写入flink安装目录下的conf/flink-conf.yaml文件中
        #flink_conf_yaml_content=InlineTemplate(params.flink_conf_yaml_content)
        #File(format("{flink_base_dir}/flink/conf/flink-conf.yaml"), content=flink_conf_yaml_content, owner=params.flink_user)
 
        #确认params.flink_user对所有文件有权限
        cmd = format("chown -R {flink_user}:{flink_group} {flink_base_dir}")
        Execute(cmd)

        #删除安装包
        #cmd = format("cd {flink_base_dir_master}; rm -rf {flink_edition_name}")
        #Execute(cmd,user=params.flink_user)
        
        Execute('echo "flink install complete"')

   
    #配置flink
    def configure(self,env):

        import params,status_params
        env.set_params(params)
        env.set_params(status_params)
       
        #声明hadoop位置
        cmd = format("export HADOOP_CONF_DIR={hadoop_conf_dir}")
        Execute(cmd,user=params.flink_user)        
       
        #确保pid存放目录存在
        Directory(params.pid_file_dir,mode=0755,cd_access='a',owner=params.flink_user,group=params.flink_group,create_parents=True)

        #将用户填写的flink的pid文件存放路径追加到flink安装目录下bin目录的config.sh文件中
        cmd = format('echo "FLINK_PID_DIR=\'{pid_file_dir}\'" >> {flink_base_dir}/flink/bin/config.sh')
        Execute(cmd,user=params.flink_user)        

        #将修改后的flink-conf.yaml文件内容写入flink安装目录下的conf/flink-conf.yaml文件中
        flink_conf_yaml_content=InlineTemplate(params.flink_conf_yaml_content) 
        File(format("{flink_base_dir}/flink/conf/flink-conf.yaml"), content=flink_conf_yaml_content, owner=params.flink_user)

        Execute('echo "Configuration complete"')

    

    def stop(self,env):
        
        import params
        env.set_params(params)
        
        #正常情况下，通过安装包中的脚本停止服务
        cmd = format('cd {flink_base_dir}/flink/bin/;./stop-cluster.sh')
        Execute(cmd,user=params.flink_user)        

        #读取flink的相关进程pid
        with open(params.pid_file_dir+'/flink.pid','r') as f:
            pid_list = f.read().split('\n')
            f.close()
        #正常杀死进程（这里没有使用Ambari服务提供的Execute()方法执行kill命令，是因为：由于某些原因pid已经被杀死后，再用Execute()进行kill动作，会抛出异常，然后服务停止）
        """
        for pid in pid_list: 
            Execute('kill {pid}'.format(pid=pid))
        """
        os.system('kill {pids}'.format(pids=' '.join(pid_list)))
        #再强杀一次，确保进程全部杀死
        """
        for pid in pid_list:
            Execute('kill -9 {pid}'.format(pid=pid))
        """
        os.system('kill -9 {pids}'.format(pids=' '.join(pid_list)))

        Execute('echo "Stop flink success"')        


    def start(self,env):

        import params
        env.set_params(params)
      
        #配置文件生效
        self.configure(env)
       
        #启动flink
        cmd = format("cd {flink_base_dir}/flink/bin; ./{flink_start_command}")
        Execute(cmd,user=params.flink_user)  
       
        #将相关pid写入/var/run/flink/flink.pid
        """
        pid_file_list = os.listdir(params.pid_file_dir) #执行start_cluster.sh对应的pid文件
        if 'flink.pid' in pid_file_list:
            pid_file_list.remove('flink.pid')
         
        cmd = format('cat {pid_file_dir}/{file1} {pid_file_dir}/{file2} > {pid_file}'.format(file1=pid_file_list[0],file2=pid_file_list[1]))        
        Execute(cmd,user=params.flink_user)
        """
        cmd = format('cat {pid_file_dir}/flink-{flink_user}-standalonesession.pid {pid_file_dir}/flink-{flink_user}-taskexecutor.pid > {pid_file_dir}/flink.pid',user=params.flink_user)
        Execute(cmd,user=params.flink_user)
         
        Execute('echo "Start flink success"',user=params.flink_user)
        
   
    def status(self,env):
        import status_params
        env.set_params(status_params) 
       
        #使用内置方法检查pid文件状态 
        check_process_status(status_params.pid_file)


if __name__=='__main__':
    FlinkMaster().execute()  
```

## 四、params.py

这个文件存在的目的，是为了用户在写flink_master.py/flink_slave.py的时候，能像python中的dict通过key读取value值一样，读取用户配置的参数信息。

实例：

```
#!/usr/bin/env python
from resource_management import *
from resource_management.libraries.script.script import Script
import sys, os, glob
from resource_management.libraries.functions.version import format_stack_version
from resource_management.libraries.functions.default import default


# server configurations
config = Script.get_config() #Ambari服务实现的一个方法，作用是在这个脚本里可以像python中dict获取参数一样读取configuration目录下的配置文件中参数


# params from flink-conf.yaml
flink_user = config['configurations']['flink-env']['flink.user']
flink_group = config['configurations']['flink-env']['flink.group']
flink_base_dir = config['configurations']['flink-env']['flink.base.dir']
flink_base_dir_slave = config['configurations']['flink-env']['flink.base.dir.slave']
hadoop_conf_dir = config['configurations']['flink-env']['hadoop.conf.dir']
pid_file_dir = config['configurations']['flink-env']['pid.file.dir']
pid_file = pid_file_dir+'/flink.pid'
log_file_dir = config['configurations']['flink-env']['log.file.dir']
flink_edition_name = config['configurations']['flink-env']['flink.edition.name']

flink_conf_yaml_content = config['configurations']['flink-conf-yaml']['flink_conf_yaml_content']

flink_start_command = config['configurations']['flink-env']['flink.start.command']
```

## 五、安装过程

以flink为例。

前提：

（1）将flink安装源文件放到flink-env.xml中指定的flink.base.dir目录下，给文件加权限。

（2）将配置ignore_groupsusers_create打开

```
cd /var/lib/ambari-server/resources/scripts
python configs.py -u admin -p admin -n `集群名称`_name -l `ambari-server所在主机ip` -t 8080 -a get -c cluster-env |grep -i ignore_groupsusers_create
"ignore_groupsusers_create": "false",
python configs.py -u admin -p admin -n `集群名称`_name -l `ambari-server所在主机ip` -t 8080 -a set -c cluster-env -k ignore_groupsusers_create -v true
```
*参考：*[https://www.cnblogs.com/barneywill/p/10281678.html](https://www.cnblogs.com/barneywill/p/10281678.html)

安装：

（1）将写好的FLINK目录放到/var/lib/ambari-server/resources/stacks/HDP/3.0/services、/var/lib/ambari-agent/cache/stacks/HDP/3.0/services目录下，

（2）执行`ambari-server restart`命令重启ambari-server，等待服务加载完

（3）即可通过web界面的`Add Service`按钮部署flink

安装失败重新安装：

（1）curl -u admin:admin -H "X-Requested-By: ambari" -X DELETE  http://`ambari-server所在主机ip`:8080/api/v1/clusters/`集群名称`/services/`要删除的应用`

如：curl -u admin:admin -H "X-Requested-By: ambari" -X DELETE  http://master:8080/api/v1/clusters/wow/services/FLINK
*参考：*[https://blog.csdn.net/levy_cui/article/details/51143113](https://blog.csdn.net/levy_cui/article/details/51143113)

（2）ambari-server restart  
 
注意：要将jdk本地安装目录中的java命令`/usr/local/java/bin/java`链接到`/usr/local/bin`下，在`/usr/local/bin`目录下执行`ln -s /usr/local/java/bin/java java`。因为扩展有些第三方应用时，会到指定的目录下寻找java命令，设置的环境变量不管用，比如canal。

[Ambari扩展flink_代码模版](https://github.com/muyalei/muyalei.github.io/tree/gh-pages/tools)


## 六、注意

1、Ambari卸载、重装

参考：[https://github.com/muyalei/muyalei.github.io/blob/gh-pages/_posts/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3/2019-11-20-Ambari%E5%8D%B8%E8%BD%BD%E3%80%81%E9%87%8D%E8%A3%85.md](https://github.com/muyalei/muyalei.github.io/blob/gh-pages/_posts/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3/2019-11-20-Ambari%E5%8D%B8%E8%BD%BD%E3%80%81%E9%87%8D%E8%A3%85.md)

2、Ambari上创建集群，可能出现的各种问题参考[2019-11-27-Ambari扩展第三方应用.md](2019-11-27-Ambari扩展第三方应用.md)
