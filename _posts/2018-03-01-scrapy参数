---
layout:     post
title:      scrapy参数
subtitle:   scrapy
date:       2018-03-01
author:     muyalei
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - scrapy
---

  
### 生成Request实例时可用的几个参数
1.headers参数指定请求头，使用dict包含所有的请求头参数；
2.dont_filter 指定是否启用url去重，默认False（启用）；
3.meta 用法：<br>
  *用来传递框架保留参数，如dont_redirect、handle_httpstatus_list
  使用方式1：```yield scrapy.Request(url=self.url_data.format(city_code=city_code,page_num=page_num),headers=self.headers,meta={'dont_redirect':True,'handle_httpstatus_list':[301,302]},dont_filter=True,callback=lambda response,city_name=city_name:self.parse_data(response,city_name))  #dont_filter=True告诉scheduler不进行重复请求过滤```<br>
  使用方式2：scrapy.Request(...).meta['a'] 
  *用来向callback调用的函数传递额外参数，如：
  ```
  q = scrapy.Request(...)  #生成Request实例
  q.meta['a'] = 'a'  #给该Request通过callback调用的函数传递一个参数'a'
  yield q  
  ....... 
  response.meta['a']  #被调用的函数，通过Response.meta['a'] 拿到Request传递过来的参数；
  ```
  此外，向callback指定的函数传递参数，还有另外一种方式：<br>
  ```
  callback=lambda response,city_name=city_name:self.parse_CityInfo(response,city_name)
  ```
  通过lambda表达式，将参数传递给被调用的函数parse_CityInfo
  
### 自动重定向问题
  1.REDIRECT_ENABLED = False  #全局设置，禁止自动重定向
  2.scrapy.Request(url,meta={'dont_redirect':True,'handle_httpstatus':[301,302]})<br>  
    handle_httpstatus_list:[..] 也可写成类的属性 
    ```
    class TothegoSitemapHomesSpider(SitemapSpider):
    handle_httpstatus_list = [302]  #默认情况下，scrapy的spider中间件的HttpErrorMiddleware会过滤掉所有的返回状态码不在200-300（不包括300）之间的响应，该参数使用户编写的spider可以处理响应状态码是302的response
    ```
    响应状态码是不是2xx的响应，框架当成错误响应，默认情况下直接丢弃。添加handle_httpstatus_list=[404,301,302]的含义是：当响应
    状态码是404、301、302的时候，scrapy也会调用callback指定的函数处理响应结果，而不是将响应结果交给框架处理。
  
### 保存结果到文件
如下例：<br>
```
scrapy crawl meizitu -s FEED_EXPORT_ENCODING=utf-8 -o meizitu.json --logfile=./meizitu.log
```
指定输出结果编码是utf-8；-o指定文件名（后缀名指定要保存的格式）；--logfile指定日志保存位置。 
