By 2050, the global human population is expected to exceed nine billion.
Achieving food security means ensuring that all people have consistent, affordable access to the right nutrients, despite land and water limitations, climate change, and the growing prevalence of resource-intensive Western-style diets that accompany rising incomes.
Surmounting these challenges will not be easy.
But, by taking concerted action to encourage innovation, strengthen market linkages, and support smallholder farmers and women, developing countries can build productive, stable, resilient, and equitable agricultural sectors, achieve sustainable economic growth, and guarantee food security for all.
First, the public and private sectors must ramp up investment in research and development, as well as in the extension and adoption of effective, accessible, and affordable technologies – whether conventional, intermediate, or new platform – according to each country or region’s individual needs.
Given that little suitable land remains unused, and that much of what is being farmed is increasingly degraded and eroded, investment in sustainable intensification (systems for increasing crop yields, while using fewer resources and minimizing environmental damage) is crucial.
For example, conservation agriculture, which aims to reduce or eliminate the need for damaging and labor-intensive interventions like mechanical soil tillage, can increase yields while protecting vulnerable areas from erosion and improving soil fertility.
In Zambia, research conducted by local governments, in collaboration with the anti-poverty charity Concern Worldwide, found that new hybrid seeds produced roughly four to five tons of maize per hectare, compared to Africa’s average of one ton per hectare.
Moreover, smallholder farmers – who are essential to productive, stable, resilient, and equitable agricultural development – should be given the needed tools and support to capture more benefits from value chains, while minimizing risk.
This requires building and maintaining fair and efficient input and output markets that connect them – as well as larger-scale farmers – physically and virtually to opportunities to increase their incomes.
The Alliance for a Green Revolution in Africa has worked with governments, international organizations, charitable foundations, private industry, and farmers’ groups to train and support more than 5,000 agrodealers in eastern and western Africa as they open stores to sell key inputs in small, affordable quantities.
As a result, farmers can travel shorter distances to acquire needed supplies.
In one area of Kenya, farmers who had to travel 17 kilometers to reach an agrodealer in 2004 had to travel only four kilometers three years later.
At the same time, smallholder farmers need easier access to markets to sell their crops for a fair price, rather than relying on expensive middlemen or inefficient government bodies.
An alternative would be to establish some form of cooperative or contract-based farm association that can negotiate fair prices.
Governments must also develop and implement policies aimed at ensuring that those who are typically marginalized from the formal food industry – women, young people, ethnic minorities, and non-landowners – have reliable access to adequate nutrition and opportunities to participate in agricultural production.
As farmers, mothers, educators, and innovators, women provide a critical link between food production, consumption, and future progress on food security.
Indeed, giving female farmers access to the same resources as their male counterparts could reduce the number of undernourished people worldwide by 100-150 million.
Finally, political leaders must consistently pursue this agenda at the international, regional, national, and local levels.
To that end, they must honor their commitments – made through international institutions, such as the G-8, the G-20, and the African Union – to increasing investment in agricultural development and to combating global hunger.
Likewise, they must offer sustained support to ongoing national initiatives, thus encouraging further investment and cooperation.
John Kufuor, Ghana’s president from 2001 to 2009, exemplified such leadership, boosting investment in agricultural research, farmer education, and infrastructure projects, such as roads, warehouses, and cold storage.
As a result, the proportion of people living in poverty fell from 51% in 1991-92 to 28.5% in 2005-06.
Over the last 25 years, Ghana’s agricultural sector has grown at an average annual rate of 5%.
Such experiences provide grounds for optimism.
By investing in and spreading innovative technologies, strengthening market linkages, encouraging visionary leadership, and targeting those most in need – and thus with the most potential – we can feed the world.
Less of an Ass
PARIS – “If the law supposes that,” says Mr. Bumble in Oliver Twist, “the law is a ass – a idiot.”
For decades, Britain’s libel laws had been living down to Mr. Bumble’s expectations.
But freedom of expression worldwide received a boost – and Britain’s reputation for commonsense was somewhat restored – in April, when Parliament adopted legislation revising the country’s libel law.
Previously, corporations and individuals all over the world who claimed that they had been defamed – even if those suing or those who allegedly defamed them had little or no connection to the United Kingdom – would bring lawsuits for libel in the British courts.
The practice was widely known as “libel tourism.”
Many plaintiffs who brought such lawsuits – Russian and Ukrainian oligarchs, Arab princes, African dictators, and unscrupulous bosses – had little chance to prevail.
But the point was not to win.
Often, their targets had much fewer resources, which meant that a libel suit requiring both sides to spend substantial amounts could be effective in silencing critics even if it did not succeed.
Within the United Kingdom itself, the law meant that many important issues could not be fully debated.
The passage of libel reform is attributable to a campaign launched more than three years ago by three organizations: English PEN, a writers association; Index on Censorship, a bimonthly journal that has monitored censorship worldwide and published the works of censored writers for the past four decades; and Sense About Science, an organization that promotes scientific knowledge and understanding.
The targeting of scientific journals and scientists for exposing charlatans was a leading factor in generating public support for reform of the UK’s libel law.
The cases involving science included a costly lawsuit against Nature, one of the world’s best-known and most widely respected scientific journals.
Nature had to contend with a libel suit for pointing out that a physics journal had published many articles by its editor, and that these articles had not been subjected to peer review.
Though Nature defended itself successfully, the suit cost it a lot of money and tied up many of its staff members for long periods.
Other libel suits involved unproven cancer therapies.
The science case that probably played the most significant role in the campaign was a suit filed by the British Chiropractic Association against science writer Simon Singh for an article he published in The Guardian in 2008, in which he discussed “bogus treatments.”
Singh won his case, but it cost him dearly in time and legal expenses.
One of the cases that illustrated the kind of “tourism” encouraged by the law involved a suit by a Saudi businessman against an American author who said in her book that the businessman had provided financial support to Al Qaeda.
Apparently, 23 copies of the book were sold in the United Kingdom. That provided a sufficient nexus for the British courts to accept jurisdiction.
Though the American author did not hire British counsel and did not try to defend herself in the UK, she was ordered to pay damages, arousing outrage in the United States.
The US Congress adopted legislation, signed by President Barack Obama, making such judgments unenforceable in American courts.
The revised British law continues to place the burden of proof on the defense.
But the standard that must be met has been changed.
The new law permits an author or publisher who is sued to invoke a “public interest” defense.
Moreover, corporations, charities, and other institutions filing libel suits will now have to show that they suffered financial damage.
Singh argues that this requirement by itself would have prevented the suit against him by the British Chiropractic Association from going forward.
And libel tourism will be drastically reduced by a new rule that excludes suits from outside the European Union if it cannot be shown that the UK is the most appropriate place to bring the case.
British law firms that have apparently made a lot of money representing libel plaintiffs from around the world impeded adoption of the new law through intense lobbying.
The scientists, writers, and anti-censorship activists who led the campaign were assisted in Parliament by Lord Lester, a well-known British civil liberties lawyer, who introduced a Private Members’ Bill in 2010, and eventually by endorsement of reform by all three major political parties.
Nearly 400 years ago, in 1644, John Milton published his Areopagitica, an essay denouncing a measure in Parliament for licensing the press that was intended, among other things, to suppress libelous publications.
That essay is widely regarded as the start of the worldwide movement for freedom of speech and the press.
Last month’s victory by scientists, writers, and anti-censorship campaigners suggests that the movement launched by Milton still has life in his own country.
A Vital and Enduring Alliance
In recent years, many experts and commentators have said that the Atlantic Alliance would crumble or become irrelevant.
As a former ambassador to the North Atlantic Treaty Organization (NATO), I can say from experience that such dire predictions are nothing new.
As America’s current Secretary of Defense, it is clear to me that the transatlantic partnership is as relevant and essential as ever.
Consider the historic events that have taken place in the past year and the role played by the United States and Europe.
NATO added seven new members – nations eager to contribute to the Alliance in powerful ways.
In Afghanistan, eight million voters, 40% of them women, chose their first democratically elected President in 5,000 years.
In the Palestinian Authority, a democratically elected president offers the hope of a new chance for peace.
In Ukraine, ordinary citizens demonstrated the depth of their commitment to free and fair elections.
In Iraq, Saddam Hussein’s former subjects braved threats and voted for the first time with ballots that offered a choice of 70 political parties, rather than only one.
Across the country, voters arrived on crutches and in donkey carts, passing by posters that threatened: “You vote, you die.”
What a damaging blow to the extremists, whose ideology the voters so clearly rejected.
While there have been differences over Iraq, such issues among longtime friends are not new.
Consider just a few of the divisions that have come up among NATO allies over the past decades.
In the 1960’s, France decided to pull out of the NATO integrated command and asked NATO forces to leave its territory.
In the 1980’s there was profound disagreement and controversy over President Ronald Reagan’s decision to deploy medium-range missiles in Europe.
In fact, as NATO Ambassador in the 1970’s, I had to fly back to testify against legislation in the US Congress to withdraw America’s forces from Europe in the middle of the Cold War.
Our Atlantic Alliance has navigated through some choppy seas over the years, but we have always been able to resolve the toughest issues.
That is because there is so much that unites us: common values, shared histories, and an abiding faith in democracy.
Today, we also share a common enemy.
Extremists have targeted all civilized societies across the globe: in New York and Washington; Istanbul; Madrid; Beslan; Bali; and more.
They do not seek an armistice with the civilized world.
They will not negotiate a separate peace.
They would like nothing better than for America and Europe to be at odds, rather than working together.
The arrests of numerous terrorist suspects last month by French and German authorities made clear that no one nation can do the critical work necessary to win the struggle against extremists.
Often quietly, America and European nations are sharing intelligence, capturing terrorists, and disrupting their finances.
As a result, some three-quarters of known al-Qaeda leaders have been killed or captured, and others are on the run.
Nor can any one nation stop the proliferation of dangerous weapons.
This is why some 60 nations have joined the Proliferation Security Initiative in an effort to keep deadly weapons from dangerous regimes.
In 2003, German, Italian, British, and American authorities confiscated nuclear equipment bound for Tripoli, leading to Libya’s decision to open its weapons inventories to inspectors.
Every NATO nation has personnel serving in the International Security Assistance Force in Afghanistan, which just changed command from a French to a Turkish general.
One of NATO’s newest members, Lithuania, is taking leadership of a Provincial Reconstruction Team – joining other European nations in contributing to Afghanistan’s stability and progress.
Indeed, more than half of all NATO nations have had forces in both Afghanistan and Iraq.
As the Iraqi people take more steps along the challenging road to democracy, more NATO countries have agreed to help train Iraqi security personnel by providing funds or equipment and by establishing a war college and military academies.
Members of NATO share much more than an alliance; we are united by ties of blood and purpose, a heritage of liberty, and a calling to confront extremists’ violence – and defeat it.
In the 60 years since World War II came to an end, we have counted on each other in times of peril and challenge.
I am old enough to remember both the rise and fall of the Berlin Wall, and the ascent and collapse of Nazism, of Fascism, and of Soviet Communism. Together the members of NATO have helped to protect Kosovo and recently brought aid to the victims of a devastating tsunami.
Great achievements are possible when the Atlantic community is united.
That unity need not mean a uniformity of tactics or views, but rather a union of purpose.
Those who cherish free political systems and free economic systems share similar hopes.
Working together, those hopes can become realities for many more people.
A Vote against Voting in Pakistan
ISLAMABAD &#45;&#45; As Pakistan gears up for its parliamentary election on February 18, many observers hope that the vote will usher in a period of stability and calm by lending popular legitimacy to the government.
But sometimes democracy is best served by refusing to participate.
The upcoming election, to be held under the illegal Provisional Constitutional Order (PCO) implemented following President Pervez Musharraf’s state of emergency on November 3, is such a case, which is why my party and its coalition partners are boycotting the vote.
To be sure, contesting the election would provide my party with a great opportunity to take issues to the people.
In fact, my party’s support has been growing, with opinion polls now indicating that it is the second most popular in the frontier province – and gaining ground in every other province.
But elections by themselves don’t bring democracy.
Zimbabwe’s president, Robert Mugabe, loves elections.
Egyptian President Hosni Mubarak has been holding elections for 27 years.
Uzbekistan’s Islam Karimov has been in power for 30 years, and has just been “elected” to a fresh seven-year presidential term.
Elections are meaningful only if they are perceived to be free and fair, which requires independent referees.
When my party started eleven years ago, we called ourselves the Movement For Justice.
We demanded an independent judiciary, because we believed that democracy and prosperity are impossible without the rule of law, and that the rule of law requires a judiciary that can act as a constraint on the government.
Having gone to university in western countries, we were inspired by the American system of check and balances.
So it is a shock to us that the US State Department keeps talking about free and fair elections and abolishing the state of emergency, but without mentioning the reinstatement of the judges – including the Chief Justice of the Supreme Court – that Musharraf illegally dismissed.
If the judges are not reinstated, how can there be free and fair elections?
Who decides what is free and fair?
Musharraf?
This is where the battle lines are now drawn, and where the future of the country will be decided.
If the Chief Justice and the judges are reinstated, we can move toward a genuine democratic system.
But if Musharraf manages to get his own PCO judges established in the country, then we will head toward a period of turmoil.
After all, how can the party of a man who has less than 5% support win the election now without rigging it?
Unfortunately, most of the political parties have failed to stand up for the democratic process.
Major parties like the Pakistan Muslim League (Nawaz) have decided to participate, following the lead of the late Benazir Bhutto’s People’s Party.
And, of all the major parties that are contesting the election, only the PMLN is demanding the reinstatement of the judges.
Fortunately, the people of Pakistan – students, opinion makers, and, above all, lawyers – are standing up for the judges, doing the work that should have been done by political parties.
We see lawyers marching, getting beaten up, filling the jails, and yet remaining resolute.
They are suffering huge financial losses by boycotting the courts, and yet they are determined that the Chief Justice must be reinstated.
So the dividing line in Pakistan is not between liberals and extremists, but between those who support the status quo and those who oppose it.
Parties that call themselves democratic are not only going along with Musharraf in this fraudulent election, but are also helping to restore the status quo.
The solution to dysfunctional democracy is not military dictatorship, but more democracy.
Pakistanis understand democracy, because we have a democratic culture.
Our founder was a great constitutionalist, and Pakistan came into being through the vote.
The problem has been that because we have lacked an independent judiciary, we have not had an independent election commission.
So all our elections, except for one in 1970, have been rigged.
India, with which Pakistan shares a similar background, went through 40 years of dysfunctional democracy with a one-party system.
But in the last 16 years it has begun to reap the fruits of genuine democratic competition, because an independent judiciary and electoral commission gives people confidence that their vote can make a difference.
Until we have the same in Pakistan, no election can be free and fair.
For two and a half years, I supported Musharraf and believed his promises to bring genuine democracy to Pakistan.
I’ve learned my lesson about Musharraf.
But, more importantly, no military dictator can succeed where Musharraf has so clearly failed.
Winston Churchill once said, “War is too serious a business for generals.”
The same is true of democracy.
Dethroning King Coal
MELBOURNE – Earlier this year, the concentration of carbon dioxide in the atmosphere reached 400 parts per million (ppm).
The last time there was that much CO2 in our atmosphere was three million years ago, when sea levels were 24 meters higher than they are today.
Now sea levels are rising again.
Last September, Arctic sea ice covered the smallest area ever recorded.
All but one of the ten warmest years since 1880, when global records began to be kept, have occurred in the twenty-first century.
Some climate scientists believe that 400 ppm of CO2 in the atmosphere is already enough to take us past the tipping point at which we risk a climate catastrophe that will turn billions of people into refugees.
They say that we need to get the amount of atmospheric CO2 back down to 350 ppm.
That figure lies behind the name taken by 350.org, a grassroots movement with volunteers in 188 countries trying to solve the problem of climate change.
Other climate scientists are more optimistic: they argue that if we allow atmospheric CO2 to rise to 450 ppm, a level associated with a two-degree Celsius temperature rise, we have a 66.6% chance of avoiding catastrophe.
That still leaves a one-in-three chance of catastrophe – worse odds than playing Russian roulette.
And we are forecast to surpass 450 ppm by 2038.
One thing is clear: if we are not to be totally reckless with our planet’s climate, we cannot burn all the coal, oil, and natural gas that we have already located.
About 80% of it – especially the coal, which emits the most CO2 when burned – will have to stay in the ground.
In June, US President Barack Obama told students at Georgetown University that he refused to condemn them and their children and grandchildren to “a planet that’s beyond fixing.”
Saying that climate change cannot wait for Congress to overcome its “partisan gridlock,” he announced measures using his executive power to limit CO2 emissions, first from new fossil-fuel power plants, and then from existing ones.
Obama also called for an end to public financing of new coal plants overseas, unless they deploy carbon-capture technologies (which are not yet economically viable), or else there is, he said, “no other viable way for the poorest countries to generate electricity.”
According to Daniel Schrag, Director of Harvard University’s Center for the Environment and a member of a presidential science panel that has helped to advise Obama on climate change, “Politically, the White House is hesitant to say they’re having a war on coal.
On the other hand, a war on coal is exactly what’s needed.”
Schrag is right.
His university, like mine and many others, has a plan to reduce its greenhouse-gas emissions.
Yet most of them, including Schrag’s and mine, continue to invest part of their multi-billion-dollar endowments in companies that extract and sell coal.
But pressure on educational institutions to stop investing in fossil fuels is beginning to build.
Student groups have formed on many campuses, and a handful of colleges and universities have already pledged to end their investment in fossil fuels.
Several US cities, including San Francisco and Seattle, have agreed to do the same.
Now financial institutions, too, are coming under fire for their involvement with fossil fuels.
In June, I was part of a group of prominent Australians who signed an open letter to the heads of the country’s biggest banks asking them to stop lending to new fossil-fuel extraction projects, and to sell their stakes in companies engaged in such activities.
Speaking at Harvard earlier this year, former US Vice President Al Gore praised a student group that was pushing the university to sell its investments in fossil-fuel companies, and compared their activities to the divestment campaign in the 1980’s that helped to end South Africa’s racist apartheid policy.
How fair is that comparison?
The dividing lines may be less sharp than they were with apartheid, but our continued high level of greenhouse-gas emissions protects the interests of one group of humans – mainly affluent people who are alive today – at the cost of others.
(Compared to most of the world’s population, even the American and Australian coal miners who would lose their jobs if the industry shut down are affluent.)
Our behavior disregards most of the world’s poor, and everyone who will live on this planet in centuries to come.
Worldwide, the poor leave a very small carbon footprint, but they will suffer the most from climate change.
Many live in hot places that are getting even hotter, and hundreds of millions of them are subsistence farmers who depend on rainfall to grow their crops.
Rainfall patterns will vary, and the Asian monsoon will become less reliable.
Those who live on this planet in future centuries will live in a hotter world, with higher sea levels, less arable land, and more extreme hurricanes, droughts, and floods.
In these circumstances, to develop new coal projects is unethical, and to invest in them is to be complicit in this unethical activity.
While this applies, to some extent, to all fossil fuels, the best way to begin to change our behavior is by reducing coal consumption.
Replacing coal with natural gas does reduce greenhouse-gas emissions, even if natural gas itself is not sustainable in the long term.
Right now, ending investment in the coal industry is the right thing to do.
A War on Tolerance
AMSTERDAM &#45;&#45; When “tolerance” becomes a term of abuse in a place like the Netherlands, you know that something has gone seriously wrong.
The Dutch always took pride in being the most tolerant people on earth.
In less feverish times than these, no one could possibly have taken exception to Queen Beatrix’s speech last Christmas, when she pleaded for tolerance and “respect for minorities.”
But Geert Wilders, leader of the right-wing, anti-Muslim Freedom Party, was so disgusted by the Dutch queen’s “multi-cultural rubbish” that he wanted her to be stripped of her constitutional role in the government.
Wilders, a popular rabble-rouser whose party occupies nine seats in the Dutch parliament, compares the Koran to Hitler’s Mein Kampf, wants to stop Muslims from moving to the Netherlands, and thunders that those who are already in the country should tear up half the Koran if they wish to stay.
Tolerance towards Islam is cowardly appeasement in his eyes.
He thinks that Europe is in peril of being “Islamized.”
“There will soon be more mosques than churches,” he says, if true Europeans don’t have the guts to stand up and save Western civilization.
Notwithstanding his call to ban the Koran, Wilders and his admirers claim to believe in unfettered free speech as a Western birthright.
Beatrix stated that the right to free speech does not automatically mean the right to offend.
Wilders disagrees.
No criticism of Islam, however offensive, should ever be hampered by political correctness.
Wilders uses every opportunity to test Muslims’ (often very limited) tolerance.
His latest provocation is a short film denouncing Islam, which is yet to be shown, but has already caused panic all around.
Remarkably for a Dutch politician – and a minor one, at that – news of Wilders’s antics has reached the world press.
So Dutch embassies are bracing themselves for violent demonstrations, and the government is considering special security measures.
Some commentators suggest that Wilders, born and raised as a Catholic in a provincial Dutch town, is, like his Muslim enemies, a true believer, driven by the goal of keeping Europe “Judeo-Christian.”
Perhaps, but this is probably a red herring.
His war on Islam is also, and perhaps even mainly, a war on the cultural and political elites, the Dutch intellectual establishment, the Eurocrats of Brussels, and the liberal-minded queen.
Indeed, his speeches are studded with references to arrogant elites who are out of touch with the feelings of the common man.
“Tolerance” is seen as weak and elitist, typical of people who live far removed from the harsh realities of the street, where violent and unruly foreigners menace upstanding Dutch folks.
This notion of the elitist appeaser is not confined to the Netherlands.
In Israel, the educated Jewish activists who criticize Israeli abuses against Palestinians, the peaceniks who believe that negotiation is better than violence and that even Arabs have rights, are called, with a knowing sneer, “beautiful souls.”
The common man, rooted in the real world, supposedly knows better: uncompromising toughness, the hard line, is the only way to get results.
In the United States, the word “liberal,” in the mouths of populist radio hosts and right-wing politicians, has become almost synonymous with “effete East Coast snob” or, worse, “New York intellectual.”
Liberals, in this view, are not only soft, but are somehow distinctly un-American.
The association of elites with foreignness, tolerance, and metropolitan cities is nothing new.
Elites often can speak foreign languages, and big cities are traditionally more tolerant and open to mixed populations.
Modern populism – American politicians running, or pretending to run, “against Washington,” or French populists speaking for “deep France” – is invariably hostile to capital cities.
Brussels, the capital of the European Union, stands for everything populists, whether left or right, hate.
And Muslim immigrants live in Amsterdam, London, or Marseilles, not in the kind of small towns where right-wing populists find most of their support.
Still, the politics of resentment works best when it can tap into real fears.
There are reasons for people to feel anxious about economic globalization, pan-European bureaucracy, the huge and not always effectively controlled influx of immigrants, and the aggression of radical political Islam.
These anxieties have too often been ignored.
There is a sense among many Europeans, not just in the Netherlands, that they have been abandoned in a fast-changing world, that multi-national corporations are more powerful than nation-states, that the urban rich and highly educated do fine and ordinary folks in the provinces languish, while democratically elected politicians are not only powerless, but have abjectly surrendered to these larger forces that threaten the common man.
Tolerance is seen as not just weak, but as a betrayal.
The Muslim threat is, of course, not a fantasy.
A small number of ideological extremists has inflicted real violence in the name of Islam, and will continue to do so.
But the popular resentment of Islam goes deeper and wider.
Wilders, and others like him, are not just attacking Islamic extremists.
His success is based on that sense of tolerance as betrayal.
And, as so often happens, the loathing of elites has found an outlet in the loathing of outsiders, who look different and whose ways are strange.
We must fight Islamic extremism, but not by tapping into the darkest gut feelings of the unthinking mob.
Nothing good ever came from that.
A Warrant of Hypocrisy
LONDON – Earlier this month, the International Criminal Court (ICC) upheld the request of the court’s chief prosecutor to issue an arrest warrant for Omar el-Bashir, the President of Sudan, charging him with war crimes and crimes against humanity.
Bashir responded by expelling foreign aid agencies looking after the refugee camps in Darfur.
This is the first time that a sitting head of state has been indicted for war crimes, with reaction around the world mainly divided between those who hailed the move as a great step for international justice and those who condemned it as colonialism.
Both positions are hopelessly buried in intellectual and moral fog.
The warrant was no leap forward.
From the legal point of view, it makes no difference whether the accused is a sitting or former head of state.
But it makes an enormous practical difference that an incumbent ruler can do a lot more future damage to his people than an ex-ruler, and therefore should be given no incentive to retaliate.
As a result of Bashir’s policies, 300,000 people are estimated to have died and 2.7 million displaced in Darfur.
The expulsion of the aid agencies has put over a million Darfuris at risk of epidemics and starvation.
According to the statute that established the ICC, the prosecutor is required to ensure that any prosecution is in the interests of the victims as well as of justice.
But, to lawyers like the ICC prosecutor, the abstract claims of justice are more vivid than any concrete duty of protection.
In this case, justice comes with poisoned arrows.
Emboldened by the warrant and its elusive suggestion of international support, the Darfuri rebels, the Justice and Equality Movement, have walked out of peace talks with Sudan’s government.
Meanwhile, Bashir, with little to lose, will no doubt take the opportunity to attack his enemies.
The counter-argument is that the threat of indictment will deter rulers from wicked behavior.
But the law will deter only if its sanctions are credible.
A law that cannot be enforced deters no one.
In fact, it weakens respect for law.
Moreover, while the fear of being hauled off to The Hague may have
Whatever the attractions of giving criminals “nowhere to hide, whatever the consequences,” the consequences cannot be ignored when the criminals are heads of state.
The policy of never negotiating with terrorists cannot be scaled up to state level when hundreds of thousands of lives are at stake.
The charge of colonialism, meanwhile, is simply reflex: colonialism no longer exists.
The charge that international law is
In the Nuremberg trial of 1946, which laid the basis of current international law, the main charge against the Nazi leaders was that of “planning and waging aggressive war.”
Prohibition of war except for self-defense is embedded in the United Nations Charter.
But the ICC’s creators deemed the waging of aggressive war – which the International Military Tribunal at Nuremberg called “the supreme international crime” – to be outside the court’s jurisdiction.
This guaranteed legal immunity for the leaders who carried out the invasion of Iraq.
The charge of selective application also applies to the Bashir warrant.
Bashir stands accused of war crimes and crimes against humanity.
The latter were first defined in the Nuremberg principles of 1950 to include murder, extermination, enslavement, deportation and “other inhumane acts.”
The answer is simple: where the interests of a UN Security Council member or one of their clients are at stake, the court’s jurisdiction ends.
The ICC is like a cobweb: small flies get stuck, but wasps and hornets get through.
Until the United States ratifies the ICC treaty, the Court is bound to seem to many to be little more than a politicized kangaroo court.
Without American support, it has little hope of earning legitimacy, let alone doing its job effectively.
The Security Council has the power to defer the warrant for Bashir’s arrest for renewable periods of one year.
It can do this indefinitely, and it seems likely that it will.
The idea is that deferring the warrant will give the Security Council leverage over Sudan.
Gareth Evans, a former Australian Foreign Minister, has called it “a powerful diplomatic tool,” while the Washington Post has called for the warrant to be used “as a bargaining chip with Mr. Bashir and his Chinese and Arab allies.”
They believe that the threat of arrest can be used to force Bashir to mend his ways.
If this proves true, the ICC and its sponsors have muddled justice with diplomacy.
If the world can dispense justice only at the expense of the weak and to the advantage of the strong, it should stick to the older tools of crime prevention: force and negotiation, and leave justice out of it.
A Watershed Doctrine for America
LOS ANGELES – As the United States stumbles through its economic challenges at home, the pressure of world events will not subside.
But America’s ability to address them has changed.
Its fiscal weakness limits its ability to act as global policeman.
Despite the relatively costless overthrow of the Qaddafi regime, America’s prolonged interventions in Afghanistan and Iraq have severely strained the public’s tolerance for an active foreign policy.
Nonetheless, the US seems destined to remain the world’s most important actor for the foreseeable future.
But today it is an actor without a script – it lacks a strategic guide comparable to the Cold War’s containment doctrine to prioritize policy.
Quite simply, the ad hoc policymaking that directed interventions in the Balkans, Somalia, southwest Asia, and the Middle East in the past two decades will not suffice in this new era of limitations.
This suggests that the US should seek out an overarching strategy to discipline its impulses to fight wars of choice or engage in nation-building efforts.
President Barack Obama’s 2010 National Security Strategy nurtures broad policy aspirations – “[n]ow we must position the United States to champion mutual interests among nations and peoples” – but falls short as a practical guide. I suggest an alternative strategy, one already embedded in America history, though largely unrecognized.
But making explicit what lies implicit can sharpen US decision-making.
I call this strategy the “Watershed Doctrine.”
A watershed is a tipping point, a turning point, a game changer.
When the US has confronted a “negative watershed” – a lethal threat to the country – it committed meaningful financial and human resources in order to address the risks.
Positive watersheds – opportunities to engineer seismic shifts in international or regional political affairs through nation-building, or to use economic and military assistance to prevent plausible negative watersheds – demand an equal level of commitment.
The Watershed concept provides policymakers with a standard to use – or at the very least to debate.
It is an organizing tool for policymaking: Is an international challenge a watershed or not?
If so, get involved.
If not, stay out.
We find watersheds throughout American history.
The War of 1812 and the Civil War are clear examples.
Had American forces not expelled the British from US territory in the first, and had Abraham Lincoln and the Union not prevailed in the second, the country would have been balkanized and unable to become the dominant power of the twentieth century.
By contrast, America’s flirtation with colonialism in the Spanish American War, its involvement in Mexico, Central America, and the Caribbean throughout the twentieth century, and, arguably, World War I, were not watersheds for the US.
But America’s inability after the Great War to overcome Old World politics at Versailles and isolationism at home marked a failed opportunity to promote a positive watershed.
That failure placed the world on the path to the negative watershed posed by Nazi Germany and Imperial Japan.
Nothing foreordained that the US and its allies would prevail.
Had the Axis’s negative watershed succeeded, the US would have become a far different country.
A positive watershed, under-appreciated today, developed in the years immediately after World War II with the political transformation of Germany and Japan.
America’s remarkable investment of resources in this outcome made both countries stable, peaceful democracies, thereby eliminating them as adversaries and turning them into vital bulwarks against the next harbinger of a negative watershed, the Soviet Union.
Unlike the battle against the Axis, the US fought the Cold War in many ways, on many fronts, and over many decades – using politics, economics, and nuclear deterrence, as well as limited armed action, to ensure the USSR’s containment.
In time, the US had to accept that each political contest or military battle lost was not a watershed as long as its core interests in Europe, the Far East, and Latin America were not threatened. Through trial and error – backed by a durable political and economic system – the US prevailed and the Soviet Union disintegrated.
The rise of Islamic fundamentalism poses another historic challenge, though one that is far more inchoate than any that the US has faced before.
In other times, the challenge would not even be called a watershed.
But the risk that weapons of mass destruction could be turned against the US makes it so.
Then there is the “Arab Spring,” a potential positive watershed that calls upon the US to decide how deep a political, economic, and military commitment it ought to make to nurture positive results.
Today, the US is a more sober and realistic country than it was in the heyday of the early post-Cold War period.
But, in the aftermath of setbacks in regions where it intervened, and with heightened economic distress at home, the US finds itself uncertain about how to respond to changing global events.
Pursuing a “Watershed Doctrine” might provide the right answer.
A Weak Start for START
LOS ANGELES – A strange sense of déjà vu is gripping Washington these days, as the debate over ratification by the United States Senate of the New Strategic Arms Reduction Treaty (New START) with Russia heats up.
Spats have broken out between the Obama administration, future presidential contenders, senators, and arms control and defense experts. There may not be nostalgia for the Cold War in any of this, but much of that era’s mindset can be perceived again in the arguments being knocked about.
The Senate must decide whether New START enhances American security.
Unfortunately, whatever the decision -- which has been delayed perhaps until late Fall to allow Obama’s administration more time to muster support for the treaty -- the US and Russian governments will continue to place each other in the nuclear crosshairs for the foreseeable future.
New START builds on a legacy of strategic nuclear arms limitation that goes back to the 1970’s.
Former US Secretary of State Henry Kissinger captured the allure in recent testimony: “The subject of nuclear arms control grew out of the seemingly paradoxical effort of those who had created the largest and most destructive arsenals to avoid by negotiation the ultimate consequences of their own decisions.”
Over the years “avoiding…the ultimate consequences” through limitations butted against the bitter legacy of the surprise attacks suffered by both the US and Russia in World War II.
After the war, each adopted a “never be surprised again” policy, and so went on to invest trillions of dollars in a multitude of hardened, mobile, and concealed nuclear weapons to deter the other.
The result produced tens of thousands of nuclear warheads.
In time, strategic arms control treaties became the measure of the political relationship.
With the Soviet Union’s collapse, a unique opportunity to end the nuclear competition emerged.
While elimination did take place in the former Soviet Republics, the Kremlin hung on to its nuclear arsenal – the last vestige of Russia’s former superpower status.
Likewise, US administrations have remained wedded to the Bomb.
As a result, the “nuclear hostage” relationship of the Cold War continued, capped in 2002 by the Strategic Offensive Reduction Treaty, which set the upper limit on warheads at 2,200 by 2012.
In the spring of 2009, speaking in Prague, Obama advanced a bold ambition: a world without nuclear weapons.
But his audacity confronted a world in which the Bomb remained at the heart of many countries’ deterrence strategies.
Obama muddled his message further by admitting that he did not expect to see abolition in his lifetime.
Nonetheless, New START marks a step in the direction of disarmament.
It would limit each country to 1,550 strategic warheads on 700 deployed delivery vehicles.
Verification relies on 18 on-site inspections, notification of forces in and out of service, missile-test flight information and other data exchanges, plus a consultative commission to iron out compliance.
Were the US Senate to fail to ratify New START, the treaty’s proponents argue that the US would lose predictability about Russia’s nuclear activities, resulting in greater distrust and risk of miscalculation, making both sides less secure.
But arms-control skeptics take issue with this. Throughout the Cold War, they viewed restraints on America’s development and fielding of nuclear weapons as compromising national security.
Fears that the Soviet Union would cheat reinforced their position. And cheating did indeed upset the broader superpower relationship.
Today, similar apprehensions stoke opposition to New START.
To allay such concerns, the Obama administration committed to a multi-year increase in the budgets of the US military’s nuclear-weapons laboratories.
And in the April 10 release of the Nuclear Posture Review, Obama’s administration warned nuclear-armed states and others tempted to violate the Nuclear Non-Proliferation Treaty that they would remain nuclear targets.
Missile defense has become another bone of contention.
The language in the preamble to New START states that the agreement will not “undermine the viability and effectiveness of the strategic offensive arms of the Parties.”
Critics contend that the clause, along with the Kremlin’s implied warning that it could withdraw from the treaty unilaterally were America’s defenses to become too robust, provides the Kremlin with leverage to impede deployment of any strategic missile-defense system.
The Obama administration repeatedly denies such claims, along with others that the treaty’s verification provisions remain insufficient.
It scoffs at assertions that Russia would cheat by multiplying warheads on bombers or new rail-based missile carriers, arguing that the Kremlin would want to avoid America’s compensatory response.
But Obama’s team does concede one point: New START fails to curtail Russia’s large numerical advantage in tactical nuclear weapons.
Arguing that short-range devices pose no risk to the American homeland, US negotiators plan to press for reductions in follow-on talks.
Despite the claims by both the Bush and Obama administrations that Russia and the US are no longer adversaries, it seems that the rapprochement has not translated into elimination of mutual nuclear targeting.
The result, even if new START is ratified, should satisfy no one.
A Window of Opportunity for European Defense
MADRID – With budgets exceptionally tight in Europe nowadays, worries about European defense have been growing.
Paradoxically, however, developments in 2010 offer hope for the future.
The defense agreement signed in November by France and the United Kingdom is composed of two treaties, which cover joint deployment of their armed forces, nuclear deterrence, and improved equipment and communications.
This initiative has the firm political backing of both countries’ leaders, and expresses a clear determination to unite against common threats.
Implemented correctly, these treaties could become a hopeful precedent for the entire European Union.
By transcending strictly national limits, these treaties chart the future path of European defense and will help determine the course of Europe’s relations with the United States and NATO.
To better judge the treaties’ worth, we must remember the context in which they were conceived.
In 1998, the Saint Malo Declaration by French President Jacques Chirac and British Prime Minister Tony Blair indicated both countries’ determination to reinforce the EU’s security and defense capabilities.
Originally reluctant to accept a Europe with autonomous military capacity, the United Kingdom had learned from the intervention in Kosovo that the EU must be able to respond to crises rapidly and efficiently.
The Saint Malo Declaration signaled that the EU’s leading military powers were prepared to develop their own defense policy, though one not fully autonomous of NATO.
Indeed, through the Berlin Plus agreements, which facilitate use of NATO resources for missions undertaken under the European Defense and Security Policy (ESDP), NATO recognized the ESDP’s maturation over the past decade.
Indeed, the EU has undertaken 24 missions in Europe, Africa, and Asia, differing in nature, scope, and aims, and combining military and civilian means.
Today, the EU is being asked to conduct complex missions in adverse circumstances.
In doing so, Europe must draw on the lessons of its past successes.
We Europeans need to respond favorably, quickly, and effectively. Defense missions must be more adaptable, prompt, multinational, and multi-instrumental.
They must be focused on stability and security, regardless of the security situation or the nature of the conflict.
Yet it is clear that European defense is now struggling mightily with public financing.
Moreover, the latest Eurobarometer poll shows that defense is the last thing that Europeans are worried about.
It is precisely here that the Franco-British agreement becomes vitally important.
The treaties mark an attempt to balance action and ambition in a context of economic crisis, fiscal consolidation, large-scale defense transformations, increasing interdependencies, and global threats – from terrorism and nuclear proliferation to climate change, resource scarcity, and epidemics – that are impossible to tackle unilaterally.
It also sets a precedent for the UK, preparing the way for future prime ministers to make advances in this direction.
Reinforcing both countries’ military capacities indirectly reinforces those of the EU. The quest for synergies and efficiency that is implied by the agreement could well become a driving force for the European Defense Agency.
The British may now consider the EDA a defense expenditure, but, when better defined, it could represent a source of savings for every EU country.
Moreover, the agreements foresee cooperation on cyber-security, terrorism, satellite communications, and maritime security, which are also key elements of the Lisbon Treaty.
Likewise, the joint expeditionary forces established under the treaties could lead to the eventual creation of a wider structure, as they already contemplate “bilateral cooperation with NATO, the European Union, the United Nations, or other operations.”
Solidarity and agreement on political objectives are the pressing concerns of our age.
The new pact between France and the UK could be a historic step toward rationalizing defense spending rather than toward demilitarizing Europe.
It all depends on the path chosen.
In times of financial crisis, EU member states are unlikely to increase defense spending.
But if France and the UK understand how much their projection of power is linked to that of Europe, if they make cooperation reciprocal and expand it to other European countries – according to the formula foreseen in the treaties – we could eventually see an EU with the ability to assume the defense role expected of it by the global community.
By forcing greater efficiency and collaboration, misfortune can yield benefit.
This path can also ease US concerns about lower European defense spending.
The Franco-British treaties do not address commitments to NATO, a key US interest, because any reduction in the number of European troops deployed abroad inevitably implies a greater economic burden for the US.
The Franco-British agreement does, however, imply progress toward joint European military action, both in Europe and on the international scene, which will encourage the US.
So will the fact that the initiative comes from Europe’s two major military powers (whose combined defense spending represents half of the Continent’s total), both of which have permanent seats on the UN Security Council.
All of this is part of the transatlantic community’s continuing transformation from a set of organizations designed to defend territory against a known aggressor to something more flexible and dynamic.
Establishing joint management and overhauling conventional defense capacities will be a two-pronged challenge: functional, owing to the traditional schema of defense organizations, and political, inasmuch as a cession of state sovereignty will be required.
Another, equally important challenge is cooperation between NATO and Russia, which agreed at NATO’s Lisbon summit in November to collaborate on the Alliance’s anti-missile defenses.
This relationship must be based on cooperation that benefits both sides, and that respects certain common principals of governance and non-interference.
But coordinating and sharing capacities can help both partners deal with the new nature of conflicts.
Here, the EU can exercise leadership, for this is a political process that has only just begun.
As British Prime Minister David Cameron said of the agreement with France: “This is the beginning of something new, not an end in itself” – words that echo those of Jean Monet, one of the Union’s founding fathers, on cooperation in the West. “This is not an end in itself,” Monet said.
“It is the beginning of the path toward a more ordered world that we must attain if we want to escape destruction.”
The Franco-British agreement in 2010 was one hopeful sign for 2011 and beyond: a step along the arduous but necessary path toward greater European security.
A World Bank for a New World
NEW YORK – The world is at a crossroads.
Either the global community will join together to fight poverty, resource depletion, and climate change, or it will face a generation of resource wars, political instability, and environmental ruin.
The World Bank, if properly led, can play a key role in averting these threats and the risks that they imply.
The global stakes are thus very high this spring as the Bank’s 187 member countries choose a new president to succeed Robert Zoellick, whose term ends in July.
The World Bank was established in 1944 to promote economic development, and virtually every country is now a member.
Its central mission is to reduce global poverty and ensure that global development is environmentally sound and socially inclusive.
Achieving these goals would not only improve the lives of billions of people, but would also forestall violent conflicts that are stoked by poverty, famine, and struggles over scarce resources.
American officials have traditionally viewed the World Bank as an extension of United States foreign policy and commercial interests.
With the Bank just two blocks away from the White House on Pennsylvania Avenue, it has been all too easy for the US to dominate the institution.
Now many members, including Brazil, China, India, and several African countries, are raising their voices in support of more collegial leadership and an improved strategy that works for all.
From the Bank’s establishment until today, the unwritten rule has been that the US government simply designates each new president: all 11 have been Americans, and not a single one has been an expert in economic development, the Bank’s core responsibility, or had a career in fighting poverty or promoting environmental sustainability.
Instead, the US has selected Wall Street bankers and politicians, presumably to ensure that the Bank’s policies are suitably friendly to US commercial and political interests.
Yet the policy is backfiring on the US and badly hurting the world.
Because of a long-standing lack of strategic expertise at the top, the Bank has lacked a clear direction.
Many projects have catered to US corporate interests rather than to sustainable development.
The Bank has cut a lot of ribbons on development projects, but has solved far too few global problems.
For too long, the Bank’s leadership has imposed US concepts that are often utterly inappropriate for the poorest countries and their poorest people.
For example, the Bank completely fumbled the exploding pandemics of AIDS, tuberculosis, and malaria during the 1990’s, failing to get help to where it was needed to curb these outbreaks and save millions of lives.
Even worse, the Bank advocated user fees and “cost recovery” for health services, thereby putting life-saving health care beyond the reach of the poorest of the poor – precisely those most in need of it.
In 2000, at the Durban AIDS Summit, I recommended a new “Global Fund” to fight these diseases, precisely on the grounds that the World Bank was not doing its job.
The Global Fund to Fight AIDS, TB, and Malaria emerged, and has since saved millions of lives, with malaria deaths in Africa alone falling by at least 30%.
The Bank similarly missed crucial opportunities to support smallholder subsistence farmers and to promote integrated rural development more generally in impoverished rural communities in Africa, Asia, and Latin America.
For around 20 years, roughly from 1985 to 2005, the Bank resisted the well-proven use of targeted support for small landholders to enable impoverished subsistence farmers to improve yields and break out of poverty.
More recently, the Bank has increased its support for smallholders, but there is still far more that it can and should do.
The Bank’s staff is highly professional, and would accomplish much more if freed from the dominance of narrow US interests and viewpoints.
The Bank has the potential to be a catalyst of progress in key areas that will shape the world’s future.
Its priorities should include agricultural productivity; mobilization of information technologies for sustainable development; deployment of low-carbon energy systems; and quality education for all, with greater reliance on new forms of communication to reach hundreds of millions of under-served students.
The Bank’s activities currently touch on all of these areas, but it fails to lead effectively on any of them.
Despite the excellence of its staff, the Bank has not been strategic or agile enough to be an effective agent of change.
Getting the Bank’s role right will be hard work, requiring expertise at the top.
Most importantly, the Bank’s new president should have first-hand professional experience regarding the range of pressing development challenges.
The world should not accept the status quo.
A World Bank leader who once again comes from Wall Street or from US politics would be a heavy blow for a planet in need of creative solutions to complex development challenges.
The Bank needs an accomplished professional who is ready to tackle the great challenges of sustainable development from day one.&nbsp;
A World of Convergence
WASHINGTON, DC – For almost two centuries, starting around 1800, the history of the global economy was broadly one of divergence in average incomes.
In relative terms, rich countries got even richer.
There was growth in the poorer countries, too, but it was slower than rich-country growth, and the discrepancy in prosperity between rich and poor countries increased.
This “divergence” was very pronounced in colonial times.
It slowed after the 1940’s, but it was only around 1990 that an entirely new trend could be observed – convergence between average incomes in the group of rich countries and the rest of the world.
From 1990 to 2010, average per capita income in the emerging and developing countries grew almost three times as fast as average income in Europe, North America, and Japan, compared to lower or, at most, equal growth rates for almost two centuries.
This has been a revolutionary change, but will this 20-year-old trend continue?
Will convergence remain rapid, or will it be a passing phase in world economic history?
Long-term projections based on short-term trends have often been mistaken.
In the late 1950’s, after the Soviet Union launched the first spacecraft, eminent Western economists predicted that Soviet income would overtake that of the United States in a few decades.
After all, the Soviet Union was investing close to 40% of its GDP, twice the ratio in the West.
Later, in the 1980’s, Japan’s spectacular growth led some to predict that it would overtake the US, not only in per capita terms, but even in terms of some measures of “economic power.”
These kinds of projections have often been based on simple extrapolations of exponential trends.
Over two or three decades, substantial differences in compound growth rates quickly generate huge changes in economic size or per capita income.
Will the recent predictions of rapid ongoing global convergence similarly turn out to be wrong, or will most of the emerging countries sustain a large positive growth differential and get much closer to the advanced economies’ income levels?
Understanding the phenomenon of “catch-up” growth is key to answering this question.
Trade and foreign direct investment have made it much easier for emerging countries to absorb and adapt best-practice technology invented in the advanced economies.
The information revolution, allowing much easier access to and diffusion of knowledge, has accelerated the process.
Once they developed the basic institutions needed for a market economy and learned how to avoid serious macroeconomic policy mistakes, emerging countries started benefiting from catch-up growth.
Those with very high investment rates, mostly in East Asia, grew faster than those with lower investment rates; but, overall, catch-up growth probably has been adding 2-4 percentage points to many emerging and developing countries’ annual growth rates.
At the same time, population growth decreased, adding at least another point to the pace of per capita growth.
This process will likely continue for another decade or two, depending on where in the process particular countries are.
It is true that catch-up growth is easier in manufacturing than in other sectors, a point recently emphasized by Dani Rodrik of Harvard University, and it may be that a good portion of it has been exhausted in manufacturing by the best-performing firms in emerging countries.
But there is still a lot of “internal” room for catch-up growth, as less efficient domestic firms become more competitive with more efficient ones.
The dispersion of “total factor productivity” – the joint productivity of capital and labor – inside emerging countries has been found to be large.
Moreover, sectors such as agriculture, energy, transport, and trade also have catch-up-growth potential, through imports of technology, institutional know-how, and organizational models.
Of course, temporary disturbances, a worsening of global payments imbalances, or macroeconomic policy mistakes, including those made in advanced economies and affecting the entire world economy, could undermine global growth.
But the underlying “convergence differential,” owing to catch-up growth, is likely to continue to reduce the income gap between the old advanced economies and emerging-market countries.
The Soviet Union never was able to build the institutions to allow for catch-up economic growth.
Japan slowed down after it had basically caught up.
China, India, Brazil, Turkey, and others may have firms operating close to the world’s technological frontier, but they still have a lot of unused catch-up potential.
The more that these countries can invest while ensuring macroeconomic stability and balance-of-payments sustainability, the faster they can adopt better technology and production processes.
In that case, they can continue to catch up, at least for the next decade or more.
The convergence process is going to slow, but not yet.
A World of Regions
NEW YORK – In almost every part of the world, long-festering problems can be solved through closer cooperation among neighboring countries.
The European Union provides the best model for how neighbors that have long fought each other can come together for mutual benefit.
Ironically, today’s decline in American global power may lead to more effective regional cooperation.
This may seem an odd time to praise the EU, given the economic crises in Greece, Spain, Portugal, and Ireland.
Europe has not solved the problem of balancing the interests of strong economies in the North and those of weaker economies in the South.
New regional organizations, such as the African Union, look to the EU as a role model for regional problem-solving and integration.
Yet, to this day, most regional groupings remain too weak to solve their members’ pressing problems.
In most other regions, ongoing political divisions have their roots in the Cold War or the colonial era. During the Cold War, neighbors often competed with each other by “choosing sides” – allying themselves with either the United States or the Soviet Union.  Pakistan tilted towards the Americans; India towards the Soviets.
Countries had little incentive to make peace with their neighbors as long as they enjoyed the financial support of the US or the USSR.
On the contrary, continued conflict often led directly to more financial aid.
Indeed, the US and Europe often acted to undermine regional integration, which they believed would limit their roles as power brokers.
Thus, when Gamal Abdel Nasser launched a call for Arab unity in the 1950’s, the US and Europe viewed him as a threat.  The US undercut his call for strong Arab cooperation and nationalism, fearing a loss of American influence in the Middle East.
As a result, Nasser increasingly aligned Egypt with the Soviet Union, and ultimately failed in the quest to unite Arab interests.
Today’s reality, however, is that great powers can no longer divide and conquer other regions, even if they try.
The age of colonialism is finished, and we are now moving beyond the age of US global dominance.
Recent events in the Middle East and Central Asia, for example, clearly reflect the decline of US influence.
America’s failure to win any lasting geopolitical advantage through the use of military force in Iraq and Afghanistan underscore the limits of its power, while its budget crisis ensures that it will cut its military resources sooner rather than later.
Similarly, the US played no role in the political revolutions underway in the Arab world, and still has not demonstrated any clear policy response to them.
President Barack Obama’s recent speech on the Middle East is a further display of America’s declining influence in the region.
The speech drew the most attention for calling on Israel to return to its 1967 borders, but the effect was undercut when Israel flatly rejected the US position.
The world could see that there would be little practical follow-up.
The rest of the speech was even more revealing, though it drew little public notice.
When Obama discussed the Arab political upheavals, he noted the importance of economic development.
Yet when it came to US action, the most that the US could offer financially was slight debt relief for Egypt ($1 billion), scant loan guarantees ($1 billion), and some insurance coverage for private investments.
The real message was that the US government would contribute very little financially to the region’s economic recovery.
The days when a country could depend on large-scale American financing are over.
We are, in short, moving to a multi-polar world.
The Cold War’s end has not led to greater US dominance, but rather to the dissemination of global power to many regions.  East Asia, South Asia, Latin America, and the Middle East have new geopolitical and economic influence.
Each region, increasingly, must find its own path to economic development, energy and food security, and effective infrastructure, and must do so in a world threatened by climate change and resource scarcity.
Each region, therefore, will have to secure its own future.
Of course, this should occur in a context of cooperation across regions as well as within them.
The Middle East is in a strong position to help itself.
There is a high degree of economic complementarity between Egypt and the oil-rich Gulf States.
Egypt can supply technology, manpower, and considerable expertise for the Arab region, while the Gulf provides energy and finance, as well as some specialists.
The long-delayed vision of Arab economic unity should be returned to the table.
Israel, too, should recognize that its long-term security and prosperity will be enhanced as part of an economically stronger region.
For the sake of its own national interests, Israel must come to terms with its neighbors.
Other regions also will find that the decline of US power increases the urgency of stronger cooperation between neighbors.
Some of the greatest tensions in the world – say India and Pakistan, or North and South Korea – should be defused as part of region-wide strengthening.
As the EU shows, ancient enmities and battle lines can be turned into mutually beneficial cooperation if a region looks forward, to resolving its long-term needs, rather than backward, to its long-standing rivalries and conflicts.