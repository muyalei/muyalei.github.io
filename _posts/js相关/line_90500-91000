Rather, they will be structural market failures of participation that are not amenable to any straightforward and easily implemented cure.
Hope or Hype for Personalized Medicine?
STANFORD – During the past several decades, treatment for a variety of conditions has begun to shift from a “one size fits all” approach to a more personalized strategy.
As a result, patients can more often be matched to the best drug for their genetic makeup or the exact subcategory of their disease.
This enables physicians to avoid prescribing a medication (or a dosage) that might cause serious side effects in certain populations.
In other words, even among patients who apparently have the same disease and symptoms, the treatment for each one would be determined by various predictive or prognostic tests.
Eventually, these tests could extend even to the sequencing of the DNA in an individual patient’s cancer cells, for example.
But, while this high-tech approach could be a boon to patients, it could prove detrimental to drug companies’ bottom lines.
The reasons are subtle.
Personalized drug therapy uses biological indicators, or “biomarkers” – such as DNA sequences or the presence or absence of drug receptors – as an indicator of how patients should be treated, as well as to estimate the likelihood that the intervention will be effective.
This concept is not new: it has been known for decades, for example, that people who have a genetic deficiency of an enzyme called G6PD can experience severe and precipitous anemia if they are exposed to certain drugs.
Similarly, ethnic groups and individuals vary widely in their ability to clear medications from the bloodstream, owing to differences in the activity of the enzymes that metabolize, or degrade, drugs.
That is important because low metabolizers clear certain drugs slowly and have more medication in their systems for longer periods of time than high metabolizers.
Thus, the former might be prone to overdose, and the latter to insufficient levels of the same drug.
Prognostic biomarkers have begun to make a big difference in cancer therapy.
Drugs such as Erbitux and Vectibix work only in tumors containing the normal version of a gene called KRAS.
If mutations of KRAS are present, the drugs are ineffective.
Such mutations explain about 30-40% of cases in which patients fail to respond to these drugs, and mutations in another gene called BRAF could account for another 12%.
Knowing this crucial information about a cancer patient’s genes will reduce sharply the number who are unnecessarily subjected to the side effects (and expense) of drugs that will not work.
Improving the efficacy and reducing the side effects of drug therapy will be a boon to doctors, patients, and insurance companies, to be sure, but why should pharmaceutical companies embrace personalized medicine in the long term?
On the positive side, the presence of biomarkers will enable drug companies to perform smaller, better-targeted clinical studies in order to demonstrate efficacy.
In any kind of experiment, a fundamental principle is that the greater the number of subjects or iterations, the greater the confidence in the study’s results.
Unless the effect of the intervention is profound, small studies generally have large uncertainties in results.
That is where biomarkers make a difference.
They can help drug makers to design clinical studies that will show a high “relative treatment difference” between the drug and whatever it is being compared to (often a placebo, but sometimes another treatment).
Thus, when drugs are ultimately approved based on the use of biomarkers, the description of the medication’s approved uses, which is printed on the label, might be more restrictive – that is, it might reduce the size of the patient population for which the drug is intended.
For example, a drug broadly approved for “arthritis” – inflammation of joints that may be due to dozens of different disease processes – can be more widely marketed than one approved to treat only the arthritis that accompanies psoriasis or gout.
In reality, however, the situation is more complex.
Assessments of safety and efficacy often do not move closely in tandem, so that even if smaller, better-targeted clinical trials offer clear evidence of a drug’s efficacy, regulators might demand far larger studies to provide evidence of the drug’s safety.
Increasingly defensive about accusations that drugs and vaccines are inadequately tested for safety, in recent years safety-obsessed regulators have required massive, hugely expensive, and time-consuming clinical trials designed to detect even very rare side effects.
Consider, for example, that before its US approval, a vaccine against rotavirus (a common, sometimes fatal gastrointestinal infection in children) was tested in more than 72,000 children – and another 40,000-plus in post-marketing studies.
On a similar scale, a vaccine to prevent human papilloma virus infection and cervical cancer was tested in almost 30,000 young women.
Such studies are very costly, and, by any reasonable standard, the number of patients included in them is grossly excessive.
Thus, the impact of personalized medicine in the short term might be positive at the patient’s bedside, but vast clinical trials to demonstrate the safety of new drugs will impose huge development costs that manufacturers might never recover.
(Currently, only about one in five drugs approved by US regulators ever recoup their development costs.)&#160;This situation would not be sustainable in the long term.
If society is to derive the maximum benefit from personalized medicine – which will require companies to pursue it – regulators worldwide will need to adopt reasoned and reasonable policies.
Hoping for the Best Against Trump
NEW YORK – Is there any reason for liberals to feel optimistic after a year of political disasters?
Is there even a shred of silver lining to be found in the tatters of Brexit, Donald Trump’s election, and European disunity?
Christians believe that despair is a mortal sin, so one might as well try to find a glimmer of hope.
In the United States, many liberals console themselves with the belief that the obvious dangers of being governed by an ignorant, narcissistic, authoritarian loudmouth backed by billionaires, ex-generals, peddlers of malicious fake news, and neophytes with extreme views will help to galvanize a strong political opposition.
Trump, it is hoped, will concentrate the minds of all who still believe in liberal democracy, be they left or even right of center.
In this scenario, civil-rights groups, NGOs, students, human-rights activists, Democratic members of Congress, and even some Republicans, will do everything in their power to push back against Trump's worst impulses.
Long-dormant political activism will erupt into mass protest, with resurgent liberal idealism breaking the wave of right-wing populism.
Well, perhaps.
Others seek comfort in the expectation that Trump’s wildly contradictory plans – lower taxes, while raising infrastructure spending; helping the neglected working class, while slashing welfare and repealing the Affordable Care Act – will suck his administration into a swamp of infighting, incoherence, and incompetence.
All these things might happen.
But protest alone won’t be of much help.
Anti-Trump demonstrations in big cities will no doubt annoy the self-loving new president, and the moral glow of joining the resistance will warm the protesters.
But without real political organization, mere protest will go the way of Occupy Wall Street in 2011; it will peter out into ineffectual gestures.
One of the most dangerous ideas of contemporary populism is that political parties are obsolete, and should be replaced by movements led by charismatic leaders who act as the voice of “the people.”
By implication, all dissenters are enemies of the people.
That way lies dictatorship.
Liberal democracy can be saved only if mainstream parties can regain voters’ trust.
The Democratic Party must get its act together.
“Feeling the Bern” (the mantra of Bernie Sanders’ leftist campaign) will not suffice to stop Trump from inflicting great harm to institutions that were carefully constructed more than two centuries ago to protect American democracy from demagogues like him.
The same thing is true of international arrangements and institutions, whose survival depends on the willingness to defend them.
Trump has expressed his indifference to NATO, and US security commitments in East Asia.
His election will further erode Pax Americana, already battered by a succession of foolish wars.
Without the US guarantee to protect its democratic allies, institutions built after World War II to provide that protection would not survive for very long.
Perhaps there is a tiny ray of hope in this gloomy prospect.
Europe and Japan, not to mention South Korea, have become too dependent on US military protection.
The Japanese have fairly large armed forces, but are hampered by a pacifist constitution written by Americans in 1946.
Europeans are completely unprepared to defend themselves, owing to inertia, complacency, and lassitude.
It is just possible that Trump’s blustering “America first” rhetoric will galvanize Europeans and East Asians into changing the status quo and doing more for their own security.
Ideally, European countries should build an integrated defense force that would be less dependent on the US.
And the countries of Southeast and East Asia could construct a Japanese-led variant of NATO to balance the domineering might of China.
But even if these arrangements came to pass (a huge if), it would not happen soon.
Europeans are unwilling to pay higher taxes for their own defense.
Germany has neither the wherewithal, nor the will to lead a military alliance.
And most Asians, including many Japanese, would not trust Japan to lead such a coalition in Asia.
The current Japanese government, under Prime Minister Shinzo Abe, would like to revise the pacifist constitution, as a necessary first step toward weaning the country off its total dependence on the US.
But Abe’s revisionism is rooted in a nationalist ideology, which is prone to justifying historical atrocities instead of drawing lessons from them.
This alone disqualifies Japan from leading others in a military pact.
So, while it might be time to rethink the world order built by the US on the ruins of WWII, the Trump presidency is unlikely to bring this about in a careful and orderly manner.
His election is more like an earthquake, unleashing forces no one can control.
Instead of encouraging the Japanese to think about collective security in a responsible way, Trump's indifference is more likely to play to the worst instincts of panicky Japanese nationalists.
Europe is in no shape to rise to the challenge of Pax Americana’s erosion, either.
Without a greater sense of pan-national European solidarity, European institutions will soon become hollow, and perhaps even cease to exist.
But this sense is precisely what the demagogues are now undermining with such conspicuous success.
If there is reason for confidence, it is not in the liberal democratic world, but in the capitals of its most powerful adversaries: Moscow and Beijing.
Trump, at least in the short term, seems to be good news for Russian President Vladimir Putin and his Chinese counterpart Xi Jinping.
Without credible American leadership, or a strong alliance of democracies, there won’t be much left to restrain Russian or Chinese ambitions.
This might not lead to catastrophe in the next few years.
Russia and China are more likely to test the limits of their power slowly, bit by bit: Ukraine today, perhaps the Baltics tomorrow; the South China Sea islands now, Taiwan later.
They will push, and push, until they push too far.
Then anything may happen.
Great powers often blunder into great wars.
This is no reason for despair, as we begin the New Year, but no reason to be optimistic, either.
Horse Trading and Climate Change
AMSTERDAM – When the panda smiles, the world applauds.
Or so it seemed after Chinese President Hu Jintao’s recent speech at the United Nations.
Judging by the way much of the media reported his words, it seemed as if China had actually made an important announcement on cutting greenhouse-gas emissions.
It hadn’t.
All President Hu really said was that China would now “endeavour” to curb its carbon emissions by a “notable” margin.
But how does one measure “endeavour” or “notable”?
As someone with close links to the Chinese administration told me when pressed: “What was said was actually pretty meaningless.”
Indeed, there were no specific targets and, as any China watcher knows, the “greening” of the government is old news.
Official Chinese policy in recent years has been to make GDP growth greener.
But not at the expense of growth itself – and China plans to grow pretty fast.
At least the panda smiled.
Poor Barack Obama didn’t even have that to offer.
He offered no pledge to cut emissions in the United States, and, with vote-sapping battles already underway over health-care reform, one wonders how much time and energy Obama will have for environmental imperatives.
If all the world got out of this UN General Assembly meeting of government leaders was insubstantial rhetoric, the worse news is that it got more of the same at the G-20 meeting in Pittsburgh.
As one finance minister told me rather wistfully, when I asked him what had actually been delivered on climate change: “Words,” he said, &quot;just words.”
Given that there are little more than two months until the Copenhagen summit on climate change, which is supposed to frame the successor agreement to the Kyoto Protocol, this is depressing.
Perhaps the only people not suddenly depressed are those immersed in the negotiations.
With more than a thousand points still to be agreed, all the policymakers I’ve spoken to recently say that they cannot see how a meaningful deal can be reached by December in Copenhagen.
In reality, everyone is gearing up behind the scenes for a “Copenhagen 2,” and what those involved in the negotiations are calling “an even greater slog.”
Even if some sort of communiqué is cobbled together in December – and countries with elections coming up, such as the United Kingdom, will push for one – it is hard to believe that it will contain sufficient detail or reflect the proper level of commitment to have the impact so desperately needed.
“Copenhagen 1” was always bound to fail, partly because – and this may sound strange at first – it is all about climate change.
Although cuts in CO2 emissions and agreement on funding and finance are necessary goals, the geopolitical reality is that climate change cannot be decoupled from trade or discussions on exchange rates, the IMF, reform of the UN, and so on.
There is a quid pro quo that no one explicitly talks about but which must be addressed: trade-offs between these negotiations, not just within them.
Meaningful action on climate change will not be seen until it is agreed within this broader framework.
This means taking the issue out of its current compartment and being realistic enough to understand that Brazil’s position on cutting down rainforests, for example, will be affected by whether or not it is given a seat on the UN Security Council.
It means being sophisticated enough to understand that as long as China feels under pressure to stop propping up the renmimbi, it is unlikely to deliver commitments on emissions cuts.
Widening the scope of the next round of negotiations so that much more can be used as bargaining chips would make the job of the negotiators considerably harder.
But it would also give them considerably more to work with.
In fact, there is no other way to prevent the process from remaining a zero-sum game.
Worryingly, “Copenhagen 2” will not only have to navigate this complicated terrain, but it must do so in less than five years.
The climate bomb is ticking, and there is a palpable sense of urgency among policymakers.
For, as the UN’s Intergovernmental Panel on Climate Change has explicitly warned, if emissions do not fall before 2015, and only fall from then onwards (and the overall trend is that they have been rising), we will reach the point of no return.
At that point, the Armageddon scenarios of droughts, rising sea levels, floods, energy and resource wars, and mass migration will become a reality.
Just think of the images of recent storms and floods in the Philippines and Vietnam that displaced and killed thousands, and multiply those horrors manifold. That is what we are up against.
Climate change negotiations are arguably the most important of our lifetime, because their outcome will determine the fate of our planet.
It is essential that they take place within structures and frameworks that encourage agreement by putting other major multilateral issues up for discussion.
The world’s governments must be able to trade horses if pandas and presidents are to do more than smile.
Houses in the Air
Over the past six months, attention and worry have shifted from America’s enormous trade deficit to its surging property markets and real-estate bubble.
At least two of the reasons for high – and rising – home prices in the United States are well understood.
What remains highly uncertain, however, is whether an obviously overheating market can be cooled without sending America, and its main trading partners around the world, into an economic tailspin.
The US housing boom is due, first, to low interest rates, which mean that large amounts of money can be borrowed for mortgages with moderate monthly payments.
Low interest rates strengthen the ability to pay, and thus boost demand.
And, with demand high and housing supply fixed – at least in the short run – prices go up.
Second, the 70-year period that began with the widespread diffusion of the automobile –during which one could get nearly anywhere in a typical metropolitan area in half an hour or less – is over.
Before there was widespread automobile ownership, land prices depended on location, and proximity to the central city or to the local railroad station carried a premium.
Now, with serious congestion slowing traffic in major cities to a crawl, the land gradient in housing prices is steep once again.
Perhaps this steepening of the location gradient could be delayed for a decade if we were willing to shift to denser residential patterns.
We could, for example, tear down San Francisco’s row houses and replace them with buildings more like those of New York’s Upper West Side.
But we aren’t willing to do that.
These two factors – low mortgage rates, and the fact that the country has filled up so much that our cars no longer marginalize location costs – go a long way toward explaining the surge in housing prices over the past decade or so.
But they don’t go all the way.
On top of these two powerful fundamental factors sits a bubble.
The bubble is filled by people with money who are buying extra houses because they think home prices will continue to rise, and by people without money who are buying $400,000 houses in less-fashionable neighborhoods with zero percent down and floating interest rates.
Both groups’ demand is inherently ephemeral. When the first group discovers that housing prices don’t always go up, they will try to dump their properties.
And when the second group discovers that interest rates don’t always stay low, many of them will be unable to meet their higher mortgage payments and will likewise try to dump their properties.
The end of the American housing bubble might not turn out badly.
But if it does, it will probably be due to a sharp rise in interest rates.
This could happen for two reasons. First, investors, recognizing that the dollar is overvalued and that they are likely to suffer large losses when it returns to its fundamental value, could start selling their Treasury bonds, corporate bonds, and mortgage-backed securities.
As the prices of these assets fall, their yields will rise.
At some point, the yields on bonds and mortgages will be high enough that investors’ appetite for yield will balance their fear of exchange-rate depreciation.
In the corridors around my office, all the economists agree that this factor should have pushed US interest rates up three years ago.
But so far it has not.
Does this mean that a hurricane could hit world financial markets at any moment?
Yes.
Or it could also mean that economists’ baseline model of the international economy – especially the assumption of “uncovered interest parity,” which holds that foreign interest income expressed in the domestic currency should equal the domestic interest rate – is simply wrong.
The second factor that could push US interest rates sharply upward is not fear of a decline in the future value of the dollar, but the fact of a past decline in its value.
The US imports the equivalent of 16% of its GDP.
A 40% fall in the value of the dollar – of which half passes through to increased dollar prices of imports – thus implies a 3.2% rise in the overall price level.
A Federal Reserve committed to effective price stability will likely raise interest rates rather than allow any year’s inflation rate to jump from 3% to 6%.
If there is a sharp spike in interest rates – caused either by capital flight in anticipation of a dollar decline or by tight monetary policy in reaction to a dollar decline comes to pass – we will see how good the Federal Reserve really is.
If interest rates rise too far, then the collapse in housing values will lead to large-scale foreclosures and a collapse in consumption spending as well.
This would mean a depression not just for the US, but for Asia and probably Europe as well, for the US can remain the world’s importer of last resort and guarantor of effective demand only as long as its domestic consumption is strong.
But if interest rates don’t rise far enough, the value of the dollar will spiral downward and US inflation will spiral upward like in the 1970’s, setting the stage for the type of extremely painful measures imposed by then Federal Reserve Chairman Paul Volcker.
In these circumstances, straight is the gait and narrow is the path that the Federal Reserve will have to walk – hardly an enviable position.
And yet journalists – not very experienced reporters, to be sure – ask me who is likely to get the “plum job” of Fed Chair next year.
3D Fantasies
NEW YORK – How will 3D printing change the world?
Today, you can read about jewelry and custom can openers, much as three decades ago you could have read that the personal computer would enable people to keep their recipes organized.
Of course, PCs became much more useful than that.
Many entrepreneurs and small businesspeople can now run their entire operations on a computer, and people keep their recipes not only organized, but also online.
They also track their workouts, monitor their babies, and amass huge collections of digital friends (for better or worse).
The Internet changed the balance of power between individuals and institutions.
It enabled millions of people to have jobs without having bosses.
Instead, they have agents – such as TaskRabbit or Amazon Web Services or Uber – who match providers and customers.
I think we will see a similar story with 3D printing, as it grows from a novelty into something useful and disruptive – and sufficiently cheap and widespread to be used for (relatively) frivolous endeavors as well.
We will print not just children’s playthings, but also human prostheses – bones and even lungs and livers – and ultimately much machinery, including new 3D printers.
So, even as custom-manufactured goods become cheaper and people talk about local manufacture as well as local foods, other goods may get more expensive if we do it right.
“Juan got his wife Alice a real wooden chair for her birthday!” you might hear.
But their daughter Mika got a reprinted chair made from the same old materials plus a little more, marking her growth from her last birthday.
Only the size and the filigree on the back are different, reflecting her new interest in space travel; last year, it was horses.
Like computers and the Internet, 3D printing will affect business and behavior around the world and across industries.
Already, there is a growing number of shared 3D printing services, enabling you to print something of your own design or use (a customized version of) designs that you can find in online catalogues or order through 3D design shops.
Over time, these print shops will replace thousands of stores carrying millions of items, some of which sit around for months waiting to be bought.
They will print goods using designs from online services that offer designs for both open-source, free-design goods and branded goods that may not seem very distinct except for a logo.
Indeed, branding and intellectual property issues will become increasingly “complicated” for hardware, just as they are now for software and content.
Many people will have to shift from controlling design to offering better services to make money, or perhaps band together under a particular brand known for some other quality.
Materials may come to be one such differentiator, as illustrated by a startup called Emerging Objects.
As in the world of content and software, new design brands are likely to emerge and die more quickly; the pace of change will increase and it will be harder to stay on top for long.
Outside the world of manufacturing, where mass-produced goods may still have a substantial cost advantage over custom-printed ones, 3D printing will have far greater impact downstream, in the market for spare parts and replacements, where demand is less predictable but more precise.
(If you want a widget, any widget will do, but once you have widget 94303, only part 94303A will satisfy you.)
One early example is KeyMe.net, which makes house keys on demand.
The user needs one original, which he registers by inserting into the KeyMe kiosk; he can then store that design anonymously in KeyMe’s database, with unique access to it via his fingerprints and email (but with no reference to a physical address).
Then, when he loses the key or needs a spare, he can get a new copy at any location with a kiosk – of which there will soon be many, the company hopes.
The cost in money (let alone convenience) is a fraction of that for going to an ordinary key maker – especially at the hours when such emergencies usually occur.
KeyMe does not actually use 3D printing; it cuts them out of blanks the “traditional” way, but uses the same kind of electronic design representation that a 3D printer would.
In fact, I consider it a brilliant forerunner of the overall impact of 3D printing – making the occasional production of cheap copies of a specific item easy and available anywhere, anytime.
Today, for example, many businesses are devoted to managing and storing spare parts.
Each location needs to carry thousands of different spare parts because it is not clear which ones will be needed where.
But, in the future, if something breaks, you will be able to take it over to the 3D print shop to be reprinted.
Better yet, the shop may be able to reuse the materials in your broken part – saving the costs and environmental burden of throwing things away, shipping them somewhere, and so forth.
Consider Apple power cords (the item that I lose most often), which are a huge source of profit for all involved.
That will change - hallelujah!
Of course, my reduced cost will be someone else’s reduced revenue – and not just Apple’s.
One big loser in this world will be the freight business (along with junkyards, logistics companies, and centralized recycling operations).
When things can be made, used, broken/worn out, and recycled closer to home, the need for transport is reduced dramatically.
Recycled materials do not need to be delivered to centralized processing centers and then forwarded to factories.
Products will not need to be made in those factories and then shipped to customers or to inventory centers.
Right now, US inventories held by manufacturers, wholesalers, and retailers are valued at around $1.7 trillion – or about 10% of annual GDP.
This includes many things that cannot be 3D-printed (anytime soon, at least), but it does hint at how much stuff is just sitting around.
In the short run, this means greater efficiency and more and speedier recycling, happening locally rather than centrally.
In the long run, 3D printing will allow more efficient use of physical resources and faster diffusion of the best designs, boosting living standards around the world.
How Accurate Are Your Pet Pundits?
Every day, experts bombard us with their views on topics as varied as Iraqi insurgents, Bolivian coca growers, European central bankers, and North Korea’s Politburo. But how much credibility should we attach to the opinions of experts?
The sanguine view is that as long as those selling expertise compete vigorously for the attention of discriminating buyers (the mass media), market mechanisms will assure quality control.
Pundits who make it into newspaper opinion pages or onto television and radio must have good track records; otherwise, they would have been weeded out.
Skeptics, however, warn that the mass media dictate the voices we hear and are less interested in reasoned debate than in catering to popular prejudices.
As a result, fame could be negatively, not positively, correlated with long-run accuracy.
Until recently, no one knew who is right, because no one was keeping score.
But the results of a 20-year research project now suggest that the skeptics are closer to the truth.
I describe the project in detail in my book Expert Political Judgment: How good is it?
How can we know?
The basic idea was to solicit thousands of predictions from hundreds of experts about the fates of dozens of countries, and then score the predictions for accuracy.
We find that the media not only fail to weed out bad ideas, but that they often favor bad ideas, especially when the truth is too messy to be packaged neatly.
The evidence falls into two categories.
First, as the skeptics warned, when hordes of pundits are jostling for the limelight, many are tempted to claim that they know more than they do.
Boom and doom pundits are the most reliable over-claimers.
Between 1985 and 2005, boomsters made 10-year forecasts that exaggerated the chances of big positive changes in both financial markets (e.g., a Dow Jones Industrial Average of 36,000) and world politics (e.g., tranquility in the Middle East and dynamic growth in sub-Saharan Africa).
They assigned probabilities of 65% to rosy scenarios that materialized only 15% of the time.
In the same period, doomsters performed even more poorly, exaggerating the chances of negative changes in all the same places where boomsters accentuated the positive, plus several more (I still await the impending disintegration of Canada, Nigeria, India, Indonesia, South Africa, Belgium, and Sudan).
They assigned probabilities of 70% to bleak scenarios that materialized only 12% of the time.
Second, again as the skeptics warned, over-claimers rarely pay penalties for being wrong.
Indeed, the media shower lavish attention on over-claimers while neglecting their humbler colleagues.
We can see this process in sharp relief when, following the philosopher Sir Isaiah Berlin, we classify experts as “hedgehogs” or “foxes.”
Hedgehogs are big-idea thinkers in love with grand theories: libertarianism, Marxism, environmentalism, etc. Their self-confidence can be infectious.
They know how to stoke momentum in an argument by multiplying reasons why they are right and others are wrong.
That wins them media acclaim.
But they don’t know when to slam the mental brakes by making concessions to other points of view.
They take their theories too seriously.
The result: hedgehogs make more mistakes, but they pile up more hits on Google.
Eclectic foxes are better at curbing their ideological enthusiasms.
They are comfortable with protracted uncertainty about who is right even in bitter debates, conceding gaps in their knowledge and granting legitimacy to opposing views.
They sprinkle their conversations with linguistic qualifiers that limit the reach of their arguments: ‘but,’ ‘however,’ ‘although.’
Because they avoid over-simplification, foxes make fewer mistakes.
Foxes will often agree with hedgehogs up to a point, before complicating things: “Yes, my colleague is right that the Saudi monarchy is vulnerable, but remember that coups are rare and that the government commands many means of squelching opposition.”
Imagine your job as a media executive depends on expanding your viewing audience. Whom would you pick: an expert who balances conflicting arguments and concludes that the likeliest outcome is more of the same, or an expert who gets viewers on the edge of their seats over radical Islamists seizing control and causing oil prices to soar?
In short, the qualities that make foxes more accurate also make them less popular.
At this point, uncharitable skeptics chortle that we get the media we deserve.
But that is unfair.
No society has yet created a widely trusted method for keeping score on the punditocracy.
Even citizens who prize accuracy have little way of knowing that they are sacrificing it when they switch channels from boring foxes to charismatic hedgehogs.
Here, then, is a modest proposal that applies to all democracies: the marketplace of ideas works better if it is easier for citizens to see the trade-offs between accuracy and entertainment, or between accuracy and party loyalty.
Wouldn’t they be more likely to read pundits with better track records?
If so, pundits might adapt to accountability by showing more humility, and political debate might begin to sound less shrill.
Granted, it is not easy to create methods of keeping score that are credible across the spectrum of reasonable opinion. But in a world where, as Yeats said, “and the best lack all conviction, while the worst are full of passionate intensity,” it is worth trying.
Brexit, Voice, and Loyalty
Marriages break down if divorce (exit) is too easy; but also become unbearable if there is no sense of mutuality and discussion (voice).
Voice may also decrease if new possibilities emerge: a new potential partner means that there is no longer any pressure to discuss and improve relations within the existing arrangement.
The schema might also be applied to political relations: Hirschman wrote a memorable article showing how the ability to exit East Germany in 1989 produced a sudden breakdown of loyalty.
Europeans might rethink some of their current dilemmas in the light of Hirschman’s theory.
The marriage analogy has become a rather over-used metaphor for Europe’s efforts to integrate.
But it is clear that both voice and loyalty have become a problem for the European Union.
Many citizens and governments believe that they lack influence, or voice, which tends to reduce loyalty.
Now a more radical possibility has been raised.
British Prime Minister David Cameron has raised the possibility of a “Brexit,” a British exit from the European Union.
The polemics that preceded and followed Cameron’s recent speech on Europe showed that both British Euro-skeptics and Europe’s truest Europhiles – including such iconic figures as former European Commission President Jacques Delors – welcomed the British initiative.
Can the British exit threat shake Europe to its senses and make the United Kingdom’s effort to reform institutions more likely to succeed, or to make Europe a more stable polity?
Hirschman’s framework, which is instructive in helping us to think about how loyalty and affection can be generated, suggests that it cannot.
Countries do not like to feel isolated.
They want to see their institutions and values mirrored and replicated in their neighbors – a dynamic that builds loyalty.
As a result, the EU is constantly expanding, while the US likes to urge the world to democratize.
Democratic states are not alone in seeking to expand their influence.
The Soviet Union also wanted to surround itself with a protective buffer of like-minded states, and Italy’s Benito Mussolini was proud that for a time fascism was a competitive export.
The recognition of an exit possibility reverses that basic process of forging bonds of loyalty.
Some other attraction may appear.
One of the factors driving the UK’s sense of unease in its relations with an increasingly bureaucratized Europe is the belief that its values and institutions are closer to those of the US, or of other English-speaking former colonies.
By the 1990’s, British Euro-skeptics coined the term “Anglosphere” to describe a model that was more successful and more expansionary than that of the EU.
The US has been the “other woman” undermining Britain’s loyalty to the EU as an attractive permanent partner.
As a result, Britain has lost much of its ability to make an effective contribution to European reform.
Indeed, the last time Britain had a strong European voice was more than two decades ago.
In the mid-1980’s, then-Prime Minister Margaret Thatcher successfully pushed the idea of an integrated internal market.
The liberalization of trade and investment implied by the Single European Act was greatly inspired by a British deregulatory vision.
At the time, Delors presented the introduction of a single currency as a way to complement or complete the Single Market.
Since then, however, both the American financial model (with powerful financial institutions thriving in lightly regulated markets) and the American model of engagement (in Iraq and Afghanistan) for some time appeared more dynamic and more in accordance with the demands of a globalizing world.
Both elements of the American dream have now lost something of their appeal.
The Iraq engagement proved to be built on deception.
The financial house of cards collapsed.
But Britain remains attracted to something else, and so unwilling to engage in “voice.”
The US is appalled by the consequences of Britain’s flirtation.
It wants to remain engaged with the entire world, not just some islands off the European coast.
It is easier for the US to deal with Europe as a whole, especially when some European answers to common social dilemmas look as if they might provide solutions for America as well.
The outcome resembles a Shakespeare comedy of confused identity.
Europe and Britain are married, but Britain wants to deepen its relationship with America, while America cares more about Europe.
Loyalty-enhancing mechanisms are not easy to establish.
The best ones are positive, like rapid economic growth and rising prosperity, which underpinned the European dream in the past.
Restoring them is unlikely, at least for now.
There can also be negative incentives to loyalty that induce everyone to keep up appropriate standards of behavior.
The risk is that the comedy of misguided affection is resolved by punishing both the tempter and the tempted.
What is the modern equivalent of branding with a scarlet “A,” which was the penalty for adultery in colonial New England?
Maybe the credit-ratings agencies have the answer.
Inside America’s Tax Battle
BERKELEY – America’s recent presidential election answered the question of whether an increase in revenues will be part of the country’s long-run deficit-reduction plan.
The answer is yes: there is now bipartisan agreement on the need for a “balanced” approach that includes revenue increases and spending cuts.
But there are still deep political and ideological divisions about how additional revenues should be raised and who should pay higher taxes.
If a preliminary agreement on these questions is not reached by the end of the year, the economy faces a “fiscal cliff” of $600 billion in automatic tax increases and spending cuts that will shave about 4% from GDP and trigger a recession.
The majority of citizens agree with President Barack Obama that tax increases for deficit reduction should fall on the top 2-3% of taxpayers, who have enjoyed the largest gains in income and wealth over the last 30 years.
That is why he is proposing that the 2001 and 2003 rate cuts for these taxpayers be allowed to expire at the end of the year, while the rate cuts for other taxpayers are extended.
So far, Obama’s Republican opponents are adamant that the cuts be extended for all taxpayers, arguing that increases in top rates would discourage job creation.
This claim is not supported by the evidence.
Recent research finds no link between tax cuts for top taxpayers and job creation.
In contrast, tax cuts for the bottom 95% have a positive and significant effect on job growth.
During the past three decades, income inequality in the United States has increased significantly; indeed, the US now has the fourth-highest level of income inequality in the OECD, behind Chile, Mexico, and Turkey.
At the same time, as the largest tax cuts have gone to high-income taxpayers, the US tax system has become considerably less progressive.
The US needs fiscal measures that both curb the deficit and contain rising income inequality – and the inequality of opportunity that it begets.
But how should additional revenues be raised from top taxpayers to achieve these two goals?
Most economists believe that increasing revenues by reforming the tax code and broadening the tax base is “probably” better for the economy’s long-term growth than raising income-tax rates.
The analytical case for this belief is strong, but the empirical evidence is weak.
In theory, higher marginal tax rates have well known negative effects – they reduce private incentives to work, save, and invest.
Yet most empirical studies conclude that, at least within the range of income-tax rates in the US during the last several decades, these effects are negligible.
A recent Congressional Research Service report, withdrawn under pressure from Congressional Republicans, found that changes in the top income-tax rate and the rate on capital gains had no discernible effect on economic growth during the last half-century.
A recent review of the economic literature by three distinguished academics found no convincing evidence that real economic activity responds materially to tax-rate changes on top income earners, although such changes do affect their tax-avoidance behavior.
So Obama has evidence on his side when he says that allowing the tax cuts for high-income taxpayers to expire at the end of the year will not affect economic growth.
Republicans have proposed tax reforms in lieu of rate hikes on high-income taxpayers to raise revenues for deficit reduction.
Obama has signaled that he is willing to consider this approach, provided it increases tax revenues from the top 2-3% by at least the same amount as higher rates while protecting other taxpayers.
The federal tax system is certainly in need of reform.
Tax expenditures – which include all deductions, credits, and loopholes – account for about 8% of GDP.
Indeed, the US tax code is riddled with special preferences and contains large differences in effective tax rates across individuals and economic activities.
These differences distort decisions about investment allocation and financing.
Reforms that made the tax system simpler, fairer, and less distortionary would have a beneficial effect on economic growth, although economists concede that the size of this effect is uncertain and impossible to quantify.
Because tax expenditures are so large, limiting them could raise a significant amount of additional revenue that could be used both for deficit reduction and to finance across-the-board cuts in income-tax rates.
Analysis of the Simpson-Bowles and Domenici-Rivlin deficit-reduction plans by the nonpartisan Tax Policy Center confirms that this approach is arithmetically feasible.
Reducing large regressive tax expenditures like preferential tax rates for capital gains and dividends and deductions for state and local taxes, and replacing deductions with progressive tax credits, could generate enough revenue to finance rate cuts for all taxpayers, increase the tax code’s overall progressivity, and contribute meaningfully to deficit reduction.
But the odds of such an outcome are very low: what is arithmetically feasible is unlikely to be politically possible.
Efforts to cap popular tax expenditures will encounter strong opposition from Republicans and Democrats alike.
Nonetheless, some tax reforms are likely to be a key component of a bipartisan deficit-reduction deal, because they provide Republicans who oppose increases in tax rates for high-income taxpayers with an ideologically preferable way to increase revenue from them.
Unfortunately, it will take time to negotiate tax reforms – more time than remains until the end of the year, when the 2001 and 2003 tax cuts are scheduled to expire for all taxpayers.
But there is still time to negotiate an agreement that extends these cuts for the bottom 98%, and that contains temporary measures to cap deductions and credits for high-income taxpayers in 2013.
Such an agreement could help to break the political impasse over whether and how much these taxpayers’ rates should rise next year, thereby preventing the US from falling over the fiscal cliff and back into recession.
Saving Syria and America
DENVER – Critics of America’s Middle East policies are reminiscent of Woody Allen’s quip in Annie Hall: “The food at this place is really terrible...and such small portions.”
The United States is seen as the culprit behind many of the regions ills, and yet it is accused of not being sufficiently engaged, of “leading from behind,” of failing to support democracy, of abandoning its friends, and so on.
Given all the accusations that the US faces for its involvement in the region over the decades, one would think that America would be invited to stay home.
But the region cries out for leadership, and the US remains the only country that can provide it.
The problem for the US is not the divisions in the Middle East that it must understand and navigate better, but rather the divisions within the US that have eroded domestic consensus on many foreign-policy issues.
Those internal differences are what have kept the US on the sidelines during the latest Middle East upheavals.
America used to have essentially two varieties of foreign-policy positions: realist and idealist.
But today opinions are fragmented across a broad range of positions – a situation that also cries out for leadership.
President Barack Obama’s oft-stated view that “we need some nation building at home,” combined with his antiseptic waging of drone warfare, indicates that he is erring on the side of the isolationists of both the left and the right.
Unilateralism, it seems, is fast becoming the isolationists’ internationalism.
What the US needs is to explain better to its own people why America should engage more deeply with the Middle East’s mounting problems.
This is not to say that the US should necessarily engage with every problem.
But, whether America is engaged or not, it does need a policy.
Syria is a case in point.
The situation there, predicted by every pundit around, has metastasized and threatens to become a full-blown regional civil war.
The US has reacted to this international catastrophe by providing light arms to some rebel groups in order to inflict a pinprick on President Bashar al-Assad’s regime for its use of chemical weapons months before.
This is not serious policy.
Military assistance should support a political plan, not serve as a substitute for one.
A month ago, there was a brief moment of hope when US Secretary of State John Kerry began an effort to find a way forward with the Russians.
The Kremlin’s consequential and sustained support of Assad is serious policy, and suggests that if the US is to make progress short of confrontation with Russia, it should work with Russian leaders to narrow the differences so that, at the end of the process, a peace conference is held.
Indeed, successful US policy in the Middle East has usually included a serious Russian track.
Instead, the talks with the Russians seem to have run aground on the question of calling a conference among the warring parties to agree on elections.
But elections in sectarian conflicts tend to be merely a census, and the Assad regime and all the other players know full well that Syria is a Sunni-majority country.
There is no need for an election to determine that.
What is not known is whether there is a set of future political arrangements on which the parties could agree.
It is not known, because it has not been tried.
Meanwhile, the Obama administration has made no effort to explain what it is doing and why, engaging instead in public handwringing over the complexities of the problem.
But building monuments to difficult problems is not a policy.
As Churchill once wrote about the “Mulberry” harbors (his ingenious plan to install prefabricated floating piers a day after the Normandy landings), “the difficulties will argue for themselves.”
Obama’s explanation of a Syrian policy might look something like this: “Syria is a difficult problem that, left unchecked, could threaten US interests in the region.
No side can prevail and win outright, so there must be a negotiated settlement on the political arrangements that follow the conflict.
The US will work with partners in the region and internationally to assist the Syrians to find a way forward.
Syrians need to understand what their country will look like in the future, so that all sides can see a solution that can be secured through negotiation rather than violence.”
He should then announce concrete action to achieve this goal: “Today, I have directed State Department teams under Secretary Kerry to visit key international capitals – in Europe and Arab League countries, as well as Moscow – in an effort to agree on a set of principles around which Syrians can find common ground.”
The first principle could be that Syria should continue to exist within its current borders.
Another might be that Syria will be a federal state, with broad local autonomy.
A third could concern the shape of a future parliament.
And so forth.
When agreed, these principles could be announced as an international peace plan.
Only when one or more parties to the conflict reject it has the moment arrived to consider a serious effort to arm some of the combatants.
In the end, a solution in Syria will depend on Syrians’ agreement on future political arrangements.
But the US demand that Assad step down or be removed from power has not been helpful; indeed, it has marginalized the US more than it has Assad.
No one can be expected to join negotiations aimed at his or her own political demise.
But all that is water under the bridge.
There are those who say that the Syrian crisis could have been addressed two years ago, but that now is too late.
Two years from now, some will say the same thing.
But if the US can work with partners on the specifics of a future political plan, it can still rescue Syria, not to mention itself.
Rank Mysteries
PARIS – Gibraltar received exciting news last month.
The latest Global Financial Centres Index (GFCI), published by the consultancy Z/Yen in London, revealed that the Rock had risen further and faster up the ranks than any other center – 17 places, from 70th to 53rd position, since the previous report in September 2013.
I can imagine the celebrations in Gibraltar Town, where, now that the British naval base has closed and Spain is being difficult at the border, financial services are crucial for employment.
And I can also imagine that many in Hamilton, Bermuda, which plummeted almost as far as Gibraltar climbed – 16 places, to 56th – must be crying into their rum punch.
Of course, it is also possible that Gibraltar and Bermuda have chosen to ignore the results, or dispute their significance.
Either way, there is no doubting the global obsession with league tables nowadays.
One can find a ranking for almost every form of human activity.
Commercial banks are ranked by assets.
Investment banks are ranked on a variety of metrics, as are universities – from academic results to their prowess in environmental management, or their appeal to gay students.
In the United Kingdom, you can find a table showing where it is best to live if you wish to win Britain’s National Lottery.
(Your chances are almost twice as good in the northeast as in Northern Ireland.)
When one looks closely, most of these tables are, as Henry Kissinger famously put it, “content-free.”
For one brief shining moment, the Royal Bank of Scotland was global top dog in rankings of commercial banks, and we know how that story ended.
Is this true of the GFCI, or does it contain valuable insights into how the global financial system is evolving?
The press headlines accompanying the release of the latest GFCI focused on the change at the top of the league: New York leapfrogged ahead of London, while Hong Kong and Singapore held on in third and fourth place, respectively.
Is this a significant switch?
Much speculation has centered on the recent damage to London’s reputation stemming from the scandal surrounding banks’ manipulation of the Libor interest rate.
Even if some of the machinations were carried out in other cities, there is no escaping the fact that Libor is the London Interbank Offered Rate.
Moreover, London is the biggest center for foreign-exchange trading, the new focus of regulatory attention.
And, though Bruno Iksil was a Frenchman working for the American bank JPMorgan Chase, he became known universally as the “London Whale.”
But GFCI’s detailed results do not bear out that explanation.
London’s reputational factors “are firmly above average and have not seen much change over the past five editions.”
Indeed, it seems that London’s small decline is attributable to negative scores on general factors such as the “business environment” and “infrastructure.”
Overcrowded Underground trains and Heathrow’s congestion are having an impact, though it is hard to understand why New York wins on these measures.
Riding the Subway often brings unpleasant surprises, while JFK Airport is hardly a favorite among travelers (and there remains no fast rail link to it).
And yet these subtle switches at the top of the table are not the real story.
From a ten-year perspective, the big gainers have been Hong Kong and Singapore.
It was once fashionable to argue that when China opened up to the world, Hong Kong and Singapore would suffer.
Once the Chinese got their act together, these cities’ role in intermediating the region’s finances would be marginalized by Shanghai, Shenzhen, and other new centers.
That still may happen one day, but it has not happened yet.
Hong Kong and Singapore have played their cards astutely.
The combination of an Asian market with strong Chinese connections and a system of English law and property rights continues to provide a powerful competitive advantage.
That is especially true in fund management.
Chinese companies may increasingly raise capital in Shanghai, but wealthy Chinese with money to invest like to hold it in financial centers that are perceived as safe and non-political.
In Europe, we see a different pattern.
Over 15 consecutive surveys, London’s ranking and ratings have remained broadly constant, while Zurich, Geneva, Frankfurt, and Luxembourg have gradually narrowed the gap with it – though that gap remains wide.
There is little doubt that Frankfurt has won the contest with Paris to be the eurozone’s most important financial center.
The Germans were smart to insist on putting the European Central Bank there.
Given the ECB’s new function as the eurozone’s banking supervisor, Frankfurt can consolidate its victory.
Every European Union bank will need to bend the knee to its supervisor on the Main River, even if she does happen to be a Frenchwoman, Danièle Nouy.
In the United States, Boston, San Francisco, and Washington, DC, continue to consolidate their positions as important centers for asset management and, in the last case, for regulation.
The 2010 Dodd-Frank financial-reform legislation has given the Federal Reserve Board a much larger regulatory role than it had before the crisis.
But, unless New York’s populist new mayor, Bill de Blasio, tries to run the banks out of town, Western sheriff-style, these cities do not seem likely to steal Wall Street’s crown anytime soon.
All of the best award shows include a surprise.
This year’s wild card, billed as the financial center most “likely to become more significant” in the near future, is Casablanca.
I have no idea why Casablanca is an up-and-coming center, and the GFCI’s compilers do not explain.
Sometimes, in rankings as in life, a kiss is just a kiss.
Europe’s Fitful Financial Integration
LONDON – The well-publicized troubles of Portugal’s Banco Espírito Santo this summer have reminded us that the eurozone’s financial problems are by no means resolved.
There are, no doubt, idiosyncratic factors behind the bank’s problems, stemming from its exposure to other parts of the Espírito Santo family’s empire.
But when the bank announced a first-half loss of €3.6 billion ($4.7 billion), the sudden collapse of confidence was alarming, and nervous investors are asking whether there are similar time bombs ticking elsewhere.
All eyes are now on the European Central Bank’s asset quality review, due to be completed in the next couple of months.
The AQR is the key element in a “comprehensive assessment” of Europe’s banks before the ECB formally takes on supervisory responsibility for more than 80% of the eurozone banking system in November.
The ECB, quite sensibly, wants all of the potential horrors to be visible before the takeover – so that it cannot be blamed.
With national supervisors, who are often inclined to present a rosy picture of their countries’ institutions, no longer in charge, we can hope that the assessment will be more robust than the earlier stress tests carried out under the auspices of the European Banking Authority (EBA). Those tests, unlike their equivalent in the United States, failed to rebuild confidence.
Several banks that passed with flying colors were soon obliged to raise new capital.
But the creation of the European banking union has not been the only important change to Europe’s financial regulation since the crisis.
The events of 2007-2009 made it clear that there were serious gaps and inconsistencies that needed to be addressed.
So, following the recommendations of a report prepared in 2009 by former IMF Managing Director Jacques de Larosière, the European Commission created three new pan-European authorities charged with ensuring “consistent application” of European directives.
The deal was done with a large helping of political fudge: the three biggest European Union economies – the United Kingdom, France, and Germany – were persuaded to cede some control to the center, but only if each could host an authority.
Thus, the EBA was established in London, the European Securities and Markets Authority (ESMA) is located in Paris, and the European Insurance and Occupational Pensions Authority (EIOPA) found a home in Frankfurt.
Collectively, they are known as the ESAs (European supervisory authorities).
The road to pan-European regulation over the last two decades has been winding and rocky.
In the early stages, it was assumed that the single financial market could work on the basis of mutual recognition: each country would accept the others’ regulation as broadly equivalent to its own and allow cross-border business to proceed on that basis.
That proved inadequate, as standards and rules remained very different from country to country, and gave way to an approach based on minimum harmonization, whereby core rules were to be the same across Europe, but local variations and additions remained permissible.
When that, too, proved ineffective at promoting competition, as countries used their national rules to block new entrants, the emphasis switched to maximum harmonization, with directives spelling out exactly how local rules must be applied across the EU.
That caused great concern in the City of London, but has been grudgingly accepted.
Since the global financial crisis, London has become less able to argue that it is special and must be left alone.
Now, with the establishment of central regulatory authorities, the EU has moved to the next stage of financial integration.
But, so far, these agencies’ responsibilities are very limited.
ESMA supervises rating agencies directly; but, outside banking, national authorities retain their day-to-day oversight responsibilities.
Integration-minded officials at the European Commission clearly do not regard this as a satisfactory end-state.
So they commissioned a thoughtful review of the three ESAs from Mazars, an accounting firm, which was published earlier this year.
The verdict, roughly, was “so far, so good.”
Now the Commission has followed up by publishing its own assessment.
The Commission was perhaps unlikely to be hypercritical of its own creations, and it is not.
Its report maintains that the ESAs have “quickly established well-functioning organizations aimed at contributing to restoring confidence in the financial sector,” and that market participants seem broadly satisfied with their work.
But the report’s authors believe that there is a need to expand the current mandates, develop a comprehensive approach to consumer protection, and reduce further the influence of national authorities.
The ESAs should have more power to impose their will in the interests of the EU as a whole.
Their chairs should have wider discretion to act on their own initiative.
The ESAs also need more money, which probably can come from fees levied on financial firms, and consideration should be given to merging them in a single location, presumably Brussels.
The general direction is clear.
Unless the new internal market commissioner takes a different view, the European Commission plans to move further along the road to genuine pan-European regulation.
The report now goes to the European Parliament, which can be expected to push harder for more integration, as it usually does.
A single authority, or perhaps two or three working closely together, is a logical arrangement for the eurozone, and perhaps for the entire EU financial market.
It would usefully complement the ECB’s new supervisory role.
But will London fall into line this time?
The British government, after all, has embarked on a path that runs in precisely the opposite direction – reducing the functions of central bodies and repatriating powers to national capitals.
Given the central role of London in EU financial markets, and its political sensitivity in the UK, there is bound to be trouble ahead.
The JPMorgan Problem Writ Large
PARIS – JPMorgan Chase has had a bad year.
Not only has the bank just reported its first quarterly loss in more than a decade; it has also agreed to a tentative deal to pay a fine of $13 billion to the US government as punishment for mis-selling mortgage-backed securities.
Other big legal and regulatory costs loom.
JPMorgan will bounce back, of course, but its travails have reopened the debate about what to do with banks that are “too big to fail.”
In the United States, policymakers chose to include the Volcker rule (named after former Federal Reserve Chairman Paul Volcker) in the Dodd-Frank Act, thereby restricting proprietary trading by commercial banks rather than reviving some form of the Glass-Steagall Act’s division of investment and retail banks.
But Senators Elizabeth Warren and John McCain, a powerful duo, have returned to the fight.
They argue that recent events have shown that JPMorgan is too big to be managed well, even by CEO Jamie Dimon, whose fiercest critics do not accuse him of incompetence.
Nonetheless, the Warren-McCain bill is unlikely to be enacted soon, if only because President Barack Obama’s administration is preoccupied with keeping the government open and paying its bills, while bipartisan agreement on what day of the week it is, let alone on further financial reform, cannot be guaranteed.
But the question of what to do about huge, complex, and seemingly hard-to-control universal banks that benefit from implicit state support remains unresolved.
The “school solution,” agreed at the Financial Stability Board in Basel, is that global regulators should clearly identify systemically significant banks and impose tougher regulations on them, with more intensive supervision and higher capital ratios.
That has been done.
Initially, 29 such banks were designated, together with a few insurers – none of which like the company that they are obliged to keep!
There is a procedure for promotion and relegation, like in national football leagues, so the number fluctuates periodically.
Banks on the list must keep higher reserves, and maintain more liquidity, reflecting their status as systemically important institutions.
They must also prepare what are colloquially known as “living wills,” which explain how they would be wound down in a crisis – ideally without taxpayer support.
But, while all major countries are signed up to this approach, many of them think that more is needed.
The US now has its Volcker rule (though disputes between banks and regulators about just how to define it continue).
Elsewhere, more intrusive rules are being implemented, or are under consideration.
In the United Kingdom, the government created the Vickers Commission to recommend a solution.
Its members proposed that universal banks be obliged to set up ring-fenced retail-banking subsidiaries with a much higher share of equity capital.
Only the retail subsidiaries would be permitted to rely on the central bank for lender-of-last-resort support.
A version of the Vickers Commission’s recommendations, which is somewhat more flexible than its members proposed, is in a banking bill currently before Parliament.
A number of MPs want to impose tighter restrictions, and it is difficult to find anyone who will speak up for the banks, so some form of the bill is likely to pass, and big British banks will have to divide their operations and their capital.