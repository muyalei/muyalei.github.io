But it has little coercive power, because anyone is free to try an alternative.
Its only option is to be better than the competition.
The fact that these issues are being debated is a good sign in itself – keeping Google and its watchers on guard.
Fortunately, a wary press corps, powerful governments, and nervous competitors watch its every move, hoping the company to fight its many temptations.
Abuse of power is evil, but power itself is not. 
Big Brother, Tibet, and the Sichuan Earthquake
Shanghai – Tight media control of the unrest in Tibet has been followed by what, to some, looks like far more open coverage of the devastating earthquake in Sichuan province.
Is this a change in China’s media strategy, or just a short term change in tactics? 
This question stands out in view of Chinese public opinion in the latter phase of the Tibet crisis.
Much to the consternation of the Western media, Chinese people worldwide lashed out against its allegedly biased coverage of the Tibetan riot.
Throngs of Chinese expatriates and students took to the streets, protesting the prejudice they perceived in Western media reports.
Angry youngsters even founded Web sites such as anti-cnn.com to express their outrage.
Western reporting, once commended for its veracity, now seems discredited across China, although sympathetic coverage of the loss of life in Sichuan may have redeemed the Western media somewhat.
Even Chinese liberals admit that Western journalists blundered badly in Tibet, using cropped images and false captions as evidence of China's heavy-handed rule.
One sarcastic posting on China's popular Web portal Tianya even went so far as to say that “CNN is of the same ilk as CCTV (China Central Television).
Both talk grandiosely and profusely about impartiality.
Ironically, both turn out to be hypocrites.”
One can argue that this trend bodes ill for China.
But pessimism is misplaced.
Much of the Chinese wrath is directed at biased reports, not at Western media in general.
And when one looks more closely at how Chinese responded, both to the unrest in Tibet and the Sichuan earthquake, one sees tangible signs that the Chinese are embracing a greater degree of free speech.
Despite a news blackout during the riots in Lhasa, for example, Chinese Internet users managed to dodge the country’s censorship.
Much as they loathed domestic publications for blindly following the guidelines of Xinhua, China’s state news agency, they were similarly contemptuous of Western media that mishandled the story.
As a result, those Chinese who use the Internet as a source for news awakened to the fact that no account – Chinese or Western – is flawless.
Such skepticism, which is a fundamental attribute of the democratic mind, may have played a role in pushing the government toward more openness in Sichuan.
Indeed, the fact that many school buildings were flattened in Sichuan prompted an outcry from ‘netizens,’ who grilled local officials about whether it substandard building codes or even a notorious “toufuzha construction scandal,” namely, jerry-built projects, that had led to the disproportionate number of dead pupils.
Under mounting public scrutiny, government officials felt compelled to promise that those responsible will be brought to justice.
Unlike in the past, when Chinese Internet users passively received information, years of exposure to concepts such as human rights and democracy have emboldened them to challenge entrenched yet dubious views, even if it means iconoclasm.
Chinese audiences are as fed up with the glowing encomiums broadcast by CCTV as they are with the simplistic, context-free reporting of Western media.
Caught in the middle, Chinese increasingly sift for the truth on their own.
Many, indeed, tried to present to the outside world their own version of the Tibet story, rebutting the orthodox narrative – be it Chinese or Western – and posting comments and footage on YouTube and the BBC's bulletin board.
Moreover, due to their repeated queries for explanation, a few Western media outlets eventually owned up to their mistakes.
After China’s government became aware that independent grassroots movements could convince ordinary Chinese where government propaganda had failed, it lifted its initial ban on reporting on Tibet.
“Net nannies” – as China’s Internet censors are often dubbed – blocked sensitive articles less frequently.
China’s government has apparently begun to appreciate the limitations of cover-ups and stonewalling, and perhaps also the merits of allowing some room for free speech.
This thirst for unbiased information highlights the dramatic change that the Internet has brought to China’s political landscape.
Nowadays, the government no longer monopolizes information and the right to process it.
Insightful bloggers attract considerably more clicks than do official mouthpieces.
A “virtual civil society” is in the making.
But can Web activism mature into a full-blown campaign for free speech without being manipulated by the government or blindfolded by Western media?
The answer may prove to be mixed.
Admittedly, the fierce popular backlash against Western media was partially motivated by nationalist ardor, which played into the government’s hands.
The Internet can foster more demagoguery than sober analysis.
But the best way to prevent this is to create an environment in which opposing views can clash freely, enabling truth ultimately to triumph.
On the government’s part, the more open media in Sichuan may be mere posturing to appease critics after the Tibet upheaval and the scuffle over the Olympic torch.
The government’s willingness to address squarely questions about shoddy infrastructure will be a key test of the genuineness of its supposed new found tolerance of freeish speech.
Although free speech is no panacea for China’s woes, only when it is established will the country’s progress be sustainable.
Despite the watchful eyes of Big Brother in Beijing, the Internet is sowing the seeds of free speech in China.
That may be the most important lesson of the crisis in Tibet and Sichuan.
The Conglomerate Way to Growth
CAMBRIDGE – Countries do not become rich by making more of the same thing.
They do so by changing what they produce and how they produce it.
They grow by doing things that are new to them; in short, they innovate.
Many countries have been altering their growth strategies to reflect this insight.
But they are being distracted by some of the greatest – but atypical – examples of success.
We all have heard of Steve Jobs, Bill Gates, and Mark Zuckerberg – twenty-something college dropouts who built billion-dollar companies at the cutting edge of global innovation.
We have heard of the many start-ups that they and others acquired for hundreds of millions of dollars - Instagram, Skype, YouTube, Tumblr, and, most recently, Waze.
So why not emulate these successes?
The main problem is that these examples are peculiar to the software industry, which provides a woefully insufficient blueprint for the rest of the economy.
The software industry is unique, because it has unusually low barriers to entry and ready access to a huge market through the Internet.
A start-up is typically just a group of kids with a good idea and programming skills.
All they need is time to write the code.
Incubators provide them with space, legal advice, and contacts with potential clients and investors.
But consider a steel, automobile, or fertilizer plant – or a tourist resort, a hospital, or a bank.
These are much more complex organizations that must start at a much larger scale, require much more upfront investment, and need to assemble a more heterogeneous team of skilled professionals.
This is not something at which a young college dropout is bound to excel, because he lacks the experience, the organization, and the access to capital that these ventures require.
And, compared to software development, these activities also require more infrastructure, logistics, regulation, certifications, supply chains, and a host of other business services – all of which demand coordination with public and private entities.
Most important, these activities are most likely to be central to economic growth in developing and emerging countries.
So, how will companies in these sectors arise, and what can be done to stimulate their formation?
Many developing-country governments are ignoring that question.
For example, Chile’s government, obsessed with so-called “horizontal” policies that do not tilt the playing field in favor of any industry, recently implemented Start-Up Chile, a program with standardized rules to encourage new ventures.
Although the rules were designed for all industries, the scheme attracts almost exclusively software ventures – the only ones that can be formed with the low level of support that the program provides.
Other industries face more daunting chicken-and-egg problems: countries lack the capabilities that growth industries demand, yet it is impossible to develop these capabilities unless the industries that require them are present.
One way to solve this coordination problem is through vertical integration – that is, firms that can solve internally the coordination of the supply and demand for any new capability.
That is why national business groups – conglomerates – often play a key role in transforming an economy and its exports.
This is especially true in developing counties, where many markets are missing and the business environment is often extremely challenging.
Conglomerates can use their knowledge, managerial skills, and financial capital to venture into new industries.
They can start things at a scale that would be impossible for a start-up.
They can make credible commitments to future suppliers and influence the business ecosystem to make new industries feasible.
Consider South Korea.
In 1963, the country exported goods worth less than $600 million at today’s prices, mostly primary products such as seafood and silk.
Fifty years later, it exports goods worth almost $600 billion, mostly electronics, machinery, transportation equipment, and chemical products.
This transformation was not achieved through independent start-ups. It was done through conglomerates, or chaebols in Korean.
For example, Samsung started as a trading company, moved to food processing, textiles, insurance, and retail, and then on to electronics, shipbuilding, engineering, construction, and aerospace, just to name a few activities.
South Korea’s transformation was reflected in the transformation of its leading companies.
But, in many developing countries, conglomerates have not played an equivalent role.
They have focused on non-tradable goods and services – those that cannot be imported or exported – and have eschewed international competition.
They have focused on banking, construction, distribution, retail, and television broadcasting.
Once these companies dominate one market, they move to another that is equally sheltered from competition and devoid of export opportunities, often using their size and political influence to keep out would-be competitors.
Instead of becoming agents of change, they often prevent change.
(Indeed, the big economic debate in South Korea nowadays concerns whether the chaebols are stifling innovation by preventing start-up competitors from challenging them.)
The productive transformation that developing countries need is much easier to achieve with the support, rather than the obstruction, of their conglomerates.
But ensuring such support requires policies that nudge (or even shove) conglomerates toward export industries that can grow beyond the limits of the domestic market – industries in which competition will encourage the discipline that they lack as a result of dominating local markets.
To succeed, conglomerates need the support of government and the acceptance of society.
They must earn it through their contribution to the growth of employment, exports, and tax revenues, and to the country’s technological transformation.
That is what General Park Chung-hee (South Korea’s longtime ruler, and father of current President Park Geun-hye) pressured the chaebols to do in the early 1960’s.
And it is what governments and civil societies in developing countries today should demand of their conglomerates.
Big Countries, Small Wars
LONDON – US President Barack Obama has vowed to avenge the murder of J. Christopher Stevens, America’s former ambassador to Libya.
How he proposes to do this is unclear – historical precedent is of little use.
In 1864, the Emperor of Abyssinia took hostage the British consul, together with some missionaries, in the country's then-capital, Magdala.
Three years later, with Emperor Tewodros still refusing to release them, the British dispatched an expeditionary force of 13,000 troops, 26,000 camp followers, and 44 elephants.
In his book The Blue Nile, Alan Moorehead described the expedition thus: “It proceeds first to last with the decorum and heavy inevitability of a Victorian state banquet, complete with ponderous speeches.”
Yet it was a fearsome undertaking.
After a three-month journey through the mountains, the British reached Magdala, released the hostages, and burned the capital to the ground.
Emperor Tewodros committed suicide, the British withdrew, and their commander, Lieutenant-General Sir Robert Napier, was made Baron Napier of Magdala.
Today's great powers have relied on similar methods, also heavy with rhetoric, against puny opponents, but with far less convincing results.
The United States put 500,000 troops into Vietnam in the 1960’s, but withdrew before North Vietnam overran the South in 1975.
The Russians began pulling their 100,000 troops from Afghanistan in 1987, after nine years of fighting had failed to subdue the country.
Now, 25 years and $500 billion later, roughly 100,000 NATO troops, mainly American, are about to leave Afghanistan, with the Taliban still controlling much of it.
Meanwhile, the US has withdrawn 150,000 troops from Iraq, after nine years of frustration.
The evidence is clear: big countries can lose small wars.
So, if massive use of force fails, how is a big country, believing that its interests or moral duty compel it to intervene in the affairs of a small one, to do so successfully?
Gillo Pontecorvo’s brilliant 1966 film The Battle of Algiers spelled out the dilemma for the occupying colonial power.
The FLN (National Liberation Front) uprising against French rule in Algeria started in 1954 with assassinations of policemen.
The French at first responded with orthodox measures – more police, curfews, martial law, etc. – but the insurgency spread amid growing atrocities by both sides.
In 1957, the French sent in paratroopers.
Their commander in the film, Colonel Mathieu (based on General Jacques Massu), explained the logic of the situation from the French point of view.
The way to crack the insurgency was not to antagonize the people with oppressive, but “useless” measures; it was to take out the FLN’s command structure.
Eliminate that and the result would be a leaderless mass.
This required the use of torture to identify and locate the leaders, followed by their capture or assassination.
Torture was illegal, but, as the Colonel explained, “If you want France to stay, you must accept the consequences.”
Colonel Mathieu is the unsung hero of current counter-insurgency orthodoxy, which requires a minimum military presence in the target country, mainly of intelligence agencies like the CIA and “special forces.”
Through “rendition,” a captured suspect can be handed over to a friendly government to be tortured, and, on the basis of the information thus gathered, “kill lists” can be compiled.
The killing of Osama bin Laden last year required an actual hit squad to verify its success, but normally assassinations can be left to drones – unmanned aircraft, mainly used for surveillance, but which can be armed with computer-guided missiles.
Not surprisingly, the US is the leading developer and user of drones, with a fleet of 7,500.
An estimated 3,000 drone killings have taken place, mostly in Pakistan, but also in Yemen and Somalia.
The other half of the counter-insurgency strategy is to win the “hearts and minds” of populations that are susceptible to terrorist propaganda.
The Americans did this in Vietnam by pouring in consumer goods and building up infrastructure.
They are doing the same in Iraq and Afghanistan.
The civilian side of “nation building,” it is reckoned, will be made easier by the absence of a heavy-handed foreign military presence.
Trying to win hearts and minds is certainly an improvement over bombing or shooting up the local population.
But the new way of conducting “asymmetrical warfare” does raise uncomfortable ethical and legal issues.
The United Nations Convention on Torture explicitly forbids “cruel, inhuman, or degrading treatment or punishment,” so their use must be denied.
Also, assassination by drones inevitably leads to the killing of innocent civilians – the very crime that defines terrorism.
Even putting aside moral and legal questions – which one should never do – it is doubtful whether the strategy of torture and assassination can achieve its pacifying purpose.
It repeats the mistake made in 1957 by Massu, who assumed that he faced a cohesive organization with a single command structure.
Relative calm was restored to Algiers for a couple of years after his arrival, but then the insurgency broke out again with redoubled strength, and the French had to leave the country in 1962.
Today, the international community similarly misconceives the nature of the “war” that it is fighting.
There is no single worldwide terrorist organization with a single head.
Insofar as Al Qaeda still exists at all, it is a Hydra that sprouts new heads as fast as the old ones are cut off.
Trying to win “hearts and minds” with Western goods simply corrupts, and thus discredits, the governments established by those intervening.
It happened in Vietnam, and it is happening now in Iraq and Afghanistan.
We are being driven slowly but ineluctably to the realization that the people whom we are fighting will, to a significant extent, inherit the shattered countries that we leave behind.
They are fighting, after all, for their peoples’ right to (mis)manage their affairs in their own way.
Blame the French Revolution for having bequeathed to us the idea that self-government is always better than good government.
An Economics to Fit the Facts
CAMBRIDGE – The economics profession was arguably the first casualty of the 2008-2009 global financial crisis.
After all, its practitioners failed to anticipate the calamity, and many appeared unable to say anything useful when the time came to formulate a response.
But, as with the global economy, there is reason to hope that the discipline is on the mend.
Mainstream economic models were discredited by the crisis because they simply did not admit of its possibility.
And training that prioritized technique over intuition and theoretical elegance over real-world relevance did not prepare economists to provide the kind of practical policy advice needed in exceptional circumstances.
Some argue that the solution is to return to the simpler economic models of the past, which yielded policy prescriptions that evidently sufficed to prevent comparable crises.
Others insist that, on the contrary, effective policies today require increasingly complex models that can more fully capture the chaotic dynamics of the twenty-first-century economy.
This debate misses the point.
Simple models have their place.
They are useful for making the straightforward but counterintuitive points that distinguish macroeconomics from other fields of economic analysis.
We rely on such models to explain, for example “the paradox of thrift,” whereby individual decisions to increase saving can, by depressing spending and output, result in the population as a whole saving less.
At the same time, complex models can be useful for illustrating special cases and reminding us that the world is a messy place.
Neither class of models is useful, however, for providing the practical advice that policymakers need in a crisis.
Both are too stylized to be of use when analyzed in the abstract.
To make them useful, evidence is required.
In fact, largely unbeknownst to the protagonists in this debate over models, an evidentiary revolution is already underway.
While older members of the economics establishment continue to debate the merits of competing analytical frameworks, younger economists are bringing to bear important new evidence about how the economy operates.
For example, a longstanding debate in macroeconomics has focused on how prices respond to news about the economy, and whether companies pass through to consumers changes in import prices that result from exchange-rate movements.
Today, “big data” promises to enhance our ability to understand and even predict such responses.
One application of this approach, the Billion Prices Project at MIT, uses billions of observations from online retail websites to track inflation.
A second approach relies not on big data but on new data.
Economists are using automated information-retrieval routines, or “bots,” to scrape bits of novel information about economic decisions from the World Wide Web.
Websites where commercial artists submit designs for company logos and freelance editors offer services for authors promise to shed new light on issues like the determinants of innovation.
A third approach employs historical evidence.
A number of commentators have observed that the global financial crisis was good for economic history, because it directed attention to previous crises and to the insights that could be gleaned from studying them.
In fact, economic history never stopped playing its role in economic research.
But the financial crisis served as a useful reminder that history is replete with similar events and with evidence concerning which policy responses work.
This realization then dovetailed with the availability of more extensive historical data on the operation of the economy.
Economic historians have long gathered information from parish registers, population censuses, and corporate financial statements.
But working in dusty archives has become easier with the advent of digital photography, mechanical character recognition, and remote data-entry services.
Larger data sets are enabling economic historians to address key questions – for example, how aggregate economic conditions affect labor-force participation decisions in different times and places – more effectively than ever before.
This reference to different times and places points to the fourth and final focus of the new empirical research: institutions.
Macroeconomic models have tended to neglect the role of institutions, ranging from trade unions and employer associations to property-rights regimes and mechanisms for redistribution.
Taking them seriously means considering long historical intervals, because institutions change slowly and vary significantly only over time.
Renewed attention to history is thus allowing economists to consider more systematically the role of institutions in macroeconomic outcomes.
These developments amount to a sea change in economics.
As recently as a couple of decades ago, empirical analysis was informed by relatively small and limited data sets.
To be sure, analytical frameworks are still needed to help make sense of the data.
But now there is reason to hope that, in the future, economists’ conclusions and policy advice will be shaped not by those frameworks’ elegance, but by their ability to fit the facts.
Big Money Merges with Big Brother
PARIS – All over the world, Internet users entertain romantic delusions about cyberspace.
To most of us Web surfers, the Internet provides a false sense of complete freedom, power, and anonymity.
Every once in a while, of course, unsolicited messages and ads that happen to be mysteriously related to our most intimate habits intrude.
They remind us that we Internet users are, indeed, under constant virtual surveillance.
When the watchers have only commercial motives, such “spam” feels like a minor violation.
But in China or Russia, the Internet is patrolled not by unsolicited peddlers, but by the police.
So Russian human-rights activists and the environmental organization Baikal Environmental Wave should not have been surprised when, earlier this month, flesh and blood policemen – not Internet bots – confiscated their computers and the files stored within them.
In the time of the Soviet Union, the KGB would have indicted these anti-Putin dissidents for mental disorders.
This supposedly being a “new Russia,” cyber-dissidents are accused of violating intellectual property rights.
You see, they were using Microsoft-equipped computers and could not prove that the software had not been pirated.
By confiscating the computers, the Russian police could supposedly verify whether or not the Microsoft software that the activists were using had been installed legally.
On the surface, Microsoft and Prime Minister Vladimir Putin’s police look like strange bedfellows.
But are they?
Microsoft’s authorized representatives declared that they could not oppose the Russian police actions, because the Seattle-based company had to abide by Russian law.
Such an ambiguous declaration can be interpreted either as active support for the Russian police or as passive collaboration.
Moreover, in previous cases, Microsoft assisted the Russian police in their investigations of non-governmental organizations.
Clearly, human-right activists in Russia cannot and should not count on Microsoft as an ally in their efforts to build a more open society.
But Microsoft’s ambiguous – at best – behavior is part of a pattern.
Indeed, the record of Internet companies in authoritarian countries is both consistent and grim.
Yahoo set the pace in pioneering the active collaboration of Internet and high-tech firms with political repression.
In 2005, Yahoo gave the Chinese police the computer identification code for a dissident journalist, Shi Tao.
Shi Tao had sent a message in praise of democracy, which the censors had detected.
Following Yahoo’s lead, the police arrested him.
Shi remains in jail to this day.
At that time, Yahoo’s managers in the United States, like Microsoft in Russia, declared that they had to follow Chinese law.
Shi Tao, in his jail cell, was undoubtedly pleased to learn that China is ruled by law, not by the Communist Party.
After all, the rule of law is what Shi Tao is fighting for.
Google, at least for a short while, seemed to follow different guidelines in its Chinese business, appearing to adhere to its widely proclaimed ethical principle, “Don’t be evil.”
To protest against censorship, the Silicon Valley-based company relocated from mainland China in 2009 to the still relatively free Hong Kong.
On the Hong Kong-based search engine, Chinese internauts could read about Taiwan, the Tiananmen Square massacre of 1989, or the Dalai Lama.
On Google.cn, these sources, along with the results of searches using many other forbidden terms, simply did not appear.
Google’s move seemed to reconcile its proclaimed libertarian philosophy with its business ethics.
But that reconciliation did not last long: Google, after all, had accepted censorship from the beginning of its efforts in China, in 2006, in order to gain entry into the Chinese market.
After six months of life in Hong Kong, money talked: Google reinstated its mainland China service, and with the same level of censorship as before.
In the end, Google, not the Chinese Communist Party, lost face.
Yahoo, Google, and Microsoft have thus followed a strikingly similar road: access to lucrative markets trumped ethical anxiety.
The tools that they provide are politically neutral.
Dissidents try to use them to pursue a democratic agenda.
Police use them to detect and repress dissidents.
Either way, Microsoft, Yahoo, and Google make money – just like, say, IBM, which in the 1930’s sold its computing machines to the Nazi regime: the Nazis used these machines to make the destruction of their victims routine and bureaucratic.
Should we be shocked that Internet companies put profits ahead of morals?
After all, they are ordinary, profit-seeking corporations, just like the IBM of Hitler’s era.
Internet companies may, more than most, hide their true motives behind ersatz, democratic-sounding slogans, but in the end they are advertising products like any other.
In advertising or self-promotion, the choice of words is determined by customer expectations, not by managers’ philosophy, as they mostly have none.
Capitalism is always a trade-off: we must live with unethical behavior by money-making corporations that provide us with useful new tools.
These tools can be used by Iranians fighting dictatorship, or by Tibetan dissidents trying to save their culture.
They also can be used to compute the number of exterminated Jews, to arrest a Chinese dissident, or to break a human-rights group in Russia.
Microsoft in Russia or Google in China teach us that capitalism is not ethical: it is only efficient.
Entrepreneurs are greedy by definition: if they were not, they would go bankrupt.
An open society will never be created or sustained by righteous entrepreneurs or be the mere byproduct of political engineering.
Liberty, as always, remains the endeavor of vigilant, free men and women.
Turkey’s Hot-Money Problem
NEW YORK – The ongoing financial volatility in emerging economies is fueling debate about whether the so-called “Fragile Five” – Brazil, India, Indonesia, South Africa, and Turkey – should be viewed as victims of advanced countries’ monetary policies or victims of their own excessive integration into global financial markets.
To answer that question requires examining their different policy responses to monetary expansion – and the different levels of risk that these responses have created.
Although all of the Fragile Five – identified based on their twin fiscal and current-account deficits, which make them particularly vulnerable to capital-flow volatility – have adopted some macroprudential measures since the global financial crisis, the mix of such policies, and their outcomes, has varied substantially.
Whereas Brazil, India, and Indonesia have responded to surging inflows with new capital-account regulations, South Africa and Turkey have allowed capital to flow freely across their borders.
Consider Turkey’s response, which has been characterized by an unwavering commitment to capital-account openness.
Though political developments in Turkey have been attracting the most attention lately, the country’s current crisis is rooted in economic weaknesses, reflected in declining investor confidence and the sharp depreciation of the lira’s exchange rate.
This instability has raised fears of emerging-market contagion, with South Africa especially susceptible, owing to its capital-account openness.
In lieu of capital-flow restrictions, Turkey’s monetary authorities began to cut overnight borrowing rates in November 2010, in order to reduce the profitability of the carry trade (purchases of foreign-currency assets to take advantage of a higher interest rate).
The hope was that longer-term capital flows would finance the widening current-account deficit, which exceeded 8% of GDP at the time, mitigating the risk of a sudden stop in external financing.
While many market observers applauded Turkey’s central bank for its bold, unorthodox policy mix, the International Monetary Fund criticized the Turkish authorities for increasing inflation expectations and fueling further credit growth.
But the IMF did not explicitly recommend that Turkey employ capital-account regulations, despite the mounting evidence from its own staff that the introduction of such rules was working in many emerging markets’ favor.
Without capital-account management, Turkey’s central bank expected to achieve financial and price stability by complementing the reduction in overnight rates with domestic macroprudential tools aimed at reducing excessive credit growth.
The main measures to control credit growth were a gradual increase in reserve requirements, beginning in 2010; some restrictions on consumer loans; and the introduction of credit-growth caps in the second half of 2011.
Officials argued that such tools are more effective than capital-flow measures, which “are, in general, hard to implement and rather easy to circumvent.”
But domestic prudential measures could have only a limited effect on the rate of credit growth, because the growth was driven primarily by booming capital inflows.
Thus, domestic credit growth began to decelerate only in August 2011, when the escalation of the eurozone crisis made global investors more wary of risky emerging markets.
Paradoxically, while Turkey’s monetary authorities acknowledged this relationship, they continued to attribute the decline in credit growth to the success of their prudential measures.
Then, last May, the US Federal Reserve announced its intention to begin to “taper” its multi-trillion-dollar asset-purchase program – so-called “quantitative easing” – triggering large-scale capital flight from emerging markets.
There was no denying it: the emerging-market capital explosion was over, and the credit and asset bubbles that it had fueled were in danger of imploding.
By contrast, Brazil and India did not shy away from reimposing capital-account restrictions.
Both economies are now far less fragile than Turkey and South Africa.
Given this, perhaps the real question is why Turkey refrained from using capital-account regulations, when almost all of its emerging-market counterparts were using them in some form.
Was the financial sector too powerful for its policymakers?
Were its central bankers too committed to the IMF’s previous view that inflation-targeting can work only under conditions of capital-account convertibility?
Or was it because politicians benefited from the economic boost that inflows of short-term “hot money” provide, and thus were willing to ignore the consequences?
If there is a lesson to be learned from Turkey’s monetary-policy experiment, it is that domestic prudential regulations and monetary-policy tools should be viewed as complements to – not substitutes for – capital-account management.
As for Turkey, its only hope to avoid an even deeper economic crisis is to take determined action to mitigate the economic risks that have been allowed to accrue over the last few years.
Given the political instability that the country is currently facing, however, such an outcome is uncertain, at best.
The Price of Biodiversity
DHAKA – We humans do not only share the planet with a range of other species, including plants, animals, and even microbes; we also depend on them for our survival.
Can we determine the economic value of protecting the natural world?
Some people will balk at the idea of putting a price tag on biodiversity, viewing its protection as an obvious imperative.
But they would undoubtedly also agree that preventing human death and suffering, while providing food, water, and an education to all, is vital.
The reality is that there are simply not enough resources to do everything.
Hard choices have to be made.
Fortunately, economics can help us determine how to do the most good with the resources we have.
This is particularly relevant today, as the world's 193 national governments work to establish the Sustainable Development Goals to guide global development efforts for the next 15 years.
The SDGs will be modeled on the Millennium Development Goals, which were agreed in 2000 and focused on objectives like lowering maternal and infant mortality, eradicating poverty, and improving access to primary education.
So far, a huge number of potential SDG targets have been proposed, some of which relate to biodiversity.
But, though trillions of dollars will be spent on the SDGs, there are simply not enough resources to complete every project.
That is why world leaders must focus on the targets that will have the greatest impact.
My think tank, the Copenhagen Consensus, is working with more than 60 top economists and several Nobel laureates to identify which targets promise the highest return on investment.
Preserving biodiversity, it turns out, is not only desirable; according to three new studies by the economists Anil Markandya, Luke Brander, and Alistair McVittie, it also makes good financial sense, at least for some projects.
Protecting forests is a good place to start, with every dollar spent bringing benefits worth about $10.
Some of the resources that forests provide – such as timber, firewood, and tourism – can be valuated relatively easily.
But the value of others – such as the wide range of animal species they support and their intrinsic worth to people – is more difficult to quantify.
In attempting to do so, economists have conducted surveys to find out how much people would be prepared to pay to protect forests and the animal species they support.
Forests also serve as an enormous “carbon sink," storing atmospheric carbon dioxide for many decades or centuries; thus, protecting forests would help to mitigate climate change.
Moreover, forests absorb intense rainfall, thereby reducing the risk of flooding.
The 2010 flooding in Pakistan, for example, would have been far less devastating if so many trees from upper slopes had not been felled.
The conclusion is thus that each dollar spent on conserving forests would yield $5-15 worth of social good, including tangible benefits, such as from logging or carbon capture, and “soft" gains, like preserving forests' intrinsic beauty.
Conserving the world's wetlands – which also provide valuable services, including protection of coastal areas and river valleys from flooding – is also sensible, providing a tenfold return on each dollar spent.
But protecting coral reefs would bring the highest returns, amounting to an extraordinary $24 worth of benefits for every dollar spent.
Like forests, coral reefs provide multiple services – including tourism and fish nurseries, which help to sustain commercial fishing – and have an intrinsic value to people.
To reduce the loss of coral reefs by half would cost about $3 billion each year – and yield at least $72 billion in benefits.
Not all projects aimed at protecting biodiversity are a smart use of public resources.
Creating additional nature reserves, for example, might sound like a great way to protect more species' natural habitats, but the economic benefits would not cover the nearly $1 trillion in costs.
Doubling the area of protected coastal land and bringing substantial areas of open ocean into reserves is a particularly formidable task.
Clearly, protecting coral reefs is a much better use of limited resources.
Though the SDGs will aim largely to improve daily life for the very poor, a cool-headed economic assessment suggests that there are also smart biodiversity targets that should be considered.
If world leaders take advantage of cost-benefit analysis to separate the wheat from the chaff, the next 15 years could be a boon for global development – including the preservation of biodiversity.
Pangan di Era Biofuel
ROMA – Dalam beberapa tahun terakhir, biofuel (bahan bakar nabati) telah menjadi pokok perdebatan.
Bagi sejumlah pihak, sumber energi terbarukan yang dihasilkan dari bahan organik ibaratnya sama dengan tongkat sihir dalam perjuangan melawan perubahan iklim.
Namun yang lainnya memandang biofuel sebagai ancaman terhadap keberlangsungan hidup, sebab tanaman yang digunakan untuk menghasilkan biofuel harus bersaing dengan lahan pertanian dan air yang sebaliknya dapat dimanfaatkan untuk memproduksi pangan.
Akan tetapi ini merupakan dikotomi yang salah.
Pilihannya bukanlah antara pangan atau bahan bakar.
Kita dapat memanfaatkan keduanya.
Jika diterapkan dengan baik, biofuel dapat menjadi sarana yang efektif untuk meningkatkan keamanan pangan melalui penyediaan sumber energi berkelanjutan dan terjangkau bagi petani miskin.
Di beberapa negara-negara land-locked di Afrika, harga bensin mencapai tiga kali lipat dibandingkan rata-rata harga global, sehingga harga bahan bakar merupakan salah satu hambatan utama menuju pertumbuhan pertanian.  Perluasan penggunaan biofuel di kawasan ini dapat mendorong produktivitas dan menciptakan kesempatan kerja baru, khususnya di wilayah pedesaan.
Dampak ini bisa diperluas jika tambahan permintaan akan bahan baku untuk biofuel dapat dipenuhi oleh petani keluarga dan produsen skala kecil.
Biofuel menjadi kemutlakan dan penggunaan biofuel akan terus meningkat.
Pada tahun 2013, biofuel menyumbang 3% dari total bahan bakar alat transportasi yang digunakan di seluruh dunia, berdasarkan laporanFood and Agricultural Organization (FAO) dan OECD.
Meskipun angka ini dinilai akan tetap stabil, kita dapat memperkirakan bahwa produksi biofuel akan meningkat sesuai nilai absolut seiring dengan perluasan pasar global untuk bahan bakar alat transportasi.
Sesungguhnya produksi biofuel global diperkirakan akan berlipat ganda di tahun 2013 dibandingkan dengan tingkat produksi tahun 2007.
Jika prediksi ini terbukti, maka biofuel akan menghabiskan 12% bijian-bijian kasar, 28% tebu, dan 14% minyak sayur.
Seiring dengan meningkatnya produksi jenis bahan bakar nabati ini, kita memerlukan kebijakan, program, dan kapasitas yang dapat menjamin penggunaan berkelanjutan, sehingga tidak mengacaukan pasar pangan atau membahayakan keamanan pangan, dimana kedua hal ini harus selalu menjadi prioritas pertama.
Para pemrakarsa biofuel barangkali akan terkejut melihat rendahnya kontribusi biofuel terhadap keseluruhan pasokan bahan bakar dunia.
Mesin pertama buatan Rudolf Diesel, dirancang pada akhir tahun 1800an, digerakkan oleh bahan bakar yang dihasilkan oleh minyak kacang.
Henry Ford pernah menjelajahi seluruh Florida berharap bisa membeli beberapa bidang tanah untuk menanam tebu, meyakini bahwa Amerika Serikat tidak akan mentolerir polusi yang diakibatkan pembakaran bahan bakar fosil atau ketergantungan yang tidak terlihat (implicit dependency) terkait dengan impor minyak untuk memperoleh bensin.
Daya tarik biofuel baru kembali pulih dalam beberapa dekade terakhir dikarenakan upaya-upaya menjamin produksi energi yang lebih terjangkau, menghasilkan pendapatan, dan mengurangi ketergantungan seperti yang dulu diperingatkan oleh Henry Ford.
Akhir-akhir ini, kekhawatiran akan polusi, perubahan iklim, dan keterbatasan bahan bakar fosil menimbulkan lonjakan permintaan – suatu kondisi yang harus dikendalikan.
Fleksibilitas adalah kunci upaya-upaya menaikkan tingginya kepercayaan bahwa biofuel dapat mendongkrak produktivitas pertanian, mempercepat pembangunaan di pedesaan, dan menaikkan keamanan pangan.
Sebagai contoh, pembuat kebijakan harus meredakan tekanan kompetitif antara pangan dan bahan bakar dengan merumuskan rencana untuk mengatasi ketidakstabilan harga pangan.
Lembaga berwenang dapat mewajibkan agar persentase biofuel yang dicampur bahan bakar fosil dinaikkan jika harga pangan turun dan diturunkan jika harga pangan melonjak.
Kebijakan ini akan menjadi semacam stabilisator otomatis.
Permintaan akan produk-produk pertanian yang ditujukan kepada petani-petani miskin akan tetap solid meskipun harga pangan merosot, dan konsumen pun akan terlindungi dari lonjakan harga yang ekstrim.
Target nasional pun dapat dirancang agar lebih fleksibel.
Jika arahan penggunaan biofuel diterapkan selama beberapa tahun, bukan hanya satu tahun, maka pembuat kebijakan dapat mempengaruhi permintaan untuk meminimalisasi tekanan pada harga pangan.
Pada akhirnya, di tingkat individual, fleksibilitas lebih besar dapat diperkenalkan di SPBU melalui penggunaan kendaraan bahan bakar fleksibel seperti yang digunakan di Brasil.
Jika kendaraan dilengkapi dengan mesin yang dapat digerakkan oleh bahan bakar fosil atau dicampur dengan biofuel pada jumlah tinggi, maka konsumen dapat beradaptasi dengan perubahan harga dengan beralih jenis bahan bakar.
Tidak mudah untuk mencapai keseimbangan ini.
Akan tetapi jika kita mengumpulkan pengetahuan bersama, melibatkan petani kecil di negara-negara berkembang dalam upaya ini, serta menjaga fokus kita pada pengentasan kemiskinan dan perlindungan terhadap kaum rentan, kita bisa memiliki lebih banyak bahan bakar, lebih banyak pangan, dan kemakmuran yang lebih luas bagi seluruh penduduk dunia.
Biomedicine’s Democratic Revolution
SEATTLE – Very soon, it will be economically feasible to sequence human genomes and collect massive amounts of different types of health data as standard medical practice.
Already, there are remarkable examples of how these new genetic data are changing our thinking about disease and diagnosis.
Consider the Beery twins, born in 1996 in San Diego, California.
They suffered from chronic vomiting, seizures, and muscle weakness, sending them and their parents on an odyssey of medical examinations and tests.
The first diagnosis was cerebral palsy.
Then they received a diagnosis of dystonia, a rare neurological disorder.
But treatments based on these diagnoses did not alleviate the children’s symptoms.
Frustrated, their parents had the twins’ genomes sequenced.
The results revealed that the twins had been incompletely diagnosed.
Their previously diagnosed dystonia was being caused by a genetic mutation that was interfering with the neurotransmitter serotonin.
The twins’ doctors found that the dystonia could be fully treated with a readily available serotonin replacement.
So why haven’t success stories like that of the Beery twins, together with the Internet’s power and increasingly affordable collection of molecular data, led to the construction of a knowledge network of disease?
Why aren’t scientists and doctors turning in droves to data-intensive science in order to build better “disease maps”?
One possible answer is that there are still technical barriers that block the construction and use of such networks.
With our ability to generate ever-rising oceans of molecular data – now approaching the zetabyte scale (that’s a one followed by 21 zeros) – comes the challenge of storing and deciphering this information.
But scientists and software engineers regularly face such daunting challenges, and, with DNA serving as the reference language of modern biomedical research, the technical barriers to constructing disease networks will be short-lived.
Cultural barriers are the real stumbling block.
As humans, we are highly evolved to adjust to our surroundings: we tend to adapt to a culture, well-conceived or not, and lose sight of its failings.
But when we glimpse an alternative, our culture’s inadequacies (and even insanities) are immediately apparent, which may prompt a cultural shift, collective action, and change.
The fall of the Berlin Wall in November 1989 and, more recently, the Arab Spring are clear examples of this dynamic.
Similarly, the example of the Beery twins shows us that an alternative to symptom-based medicine can be realized: the advent of genomics technology can change not just what is known, but, more importantly, how we think of ourselves.
But, in order to build the disease networks of tomorrow, we will need to move beyond the current linear approaches to science and to how scientists work.
We all like a good story that unfolds in a straightforward way, but the story of disease plays out across a poly-nodal information network, similar to what an air traffic controller might track in the skies above a major airport.
Biomedical researchers’ “lock and key” and linear-pathway representations are incomplete, and should be supplemented with disease maps that can now be built using molecular data.
We must also build the infrastructure and cultivate the relationships needed to share disease maps with basic researchers, practicing doctors, drug developers, and even the public at large.
And that could prove to be even more difficult, because the current closed nature of the medical-information system and its self-directed incentive structure block such sharing.
Patents, trademarks, and competition for resources (people, money, and accolades) seal off information and prevent molecular data from being analyzed and shared.
Rewards in biomedical research go to “solo workers,” and do nothing to acknowledge the work that can be done only by multi-functional groups.
Despite these imposing obstacles to progress, there are reasons to believe that a cultural shift is afoot: researchers from geographically distant labs are forming non-traditional “federations” to combine their data sets, work on them collaboratively, and post the results for other scientists to analyze.
Crowd-sourced competitions like DREAM Challenges and FoldIt show that important scientific findings can emerge from outside of universities and pharmaceutical companies.
And public-private partnerships between drug developers, basic researchers, and patient groups that share information pre-competitively (that is, with no or limited patent filings) are an increasingly popular way to translate scientific findings into potentially meaningful clinical benefits.
But a few successful federations, competitions, and partnerships may not be enough to transform biomedical research.
Disruptive change may be required, and here each of us can make a profound difference.
Patient groups are already organized; their members can report their symptoms online and self-enroll in clinical trials.
We can already obtain portions of our own genetic information and use it to make informed medical decisions, join existing patient groups, or create new ones.
We can provide our genetic samples to data-driven trials to learn about our likelihood to respond to particular therapies.
We can even organize to self-fund future studies or join only those studies that give us the legal right to say how and where our data are used.
In other words, patients can and should stop being the passive “sick” and actively engage to pressure clinicians, researchers, and drug developers to adapt or perish.
Democratized medicine represents the fullest flowering of the biomedical information revolution.
There are few worthier goals than a future in which citizen-patients are active participants in managing their own health.
Revolution and Reaction in Biopharming
STANFORD – Obtaining medicines from plants is not new.
Aspirin was first isolated from the bark of the willow tree in the eighteenth century.
And many other common pharmaceuticals, including morphine, codeine, and the fiber supplement Metamucil, are purified from the world’s flora.
More recently, scientists have developed techniques that take this process a step further, using genetic engineering to induce agricultural crops to synthesize high-value pharmaceuticals.
Known as “biopharming,” the great promise of this technology emerged about 15 years ago, with clinical trials of vaccines and drugs produced in bananas, tomatoes, and tobacco.
Unfortunately, progress has since stalled, owing to the vehement risk-aversion of regulators.
One early example of biopharming was the production by the biotech company Ventria Bioscience of rice that contained two human proteins, lactoferrin and lysozyme.
Once grown and harvested, the rice kernel is processed to extract and purify the proteins for use in oral rehydration solution for treating diarrhea, which is surpassed only by respiratory diseases as the leading infectious killer of children under the age of five in developing countries.
The proteins have the same structure and functional properties as those found in natural breast milk, and the process for extracting them is analogous to that used routinely for the production of therapeutic proteins from organisms like bacteria and yeast.
Research in Peru showed that fortifying an oral-rehydration solution with the proteins extracted from Ventria’s rice substantially lessens the duration of diarrhea and reduces the rate of recurrence – a near-miraculous advance for people in the developing world.
But regulators can undo miracles, and they regularly do.
When Ventria approached the US Food and Drug Administration in 2010 for recognition that these proteins are “generally recognized as safe” (a regulatory term of art), it received no response.
Without an endorsement by the FDA, the company was unwilling to market the product, and so it remains unavailable, tragically depriving children in developing countries of a life-saving therapy.
Even field testing biopharmed plants has proved problematic.
In 2003, the US Department of Agriculture announced onerous new rules for testing crops engineered to produce pharmaceuticals.
The ostensible objective of the regulation is to avoid contaminating food supplies with drugs, especially when edible crops are used to produce them.
But the food industry’s worries that biopharmed plants could contaminate their products are overblown.
And in any case, the risk can be mitigated in several ways, most obviously by using non-food plants like tobacco.
In fact, even if biopharmed plants were to contaminate food crops, the likelihood that consumers would end up with harmful amounts of prescription drugs in their corn flakes, pasta, or tofu is very small.
Gene flow is an age-old process that is well understood by farmers, who grow hundreds of crops, virtually all of which have been genetically improved in some way with a variety of techniques.
As a result, they have developed meticulous strategies for preventing pollen cross-contamination in the field – when and if it is necessary for commercial reasons.
Even if some crops were to become contaminated, the chances that active drug substances would be present in the final food product at sufficient levels to have an adverse effect on human health would remain very small.
The biopharmed plant would be pooled into a large harvest, where its pharmaceuticals would be heavily diluted.
The active agent would then need to survive milling and other processing, and then cooking, and it would need to be orally active, which protein drugs most often are not, because they are digested in the stomach.
The chance of all of this occurring is not zero, of course.
But, with a combination of factors – including natural selection, farmers’ pursuit of their commercial self-interest, and liability concerns – militating against such a possibility, the odds are very long, and the impact would almost certainly be very low.
When you weigh this against the possibility of the development of the drug industry’s Next Big Thing or, at the very least, a new method to produce high-value compounds at low cost, regulators’ preoccupation with such unlikely events appears to be misplaced.
Biopharming has much to offer us.
If we are to reap what we can sow, however, we will need reasonable, science-based policies from regulators worldwide.
Sadly, to borrow a phrase from the late Nobel laureate economist Milton Friedman, that is like wishing that our cats could bark.
The Power to Develop
CANBERRA – Trade-offs are an inherent part of life. We all recognize this from our private budgets.
To fix the roof, we may have to accept a less extravagant summer vacation.
When we pick a cheaper wine, we can splurge on dessert.
Trade-offs also pervade environmental policy: Cutting more of one pollutant, for example, leaves fewer resources to address other issues.
For example, coal is phenomenally polluting, but it also provides for cheap and reliable power, which drives development.
Over the past 30 years, China has lifted 680 million people out of poverty, mostly through the use of coal.
The average Chinese has become more than 13 times richer.
At the same time, Beijing and numerous other Chinese metropolises are experiencing debilitating smog, reminiscent of London in the 1950’s.
About 1.2 million Chinese die prematurely each year because of outdoor air pollution.
Measurements from Beijing show that upwards of 16% of the air pollution comes from coal.
The World Bank estimates that China’s total annual air-pollution costs – based on what Chinese themselves indicate they are willing to pay to reduce their risk of dying – could be as high as 4% of GDP.
And yet the Chinese trade-off has been phenomenally beneficial.
In 1982, the average Chinese earned $585 a year; last year, she earned $7,958.
Meanwhile, the annual per capita environmental cost is $318.
So, not surprisingly, most other developing countries would gratefully seize the opportunity to replicate China’s growth pattern – including its pollution.
Of course, the Chinese could do more to cut air pollution.
It is estimated that meeting the World Health Organization’s interim standards could reduce damages by $80 per capita.
But that pales in comparison to the $600 increase in per capita income in 2013.
Nonetheless, many who live in rich countries confidently declare that this trade-off is not in the interest of the poor.
The United States, the United Kingdom, and other European countries announced this year that they will not support international finance for coal-fired power plants in developing countries.
These countries abstained in 2010 when the World Bank helped finance South Africa’s Medupi coal-fired power plant.
Today, they would vote it down.
But Medupi will provide 10% of South Africa’s electricity and prevent rolling blackouts.
As the South African finance minister, Pravin Gordhan, explained, “to sustain the growth rates we need to create jobs, we have no choice but to build new generating capacity – relying on what, for now, remains our most abundant and affordable energy source: coal.”
The US government even acknowledged that, without a coal-fired power plant, South Africa’s “economic recovery will suffer, adversely impacting electrification, job creation, and social indicators.”
Energy poverty is even more acute for the three billion people – almost half of the world’s population – who burn dung, cardboard, and twigs indoors to cook and keep warm.
The WHO estimates that while outdoor air pollution in developing-country cities may be ten times higher than in advanced-country cities, average indoor air pollution, caused by burning wood and dung, is a hundred times higher.
Indeed, indoor air pollution kills 3.5 million people each year, making it the world’s deadliest environmental problem.
The world’s three billion energy-poor people need cheap electricity to cook and keep warm.
And, for the foreseeable future, that electricity will be generated by fossil fuels.
Some environmental campaigners argue for cleaner stoves.
But, while this might be part of the solution, it is essentially telling the poor to live with slightly less polluting open fires in their homes.
Moreover, studies indicate that even significant air-pollution reduction starting at high levels will have only a minor impact.
Others claim that renewables are the way to go.
Green energy, especially wind, can indeed help African countries, for example, get some electricity to remote, rural areas; but the grid will do the most good for the most people.
According to a recent World Bank study, distributed renewable energy “will be the lowest cost option for a minority of households in Africa, even when likely cost reductions over the next 20 years are considered.”
Popular solar lights cost almost $2 per kWh.
Using hydro, gas, and oil, the grid cost for the main population centers in Ethiopia, Ghana, and Kenya will likely be $0.16-25 per kWh.
In South Africa, where coal powers 90% of electricity, the cost is just $0.09 per kWh.
True, electricity from coal will cause extra air pollution.
But pollution from indoor air pollution, which would disappear with electrification, accounts for 16% of outdoor air pollution.
Even assuming (unrealistically) that coal produces all of the world’s air pollution, we could generate 250 kWh/year with coal for every one of the three billion energy-poor people and still end up with lower air pollution.
Moreover, it is easy and fairly cheap to cut coal pollution 90% or more with scrubbers.
For many opponents of coal, the issue is global warming.
According to Christiana Figueres, the United Nations climate chief, coal-fueled development has “an unacceptably high cost to human and environmental health.”
She argues that we need to close 75% of the planet’s coal-fired power plants, including all of South Africa’s, because they emit too much CO2.
Al Gore’s climate adviser, James Hansen, argues that if we allow developing countries to “come up to the level of the developed world, then the planet is done for.”
Yes, the world needs to address global warming (mainly through higher investments in green research and development, and by promoting exploitation of cheap, less-polluting shale gas).
But global warming will cause damage worth possibly 1-5% of GDP by the end of the century, when the UN expects developing-world incomes to have risen by 1,400-1,800%.
Meanwhile, poverty is killing millions right now, with an impact on global GDP that is likely an order of magnitude higher.
And too many people, however well-intentioned, are unwilling to acknowledge the tradeoffs needed to improve poor people’s lives.
The Realism of Global Optimism
PRAGUE – Read a newspaper or watch the evening news, and the world always seems to be getting worse.
One problem after another is put under a spotlight.
The more death, destruction, and despair, the better.
As one Danish journalism textbook puts it: “A good story is usually bad news.”
Only occasionally do we get uplifting, things-are-getting-better stories.
When we do, they feel like a guilty pleasure.
As a result, we often think that the world is in worse shape than it is – even if we think our own lives are improving.
Consider this: Since 1978, American consumers have been asked whether their current financial situation is better or worse than it was a year earlier.
Over the past 25 years, an average of 38% have said they are doing better, while 32% have said they are doing worse.
But, when asked the same question about the overall US economy, an average of 47% have said it is doing worse, compared to 38% who think it is doing better.
More people think their lives are improving, while others are doing worse, probably because of journalists’ persistent bias in favor of bad news.
The phenomenon is not limited to the United States.
Since 1977, Gallup International has asked people around the world whether they believe their lives will be better next year than they were the year before.
For 2014, almost 50% of those surveyed said that their lives will be better, with just 20% saying they will be worse off.
Yet, asked for their opinion of how the world economy will fare, the score is almost even, with 32% believing that it will be better, and 30% that it will be worse.
So it is worth stepping back and recognizing that many indicators point to a world that is improving.
New data from the World Bank show that the proportion of extremely poor people has more than halved over the last 30 years, from 42% of the global population in 1981 to 17% in 2010.
While 1.2 billion people in the developing world still live on less than $1.25 per day – a problem that we certainly must address – the rate of extreme poverty has never been lower.
Economists estimate that in 1820, more than 80% of all people were extremely poor.
Similarly, consider the amazing improvements in education.
Illiteracy today still afflicts 20% of the world’s population, but that is down sharply from an estimated 70% in 1900.
In the prosperous West, rapid increases in literacy were achieved early in the twentieth century.
In developing countries, similarly large (and continuing) gains were made from 1970 to 2000, with China recording the biggest improvement.
The costs of poor education are substantial.
For example, Pakistan and South Korea started with about the same level of education and income in 1950.
Today, the average South Korean has 12 years of education, whereas the average Pakistani has fewer than six.
South Korea’s per capita income grew 23-fold over this period, compared to Pakistan’s three-fold growth.
Together with the Copenhagen Consensus, economists have attempted to assess the cost of illiteracy.
We estimate that if there had been no illiteracy in 1900, the world would have been $240 billion richer (in inflation-adjusted terms), equivalent to about 12% of global GDP at the time.
So, the global illiteracy problem in 1900 can be said to have cost the world 12% of GDP.
Today, the cost of global illiteracy is down to 7% of GDP.
By 2050, when illiteracy will reach about 12%, the cost will have dwindled to just 3.8% of GDP.
Likewise, war carries a high economic and human cost.
But, while the images of it that we see are more immediate and vivid than ever, our perception of ubiquitous conflict is wrong.
In the twentieth century, conflict killed 140 million people, including 78-90 million in the two world wars.
The good news, which is not often publicized (precisely because it is good), is that scenarios in which military spending is higher, the same, or lower in the future suggest that the high military costs of the twentieth century have been turned into what looks like a permanent peace dividend.
World War I cost about 20% of global GDP, and WWII cost almost twice as much.
When examining the cost of conflict, the Copenhagen Consensus economists estimate the actual costs of global military expenditure.
There are still plenty of problems in the world, as the news media point out every day.
And we do need to focus on eliminating poverty, stamping out illiteracy, and promoting peace.
But we also need to remember that the world is a better place overall than we think.
The Davos Apocalypse
FORT LAUDERDALE – At the World Economic Forum’s annual meeting in Davos last month, leading participants called for a rapid shift to cleaner energy to tackle climate change.