Al-Qaeda lost the sanctuaries from which it planned its attacks; many of its leaders were killed or captured; and its central communications were severely disrupted.
Then the Bush administration succumbed to hubris and made the colossal mistake of invading Iraq without broad international support.
Iraq provided the symbols, civilian casualties, and recruiting ground that the jihadi extremists had sought in Afghanistan.
Iraq was George Bush’s gift to Osama bin Laden.
Al-Qaeda lost its central organizational capacity, but it became a symbol and focal point around which like-minded imitators could rally.
With the help of the Internet, its symbols and training materials became easily available around the world.
Whether al-Qaeda had a direct role in the Madrid and London bombings, or the recent plot to blow up airliners over the Atlantic, is less important than the way it has been transformed into a powerful “brand.”
The second round went to the extremists.
The outcome of future rounds in the struggle against jihadi terrorism will depend on our ability to avoid the trap of “jujitsu politics.”
That will require more use of the soft power of attraction rather than relying so heavily on hard military power, as the Bush administration has done.
For the struggle is not a clash of Islam vs. the West, but a civil war within Islam between a minority of terrorists and a larger mainstream of non-violent believers.
Jihadi extremism cannot be defeated unless the mainstream wins.
Military force, intelligence, and international police cooperation needs to be used against hardcore terrorists affiliated with or inspired by al-Qaeda, but soft power is essential to attracting the mainstream and drying up support for the extremists.
US Secretary of Defense Donald Rumsfeld once said that the measure of success in this war is whether the number of terrorists we are killing and deterring is larger than the number that the terrorists are recruiting.
By this standard, we are doing badly.
In November 2003, the official number of terrorist insurgents in Iraq was given as 5,000.
This year, it was reported to be 20,000.
As Brig. General Robert Caslen, the Pentagon’s deputy director for the war on terrorism, put it, “We are not killing them faster than they are being created.”
We are also failing in the application of soft power.
According to Caslen, “We in the Pentagon are behind our adversaries in the use of communication – either to recruit or train.”
The manner in which we use military power also affects Rumsfeld’s ratio.
In the aftermath of 9/11, there was a good deal of sympathy and understanding around the world for America’s military response against the Taliban.
The US invasion of Iraq, a country that was not connected to the 9/11 attacks, squandered that good will, and the attractiveness of the US in Muslim countries like Indonesia plummeted from 75% approval in 2000 to half that level today.
Indeed, occupying a divided nation is messy, and it is bound to produce episodes like Abu Ghraib and Haditha, which undercut America’s attractiveness not just in Iraq, but around the world.
The ability to combine hard and soft power is smart power.
When the Soviet Union invaded Hungary and Czechoslovakia during the Cold War, it undercut the soft power that it had enjoyed in Europe in the aftermath of World War II.
When Israel launched a lengthy bombing campaign in Lebanon last month, it created so many civilian casualties that the early criticisms of Hezbollah by Egypt, Jordan, and Saudi Arabia became untenable in Arab politics.
When terrorist excesses killed innocent Muslim civilians such as Egyptian Islamic Jihad did in 1993 or Abu Musab al-Zarqawi did in Amman in 2005, they undercut their own soft power and lost support.
The most important lesson five years after 9/11 is that failure to combine hard and soft power effectively in the struggle against jihadi terrorism will lead us into the trap set by those who want a clash of civilizations.
Muslims, including Islamists, have a diversity of views, so we need to be wary of strategies that help our enemies by uniting disparate forces behind one banner.
We have a just cause and many potential allies, but our failure to combine hard and soft power into a smart strategy could be fatal.
The Middle East’s Lost Decade
BERLIN – The United States has waged three wars since Al Qaeda’s terrorist attacks on September 11, 2001: against Al Qaeda, in Afghanistan, and in Iraq.
The first two were forced upon the US, but the third was the result of a willful, deliberate decision by former President George W. Bush, taken on ideological grounds and, most likely, for personal reasons as well.
Had Bush, former Vice President Dick Cheney, former Secretary of Defense Donald Rumsfeld, and their neocon allies been forthright about their intentions – to bring down Saddam Hussein by means of war, thereby creating a new, pro-Western Middle East – they never would have received the support of Congress and the American public.
Their vision was both naive and reckless.
So a threat – Iraqi weapons of mass destruction – had to be created.
As we now know, the threat was based on lies (aluminum tubes for a nuclear-weapons program, for example, meetings between the 9/11 plot leader, Mohamed Atta, and Iraqi officials in Prague, and even glaring forgeries like supposed Iraqi orders for yellowcake uranium from Niger).
Such were the justifications for a war that was to claim the lives of almost 5,000 US soldiers and more than 100,000 Iraqis.
Add to that the millions more who were injured and displaced from their homes, as well as the destruction of one of the world’s oldest Christian communities.
For this, the US alone spent up to $3 trillion.
Bush’s war against Saddam did radically change the Middle East, though not as he envisaged.
For starters, if the US had set out to destabilize Iraq, its efforts could hardly have been more successful: ten years later, the country’s viability as a single state has never been in greater doubt.
With Saddam gone, Iraq’s Shia majority assumed power after a horrendous civil war, leaving Iraq’s defeated Sunnis longing for revenge and waiting for an opportunity to regain their ascendancy.
The Kurds in the north cleverly and adeptly used the window of opportunity that opened before them to seize de facto independence, though the key question of control over the northern city of Kirkuk remains a ticking time bomb.
And all are fighting for as large a share of Iraq’s enormous oil and gas reserves as they can get.
Taking stock of “Operation Iraqi Freedom” a decade later, the Financial Times concluded that the US won the war, Iran won the peace, and Turkey won the contracts.
I can only agree.
In political terms, Iran is the big winner of Bush’s war.
Its number-one enemy, Saddam, was dispatched by its number-two enemy, the United States, which presented Iran with a golden opportunity to extend its influence beyond its western border for the first time since 1746.
Bush’s war, with its poor strategic vision and worse planning, increased Iran’s regional standing in a way that the country was unlikely ever to have achieved on its own.
The war enabled Iran to assert itself as the dominant power in the Gulf and the wider region, and its nuclear program serves precisely these ambitions.
The losers in the region are also clear: Saudi Arabia and the other Gulf states, which feel existentially threatened, and have come to regard their own Shia minorities as an Iranian fifth column.
They have a point: with the Shia in power in Iraq, Iran will seek suitable opportunities to use local Shia populations as proxies to assert its hegemonic claims.
This is what is fueling Bahrain’s domestic turmoil, beyond the Shia majority’s local grievances.
Leaving aside the lies, fictions, and questions of morality and personal responsibility, the critical mistake of America’s war against Iraq was the absence of either a viable plan or the necessary strength to enforce a Pax Americana in the Middle East.
America was powerful enough to destabilize the existing regional order, but not powerful enough to establish a new one.
The US neocons, with their wishful thinking, grossly underestimated the scale of the task at hand – unlike the revolutionaries in Iran, who quickly moved in to reap what the US had sowed.
The Iraq war also marked the beginning of America’s subsequent relative decline.
Bush squandered a large part of America’s military strength in Mesopotamia for an ideological fiction – strength that is sorely missed in the region ten years later.
And there is no alternative to be seen without America.
While there is no causal link between the Iraq war and the Arab revolutions that began in December 2010, their implications have combined in a malign manner.
Since the war, the bitter enmities between Al Qaeda and other Salafist and Sunni Arab nationalist groups have given way to cooperation or even mergers.
This, too, is a result brought about by the American neocon masterminds.
And the regional destabilization triggered by the Arab revolutions is increasingly converging on Iraq, mainly via Syria and Iran.
Indeed, the gravest current danger to the region is a process of national disintegration emanating from the Syrian civil war, which is threatening to spread not only to Iraq, but also to Lebanon and Jordan.
What makes Syria’s civil war so dangerous is that the players on the ground are no longer its driving forces.
Rather, the war has become a struggle for regional dominance between Iran on one side and Saudi Arabia, Qatar, and Turkey on the other.
As a result, the Middle East is at risk of becoming the Balkans of the twenty-first century – a decline into regional chaos that began with, and was largely the result of, the US-led invasion ten years ago.
Winning the Confidence Game
NEW HAVEN – On April 2, the G-20 will hold a summit in London to discuss what we may hope will be an internationally coordinated plan to address the world economic crisis.
But can such a plan really work?
The basic problem, of course, is confidence.
People everywhere, consumers and investors alike, are canceling spending plans, because the world economy seems very risky right now. The same thing happened during the Great Depression of the 1930’s.
A contemporary observer, Winthrop Case, explained it all in 1938: economic revival depended “on the willingness of individual and corporate buyers to make purchases that necessarily tie up their resources for a considerable length of time.
For the individual, this implies confidence in the job, and in the end comes equally back to the confidence of industry leaders.”
Unfortunately, confidence did not return until World War II ended the depression.
If the leaders meeting in London are to succeed where governments failed in the 1930’s, they must commit themselves to a fiscal target that is sufficient to restore full employment under normal credit conditions.
They must also commit themselves to a credit target that will restore lending to normal.
People will not spend normally unless they have both a job and normal access to credit.
During the Great Depression, such targets were not used on a large enough scale, merely fueling public despair that stimulus policies would ever work.
The G-20 Summit should also be an occasion for affirming some basic principles.
Confidence isn’t built up on the basis of spending or lending alone.
People need to believe that the money represents something more lasting than stimulus measures, which may eventually end in failure.
After all, the Great Depression did not end simply because of the massive stimulus of war-related expenditures.
Why should World War II have produced any confidence in the future?
To be sure, World War II reduced the unemployment rate in the United States dramatically, from 15% in 1940 to 1% in 1944, and had a similar effect in other countries.
But this was not because of a revival in business confidence.
It was because of a nasty war, plain and simple, with people drafted into fighting, or into industries supplying the war effort.
The real recovery of confidence did not occur until after World War II, when the world did not sink back into depression.
The US Council of Economic Advisors warned of this possibility in 1949, and it was not alone.
There appears to be more than one reason why, on the contrary, confidence came roaring back.
First, there was a general perception of “pent-up demand.”
After years of privation (and in many countries the physical destruction of war), people just wanted to live normally – to rebuild, own a home, a car, and other consumer goods.
The widespread impression that there was such pent-up demand also led people to believe that there could not be another depression.
The perception of pent-up demand was like a powerful economic stimulus package, and it had the advantage that people believed it would be long-lasting.
Indeed, the same long-term confidence triggered the post-war “baby boom.”
According to some contemporary observers, however, “pent-up demand” was only part of the story.
During the brief but deep recession of 1949, the financial commentator Silvia Porter reflected on the attitudes that led to the 1929 crash: “We saw nothing wrong – in fact, we saw everything right – with the wild speculative boom and credit inflation that…culminated in the now almost unbelievable gambling orgy of 1929.”
But now, Porter wrote, after the depression and war, “We began to listen to the idea that a hundred million citizens, acting through a central government, could achieve much more than a hundred million acting as separate selfish units.
We developed, in short, a new attitude toward the responsibilities of government.”
She concluded that the positive effect of “pent-up demand” and government measures can “make sense only when viewed against the background of our changed economic and political philosophy.”
The Marshall Plan, which operated from 1947 to 1951, became a symbol of this new attitude.
The US gave billions of dollars of aid to rebuild war-ravaged countries in Europe.
The plan was widely viewed as reflecting a new kind of enlightenment, a recognition of the importance of supporting people who needed help.
Europe would not be allowed to languish, and the stimulus came from abroad.
After the war, Keynesian economic theory, which was generally not accepted or understood during the Great Depression, became the basis of a new social compact. It was a theory that was perfectly suited to a generation that had just endured exceptional sacrifices, for it reaffirmed a belief in our responsibility for each other.
The effect of economic stimulus is redoubled by this kind of inspirational belief.
That is why all of the commitments made and intentions expressed at the upcoming G-20 summit matter.
The countries represented must show a generous spirit and make the world economy work for all people.
Seemingly peripheral issues, like aid to the developing world and the poor, who suffer the most from a crisis like this one, will be part of the primary story of the renewal of confidence, just as the Marshall Plan was part of that story after World War II.
Winning the European Confidence Game
CHICAGO – If any solution to the European crisis proposed over the next few days is to restore confidence to the sovereign-bond markets, it will have to be both economically viable and politically palatable to rescuers and rescued alike.
This means paying attention not just to the plan’s technical details, but also to appearances.
There is growing consensus about any solution’s key elements.
First, Italy and Spain will have to come up with credible medium-term plans that will not just restore their fiscal health, but also improve their ability to grow their way out of trouble.
While any plan will involve pain for citizens, the markets must deem the pain politically tolerable, at least relative to the alternatives.
It is important that these plans be seen as domestically devised (though voters will have no illusions about the external and market pressures that have forced their governments to act).
At the same time, an external agency such as the International Monetary Fund could render the plan more credible by evaluating it for consistency with the country’s goals and monitoring its implementation.
Second, some vehicle – the IMF or the European Financial Stability Facility, with either entity funded directly by countries or the European Central Bank – has to stand ready to fund borrowing by Italy, Spain, and any other potentially distressed countries over the next year or two.
But there is an important caveat, which has largely been ignored in public discussions: if this funding is senior to private debt (as IMF funding typically is), it will be harder for these countries to regain access to markets.
After all, the more a country borrows in the short term from official sources, the further back in line it pushes private creditors.
That makes private lenders susceptible to larger haircuts if the country eventually defaults – and thus more hesitant to lend in the first place.
In other words, private markets need to be convinced both that there is a low probability of default (hence the importance of credible plans), and that there is some additional loss-bearing capacity in the new funding, so that, if there is a default, outstanding or rolled-over private debt does not have to bear the full brunt.
This may seem unfair.
Why should the taxpayer accept a loss when they are bailing out the private sector by providing new funding?
In an ideal world, distressed countries would default as soon as private markets stopped funding them, and they would impose the losses on private bondholders.
In the real world, however, if Italy and Spain are viewed as being solvent, or too big to fail, official funding should be structured so that it gives these countries their best chance to regain market confidence.
This does not mean that official funding should be junior to private debt in any restructuring, for that would require substantially more loss-bearing capacity from the official sector – capacity that is probably not available.
Indeed, if official funding were junior, it would be providing a larger cushion to private creditors – and thus bailing them out to an even greater extent.
The simplest solution is to treat official funding no differently from private debt – best achieved if official lenders buy sovereign bonds as they are issued (possibly at a predetermined yield) and agree to be treated on par with private creditors in a restructuring.
As the country regains market confidence, the official funding can be reduced, and eventually the bonds can be sold back to the markets.
The bottom line is that official funding must be accompanied by loss-bearing capacity.
If the funding is channeled through the IMF, and is to be treated on par with private debt, the Fund will need a guarantee from the EFSF or strong eurozone countries that it will be indemnified in any restructuring.
Of course, the IMF’s member states might be willing to accept some burden sharing if a sufficient buffer provided by the eurozone were eroded, but that cannot be taken for granted.
Once the first two elements of the plan are in place, there should be little need for the third – bond purchases by the ECB in the secondary market in order to narrow interest-rate spreads and provide further confidence.
Indeed, if the ECB intends to claim preferred-creditor status for any bonds that it buys, it is probably best that it buy very few.
Of course, the ECB will have to continue to provide support to banks until confidence about their holdings returns.
But there is one more element that is needed to assure markets that the solution is politically viable.
Citizens across Europe, whether in rescued countries or rescuing countries, will be paying for years to clean up a mess for which they were not responsible.
Not all banks voluntarily loaded up on distressed government bonds – some were pressured by supervisors, others by governments – but many have made unwise bets.
If they are seen as profiting unduly from the rescue, even as they return to their bad old ways of paying for non-performance, they will undermine political support for the rescue – and perhaps even for capitalism.
Across an arc extending from Afghanistan to East Africa, violence now also surges in Iraq, Lebanon, Somalia, and beyond, to Sudan’s Darfur region.
Everywhere, politicians, generals, and even diplomats talk of military strategies and maneuvers, but everywhere something utterly different is needed.
Stability will come only when economic opportunities exist, when a bulging generation of young men can find jobs and support families, rather than seeking their fortune in violence.
We are seeing again and again that a foreign army, whether NATO’s in Afghanistan, America’s in Iraq, Israel’s in occupied Palestine, or Ethiopia’s in Somalia, may win a battle, or even a war, but never the peace.
Peace is about dignity and hope for the future.
Military occupation saps dignity, and grinding poverty and economic disarray sap hope.
Peace can be achieved only with a withdrawal of foreign troops, and the arrival of jobs, productive farms and factories, tourism, health care, and schools.
Without these, military victory and occupation quickly turn to ashes.
The United States government has proven itself blind to these facts, but the international community also remains ill equipped to assist in the restoration of peace following conflicts in impoverished countries.
Repeatedly, a fragile peace has broken down because of the lack of economic follow-up.
Despite grand promises of foreign aid, economic reconstruction, and development in Afghanistan, Iraq, Lebanon, and elsewhere, the actual record of international assistance to post-war reconstruction is gravely deficient.
The scenario has become painfully familiar. A war ends.
An international donors’ conference is called. Pledges of billions of dollars are announced.
A smiling new head of state graciously thanks the international community, including the occupying power.
Months pass. World Bank teams from Washington start to arrive.
But actual reconstruction and recovery is delayed, perhaps for years.
Crony businesses from the US and Europe, which are utterly unfamiliar with local conditions, squander time, aid funds, and opportunities.
Two or three years pass.
The grand pronouncements become a pile of out-of-date World Bank studies.
Recriminations fly, the occupying army remains, and a new insurgency spreads.
Many factors contribute to this disarray, beginning with the shocking inability of the US, Europe, and the international organizations to understand things from the perspective of poor and displaced people.
Their lack of empathy is deplorable, but there are conceptual problems as well.
The international agencies involved in post-conflict reconstruction have so far failed to understand how to start or restart economic development in a low-income setting.
It’s important to distinguish four distinct phases of outside help to end a conflict.
In the first phase, during the war itself, aid is for humanitarian relief, focusing on food, water, emergency medicine, and refugee camps.
In the second phase, at the war’s end, aid remains mainly humanitarian relief, but now directed towards displaced people returning home, and to decommissioned soldiers.
In the third phase, lasting three to five years, aid supports the first phase of post-war economic development, including restoration of schools, clinics, farms, factories, and ports.
In the fourth phase, which can last a generation or more, assistance is directed to long-term investments and the strengthening of institutions such as courts.
The international community, and the US in particular, is dreadful at the third stage.
Once a conflict is over, aid agencies seem paralyzed.
Instead of sending help, they send study groups.
There is often a lag of years before moving from humanitarian relief to real economic development.
By the time such help actually arrives, it is often too late: war has been re-ignited.
In fact, it is possible to restart economic development through targeted “quick-impact” initiatives.
Since the economies of most impoverished post-conflict countries are based on agriculture, restarting farm output is vital.
Impoverished farmers should receive a free package of seeds, fertilizers, and low-cost equipment (such as pumps for irrigation).
When such aid is made available quickly, former soldiers will return to their farms, and can establish a livelihood by the beginning of the first growing season following the end of hostilities.
This type of aid does not require long studies, but quick action.
Similar quick-impact measures should be undertaken to control disease.
Small rural clinics can be built or rebuilt very quickly, within the first year of peace.
Solar panels and wind turbines can provide off-grid power in isolated rural areas.
Wells and cisterns can be put in place to ensure safe drinking water.
These and similar efforts can mean the difference between famine and food security, epidemic disease and health, income and utter poverty, and, most importantly, hope and despair.
Yet the window of opportunity closes quickly.
Quick-impact economic development is exactly what is needed now to help end the horrific violence and suffering in Darfur.
Sanctions, threats, and peacekeepers are only short-term measures, whereas real progress there against extreme poverty is not only achievable, but also is something that the government and rebels can agree on.
The same applies in Somalia.
But the window of opportunity closes quickly in these and other post-conflict regions.
Only by taking quick, meaningful action to fight hunger, poverty, and disease can there be a chance of creating conditions for long-term peace.
Winning the Transition
WASHINGTON, DC – Is the Arab Spring turning into a gloomy autumn?
With brutal crackdowns in Syria, a bloody civil war in Libya, and Yemen teetering on the brink of chaos, the number of skeptics is growing.
Although Egypt and Tunisia’s pro-democracy movements achieved rapid regime change, uncertainties remain in those countries, too.
After a brief period of hope, many observers now wonder whether the region is capable of producing viable, and economically vibrant, democracies.
Revolutions and their aftermaths, of course, are always fluid and fickle times, and the outcome is often perched on a knife’s edge.
Bridging the vast gap between high expectations and the reality of limited budgets and capabilities is a test in itself.
Redressing past injustice and building an economy that offers opportunity to all are major challenges as well, fraught with volatility, uncertainty, and the dangers of political opportunism.
But transitions are also times of great opportunity.
In the 1990’s, I was among those Indonesians who demanded and celebrated the departure of our own autocrat, Suharto, and I joined the new government when he left.
Many observers predicted that Indonesia, the world’s most populous Muslim country, would be unable to sustain democracy and would ultimately decline into chaos.
The task ahead of us was daunting.
But we proved the skeptics wrong, and learned some fundamental lessons.
Perhaps most importantly, we learned that there is no one-size-fits-all solution for democratization.
Each of the countries of the Middle East and North Africa will face unique challenges, which will have to be addressed on their own terms.
Even so, they all must make a real and symbolic break with the past.
The new authorities must send strong signals that the old ways are finished.
Change must be formally manifested, with new laws that are widely publicized.
Legislation that empowers citizens with freedom of expression, free and independent elections, and freedom of association is crucial, and it must be made clear to the public that no one is above the law. Anything less will undermine the transition.
Moreover, corruption is the bane of development everywhere, so new governments should move fast to establish institutions and procedures to fight it.
Transparency and accountability are powerful ideas with near-universal support, which means that new leaders should not give up when the fight becomes difficult.
Civil-society organizations, local communities, representatives of the poor and vulnerable, and women play a vital role in this regard, and they should be included at every level of decision-making.
In Indonesia, we signed a hundred laws in less than 18 months, covering everything from media freedom to elections, corruption, decentralization, and anti-trust rules.
We ratified new public-finance legislation and ensured the independence of the country’s central bank.
New leaders must also expect and manage setbacks.
In post-revolutionary times, expectations are high, and the obstacles to meeting them are enormous.
I know from personal experience that we did not always have the luxury of getting the best outcomes.
We had to compromise and settle for the best possible results.
Security threats are among the most serious setbacks in transitions.
Nationalistic sentiment is strong, and politicians and interest groups can exploit it.
Often, the security forces are holdovers from the old regime, and there is no independent judicial system.
Reforms will take time, and the old bureaucracies may not be able to implement them.
In Indonesia, we used various innovations to work around such dilemmas.
For example, we appointed an independent judge to take over the bankruptcy and corruption courts, because career judges were too tainted.
Likewise, when we started cash-for-work programs as part of our pro-poor agenda, we asked communities to run these initiatives.
More broadly, new leaders are well advised to ensure that the economy performs well.
It is important to restore economic activity and create a favorable environment for entrepreneurs, particularly small and medium-size businesses, which constitute the main engine of job creation.
The recent revolutions, it should be recalled, started with the self-immolation of a Tunisian fruit vendor, who was harassed and insulted by the authorities.
But economic success without accountability and social inclusion is not sustainable, and new governments often must face tough choices in order to protect the poor and vulnerable.
They might have to abolish mis-targeted subsidies to free up resources for more targeted and efficient anti-poverty and job-creation programs.
In Indonesia, we had to draw a line between the very poor and the near-poor.
We could not afford to raise salaries or provide subsidies for everybody.
Our help had to be targeted.
So, while we helped the neediest, we excluded others who were not poor enough to benefit.
This was a tough and unpopular choice.
Finally, countries in transition need support – not only money, but also technical know-how to implement highly complex reforms.
When I became Indonesia’s finance minister, I had 64,000 employees.
But when we had to modernize our tax system, we could not find the required expertise anywhere in our country.
Yes, we needed external assistance, but we never surrendered “ownership” of the reform process; we made it work for us.
If we Indonesians had not been in charge of our own transition, it could easily have failed.
That lesson, too, is one that all countries in transition should bear in mind.
Winning with Opium in Afghanistan
Despite considerable effort by the international community in Afghanistan since 2001 to eliminate the Taliban and al Qaeda, the insurgency in the south of the country has gathered momentum at breakneck speed in recent months.
Our field research shows that we are not winning the campaign for the hearts and minds of the Afghan people – the Taliban are.
Indeed, the international community’s methods of fighting the insurgency and eradicating poppy crops have actually helped the insurgents gain power.
The international community has so far pursued policies of destruction, rather than the promised reconstruction.
The aggressive United States-led counter-narcotics policy of crop eradication has failed to win the support of Afghans, because it has triggered a chain reaction of poverty and violence in which poor farmers, with their only livelihood destroyed, are unable to feed their families.
This has been exacerbated by the failure to provide even the most basic aid and development in the country’s poorest areas.
At the same time, communities have been torn apart as a result of bombing campaigns, which have destroyed the very homes we came to protect.
This, in addition to four years of drought, has forced entire families to leave their villages for makeshift internal refugee camps.
You do not win people over by bombing them, but by helping them.
The Taliban have exploited the failures of the international community in extremely effective anti-Western propaganda that has fueled significant doubt in the minds of the public concerning the reasons justifying the international presence in Afghanistan.
Sadly, our troops are often the first to pay the price – sometimes with their lives.
It is not too late to win back the hearts and minds of the Afghan people.
International troops are excelling in an exceptionally hostile environment, but this is not a war that will be won by military means alone.
With public perception a crucial factor in winning the war, and the Taliban poised to launch a large military initiative next spring, failure to adopt a successful local strategy could signify the last chance the international community will have to build a secure and stable Afghanistan.
But a successful strategy – one that responds to Afghanistan’s extreme poverty crisis –requires that the international community reverse course on crop eradication.
In fact, the eradication of poppy crops not only damage local communities and undermines the international community’s goals, but it is also failing: opium production last year was at an all-time high.
In September, the United Nations Office on Drugs Crime announced that poppy cultivation soared by a record-high 60%.
Eradication will never be successful in Afghanistan, because it destroys the single crop that will grow in the south’s harsh climate – and thus serves as the main source of income to millions of people.
So a new, long-term, economically sustainable solution is urgently needed – one that directly engages with the communities that are suffering most – in order to achieve the support of the deeply impoverished rural population.
As a way to address this dilemma, the Senlis Council is proposing to run scientific pilot projects to research an opium licensing system for Afghanistan, which would be a core component of the economic reconstruction process.
A system in which poppy is cultivated under license for the production of pain-killing medicines such as morphine and codeine would allow farmers to pursue their traditional livelihood and way of life, and, more importantly, to feed themselves and their families.
There is a global shortage of morphine and codeine, particularly in underdeveloped countries, where these vital medicines are often in short supply, if not completely unavailable.
Not only would poppy licensing address the poverty and hunger crises that have engulfed the south of Afghanistan; it also would stabilize existing local structures, giving communities a reason to support President Hamid Karzai’s government and the international community.
Farmers would gain a sense of ownership in counter-narcotics efforts, in sharp contrast to the current idealistic – and evidently un-achievable – policy of crop eradication.
We must have the backing of the Afghan people if we are to defeat the Taliban.
By endorsing such an initiative, the international community would demonstrate that it is in Afghanistan for the good of the local population, which would help farmers sever ties with the insurgency.
But for such a system to be successful, the extreme poverty in the south of the country must first be our top priority.
According to the World Food Program, 70% of the population lack food security.
An immediate injection of emergency food and medical aid is urgently needed to break the vicious circle of suffering and violence.
Only then could a new, long-term development strategy in Afghanistan – one that admits that the international community is not winning the war, and that the status quo is unacceptable – be implemented.
Licensing the opium crop would be a realistic and pragmatic cornerstone of that strategy’s success.
The Western Alliance in the Digital Age
MUNICH – This weekend, Helmut Schmidt and Henry Kissinger will participate in a discussion at the Munich Security Conference (MSC) – just as they did a half-century ago, when they took part in the first “Internationale Wehrkunde-Begegnung” (the forerunner of today’s conference).
In the meantime, many developments around the world have given us reason to rejoice – but also to reflect.
It is not only the crises extending from Ukraine to Syria that will prevent the MSC, the fiftieth, from becoming an exercise in self-celebration.
The transatlantic partnership, traditionally the backbone of the conference, has seen better days than these.
The United States has now at least recognized that a great deal of trust has been lost in recent months, owing to the scale of surveillance undertaken by its National Security Agency.
President Barack Obama’s speech about reforms of US intelligence-gathering activities, as well as his subsequent interview on German television, represented a first attempt to regain the confidence of America’s allies.
But it signals, at most, the beginning of an intensive transatlantic dialogue on the issue.
The topic is too broad to be discussed solely among governments and secret services.
What we need is a more comprehensive international debate that engages, say, the American and German publics, as well as the US Congress and the German Bundestag – in short, an intra-Western debate about our relationship in the digital age.
In 1963, when Ewald von Kleist invited participants to Munich for the first conference, which Americans fondly call the “Wehrkunde” to this day, the motivating idea was to invite our most important allies to a discussion about the major strategic issues directly affecting Germany and NATO.
The main topic, at that time, was the Atlantic Alliance’s nuclear strategy.
After all, Germany would have been the first victim of a nuclear confrontation between NATO and the Warsaw Pact countries.
Kleist wanted to contribute to the creation of a German “strategic community,” which could make its own contributions to the NATO debate, rather than just absorbing whatever their technologically superior US ally proposed.
In a way, we are in a similar situation today.
Though the security implications of the digital age are less tangible and not as destructive as a nuclear attack, the technological possibilities fundamentally alter the playing field of international relations.
The revelations concerning the NSA’s surveillance activities are just the start.
A future of “thinking drones” and defensive and offensive cyber weapons raises new ethical, legal, and political questions.
We Europeans need to be self-critical and admit that we are not only lagging behind in terms of technical capabilities; we are also in danger of not fully grasping in time the possibilities and dangers of the digital world.
And of course, we will hardly be able to engage in meaningful negotiations with the Americans on cyber issues unless we succeed in establishing a united stance within the European Union.
Doing so would put us in far better position to negotiate on equal terms with the US, just as we can on trade issues.
In the past, the Western allies’ participation in NATO and its Nuclear Planning Group accommodated their concerns and prevented them from becoming mere objects of US strategy.
Today, we need similar initiatives with regard to the digital world.
Those hoping to achieve true cooperation must be willing to make their own contributions.
This year’s MSC will include not only security officials from many countries.
Three dozen German MPs and a significant US Congressional delegation will also participate.
That is why the conference is an excellent opportunity to step up the transatlantic debate.
After all, let’s be honest: there will be real changes in US intelligence agencies’ behavior only if Congress regulates their activities more strictly.
The revelations and resulting debates in recent months have shown that many US politicians are also uneasy about the liberties taken by the secret services.
However, without domestic pressure, little will change.
It is all the more important that societal stakeholders – companies, NGOs, or international commissions of experts – both here and in the US become more heavily involved than before.
This issue affects us all.
The debate is not – and should not be – between Europe and the US.
Some Americans are grateful for Edward J. Snowden’s revelations about the NSA, which they believe have stimulated urgently needed public deliberation.
The institutionally assured possibility of self-criticism is, arguably, the West’s best characteristic – its outstanding trait.
Our democracies are better organized than other systems to scrutinize their own policies and respond to criticism.
In the 1960’s, the West had to agree on a common strategy for the nuclear age, and learn to deal with the atomic threat.
Subsequently, we were able to take the first steps toward arms control and disarmament.
Today, we need a similar debate in the West regarding our strategy for the digital age if we want to overcome new challenges without denying our identity as liberal democracies.
This weekend in Munich, the Schmidts and Kissingers of today and tomorrow will have an opportunity to engage in what is probably the most important strategic debate of our time: how to prevent the West from falling apart in
Wolfowitz and the World Bank at Bay
Will World Bank President Paul Wolfowitz’s troubles finally catalyze real change at the World Bank?
Will there finally be an end to the archaic practice by which the President of the United States unilaterally appoints the head of the world’s most important development agency?
Facing an extraordinary rebuke from the Bank’s ministerial oversight committee and open revolt from his professional staff, Wolfowitz has faint hope of limping through the last three years of his term.
The immediate uproar is over the exceedingly generous pay and promotion package that Wolfowitz awarded in 2005 to his girlfriend as compensation for leaving the Bank to pave the way for his arrival.
At a time when the Bank has been emphasizing high governance standards as the key to development, the recent revelation of that arrangement’s details have dealt a serious blow to the Bank’s credibility.
But even if Wolfowitz is eventually forced to resign, nothing will be gained if US President George W. Bush is allowed summarily to choose his replacement, as US Presidents have been doing ever since the Bank was founded after World War II.
Instead, the Bank’s head should be chosen in an open and transparent process that aims to select the best-qualified candidate, whether from the US, Europe, or the developing world.
Indeed, a big part of Wolfowitz’s weakness today is the way he came to his job, as an in-your-face appointment from a US administration weak at international cooperation.
The World Bank is a development finance institution.
But Wolfowitz’s background at the US State and Defense Departments gave him no real expertise or experience in either area.
Instead, his claim to fame was his role as architect of America’s failed war in Iraq.
By all accounts, Wolfowitz is brilliant, but it seems inconceivable that an open, transparent, and multilateral selection process would have chosen him to head the World Bank.
I reach this conclusion even though I am sympathetic to the Bush administration’s desire to catalyze change at the Bank.
I have long advocated shifting the Bank’s center of gravity from lending to outright grants, a policy that the Bush administration strongly endorses.
But choosing someone with no obvious background or experience in economic development was not the way to make progress on this front.
A more open selection process, indeed, would have zoomed in on the fact that Wolfowitz’s girlfriend worked at the Bank.
This may seem a trivial issue, but it is not, given the Bank’s strong policies to protect against nepotism.
If Wolfowitz were otherwise overwhelmingly the most qualified candidate, the selection committee may have found a way to finesse the issue, openly and transparently.
But, given his questionable fit for the job in the first place, the girlfriend issue might have been disqualifying.
Why does the world meekly go along with the status quo and let the US dictate the Bank’s top position?
It is a sorry tale of poor global governance.
Europe does not get in America’s way because it wants to maintain Europe’s equally out-dated privilege of appointing the head of the International Monetary Fund, the Bank’s sister institution.
Asia has little choice but to defer to the US and Europe’s shenanigans because it is grossly under-represented in both organizations.
As for Africa, its leaders are loath to do or say anything that might interrupt the flow of World Bank largesse.
Many people, including myself, have long complained about the leadership selection process at the World Bank and the IMF.
How can the Bank and the Fund continue to go around lecturing developing economies on good governance and transparency but fail to allow change in their own houses?
Now and again, both organizations pay lip service to the issue.
But so far, they have exhibited no real desire for change.
To be fair, the IMF’s leadership is making a determined effort to give dynamic emerging economies, particularly in Asia, a bigger say in Fund governance.
If carried far enough, this process would ultimately catalyze the necessary changes.
Unfortunately, the IMF’s rebalancing efforts are proceeding at a glacial pace.
At the World Bank, nothing seems to be happening at all.
Perhaps when Gordon Brown becomes the UK’s next prime minister, he will be able to convince the G7 group of rich countries to lead the charge for change.
As head of the Fund’s ministerial oversight committee, Brown understands the issues as well as anyone.
Or perhaps the Wolfowitz debacle will prove to be the catalyst.
Maybe at last, the next World Bank or IMF president will come from outside their usual domains.
There are plenty of great potential non-American candidates.
South African Finance Minister Trevor Manuel has ably served as head of the World Bank’s oversight committee and would make a brilliant World Bank president.
And it still could be a qualified American.
What about Bill Clinton?
One way or the other, the Bank and the IMF leadership selection process urgently needs to be revamped.
What the Wolfowitz debacle tells us most clearly is that the time for patience with the status quo is over.
Women and Development
COPENHAGEN – A girl born in South Asia or sub-Saharan Africa faces a cruel double burden.
She will grow up in a region beset by poverty, disease, war or famine.
She will also confront these challenges with the added disadvantage of being female.
Although more attention is being given to gender issues, inequality persists in every culture, country, and continent.
A new study for the Copenhagen Consensus project shows that eliminating this disparity is an investment with high payoffs.
Despite global interest in education for all, many girls in poor countries continue to be denied basic education; right from the start, they are disadvantaged.
Three in five illiterate children in the world are girls.
Particularly in South Asia and sub-Saharan Africa, cultural norms and economic hardships stop parents from sending their daughters to school or from keeping them in school for as long as they enroll their sons.
This unequal investment is neither equitable nor efficient.
An obvious solution is to build more schools in places where girls and boys must be educated separately.
In poor Muslim countries like Pakistan, Yemen, and Morocco, single-sex schooling is the norm, but many rural areas can afford only one public school, which is usually set aside for boys.
In theory, about half of the education gap in these areas could be closed by building girls’ schools.
Elsewhere, supply constraints are not the problem.
Instead, policymakers must find ways to strengthen the incentives for parents to send their daughters to school.
In countries where the family’s cost of schooling girls is lowered either by a no-fee policy or by a stipend for girls who enroll in school, girls’ enrollment rate increases.
The experiences of these few countries lead us to propose a system whereby mothers are paid if their school-age daughters attend school regularly from the 3rd to the 9th grade. This would increase girls’ enrollment and also put money into women’s hands – important because studies show that money given to women is more likely to provide positive nutritional and health benefits for their children than money given to men.
It also provides the women with greater bargaining power in their own households. 
The annual cost per pupil would be $32.
Covering every eligible girl in sub-Saharan Africa and South Asia for a year would cost $6 billion.
Benefits from increased future wages and the reduction in health-care use would be between three and 26 times higher.
Pregnancy is one of the most vulnerable times for poor women; 99% of the 529,000 women who die annually from pregnancy-related complications live in developing countries.
Severe malnutrition and the absence of prenatal care during pregnancy put both mother and child at serious risk.
Spending $3.9 billion on family planning and maternal health initiatives, such as provision of emergency contraception in sub-Saharan Africa and South Asia, could avert 1.4 million infant deaths and 142,000 pregnancy-related deaths in women.
Making reproductive services available to women who cannot afford to pay their way can help prevent these deaths.
But such services must not shy away from promoting and providing modern contraceptive methods to avoid unwanted pregnancies.
Nearly 20% of women in developing countries report that they would like to stop having more children but are not using any form of contraception or family planning, possibly because reproductive services are not available.
For adolescent girls, early marriage or an unwanted pregnancy typically curtails schooling.
Delaying marriage and childbearing allows them to gain more education and perhaps more earning opportunities, as well as improved health, education, and labor market success for their future children – benefits worth ten times more than the cost of providing reproductive services.
Other tools, aside from schooling, can help women improve their income-earning ability.
Microfinance institutions, such as Bangladesh’s Grameen Bank, play a vital role in allowing self-employed women to build profitable businesses.
Small loans empower women by giving them more control over household assets and resources, more autonomy and decision-making power, and greater access to participation in public life.
Women are more likely than men to meet regular repayments and to spend their earnings on children’s health and education.
Policymakers should continue to facilitate the rollout of microfinance programs.
Studies show that each dollar loaned by a microfinance institution increases household expenditure by almost 10% in the first year, and that the benefits will continue for another 30 years.
Benefits are estimated to end up about six times higher than the costs.
Though women have the right to vote in almost every country, gender inequalities in political representation remain large.
Governments should consider gender quotas at the local level of politics.
Greater female representation may not necessarily lead to more emphasis on “female” policy priorities, but in India, village councils with gender quotas for village chiefs have higher levels of safe drinking water, better immunization coverage and roads, and less bribery.
There may be some losses from electing women because they tend to have less political experience than men, but the record in India suggests that if it took 20 years to establish a 30% share of women in local positions in other countries, the benefits would be at least double the costs of achieving this.
Being a woman need not and should not be among the greatest challenges of life.
Women for Integration
COPENHAGEN – The past decade has proven again and again that empowering women worldwide holds the key to solving many seemingly intractable issues that have otherwise stymied policymakers. Poverty in the developing world seemed ineradicable until micro-lenders saw millions of low-income, destitute women as potential entrepreneurs.
Involving African women in decision-making about crop production turns out to enable environmentally sustainable farming practices.
Runaway population growth becomes controllable when women have access to literacy and business opportunities as well as to contraception.
Could the tensions and conflicts surrounding the issue of immigration in Europe be yet another issue for which the empowerment of women holds a solution?
In a recent visit to Copenhagen to commemorate International Women’s Day, I took part in many conversations that duplicate others throughout Europe: citizens from across the political spectrum were struggling with the issue of non-European immigration and the cultural tensions that have ensued.
What does it mean to be Danish, German, or French in the presence of these millions of newcomers, most of whom come from non-democratic societies?
Some of this anxiety is pure racism; but some is not.
What would “integration” mean, and how is it achieved without the loss of cherished civil-society values?
These are not necessarily xenophobic questions: a post-enlightenment civil society, with a free press and due process, is a precious thing, and those values should not be sacrificed to politically correct moral relativism.
This issue has been given new urgency by the arrests in Ireland of alleged jihadists from several countries who are accused of plotting to murder a Swedish cartoonist who drew an image of the prophet Mohammed as a dog.
Across Europe, the discussions are growing more intense as anti-immigration platforms gain supporters in otherwise liberal countries, from Germany to France to traditionally inclusive and tolerant Denmark itself.
Then I witnessed the prototype of a true solution.
I met Elisabeth Møller Jensen, the director of KVINFO, “the Danish center for information on gender, equality and ethnicity” – an extraordinary organization funded by Denmark’s Ministry of Culture.
One of its many innovative programs is already showing results in terms of genuinely integrating immigrant families into Danish society.
By addressing immigrant women – and by viewing them as potential leaders, rather than as quiescent potential maids or service workers – KVINFO is enabling their families to witness the benefits of an open civil society in their own lives.
KVINFO began a “mentor network” aimed at immigrant and refugee women in 2002.
By 2010, it had 5,000 participants, had won awards and international acclaim for best integrative practices, and is being replicated throughout Denmark – and observers are exploring programs or partnerships modeled upon it in Canada, Spain, Portugal, and Norway.
The program pairs refugee and immigrant women in a one-to-one mentoring relationship with women who are established leaders at all levels of Danish society.
The pairing is not cursory.
A careful matchmaking process unites the interests and goals of the women on both sides, and already has paid amazing dividends.
Women who were journalists, engineers, or scientists in their countries of origin – and who could not get jobs as checkout cashiers in Denmark – have been paired with Danish counterparts and are now back in school, or working in research.
But even women who arrive with no higher education or professional skills create an “action plan.”
They learn from their mentors what options there are, how to proceed, and what to do to reach their objectives.
As they enter the workforce, their language skills improve, their household income soars, and their children see firsthand a woman in a respected, economically valued role.
Their loved ones thus learn how to thrive in a European context – occasionally coming to KVINFO events and benefiting from their mothers’ expanding network of contacts.
So, rather than feeling exploited and condemned indefinitely to the fringes of a Northern European society – and thus vulnerable to the stirrings of demagogues and extremists – these women’s children grow up fully familiar with Danish civil society, well informed about higher education and professional opportunities, and hopeful rather than cynical.
By empowering women, the whole family is lifted up and, in a supportive rather than a colonizing way, “Europeanized” in the best sense.
I am often struck by the way many Europeans use arms-length euphemisms when talking about immigrants: they want immigrants to feel “welcome” or “comfortable.” I always wonder, “But do you want them to feel French, or German, or Norwegian?”
To be fully integrated, Muslim and other newcomers to European countries must be welcomed not as perpetual visitors – even if, ideally, as nicely treated visitors – but rather as family members, as the American model does (or aspires to do).
As Møller Jensen put it, “I want these children to feel Danish .”
These young people and Denmark itself will benefit, as this “KVINFO generation” grows up with a genuine stake in Danish civil society, and seeing the world as Danes, not as guests.
Arab Women’s Unfinished Revolution
FEZ – Though women across the Middle East participated actively in the Arab Spring protests that began in late 2010, they remain second-class citizens, even where popular uprisings managed to topple autocratic regimes.
Indeed, the Islamist governments now in power in several countries seem more determined than the despots that they replaced to keep women out of politics.
In conducting interviews with women in the region, I am struck by their overall pessimism.
They fear the loss of their rights.
They see economic disintegration all around them, raising the possibility of a further increase in violence.
As social bonds fray, they feel increasingly vulnerable.
More than once, I heard them express the view that things were better before the revolutions.
Female representation in parliaments and government cabinets after the Arab Spring has been either absent or meager, and women activists worry that Islamist parties will implement reactionary policies that discriminate on the basis of gender.
In Egypt, for example, the Freedom and Justice Party, which dominates the parliament, claims that a woman cannot become President.
Egyptian women were heavily represented in the protests that brought down former President Hosni Mubarak’s regime in 2011, but they have been largely excluded from any official decision-making role ever since.
In Morocco, while there were eightwomen in the previous cabinet, today there is only one in the Islamist-led government.
In January, the Islamist-dominated parliament adopted a decree lowering the age of marriage for girls from 18 to 16, a major setback.
Moroccan feminists have protested vigorously, but to no avail.
Parliamentary representation for women has also taken a hit.
Women hold less than 1% of seats in the current Egyptian parliament; previously, they held 12%.
In Libya, a first draft of the electoral law reserved 10% of seats in the constituent assembly for women, but the quota was later abandoned.
In Tunisia, the election in 2011 brought 49 women into the 217-seat Constituent Assembly.
But 42 of these women are members of Ennahda, which regards Sharia (Islamic law) as the source of legislation.
Long-time Tunisian activists fear that Ennahda, which dominates the assembly, will use the presence of women MPs to restrict women’s rights.
The recent assassination of the secular Tunisian opposition leader Chokri Belaid has raised the stakes for women there.
Belaid was a voice on behalf of women’s rights, and the threat of increased political violence will focus on those who advocate secular equality for all Tunisians, including women.
Unfortunately, conservative forces in the Arab world repeatedly turn against women when political unrest spreads.
In Bahrain, several women protesters have been arrested and&#160;tortured.
In Yemen, the authorities call on male relatives to “tame” their women.
In Tunisia, the most Westernized of the Arab countries, women have been attacked at universities and schools, and are being forced to wear the hijab.
A woman who was allegedly raped by two policemen in September 2012 was charged with public indecency when she filed a complaint.
Likewise, in Egypt, women protesters face greater scrutiny than men.
Those arrested by the military during the anti-Mubarak protests were subjected to virginity tests as a form of intimidation.
Across the Middle East, Islamist militias have harassed, arrested, raped, and tortured women pro-democracy activists.
The model of Iran’s Islamic Revolution in 1979, which imposed second-class citizenship on women, is frequently cited as a threat in Arab countries now ruled by Islamist parties.
These countries are at a crossroads.
Women make up half of the Middle East’s population, and any hope of political and economic development must account for that fact.
Organizations like the United Nations Development Program have repeatedly issued reports demonstrating the connection between economic decline and oppression of women.
The hope for women’s progress is really a hope for a decent society in which development for all is possible.
Women on Top?
What will G-8 summit meetings be like when American President Hillary Clinton and French President Ségolène Royal join German Chancellor Angela Merkel in a formidable triangle of women’s power?
The scenario is not altogether unlikely.
Indeed, in the United States and France, there are even alternative female candidates for the presidency (Condoleezza Rice in America, Michelle Alliot-Marie in France).
Will this mean a new style of both domestic politics and international relations?
The answer is not obvious.
After all, some women have long had the strength and the will to make it to the top. Think of Indira Gandhi, Golda Meir, or Margaret Thatcher.
All three were powerful prime ministers of their countries, though perhaps not the epitome of what might be regarded as feminine values.
They all outdid men at their own game and had little time for what came to be called feminism.
Indeed, another trend may be more significant as far as political leadership is concerned.
When it comes to the formation of governments, women have managed to break out of the prison of their traditional domains, such as education and social affairs.
Foreign policy in particular has become a female aspiration.
Both the US and the European Union have women leading their foreign offices; so do half a dozen EU countries, including Britain.
Has this changed the style, indeed, the substance of foreign policy?
Undoubtedly, a shift in policy styles is occurring in many parts of the world.
In a word, it appears that the Reagan-Thatcher period is over.
While opponents of globalization still fight “neo-liberal” policies, political discourse has taken a new turn.
Words like “justice” are back in fashion; there is concern about globalization’s losers and the “underclass.”
Likewise, the leader of Britain’s Conservatives, David Cameron, startled more old-fashioned supporters of his party by saying that people released from prison “need, above all, love.”
When Prime Minister Tony Blair described the next election as a fistfight in which the “flyweight” Cameron would be carried out and the “heavyweight” Brown victorious after a short bout, he got much applause from his supporters in the House of Commons, but the remark went down badly with voters.
Somehow, people prefer “softer” values than were prevalent in the last two decades.
Yet it is not the leading women who above all represent these values.
Merkel may have been softened by having to preside over a grand coalition, but her original stance was more of the Reagan-Thatcher variety.
Yuliya Tymoshenko was clearly the most stouthearted among the leaders of Ukraine’s Orange Revolution, and no one has ever described Hillary Clinton as particularly “soft.”
On the contrary, her possible Republican opponent in 2009, Senator John McCain, while a war hero, is also a man who represents to many Americans the new soft values.
Merkel had a difficult time in the run-up to her recent party conference, because Jürgen Rüttgers, the minister-president of the largest German state, North-Rhine Westphalia, reminded the Christian Democrats of their historical support for strong social-welfare policies.
Only Royal may be said to represent softer lines against the hard-liner of the governing party, Nicolas Sarkozy.
So, have women at or near the top made no real difference to politics?
Whatever change they have brought has not been obvious.
In a sense, women’s advance is simply the normal consequence of the gradual move to effective equality of opportunity that began in the 1960’s.
It took decades to become real, and there are still countries that have a long way to go.
Despite Tymoshenko’s leading role in Ukraine, it would be surprising to see Russian President Vladimir Putin replaced by a woman, and, while there is a female vice-president in China, there is no sign of a woman becoming Japanese prime minister soon.
Even so, in many parts of the world, women have made considerable headway on the path to the top.
Not infrequently this has been helped by explicit policies.
David Cameron prides himself on a successful campaign to make 40% of all Conservative parliamentary candidates in Britain are women.