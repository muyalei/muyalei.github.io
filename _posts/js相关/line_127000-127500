Many will not return: skilled workers are six times more likely to stay away.
But now something remarkable is happening.
In some countries, the brain drain has reversed its flow.
The causes are fascinating, and there is reason to be optimistic that the vicious cycle can be broken, transforming the balance of hope and opportunity between developing and developed economies.
A new study by LinkedIn, the world’s largest online professional network and recruitment platform, has measured the net international movement of talent among its members.
Topping the list as a destination for talent is my own country, the United Arab Emirates, with a net talent gain of 1.3% of the workforce in 2013.
Other net “talent magnets” include Saudi Arabia, Nigeria, South Africa, India, and Brazil.
Most interesting, fewer than one-third of net talent importers are developed countries.
In fact, the top talent exporters in this study are Spain, the UK, France, the United States, Italy, and Ireland.
Rich countries that until recently had been tempting away our brightest minds are now sending us their own.
Of course, this is only one study, and many poor countries still suffer from a chronic talent exodus.
OECD data show that many countries in Africa and Latin America have migration rates for graduates above 50%.
We do know that brain drain is often a function of safety and security as much as economic opportunity.
Part of the tragedy playing out in Middle Eastern countries beset by conflict and instability is that if only their most talented sons and daughters could apply their skills at home, they would become part of the solution: agents of peace through development.
This makes it all the more important to examine how some developing countries succeeded in reversing the outward flow.
The basic ingredient is opportunity.
Talent flows naturally to countries that create an environment for economic growth; that make life easy for enterprise; that attract and welcome investment; and that nurture a culture of achievement.
Skills are attracted to challenge and possibility.
Opportunity on this scale is becoming a scarce commodity in many parts of the West.
But this is not the case in the developing world – at least among countries with the appetite and determination to deploy strong governance and continually raise their competitiveness.
Second, quality of life matters greatly.
A generation ago, many talented individuals would consider working outside the West a “hardship posting.”
Today, standards of living in the UAE, for example, are among the highest in the world.
We have shown that the business of reversing brain drain is also the business of creating a better life for citizens and residents.
Building happiness is, after all, the primary business of good government everywhere.
Ours is a story of great hope for the Middle East in particular, where generations of conflict and despair have driven high levels of outward migration.
I have always argued that, besides good governance, the best solutions to the divisions and strife of the Arab world lie in grassroots development and economic opportunity.
Now, we have shown that it is possible to reverse the forces that had driven away our most talented young people.
Another source of hope is that this turnaround can happen remarkably quickly.
Research shows that small countries suffer disproportionately from brain drain.
But we have shown that even for a small country like the UAE, and even in a region divided by conflict, it is worth building an island of opportunity.
But let me be clear: reversing brain drain is about more than plugging a leak.
It means turning a vicious cycle into a virtuous one.
By attracting the best talent from around the world, we can create a vibrant and diverse society that fuels innovation and prosperity – which in turn attracts still more talent.
To make this work, we must believe in people.
Human beings – their ideas, innovations, dreams, and connections – are the capital of the future.
In this sense, the “brain regain” is not so much an achievement in itself as it is a leading indicator of development, because where great minds go today, great things will happen tomorrow.
Africa’s Search for Law
LONDON – My career as a businessman in Africa has turned me into an activist for better, cleaner government and for the rule of law.
But promoting good governance is not just a matter of encouraging good leadership at the top (although I believe that definitely helps); it also requires all of us to be able to fulfill our responsibilities as citizens, and realize our rights.
In several African countries, there are impressive legal instruments in terms of independent court systems; but the challenge consists in impartial implementation.
Democratic accountability requires that citizens can use the law, as well as be subject to it.
For example, these countries have laws that prohibit seizures of land without due process and compensation for the owner; that bar public servants from accepting bribes; and that require government funds to be spent on the public good, not for private gain.
In the countries that currently do well on the Ibrahim Index of African Governance – Botswana, Ghana, South Africa, and others – citizens can use the law to protect themselves and their property from illicit encroachment, and to resolve their disputes in an impartial setting.
For those at the bottom – Somalia, the Democratic Republic of Congo, and the Central African Republic – the rule of law is a fiction that must be made real.
This work is already being carried out in places: in Sierra Leone, a country recovering from a brutal civil war, community-based paralegals are helping villagers to settle disputes peacefully; in Malawi, they are helping to reduce unnecessary imprisonment.
In Mozambique, local legal experts have helped villagers draw up proper titles to their communal lands, helping to secure their economic future.
In Kenya, community groups have used freedom-of-information laws to ensure that money earmarked for local school construction is properly disbursed.
This is the rule of law in action at the local level, and it is building, often from scratch, a culture in which disputes are settled peacefully and benefits distributed transparently.
The alternative – recourse to violence in the face of unequal access to resources – has led to a cycle of political instability in many countries, with the consequent lack of economic development that has come to characterize much of Africa’s recent history.
As the debate on the post-2015 Sustainable Development Goals unfolds at the United Nations this year, it is my fervent hope that African governments will endorse the inclusion within these goals of measurable targets for access to justice.
To be sure, the dominant themes that are emerging in the UN discussions – jobs, economic growth, infrastructure development, and poverty reduction – are all still desperately needed across the continent.
But the rule of law is a fundamental principle that does more than promote economic growth, and it would be a serious mistake not to include it in the SDG agenda.
Indeed, acknowledging that all must be equal in the eyes and practice of the law is a prerequisite for strengthening the social contract between the state and its citizens.
Without greater fidelity to the rule of law, too many African citizens will continue to see their futures blighted and their countries’ resources wasted.
If we are to build grassroots respect for the institutions and processes that constitute democracy, the state must treat its citizens as real citizens, rather than as subjects.
We cannot expect loyalty to an unjust regime.
The state and its elites must be subject, in theory and in practice, to the same laws that its poorest citizens are.
The BIS Bashers
PRAGUE – It might seem an unlikely proposition, but central banking has become exciting.
This is not necessarily a welcome development.
Decisions taken by the leading monetary authorities since the 2008-2009 global financial crisis have been unorthodox, creative, and at times risky.
Their high-stakes choices today will affect the global economy for decades to come.
Moreover, central bankers have become more vocal in expressing strongly held positions in the mass media, as if seeking to win over popular opinion.
It is a potent and dangerous mix.
In this environment, sober, informed voices, like that of the Bank for International Settlements, the central bank of central banks, should also be given a fair hearing.
Unfortunately, many central bankers have sought to marginalize the BIS rather than engage with it.
One of the most contentious debates has been over when to end the “unconventional” monetary-policy measures that were introduced in the aftermath of the financial crisis to ensure that banks continued to lend, thereby stimulating growth and averting deflation.
Some central bankers now worry that ending these measures prematurely will tip the economy back into recession.
Yet others fear that the current strategy, though originally intended to prevent an economic collapse, is now sowing the seeds of future instability, including the emergence of another asset-price bubble.
In their efforts to resolve such dilemmas, policymakers are also wrestling over whether to focus on traditional monetary tools such as interest rates, or make greater use of so-called “macro-prudential measures,” such as capital add-ons and buffers or adjustments to banks’ loan-to-value ratios.
At the heart of the debate – currently being conducted within leading economies’ treasuries and central banks, as well as in supranational bodies such as the International Monetary Fund and the BIS – is the relationship between monetary policy and financial stability.
The BIS, for example, has suggested that financial stability is closely connected with monetary policy, and has advised policymakers to start weaning their economies off of easy money sooner rather than later.
Central bankers, however, seem to want to try macro-prudential tools first (and sometimes exclusively).
It is unusual to witness a clash of views among monetary policymakers that is so radical and clear-cut that it has grabbed wider political and media attention.
And, under the public spotlight, some central bankers have sought to downplay the BIS’s assessment, arguing that it is all too easy to issue far-reaching policy recommendations when one suffers none of the consequences should one’s prescription turn out to be wrong.
To be sure, a country’s domestic economic circumstances, and the tools available to policymakers, should guide policy.
And, though monetary tightening may well be advisable in some economies, it might be inappropriate in others.
But the harsh reactions to the BIS’s analysis seem misplaced and unfair.
It is always difficult to find the right monetary-policy stance for any given economy at a given moment.
Central banks employ an army of experts to try to get it right, and other institutions are seldom so well resourced to present equally sophisticated counter-arguments.
The BIS, however, is one of the few organizations that not only has the necessary research and analytical capabilities, but also a track record of making good calls.
One should not forget – as many central bankers appear to have done – that the BIS was one of the first to warn of the dangers of financial excesses, several years before the 2008 crisis.
The BIS has a right to be heard.
It exists not just to represent central banks, but also to offer ideas and intellectual feedback.
Indeed, it serves policymakers well by challenging, debating, and perhaps swaying opinion.
Rather than bash the BIS, monetary authorities should be grateful for the informed perspectives that it provides.
Moldova Comes in From the Cold
CHISINAU – Today, “color revolutions,” which a few years ago were seen as promising developments in the post-Soviet space, seem to be out of fashion.
Around the world, disappointment with democracy promotion is widespread.
Instead, consolidation of authoritarian regimes appears to be the prevailing trend.
Roughly a year ago, Moldova, a country few know about, seemed to confirm this.
On April 7, 2009, Moldova made headlines when peaceful protests against unfair elections were hijacked by a small number of provocateurs who attacked the parliament building and presidential palace.
The media termed this the “Twitter Revolution,” which was of course an exaggeration.
Yet one year later, and despite the actions of those provocateurs, a new democratic government is in charge.
The parliament building is not yet rebuilt, but the government is trying hard to rebuild Moldova as a democratic country with legitimate aspirations to join the European Union.
The protests of April 2009 were triggered by the Communist Party’s claim to have won a third consecutive term in power, following an aggressive election campaign with widespread abuses.
The then Communist government cracked down on protesters, leaving at least one person dead, while numerous allegations of widespread torture further traumatized and divided Moldovan society.
Many in Moldova and Europe believed that another authoritarian state was emerging in the European neighborhood.
But the country’s democratic forces halted the Communist Party’s attempt to bulldoze its way back into power.
The Communists needed the vote of just one MP in order to perpetuate their domination of Moldovan politics for another term by electing their president in parliament.
They failed to get that vote, and early elections were called.
As a result, a four-party “Alliance for European Integration” came to power last September.
The Alliance is working hard to consolidate Moldova’s democracy, the rule of law, and economic reform, as well as to press ahead with European integration. But there is a difficult legacy to overcome.
The global economic crisis not only hit the country hard, but, because of irresponsible electioneering, the previous government did not even try to fight it. Reckless populist promises left a gaping 16%-of-GDP budget deficit.
Fortunately, we managed to avoid economic collapse, thanks to support from the International Monetary Fund, while reducing the deficit by half.
In late March, Moldova was also promised €1.9 billion by the European Union, the United States, the IMF, the World Bank, and other donors to support a strategy of reforms under the banner “Rethink Moldova.”
The media are now much freer.
After eight years of media monopolization, in the last month and a half two new TV channels have been launched.
Investigations against some of the police and judges responsible for the human rights abuses committed last April have been launched.
The government is taking quick steps to de-monopolize the economy and break the nexus between economic and political power that characterized the previous government.
We are also working to improve the business environment and investment climate by cutting red tape and simplifying the administrative burden on foreign investors.
Relations with the EU have gained significant momentum.
We are working on a new Association Agreement, which would anchor Moldova in the European space.
We will also sign a far-reaching free-trade agreement with the EU.
Such an agreement makes sense because more than 50% of Moldova’s trade is already with the EU, while roughly 70% of Moldova’s citizens and virtually all of its political parties support European integration.
What matters deeply for Moldova’s citizens, though, is to move towards a visa-free regime with the EU.
We are already working on implementing all the necessary technical conditions.
From January 1, 2011, we will switch to biometric passports.
Our customs officials and border guards are working actively with an EU mission to modernize our border infrastructure, and we are progressing fast in border demarcation with our only eastern neighbor, Ukraine.
Moldova will be an increasingly safe neighbor for the EU and a good partner in managing migration flows.
We have also re-launched settlement talks concerning the breakaway region of Transdniestria, where the only viable basis for a solution is to make Moldova ever more economically and politically attractive to the region’s residents.
From this perspective, every step that brings us closer to the EU is also a step towards resolving this so-called “frozen conflict” – perhaps the only European secessionist conflict that can be solved through EU soft power alone.
Moldova’s reemergence from authoritarian rule after eight years is the result of elections and parliamentary procedures.
This makes Moldova the only post-Soviet state (aside from the Baltic countries) with an uninterrupted cycle of transfers of power through elections since 1991.
In a sea of pessimism about democracy in the EU’s neighborhood, some winds are still blowing in the right direction.
Closing the Skills Gap
WASHINGTON, DC – In an age of skyrocketing unemployment, it may seem reasonable to assume that companies do not have to worry about finding workers.
But a recent McKinsey survey of more than 2,800 employers worldwide has underscored just how flawed that perception is.
Four out of ten employers said that they cannot find workers to fill entry-level positions in their firms, with more than one-third of respondents saying that their businesses are suffering from a lack of appropriate skills in the labor market.
Meanwhile, young people worldwide are struggling to find jobs.
While the eurozone crisis helps to explain why more than half of young people in Greece and Spain are unemployed, rapidly growing economies like South Africa and Nigeria are experiencing similar rates of youth joblessness.
In the Middle East and North Africa, one in three young people are unemployed.
And, in the United States, roughly half of bachelor’s degree-holders under the age of 25 were jobless or underemployed upon graduation last year.
All of this points to the costly skills mismatch at play in today’s economy.
In the US alone, the opportunity cost of failing to improve education would amount to $1.7 trillion by 2030.
Similarly, by bridging its growing skills gap, China could augment its GDP by $250 billion by 2020.
So why isn’t more being done to ensure that young people acquire the skills they need?
The problem is rooted in divergent perceptions among the various players in the labor market.
More than 70% of the educational institutions surveyed by McKinsey believe that their graduates are ready for the job market; more than half of employers and young people disagree.
Closing this gap requires that educators and employers work together more closely.
Employers should communicate their requirements to educators; educators need to give their graduates the tools that will enable them to meet these requirements.
The problem is missed connections, so the solution is to make more of them.
But such synchronization will not be easy to achieve.
One-third of employers never interact with education providers, while only 15% do so once a month or more.
Both sides would benefit from building strong reciprocal ties, with employers telling educators what they need (and even helping to design curricula and offering their employees as faculty) and educators providing students with practical experience and hands-on learning.
In fact, some promising initiatives are underway.
Many employers in the auto, tourism, advanced manufacturing, and shipbuilding industries have taken to “pre-hiring” young people – that is, guaranteeing them a job if they complete a rigorous training program.
A useful example is the cooperation between Brazil’s state-owned energy giant Petrobras and Prominp – a coalition of government agencies, businesses, trade associations, and labor unions – aimed at unleashing the full potential of the country’s oil and gas sector.
First, Petrobras and Prominp develop a five-year personnel projection in specific skill areas, such as shipyard welding, pipefitting, and petroleum engineering.
Prominp then identifies an education provider to co-develop an appropriate curriculum with selected companies and train 30,000 people annually.
Petrobras pays 90% of the costs, and the government covers the rest.
But such initiatives remain too few in number and too narrow in scope to resolve the global skills mismatch.
Moreover, developing effective programs requires far more data about young people’s journey from education to employment than is currently available.
Governments can play a critical role in collecting the data needed to determine which skills are in demand and what kind of training is effective.
For example, Colombia’s Labor Observatory tracks students’ progress – including where they attended university, what they studied, when and where they were first employed, what their starting salaries were, and whether they were promoted – for up to five years after graduation.
Prospective students can use this information to gain a far more accurate picture of their future prospects.
Of course, young people must become proactive if such schemes are to be effective.
Fewer than half of the young people that McKinsey surveyed claimed to have even basic knowledge of average wages or the prevalence of job opportunities in their chosen field.
Little wonder, then, that half of them were not convinced that their post-secondary studies had improved their employment opportunities.
Students must take ownership of their education.
Before enrolling in an academic or vocational program, prospective students should research job-placement rates and learn how and how often the institution interacts with employers.
Furthermore, they should gain a comprehensive understanding of how they can build and demonstrate applied skills in their chosen field.
More generally, they should use existing labor-market data to make better-informed choices.
If the world continues on its current course, labor-market imbalances will worsen significantly in the coming years.
Indeed, the world faces a potential shortage of 30-40 million college-educated workers in 2020, and a potential surplus of 95 million low-skilled workers.
The economic benefits of rebalancing the global labor market are compelling; the human costs of failing to do so are enormous.
The imperative for businesses, educators, governments, and young people to take action could not be stronger.
An Accidental Currency War?
LAGUNA BEACH – Six and a half years after the global financial crisis, central banks in emerging and developed economies alike are continuing to pursue unprecedentedly activist – and unpredictable – monetary policy.
How much road remains in this extraordinary journey?
In the last month alone, Australia, India, Mexico, and others have cut interest rates.
China has reduced reserve requirements on banks.
Denmark has taken its official deposit rate into negative territory.
Even the most stability-obsessed countries have made unexpected moves.
Beyond cutting interest rates, Switzerland suddenly abandoned its policy of partly pegging the franc's value to that of the euro.
A few days later, Singapore unexpectedly altered its exchange-rate regime, too.
More consequential, the European Central Bank has committed to a large and relatively open-ended program of large-scale asset purchases.
The ECB acted despite a growing chorus of warnings that monetary stimulus is not sufficient to promote durable growth, and that it encourages excessive risk-taking in financial markets, which could ultimately threaten economic stability and prosperity (as it did in 2008).
Even the US Federal Reserve, which is presiding over an economy that is performing far better than its developed-world counterparts, has reiterated the need for "patience" when it comes to raising interest rates.
This stance will be difficult to maintain, if continued robust job creation is accompanied by much-needed wage growth.
This new round of central-bank activism reflects persistent concerns about economic growth.
Despite a once-unthinkable amount of monetary stimulus, global output remains well below potential, with the potential itself at risk of being suppressed.
Making matters worse, weak demand and debt overhangs are fueling concerns about deflation in the eurozone and Japan.
Anticipating falling prices, households could postpone their consumption decisions, and companies could defer investment, pushing the economy into a downward spiral from which it would be very difficult to escape.
If weak demand and high debt were the only factors in play, the latest round of monetary stimulus would be analytically straightforward.
But they are not.
Key barriers to economic growth remain largely unaddressed – and central banks cannot tackle them alone.
For starters, central banks cannot deliver the structural components – for example, infrastructure investments, better-functioning labor markets, and pro-growth budget reforms – needed to drive robust and sustained recovery.
Nor can they resolve the aggregate-demand imbalance – that is, the disparity between the ability and the willingness of households, companies, and governments to spend.
And they cannot eliminate pockets of excessive indebtedness that inhibit new investment and growth.
It is little wonder, then, that monetary-policy instruments have become increasingly unreliable in generating economic growth, steady inflation, and financial stability.
Central banks have been forced onto a policy path that is far from ideal – not least because they increasingly risk inciting some of the zero-sum elements of an undeclared currency war.
With the notable exception of the Fed, central banks fear the impact of an appreciating currency on domestic companies' competitiveness too much not to intervene; indeed, an increasing number of them are working actively to weaken their currencies.
The "divergence" of economic performance and monetary policy among three of the world's most systemically important economies – the eurozone, Japan, and the United States – has added another layer of confusion for the rest of the world, with particularly significant implications for small, open economies.
Indeed, the surprising actions taken by Singapore and Switzerland were a direct response to this divergence, as was Denmark's decision to halt all sales of government securities, in order to push interest rates lower and counter upward pressure on the krone.
Of course, not all currencies can depreciate against one another at the same time.
But the current wave of efforts, despite being far from optimal, can persist for a while, so long as at least two conditions are met.
The first condition is America's continued willingness to tolerate a sharp appreciation of the dollar's exchange rate.
Given warnings from US companies about the impact of a stronger dollar on their earnings – not to mention signs of declining inward tourism and a deteriorating trade balance – this is not guaranteed.
Still, as long as the US maintains its pace of overall growth and job creation – a feasible outcome, given the relatively small contribution of foreign economic activity to the country's GDP – these developments are unlikely to trigger a political response for quite a while.
Indeed, America's intricate trade relations with the rest of the world – which place households and companies on both sides of the production and consumption equation – make it particularly difficult to stimulate significant political support for protectionism there.
The second condition for broad-based currency depreciation is financial markets' willingness to assume and maintain risk postures that are not yet validated by the economy's fundamentals.
With central banks – the de facto best friend of financial markets these days – pushing for increasingly large financial risk-taking (as a means of stimulating productive economic risk-taking), this is no easy feat.
But, given the danger that this poses, one hopes that they succeed.
In any case, central banks will have to back off eventually.
The question is how hard the global economy's addiction to partial monetary-policy fixes will be to break – and whether a slide into a currency war could accelerate the timetable.
The Price Paradox
LONDON – In 1923, John Maynard Keynes addressed a fundamental economic question that remains valid today. “[I]nflation is unjust and deflation is inexpedient," he wrote.
“Of the two perhaps deflation is…the worse; because it is worse…to provoke unemployment than to disappoint the rentier.
But it is not necessary that we should weigh one evil against the other."
The logic of the argument seems irrefutable.
Because many contracts are “sticky" (that is, not easily revised) in monetary terms, inflation and deflation would both inflict damage on the economy.
Rising prices reduce the value of savings and pensions, while falling prices reduce profit expectations, encourage hoarding, and increase the real burden of debt.
Keynes's dictum has become the ruling wisdom of monetary policy (one of his few to survive).
Governments, according to the conventional wisdom, should aim for stable prices, with a slight bias toward inflation to stimulate the “animal spirits" of businessmen and shoppers.
In the ten years prior to the 2008 financial crisis, independent central banks set an inflation target of about 2%, in order to provide economies with a price-stability “anchor."
There should be no expectation that prices would be allowed to deviate, except temporarily, from the target.
Uncertainty relating to the future course of prices would be eliminated from business calculations.
Since 2008, the Federal Reserve Board and the European Central Bank have failed to meet the 2% inflation target in any year; the Bank of England (BoE) has been on target in only one year out of seven.
Moreover, in 2015, prices in the United States, the eurozone, and the United Kingdom are set to fall.
So what is left of the inflation anchor?
And what do falling prices mean for economic recovery?
The first thing to bear in mind is that the “anchor" was always as flimsy as the monetary theory on which it was based.
The price level at any time is the result of many factors, of which monetary policy is perhaps the least important.
Today, the collapse in the price of crude oil is probably the most significant factor driving inflation below target, just as in 2011 it was the rise in oil prices that drove it above target.
As British economist Roger Bootle pointed out in his 1996 book The Death of Inflation, the price-cutting effects of globalization have been a much more important influence on the price level than the anti-inflation policies of central banks.
Indeed, the post-crisis experience of quantitative easing has highlighted monetary policy's relative powerlessness to offset the global deflationary trend.
From 2009 to 2011, the BoE pumped £375 billion ($578 billion) into the British economy “to bring inflation back to target."
The Fed injected $3 trillion over a slightly longer period.
The most that can be claimed for this vast monetary expansion is that it produced a temporary “spike" in inflation.
The old adage applies: “You can lead a horse to water, but you can't make it drink."
People cannot be forced to spend money if they have good reasons for not doing so.
If business prospects are weak, companies are unlikely to invest; if households are drowning in debt, they are unlikely to go on a spending spree.
The ECB is about to discover the truth of this as it starts on its own €1 trillion program of monetary expansion in an effort to stimulate the stagnant eurozone economy.
So what happens to the recovery if we fall into what is euphemistically called “negative inflation"?
Benign disinflation means rising real incomes for lenders, pensioners, and workers, and falling energy prices for industry.
All sectors of the economy will spend more, pushing up output and employment (and sustaining the price level, too).
By contrast, “bad deflation" means an increase in the real burden of debt.
A debtor contracts to pay a fixed sum in interest every year.
If the value of money goes up (prices fall), the interest he pays will cost him more, in terms of goods and services he can buy, than if prices had stayed the same.
(In the reverse, inflationary case, the interest will cost him less.)
Thus, price deflation means debt inflation; and a higher debt burden means lower spending.
Given the huge levels of outstanding private and public debt, bad deflation, as Bootle writes, “is a nightmare almost beyond imagining."
But how can we stop benign disinflation from turning into bad deflation?
Apostles of monetary expansion believe that all you have to do is speed up the printing press.
But why should this be any more successful in the future than it has been in the last few years?
Avoiding deflation – and thus sustaining economic recovery – would seem to depend on one of two scenarios: either a rapid reversal in the fall of energy prices, or a deliberate policy to raise output and employment by means of public investment (which, as a byproduct, would bring about a rise in prices).
But this would mean reversing the priority given to deficit reduction.
No one can tell when the first will happen; and no governments are prepared to do the second.
So the most likely outcome is more of the same: continued drift in a state of semi-stagnation.
Confronting the Fiscal Bogeyman
BERKELEY – The world economy is visibly sinking, and the policymakers who are supposed to be its stewards are tying themselves in knots.
Or so suggest the results of the G-20 summit held in Shanghai at the end of last month.
The International Monetary Fund, having just downgraded its forecast for global growth, warned the assembled G-20 attendees that yet another downgrade was pending.
Despite this, all that emerged from the meeting was an anodyne statement about pursuing structural reforms and avoiding beggar-thy-neighbor policies.
Once again, monetary policy was left – to use the now-familiar phrase – as the only game in town.
Central banks have kept interest rates low for the better part of eight years.
They have experimented with quantitative easing.
In their latest contortion, they have moved real interest rates into negative territory.
The motivation is sound: someone needs to do something to keep the world economy afloat, and central banks are the only agents capable of acting.
The problem is that monetary policy is approaching exhaustion.
It is not clear that interest rates can be depressed much further.
Negative rates, moreover, have begun to impair the health of the banking system.
Charging banks for the privilege of holding reserves raises their cost of doing business.
Because households can resort to safe-deposit boxes, it’s hard for banks to charge depositors for safekeeping their funds.
In a weak economy, moreover, banks have little ability to pass on their costs via higher lending rates.
In Europe, where experimentation with negative interest rates has gone furthest, bank distress is clearly visible.
The solution is straightforward.
It is to fix the problem of deficient demand not by attempting to further loosen monetary conditions, but by boosting public spending.
Governments should borrow to invest in research, education, and infrastructure.
Currently, such investments cost little, given low interest rates.
Productive public investment would also enhance the returns on private investment, encouraging firms to undertake additional projects.
Thus, it is disturbing to see the refusal of policymakers, particularly in the US and Germany, to even contemplate such action, despite available fiscal space (as record-low treasury-bond yields and virtually every other economic indicator show).
In Germany, ideological aversion to budget deficits runs deep.
It is rooted in the post-World War II doctrine of “ordoliberalism,” which counseled that government should enforce contracts and ensure adequate competition but otherwise avoid interfering in the economy.
Adherence to this doctrine prevented postwar German policymakers from being tempted by excesses like those of Hitler and Stalin.
But the cost was high.
The ordoliberal emphasis on personal responsibility fostered an unreasoning hostility to the idea that actions that are individually responsible do not automatically produce desirable aggregate outcomes.
In other words, it rendered Germans allergic to macroeconomics.
The aging of the German population then made it seem urgent to save collectively for retirement by running surpluses.
And an exceptional spate of budget deficits following German reunification in 1990 appeared only to aggravate, not solve, reunified Germany’s structural problems.
Ultimately, hostility to the use of fiscal policy, as with many things German, can be traced to the 1920s, when budget deficits led to hyperinflation.
The circumstances today may be entirely different from those in the 1920s, but there is still guilt by association, as every German schoolboy and girl learns at an early age.
The US did not experience hyperinflation in the 1920s – or at any other time in its history.
But for the better part of two centuries, its citizens have been suspicious of federal government power, including the power to run deficits, which is fundamentally a federal prerogative.
From independence through the Civil War, that suspicion was strongest in the American South, where it was rooted in the fear that the federal government might abolish slavery.
In the mid-twentieth century, during the civil rights movement, it was again the Southern political elite that opposed the muscular use of federal power.
Starting in 1964, in conjunction with Democratic President Lyndon Baines Johnson’s “New Society,” the government threatened to withhold federal funding for health, education, and other state and local programs from jurisdictions that resisted legislative and judicial desegregation orders.
The result was to render the South a solid Republican bloc and leave its leaders antagonistic to all exercise of federal power except for the enforcement of contracts and competition – a hostility that notably included countercyclical macroeconomic policy.
Welcome to ordoliberalism, Dixie-style. Wolfgang Schäuble, meet Ted Cruz.
Ideological and political prejudices deeply rooted in history will have to be overcome to end the current stagnation.
If an extended period of depressed growth following a crisis isn’t the right moment to challenge them, then when is?
Farewell to Inflation Targeting?
NEWPORT BEACH – In a four-day period in mid-December, three seemingly unrelated developments suggested that modern central banking is in the midst of an historic change.
The implications go well beyond academia and policy circles.
To the extent that this shift gains momentum – which appears likely – it will affect economic performance, the functioning of markets, and asset-price valuations.
The three developments began on December 12 in the United States, where the Federal Reserve, led by Ben Bernanke, announced that it will go much further than doubling (to $1 trillion) the volume of market securities that it intends to buy in 2013 in order to stimulate the economy.
The Fed also left no doubt that it will maintain its foot on the accelerator until the US unemployment rate declines significantly, at least to 6.5%, and as long as inflation is contained at or below 2.5%.
According to most analysts, the novelty in the announcement was the Fed’s willingness to be explicit about its quantitative policy thresholds and, therefore, about the future course of its monetary policy.
But my reading of what the Fed announced (and what Bernanke said in the subsequent press conference) suggests that the innovation goes beyond this.
The Fed is taking very different approaches to the specification of the two quantitative thresholds: unemployment will be based on historical data, while inflation will be based on the Fed’s own projections.
This subtle difference has interesting operational effects.
Most important, it prioritizes the unemployment objective over the inflation target.
This realignment of the Fed’s dual mandate, which I have called the “reverse Volcker moment,” has been evident for a few months.
Let me explain by going back to the end of the inflationary 1970’s, when President Jimmy Carter appointed Paul Volcker to lead the Fed.
In order to prevent pathological inflationary dynamics from becoming embedded even more deeply in the structure of the economy (including through wage indexation), Volcker dramatically changed the policy stance and made inflation public enemy number one.
The equivalent of today’s policy rate rose to 22% as he launched a bold anti-inflationary crusade, accepting significant upfront costs for gains down the road.
This “Volcker moment” was, as students of economic history know, the catalyst not only for “winning the war against inflation,” but also for a multi-decade shift in conventional wisdom about central banking.
Most important, inflation targeting and independence from the fiscal authorities became core features of mainstream policy – a requirement for any country seeking the macroeconomic stability deemed crucial for sustained economic growth and high rates of job creation.
I suspect that historians one day will view last month’s Fed announcement as the catalyst for a similar change in conventional wisdom – both in America and around the world.
They will conclude that two factors motivated Bernanke: persistently high US unemployment – which, like the inflation problem that Volcker faced, risks becoming deeply embedded in the structure of the economy – and virtual paralysis on the part of other policymaking agencies.
There are almost five million “long-term unemployed” Americans, constituting more than 40% of total unemployment.
Millions more have dropped out of the measured labor force altogether.
And about a quarter of 16-19-year-olds in the labor force are unemployed.
All of this risks serious skill atrophy.
And the unemployed young face the additional risk of becoming a lost generation.
It is therefore doubly surprising that, aside from the Fed, America’s policymaking agencies are essentially missing in action.
The problem is not a lack of leadership from President Barack Obama, who has put forward several proposals to address the country’s unemployment problem, including a comprehensive jobs initiative.
Rather, the problem is a polarized Congress that has taken no major economic decisions in the last few years – other than missteps (like the fiscal cliff) that risk tripping the economy into recession.
With political paralysis likely to continue in 2013, notwithstanding occasional agreements, the Fed will be busy implementing the paradigm shift for central banking.
And the impact could well spread.
Which brings us to the two other developments in that four-day period in mid-December.
A few hours after the Fed’s announcement, news came that the British government was open to considering a change in the Bank of England’s policy anchor.
Unlike the Fed, the BoE’s sole objective for years has been price stability, with no additional employment mandate.
If the target is missed repeatedly, as it has been, the governor must send a public explanatory letter to the government.
Now it looks like politicians may be looking to offload onto the Bank responsibility for generating economic growth and jobs.
The third development occurred in Japan, where the newly-elected Liberal Democratic government of Shinzo Abe, commanding a two-thirds parliamentary majority, is pressing the Bank of Japan to stimulate growth – a “discussion” that looks set to evolve into something much more assertive.
In short, expect central banks to devote greater attention to unemployment.
And it is a good thing that the official sector is paying more attention to joblessness – a very good thing.
Yet, unfortunately, this shift will not solve a problem that eats away at the social fabric of any society.
As much as Bernanke and others wish otherwise – and as much as bickering politicians seek to dump policy responsibilities on others – central banks do not have the proper tools to deal with the component of the unemployment crisis that results from insufficient investment in education, training, and physical capital.
Likewise, they cannot fix debt overhangs, repair broken home financing, or address medium-term fiscal-reform challenges on their own.
The best that central banks can do is to buy time, albeit at an increasing cost, for other policymaking entities to get their act together.
If this window closes, the monetary-policy paradigm shift now visible in the US, Britain, and Japan would risk a damaging loss of credibility and political independence for institutions that are critical to well-managed economies.
Money for Nothing
COPENHAGEN – When it comes to global warming, we have plenty of hot rhetoric but very little cool reason.
This matters immensely, because the Kyoto Protocol is already among the most expensive global public policies ever enacted, and the follow-up in Copenhagen in late 2009 promises to break all records.
We better get it right, but right now we’re more likely to pay for virtually nothing.
A good example is the European Union’s newly instituted policy of cutting CO2 emissions by 20% by 2020.
Of course, it is always easier to promise than to deliver – a concern that is especially relevant in the EU.
Yet, even if the promise is kept, will the benefit outweigh the cost?
Curiously, but not surprisingly, this is not discussed very much.
A 20% reduction in the EU’s CO2 emissions, vigorously enforced throughout this century, would merely postpone temperature increases due to global warming by two years at the end of the century, from 2100 to 2102 – a negligible change.
Yet the cost would be anything but negligible.
The EU’s own estimate is about €60 billion annually , which is almost certainly a vast underestimate (its previous estimate was almost twice as much), since it requires the EU to make the reductions in the smartest way possible.
However, the EU doesn’t just want to cut emissions in the smartest possible way, but also to increase the share of renewable energy in the Union by 20% by 2020.
This increase has no separate climate effect, since we’ve already promised to cut emissions by 20%.
However, it does manage to make a poor policy decision dramatically worse.
The debate in my native Denmark is instructive, as the relevant government ministries have outlined what this decision will end up costing here, which in turn suggests the total cost for the EU.
The annual cost of an increase in renewable energy of less than 20% (18 percentage points) – and five years later, by 2025 – will be more than €2.5 billion.
And the benefit?
If Denmark sticks to this decision throughout the rest of this century, it will spend more than €200 billion to postpone global warming by five days.
Is that a sensible decision?
The total advantage to the world (measured according to all relevant criteria, such as lives saved, agricultural production increased, wetlands preserved, etc.) from Denmark’s policy would be about €11 million.
Or, for every euro spent, we would do a bit less than half a cent worth of good.
To put this in perspective, €2.5 billion could double the number of hospitals in Denmark.
And, if we really wanted to benefit the world, €2 billion could halve the number of malaria infections, saving 850 million lives this century.
People in the affected countries would live much better and become more productive, benefiting their children and grandchildren in 2100.
The last €500 million could fund an eight-fold increase in research and development aimed at improving CO2-efficient energy technologies, enabling everyone in the long run to reduce emissions much more dramatically, and at much lower cost.
So, should we halve malaria while dramatically increasing the possibility of solving global warming in the medium term?
Or should we make a pledge that does 2,000 times less good and barely alters the global climate?
It gets worse.
The €2.5 billion estimate assumes that politicians pick the cheapest renewable energy alternative.
The same money could triple the global development aid budget.
It could easily provide clean drinking water, sanitation, education, and health care to every human being on the planet, while increasing CO2-reducing R&amp;D ten-fold.
The EU’s goal of a 20% reduction by 2020 is an incredibly expensive way to signal good intentions.  But wouldn’t we rather do real good?
The EU believes it is showing the way, but if the world follows the Union, it seems that we are more likely simply to become lost.
Dirty Money and Development
WASHINGTON, DC – The world has made enormous progress in recent decades in the fight against poverty.
But, as 2015 begins, one billion people – one in seven – still live on less than $1.25 a day.
It will take a global effort to end poverty – and to find the resources to do so.
At first glance, the price tag is staggering.
We know that development aid will not be sufficient to end poverty.
It will take private sector investment, taxes collected in developing countries, and other sources of finance to do the job.
The truth is that there is enough money in the world to get it done.
One unexpected source of wealth that could play a large role is the world’s huge supply of dirty money: multinational companies’ undeclared profits, the proceeds of corruption, and the earnings of traffickers of drugs, weapons, and people – all of which is stashed away in offshore bank accounts, companies, and trusts.
Reliable numbers about the amount of dirty money around the world are difficult to come by.
But according to an estimate by the non-profit Global Financial Integrity group, $1 trillion vanishes from the developing world’s economies every year.
That is money that is badly needed for development.
This is also roughly the amount needed to fill the vast infrastructure gap that is preventing the world from addressing critical developmental challenges – from rapid urbanization to climate change and job creation.
Today, developing and emerging countries invest about $1 trillion a year in infrastructure.
They need an additional $1 trillion a year to close the gap, a necessary step to ending extreme poverty by 2030.
But a lack of implementation and enforcement of anti-money-laundering, tax transparency, and anti-corruption rules is shielding the perpetrators from prosecution.
This ultimately prevents developing countries from stopping the outflow of money that is bleeding them of essential resources.
For the schoolchild in Port-au-Prince, the new mother in Mogadishu, or the farmer in Ocotepeque, these losses have a real impact: overcrowded classrooms, non-existent health clinics, and inadequate water resources.
People’s opportunities are being stolen from them.
This is good news, particularly for the poor.
But many hurdles remain, and now the world must focus on three critical issues.
First, developing countries must build effective institutions while enforcing good governance, transparency, and accountability.
They must fight corruption, combat organized crime, and implement effective tax systems, which is even more critical in resource-rich countries.
Recent events in the Middle East and Ukraine demonstrate how the capture of state coffers by vested interests instigates conflict and undermines people’s trust in government.
But corruption, money laundering, and tax evasion are global problems, not just challenges for developing countries.
Though weak national institutions and limited law-enforcement capacity may make it easier to initiate illicit financial transfers, we need to acknowledge that dirty money often ends up in financial centers, which have become quasi-enablers.
That is why addressing the issue requires international cooperation.
Second, regulations that identify the true owners of illicit funds need to be enforced.
Once such assets are parked in opaque companies, they are often beyond the reach of tax authorities and investigators.
Again and again, the true recipients or beneficial owners of companies and trusts are shielded from disclosure by laws and regulations that inadvertently protect criminals.
This must stop.
Finally, a system for the automatic exchange of tax information among countries would limit the places where tax evaders and money launderers can easily hide their proceeds.
Almost 90 countries have now committed to begin, as early as 2017, cross-border data exchanges that would include information about account holders and certain details regarding their deposits and balances – information that could help authorities identify proceeds from corruption and illegal transactions through suspicious activity and spikes.
More action is needed this year and beyond.
At the World Bank, we are already working with our clients in developing countries to improve their governance systems, collect taxes, fight corruption, and recover stolen assets.
Our work will benefit enormously from the current push for more international cooperation in curbing illicit financial flows.
Changing much-cherished bank-secrecy laws is worth the effort.
Corruption, tax evasion, and the capture of natural-resource revenues undermine the rule of law, weaken the social fabric, erode citizens’ trust in institutions, fuel conflict and insecurity, and hamper job creation.
They are not just illegal, but also immoral, because they keep poor people poor.
Monnet’s Ghost
LONDON – Some fine ideas are rather like a beautiful object with a time bomb inside.
The ideal of a unified Europe, though not designed to explode, could well disintegrate nonetheless.
To understand why, it helps to revisit the intellectual origins of the European Union.
One of the EU’s main architects, Jean Monnet, a French diplomat and economist, spent much of World War II in Washington, DC, as a negotiator for the European allies.
After Germany’s defeat, he was convinced that only a united Europe could prevent another devastating war in the West.
“There will be no peace in Europe,” he wrote in his memoir, “if states are reconstituted on the basis of national sovereignty.”
Almost everyone on the European continent, exhausted by war, and faced with the shattered institutions of their ravaged nation-states, agreed.
Only the victorious British, with their old institutions more or less intact, voiced skepticism, not so much about continental unity as about their own participation in Europe’s ambitious project.
Of course, the ideal of a united Europe is much older than Monnet’s scheme.
If not as old as ancient Rome, it certainly goes as far back as the tenth-century Holy Roman Empire.
Since then, the European ideal has gone through many changes, but two themes remained constant.
One ideal was that of a unified Christendom, with Europe at its center.
The Duke of Sully (1559-1641) conceived of a Christian European republic, which the Turks could join only if they converted to Christianity.
The other ideal was eternal peace.
In 1713, another Catholic Frenchman, Charles-Irénée Castel, abbé de Saint-Pierre, published his Project for Perpetual Peace in Europe. There would be a European senate, a European army, and the larger member states would have equal voting rights.
In fact, the ideals of eternal peace and Christian unity were identical in the minds of the early pan-European thinkers.
Peaceful unification was a religious notion, a Christian utopia.
Never meant to be confined to the European continent, it was, like Christianity itself, a universalist aspiration.
National borders ought to be abolished in God’s earthly kingdom.
After the Enlightenment, the rationalists easily adopted religious universalism.
The French nineteenth-century statesman Alphonse de Lamartine wrote an ode to European unity along rationalist lines, entitled the Marseillaise of Peace: “In the course of enlightenment, the world rises to unity/I am the fellow citizen of every thinking person/Truth is my country.”
As France’s foreign minister in the revolutionary year of 1848, Lamartine published his Manifesto for Europe, promoting not just European unity, but that of mankind.
The European ideal has parallels in other parts of the world.
Chinese rulers, to this day, have been obsessed with central control, continental unity, and social harmony – that is, a society without political conflict.
The idea that people’s interests can and do naturally conflict is not readily admissible.
Mao’s idea of permanent revolution was an aberration in the history of Chinese political thought.
It is not difficult to imagine why the notion of a borderless, peaceful world in which political divisions and conflicts were overcome was deeply appealing after WWII.
Many blamed nationalism as the ultimate evil that had almost destroyed Europe.
A world without political strife seemed like a recipe for bliss.
Monnet was a born technocrat, who hated political conflict and almost made a fetish of unity.
(In 1940, when Hitler seemed indomitable, Monnet suggested to Winston Churchill that France and Britain might be rolled into one country.)
Like all technocrats, Monnet was also a born planner.
In this, too, he was a man of his time.
Many people believed already before the war that economies and societies should be planned as much as possible.
Franklin Roosevelt’s New Deal was one example; so, in a much more sinister way, was the fascist state.
And so, still, is China, ruled by engineers and other faceless technocrats.
The post-1945 ideal of a united Europe was very much a planner’s archetype, a technocratic Utopia.
And, certainly for Monnet and the other founders of postwar Europe, it was an entirely benign, even noble, ideal.
The problem with technocrats, however, is that they tend to be oblivious to the political consequences of their own plans.
They proceed as if politics did not exist or did not really matter.
Christine Lagarde, Managing Director of the International Monetary Fund, is a case in point.
Her recent statement that she feels no sympathy for the suffering Greeks, because they should have paid their taxes, has been widely criticized for being not just unfeeling, but hypocritical (as a diplomat she pays no taxes herself).
In fact, it is the typical sentiment of a technocrat who lacks political sense.
Crippling economic austerity, imposed by unelected bureaucrats in Brussels and Washington, is not only a social calamity; it is also poses a dangerous threat to democracy.
When people lose faith in democratic institutions to protect them, they will reach for extremism.
And so, barring a miracle, the time bomb within post-war Europe’s beautiful ideal is about to explode.
The limits of technocratic utopianism have been reached.
Fiscal union – that is, more imposed unity – may well be the rational answer to the current financial crisis, but it is a technocratic answer which would do nothing to make Europe more democratic, and would most likely provoke an extremist backlash.
Technocracy, it seems, can work well as long as most people feel that they are benefiting materially, as was true in Europe for almost 50 years, and might still be true in China.
But its legitimacy cracks as soon as a crisis erupts.
Europe is feeling the consequences today.
Who knows what might happen in China tomorrow.
Is Finance Too Competitive?
NEW DELHI – Many economists are advocating for regulation that would make banking “boring” and uncompetitive once again.
After a crisis, it is not uncommon to hear calls to limit competition.
During the Great Depression, the head of the United States National Recovery Administration argued that employers were being forced to lay off workers as a result of “the murderous doctrine of savage and wolfish competition, [of] dog-eat-dog and devil take the hindmost.”
He appealed for a more collusive business environment, with the profits made from consumers to be shared between employers and workers.
Concerns about the deleterious effects of competition have always existed, even among those who are not persuaded that government diktat can replace markets, or that intrinsic human goodness is a more powerful motivator than monetary reward and punishment.
Where the debate has been most heated, however, concerns the effects of competition on incentives to innovate.
The great Austrian economist Joseph Schumpeter believed that innovation was a much more powerful force for human betterment than was ordinary price competition between firms.
As a young man, Schumpeter seemed to believe that monopolies deaden the incentive to innovate – especially to innovate radically.
Simply put, a monopolist does not like to lose his existing monopoly profits by undertaking innovation that would cannibalize his existing business.
By contrast, if the industry were open to new players, potential entrants, with everything to gain and little to lose, would have a strong incentive to unleash the waves of “creative destruction” that Schumpeter thought so essential to human progress.
In a competitive industry, only paranoid incumbents – those constantly striving for betterment – have any hope of surviving.
As an older man, Schumpeter qualified his views to argue that some degree of monopoly might be preferable to competition in creating stronger incentives for companies to innovate.
The rationale is simple: If patent protection were limited, or if it were easy for competitors to innovate around intellectual property, a firm in a competitive market would have very little incentive to invest in pathbreaking research and development.
After all, the firm would gain only a temporary advantage at best.
If, instead, it withheld spending, and simply copied or worked around others’ R&amp;D, it could survive perfectly well – and might be better off.
Knowing this, no one would innovate.
But if the firm enjoyed a monopoly, it would have the incentive to undertake innovations that improved its profitability (so called “process” innovations), because it would be able to capture the resulting profits, rather than see them be competed away.
A “boring” bank, shielded from competition and knowing that it “owns” its customers, would want to go the extra mile to help them, because it would get its pound of flesh from their future business.
Customers can be happy even when faced by a monopoly, though they would grumble far more if they knew how much they were paying for good service!
An analogy may be useful.
A monopoly is like running on firm ground.
Nothing compels you to move, but if you do, you move forward.
The faster you run, the more scenery you see – so you have some incentive to run fast.
Competition is like a treadmill.
If you stand still, you get swept off.
But when you run, you can never really get ahead of the treadmill and cover new terrain – so you never run faster than the speed that is set.
So which industrial structure is better for encouraging you to run?
As economists are prone to say, it depends.
Perhaps one can have the best of both worlds if one starts on a treadmill, but can jump off if one runs particularly fast – the system is competitive, but those who are particularly innovative secure some monopoly rents for a while.
This is what a strong system of patent protection does.
But patents are ineffective in some industries, like finance.
The overwhelming evidence, though, is that financial competition promotes innovation.
Much of the innovation in finance in the US and Europe came after it was deregulated in the 1980’s – that is, after it stopped being boring.
The critics of finance, however, believe that innovation has been the problem.
Instead of Schumpeter’s “creative destruction,” bankers have engaged in destructive creation in order to gouge customers at every opportunity while shielding themselves behind a veil of complexity from the prying eyes of regulators (and even top management).
Former US Federal Reserve Board Chairman Paul Volcker has argued, somewhat tongue-in-cheek, that the only useful financial innovation in recent years has been the ATM.
Hence, the critics are calling for limits on competition to discourage innovation.
Of course, the critics are right to argue that not all innovations in finance have been useful, and that some have been downright destructive.
By and large, however, innovations such as interest-rate swaps and junk bonds have been immensely beneficial, allowing a variety of firms to emerge and obtain finance in a way that simply was not possible before.