The implementation of austerity policies in the periphery has caused these countries to ask for help and request that Germany take the lead by putting more money on the European table.
Nobody would deny that Germany has an interest in preserving the euro.
So why shouldn’t it support its partners with financial help to overcome the crisis?
Such support can already be found via the various rescue mechanisms – above all, the European Stability Mechanism and the implicit guarantees of TARGET 2 – that have been erected since the crisis began.
But these mechanisms must be distinguished from a regime of more or less automatic, permanent transfers.
As long as a fully-fledged political union remains a vision for the future, fiscal transfers must be legitimized by national parliaments.
For now – and probably for a long time to come – the eurozone will continue to be a union of sovereign states, with each country responsible for its own policies and for their outcome.
The no-bailout clause that was included in the monetary union’s founding treaty is an indispensable corollary.
Eurobonds, for example, would not only create moral hazard; “taxation without representation” would also violate a fundamental tenet of democracy and undermine support for the European idea.
The creation of a European banking union is another area in which misguided calls for solidarity prevail.
Establishing a single supervisory authority and a resolution mechanism are valid proposals.
But asking others to pay for the legacy of banks’ past irresponsible practices is hard to justify.
What would be the reaction if, say, Italian or Spanish taxpayers were asked to pay for the reckless behavior of the German IKB or HRE banks?
Who would not find such a request inappropriate, to say the least?
And yet when the bailout is presented the other way around, with German taxpayers asked to backstop reckless Italian or Spanish banks, somehow it is supposed to be an act of solidarity.
Legacy problems in national banking systems should be solved at the national level before the banking union moves forward.
Bailing out governments and banks is not the direction in which Germany should lead.
If Germany should lead at all, it should do so by providing a model of good economic policies for others to emulate.
It should lead by respecting the commitments enshrined in the European treaties.
Indeed, Germany set a disgraceful and damaging example when, back in 2003-2004, it undermined the European Union’s Stability and Growth Pact by not adhering to it.
Walter Hallstein, the first president of the European Commission, repeatedly stressed that the union is based on the principle of a community of nations under the rule of law (Rechtsgemeinschaft).
Today, credibility can only be restored if treaties and rules are respected again.
Think of the eurozone as a selective club.
Unless its members respect the rules by which it is defined, it will wither.
Those who violate the rules must be warned and finally sanctioned – preferably in an automatic fashion.
Those who violate the rules consistently, and even announce that they will continue in their misbehavior, should not be allowed to blackmail the community and should ultimately consider leaving the club.
Those who are concerned about permanent German dominance of the European “club” can rest easy.
Having emerged from the position of the sick man of Europe only a decade ago, Germany is now willfully, if thoughtlessly, undoing the reforms that had so strengthened its economy.
By reinforcing already-strict labor-market regulation, pursuing a misguided energy policy, and reversing pension reform, Germany is undermining its current economic position and will move in the direction of problem countries.
This regression will take time, but it will happen.
Accordingly, calls for German leadership will disappear and its strained public finances will suppress requests for financial transfers.
One wonders how the discussion about “leadership” for Europe will look then?
Our G-Zero World
NEW YORK – We live in a world where, in theory, global economic and political governance is in the hands of the G-20.
In practice, however, there is no global leadership and severe disarray and disagreement among G-20 members about monetary and fiscal policy, exchange rates and global imbalances, climate change, trade, financial stability, the international monetary system, and energy, food and global security.
Indeed, the major powers now see these issues as zero-sum games rather than positive-sum games.
So ours is, in essence, a G-Zero world.
In the nineteenth century, the stable hegemon was the United Kingdom, with the British Empire imposing the global public goods of free trade, free capital mobility, the gold standard, and the British pound as the major global reserve currency.
In the twentieth century, the United States took over that role, imposing its Pax Americana to provide security to most of Western Europe, Asia, the Middle East, and Latin America.
The US also dominated the Bretton Woods institutions – the International Monetary Fund, the World Bank, and, later, the World Trade Organization – to determine the global trade and financial rules, with the dollar as the main reserve currency.
Today, however, the US “empire” is in relative decline and fiscally over-stretched.
Moreover, the rising power, China, which is not a liberal democracy, is pursuing a model of state capitalism, and is free-riding on the current global system – on trade, exchange rates, climate change – rather than sharing in the provision of global public goods.
And, while there is general unhappiness with the US dollar, the Chinese renminbi is still far from becoming a major global reserve currency, let alone the dominant one.
This power vacuum has reinforced the absence of leadership on global economic and political governance within the G-20 since it succeeded the G-7 at the onset of the recent economic and financial crisis.
Indeed, with the exception of the London summit in April 2009, when a consensus was reached on joint monetary and fiscal stimulus, the G-20 has become just another bureaucratic forum where much is discussed, but little is agreed upon.
As a result, the global economic powers have been left bickering about whether we need more monetary and fiscal stimulus or less of it.
There are also major disagreements about whether to reduce global current-account imbalances – and about the role that currency movements should play in this adjustment.
Exchange-rate tensions are leading to currency wars, which may eventually lead to trade wars and protectionism.
Indeed, not only is the Doha round of multilateral free-trade negotiations effectively dead, but there is also a rising risk of financial protectionism as countries re-impose capital controls on volatile global financial flows and on foreign direct investment.
Likewise, there is very little consensus on how to reform the regulation and supervision of financial institutions – and even less on how to reform an international monetary system based on flexible exchange rates and the dollar’s central role as the leading reserve currency.
Global climate-change negotiations have similarly ended in failure, and disagreement reigns concerning how to address food and energy security amid a new scramble for global resources.
And, on global geopolitical issues – the tensions on the Korean peninsula, Iran’s nuclear ambitions, the Arab-Israeli conflict, the disorder in Afghanistan and Pakistan, and the political transition in autocratic Middle East regimes – the great powers disagree and are impotent to impose stable solutions.
There are several reasons why the G-20 world has become a G-Zero world.
First, when discussion moves beyond generic principles into detailed policy proposals, it’s much more difficult to reach clear agreements among 20 negotiators than among seven.
Second, G-7 leaders share a belief in the power of free markets to generate long-term prosperity and in the importance of democracy for political stability and social justice.
The G-20, on the other hand, includes autocratic governments with different views about the role of the state in the economy, and on the rule of law, property rights, transparency, and freedom of speech.
Third, the Western powers now lack the domestic political consensus and financial resources to advance an international agenda.
The US is politically polarized, and must at some point begin to reduce its budget deficit.
Europe is preoccupied with its attempt to save the eurozone, and has no common foreign or defense policy.
And Japan’s political stalemate on structural reforms has left it helpless to stem long-term economic decline.
Finally, rising powers like China, India, and Brazil are far too focused on managing the next stage of their domestic development to bear the financial and political costs that come with new international responsibilities.
In short, for the first time since the end of World War II, no country or strong alliance of countries has the political will and economic leverage to secure its goals on the global stage.
This vacuum may encourage, as in previous historical periods, the ambitious and the aggressive to seek their own advantage.
In such a world, the absence of a high-level agreement on creating a new collective-security system – focused on economics rather than military power – is not merely irresponsible, but dangerous.
A G-Zero world without leadership and multilateral cooperation is an unstable equilibrium for global economic prosperity and security.
Our Kind of Truth
NEW YORK – Rick Santorum, a former United States senator seeking the Republican Party’s nomination to challenge President Barack Obama this year, has been saying some very strange things about the Netherlands.
Ten percent of all deaths in that country, he recently claimed, are from euthanasia, half of which are forced upon helpless patients.
Old people are so frightened of being killed by homicidal doctors that they wear bracelets that read: “Do not euthanize me.”
In a way, Santorum’s canards must come as a relief to a country that has increasingly been in the news for outrageous statements by right-wing populists about Muslims and Greeks.
Indeed, Santorum’s view of the Netherlands as a kind of progressive dystopia has a slightly old-fashioned ring to it nowadays.
The Dutch were nonetheless disturbed.
Some in the country’s parliament even asked whether the foreign minister should lodge a complaint in Washington.
In fact, Santorum’s fantasies were swiftly refuted in the US itself.
The Washington Post concluded that “there was not a shred of evidence to back up Santorum’s claims,” and found it “telling” that his campaign managers did not even bother to defend them.
One US television station even apologized to a Dutch reporter in the name of the American people.
As the Post pointed out, there is no such thing as involuntary euthanasia in the Netherlands.
The patient’s consent is essential, and at least two doctors must agree that the patient’s suffering is unbearable and beyond cure.
Besides, the share of assisted deaths in Dutch mortality is nowhere near 10%.
As for those bracelets, well…
But does any of this matter to Santorum’s followers?
Probably not.
Corrections from the “elitist” mainstream media are dismissed as enemy propaganda.
As a blogger sympathetic to Santorum put it: “The Washington Post, as one would expect, attempted to discredit Santorum.”
It is disturbing, to say the least, that the most cogent refutations of bald-faced lies no longer make any impression.
After all, a democracy cannot function without a public that is properly informed.
Informing the public used to be the role of serious newspapers and television networks.
Of course, not everything in the mainstream media is always true. Mistakes are made.
News organizations have political biases, sometimes reflecting the views and interests of their owners.
But high-quality journalism has always relied on its reputation for probity.
Editors, as well as reporters, at least tried to get the facts right.
That is why people read Le Monde, The New York Times, or, indeed, the Washington Post. Filtering nonsense was one of their duties –amp#160;and their main selling point.
That has changed.
Populist demagogues in politics and the mass media are doing everything they can to discredit the quality press as propaganda organs for left-wing elites who sneer at the views of ordinary Americans.
Santorum pretends to speak for these people – that is, for a minority of Americans who are mostly white, provincial, highly religious, deeply conservative on cultural and social issues, and convinced that Obama and all Europeans are dangerous godless socialists.
The point is not whether Santorum is right or wrong factually. What he says “feels” right to his followers, because it conforms to their prejudices.
We might think, they argued, that what we read in The New York Times or Le Monde is objectively true, but everything that appears there is, in fact, a disguised form of propaganda for bourgeois class interests.
There is no such thing, the post-modern critic believes, as independence of thought. Objective truth is an illusion.
These writers are the left-wing elite, at least in academia.
But, as so often happens, ideas have a way of migrating in unexpected ways.
The blogger who dismissed The Washington Post’s corrections of Santorum’s fictional portrayal of the Netherlands expressed himself like a perfect post-modernist.
The most faithful followers of obscure leftist thinkers in Paris, New York, or Berkeley are the most reactionary elements in the American heartland. Of course, if this were pointed out to them, they would no doubt dismiss it as elitist propaganda.
Our Other Drug Problem
MILAN – With all the official and media attention given to the worldwide trade in illicit drugs, the public has at most a dim awareness of the serious problems affecting the production, testing, and sale of the legal kind: the medicines that we take to treat or cure everything from AIDS to Yellow Fever.
The development of new drugs is a complex and lengthy process.
It starts with an idea and requires a wide range of skills to bring that idea to fruition: synthesis or extraction of more or less complicated molecules, proof of their therapeutic effect in cell cultures and animals, testing for toxicity, and clinical studies.
Along this path, many potential drugs are withdrawn, and even successfully tested drugs face the additional hurdle of regulatory approval.
Finally, the drug reaches the market, where it must be followed closely, because many adverse reactions are detected only with a large number of patients and after years of use.
There are several thousand drugs currently on the market, with a worldwide value of about $3 trillion. But conditions in the drug market are far from optimal.
Ideally, drugs should have a favorable risk-benefit ratio.
Compared with other drugs with the same indications, new drugs should be selected on the basis of their safety, effectiveness, and cost.
But the financial interests involved tend to distort the process by creating incentives to overestimate the benefits of new drugs, underestimate the risks, and, above all, boost prescriptions.
What can be done?
First, new drugs should always offer added value – better efficacy, lower toxicity, or greater ease of treatment.
Unfortunately, this is not required by current legislation in Europe, where only quality, efficacy, and safety must be demonstrated, without any need for comparative studies.
There is therefore the risk that new drugs may in fact be worse than products already on the market.
New drugs are often tested against placebos or drugs that are not the best treatment available, the point being to demonstrate that the new drug is not inferior to any already on the market.
But it is ethically questionable to test a drug for “non-inferiority,” because patients are exposed to potential risks while contributing, in the best case, to the development of a drug that is no better than those already available.
Patients’ informed consent usually does not provide a clear description of a non-inferiority trial, and the lack of added value indicates that in many cases the development of a new drug is driven by commercial aims rather than patients’ needs.
Second, improvement of drug development requires more transparency from the regulatory bodies.
At present, a new drug’s producer prepares the entire dossier presented to the regulatory authority for approval; in the interests of the public, at least one of the clinical trials should be carried out by an independent non-profit organization.
Moreover, only the regulators can examine the dossiers, which are highly confidential.
It is unacceptable that patients participating voluntarily in clinical trials, and their representatives, have no right to see data that would not exist without them.
Third, better conditions for the approval of new drugs should be matched by better use of drugs, which requires better information for prescribers.
Today, information provided by drug makers largely predominates over independent information.
As a result, certain drugs are used much more frequently than would be expected from their approved indications.
This so-called “off-label” use is sustained by continuous propaganda aimed not only at doctors, but also directly at the public.
Direct but shadowy information tends to lead to “disease mongering” – the creation of diseases in order to boost prescriptions.
For example, the concept of “pre-hypertension” could extend the use of anti-hypertensive drugs dramatically, because everybody’s blood pressure rises with age. Likewise, the notion that blood cholesterol should be as low as possible clears a path to treating healthy people with anti-cholesteremic agents.
Clearly, health authorities must take closer control of information by becoming more responsible for physicians’ continuous education.
If the conditions for drug approval and marketing become more severe, pharmaceutical companies will be forced to produce fewer me-too drugs and more products of clinical importance.
Requiring longer testing periods, and possibly extra resources, could be compensated by new drugs’ greater longevity on the market, and patent coverage could be extended.
Finally, incentives must be found to encourage pharmaceutical companies to develop drugs that fulfill the needs of patients still awaiting therapy.
There are more than 6,000 rare and neglected diseases – many in developing countries – that lack remedies.
The challenge is how to produce new drugs that – because patients are too few or too poor – promise very limited returns.
A partnership between governments, non-profit research institutions, charities and pharmaceutical companies might be one way to clean up the approval process for new drugs.
If public awareness of the current problems stimulates politicians to find a solution that works, better drugs and better drug use will be achievable.
Our Summer of Extremes
BERLIN – This summer has been one of weather-related extremes in Russia, Pakistan, China, Europe, the Arctic – you name it.
But does this have anything to do with global warming, and are human emissions to blame?
While it cannot be scientifically proven (or disproven, for that matter) that global warming caused any particular extreme event, we can say that global warming very likely makes many kinds of extreme weather both more frequent and more severe.
For weeks, central Russia has been in the grips of its worst-ever heat wave, which has caused probably thousands of fatalities.
As a result of drought and heat, more than 500 wildfires have raged out of control, smothering Moscow in smoke and threatening several nuclear facilities.
Russia’s government has banned wheat exports, sending world grain prices soaring.
Meanwhile, Pakistan is struggling with unprecedented flooding that has killed more than a thousand people and affected millions more.
In China, flash floods have so far killed more than a thousand people and destroyed more than a million homes.
On a smaller scale, European countries like Germany, Poland, and the Czech Republic have also suffered serious flooding.
Meanwhile, global temperatures in recent months have been at their highest levels in records that go back 130 years.
Arctic sea-ice cover reached its lowest recorded average level for the month of June ever.
In Greenland two huge chunks of ice broke off in July and August.
Are these events connected?
Looking only at individual extreme events will not reveal their cause, just like watching a few scenes from a movie does not reveal the plot.
But, viewed in a broader context, and using the logic of physics, important parts of the plot can be understood.
This decade has been marked by a number of stunning extremes.
In 2003, the most severe heat wave in living memory broke previous temperature records by a large margin and caused 70,000 deaths in Europe.
In 2005, the most severe hurricane season ever witnessed in the Atlantic devastated New Orleans and broke records in terms of the number and intensity of storms.
In 2007, unprecedented wildfires raged across Greece, nearly destroying the ancient site of Olympia.
And the Northwest Passage in the Arctic became ice-free for the first time in living memory.
Last year, more than a hundred people were killed in bush fires in Australia, following drought and record-breaking heat.
This cluster of record-breaking events could be merely an astonishing streak of bad luck.
But that is extremely unlikely.
This is far more likely to be the result of a warming climate – a consequence of this decade being, worldwide, the hottest for a thousand years.
All weather is driven by energy, and the sun ultimately provides this energy.
But the biggest change in Earth’s energy budget by far over the past hundred years is due to the accumulation in our atmosphere of greenhouse gases, which limit the exit of heat into space.
Owing to fossil-fuel emissions, there is now one-third more carbon dioxide in the atmosphere than at any time in at least a million years, as the latest ice drilling in Antarctica has revealed.
The changes in the planet’s energy budget caused by solar variations are at least ten times smaller in comparison. And they go in the wrong direction: in recent years, the sun has been at its dimmest since satellite measurements began in the 1970’s.
So, when unprecedented extreme weather events occur, the prime suspect is naturally the biggest atmospheric change that has happened over the past hundred years – one that has been caused by human emissions.
The fact that heat waves like the one in Russia become more frequent and extreme in a warmer world is easy to understand.
Extreme rainfall events will also become more frequent and intense in a warmer climate, owing to another simple fact of physics: warm air can hold more moisture.
For each degree Celsius of warming, 7% more water is available to rain down from saturated air masses.
Drought risk also increases with warming: even where rainfall does not decline, increased evaporation dries out the soils.
The carbon-dioxide effect can also change the preferred patterns of atmospheric circulation, which can exacerbate extremes of heat, drought, or rainfall in some regions, while reducing them in others. The problem is that a reduction in those extremes to which we are already well-adapted provides only modest benefits, whereas the new extremes to which we are not adapted can be devastating, as recent events in Pakistan show.
The events of this summer show how vulnerable our societies are to weather-related extremes. But what we see now is happening after only 0.8º Celsius of global warming.
With swift and decisive action, we can still limit global warming to a total of 2º Celsius or a bit less.
Even that much warming would require a massive effort to adapt to weather extremes and rising sea levels, which needs to start now.
With weak action, like that promised by governments in Copenhagen last December, we will be on course for 3-4º Celsius of global warming. This is bound to outstrip the ability of many societies and ecosystems to adapt.
And, with no action at all, the planet could even heat up by 5-7º Celsius by the end of this century – and more thereafter.
Knowingly marching down that road would be insane.
We must face the facts: our emissions of greenhouse gases probably are at least partly to blame for this summer of extremes.
Clinging to the hope that it is all chance, and all natural, seems naive.
Let us hope that this summer of extremes is a last-minute wake-up call to policy makers, the corporate world, and citizens alike.
Our Virtual Middle Ages
Wikipedia , the online encyclopedia, is the most impressive collective intellectual project ever attempted – and perhaps achieved.
It demands both the attention and the contribution of anyone concerned with the future of knowledge.
Because of the speed with which it has become a fixture in cyberspace, Wikipedia ’s true significance has gone largely unremarked.
Since its sixth anniversary in 2007, Wikipedia has consistently ranked in the top ten most frequently viewed Web sites worldwide.
Everyday it is consulted by 7% of all 1.2 billion Internet users, and its rate of usage is growing faster than that of Internet usage as a whole.
Wikipedia is an encyclopedia to which anyone with a modicum of time, articulateness, and computer skills can contribute.
Anyone can change any entry or add a new entry, and the results will immediately appear for all to see – and potentially contest.
“Wiki” is a Hawaiian root that was officially added to English in 2007 to signify something done quickly – in this case, changes in the collective body of knowledge.
Some 4.7 million “Wikipedians” have now contributed to 5.3 million entries, one-third of which are in English, with the rest in more than 250 other languages.
Moreover, there is a relatively large group of hardcore contributors: roughly 75,000 Wikipedians have made at least five contributions in any given 30-day period.
The quality of articles is uneven, as might be expected of a self-organizing process, but it is not uniformly bad.
True, topics favored by sex-starved male geeks have been elaborated in disturbingly exquisite detail, while less alluring matters often lie fallow.
Nevertheless, according to University of Chicago Law professor Cass Sunstein, Wikipedia is now cited four times more often than the Encyclopedia Britannica in US judicial decisions.
Moreover, Nature ’s 2005 evaluation of the two encyclopedias in terms of comparably developed scientific articles found that Wikipedia averaged four errors to the Britannica ’s three.
The sharp divide between producers and consumers of knowledge began only about 300 years ago, when book printers secured royal protection for their trade in the face of piracy in a rapidly expanding literary market.
The legacy of their success, copyright law, continues to impede attempts to render cyberspace a free marketplace of ideas.
Before, there were fewer readers and writers, but they were the same people, and had relatively direct access to each other’s work.
Indeed, a much smaller, slower, and more fragmented version of the Wikipedia community came into existence with the rise of universities in twelfth- and thirteenth-century Europe.
The large ornamental codices of the early Middle Ages gave way to portable “handbooks” designed for the lighter touch of a quill pen.
However, the pages of these books continued to be made of animal hide, which could easily be written over.
This often made it difficult to attribute authorship, because a text might consist of a copied lecture in which the copyist’s comments were inserted and then perhaps altered as the book passed to other hands.
Wikipedia has remedied many of those technical problems.
Any change to an entry automatically generates a historical trace, so entries can be read as what medieval scholars call a “palimpsest,” a text that has been successively overwritten.
Moreover, “talk pages” provide ample opportunity to discuss actual and possible changes.
While Wikipedians do not need to pass around copies of their text – everyone owns a virtual copy – Wikipedia ’s content policy remains deeply medieval in spirit.
That policy consists of three rules: 1) no original research; 2) a neutral point of view; and 3) verifiability.
These rules are designed for people with reference material at their disposal but no authority to evaluate it.
Such was the epistemic position of the Middle Ages, which presumed all humans to be mutually equal but subordinate to an inscrutable God.
The most one could hope for, then, was a perfectly balanced dialectic.
In the Middle Ages, this attitude spawned scholastic disputation.
In cyberspace, the same practice, often dismissed as “trolling,” remains the backbone of Wikipedia ’s quality control.
Wikipedia embodies a democratic medievalism that does not respect claims to personal expertise in the absence of verifiable sources.
To fully realize this ideal, participation in Wikipedia might be made compulsory for advanced undergraduates and Master’s degree candidates worldwide.
The expected norms of conduct of these students correspond exactly to Wikipedia ’s content policy: one is not expected to do original research, but to know where the research material is and how to argue about it.
Compulsory student participation would not only improve Wikipedia ’s already impressive collective knowledge base, but also might help curb the elitist pretensions of researchers in the global knowledge system.
Out in Eighteen Months or One Hundred Years?
BLOOMINGTON, INDIANA – Winston Churchill once said that, in wartime, truth was so precious that it needed to be surrounded by a “bodyguard of lies.”
In America’s presidential campaign – and, sadly, within Iraq itself nowadays – the Iraq War may not be surrounded by a bodyguard of lies, but it has certainly picked up a vast entourage of partisan half-truths, cynical indifference, and uninformed stubbornness.
America’s Democrats continue to argue for complete withdrawal of United States forces from Iraq within 18 months, despite the fact that no rational observer believes that Iraqi forces will by then be able to secure Iraq’s borders and face down the country’s numerous militias, which remain armed to the teeth. 
Indeed, the Democratic plan (if it can be called one) ignores Iran’s ongoing subversion of Iraq’s state institutions, which will continue unless and until they become strong enough to resist such machinations.
Moreover, Barack Obama’s insistence that Iraq has never constituted a central front in the war on terror insults the memory of tens of thousands – perhaps hundreds of thousands – of Iraqi civilians and US troops murdered by al-Qaeda’s suicide bombers since 2003.
Indeed, by 2004, the terrorists themselves regarded Iraq as the central front of their campaign. 
Nor can one be buoyed by Joseph Biden’s repeated calls for a “soft partition” of Iraq, even though the entire Iraqi political class has rejected the notion.
As for the Republicans, setting aside Sarah Palin’s talk of America’s divine mission in the war on terror, it is inconceivable that John McCain truly believes that a US presence is sustainable in Iraq into the indefinite future.
To be fair, McCain never suggested that US troops will wage 100 years of war, as some of his critics claim.
What McCain was referring to was a peaceable presence of US forces in the country for a long period, rather like their continued presence in Japan since 1945. 
Still, even assuming that the American public would tolerate such a presence, the Iraqi public would not.
America has made too many policy mistakes, US forces are too closely associated with an unpopular and incompetent occupation, and, until recently, their tactics have been too thuggish to permit talk of a permanent presence. 
While most Iraqis understand the need for US forces to be in their country for the short term, they will not abide a permanent deployment.
McCain’s advisors would do well to consider a historical precedent: the failed British attempt at World War I’s close to maintain a long-term military presence in Iraq.
Iraqi politicians have not been exempt from posturing for political gain.
The government committed a number of blunders in its negotiations on the continued presence of US troops.
Indeed, this summer it injected itself into the US elections by seeming to endorse Obama’s plan for early withdrawal.
Then again, for three consecutive years, Iraq’s national security advisor – a physician with no credentials for the job when appointed by the US occupation authority, except that he spoke tolerable English – insisted that the next year would be the last in which American troops were needed.
Iraq’s government is demanding a withdrawal timetable from the US, not because it believes that Iraqi forces will be ready to take over soon, but to burnish its nationalist credentials ahead of next year’s parliamentary elections.
Thus, it hopes to divert public attention from still non-existent basic services, continuing sectarianism, weak oil production, scant infrastructure investment, and rampant corruption and cronyism.
Whether this strategy will succeed in obscuring the government’s record of failure in the minds of voters remains to be seen.
The problem now for Iraqi and US politicians is that, to act rationally, they will need to face down elements within their own constituencies.
They must recognize that a long-term presence by US troops is out of the question, but that US combat forces will be needed in Iraq – albeit with a diminishing role – for the next five years.
Only such a presence can consolidate the palpable, but still reversible, gains made over the past year. 
Such a force is needed to continue pursuing al-Qaeda, and to counteract pro-Iranian activities.
Ending US involvement before the Iraqis can achieve these goals on their own would be disastrous for both US and Iraqi interests.
In the meantime, US forces must support Iraqi efforts to strengthen the country’s own military and security forces, while simultaneously disbanding all militias. 
Iraq’s militias will not go quietly, yet their dissolution is essential for long-term stability, itself a sine qua non for stability in the region.
When these missions are accomplished – but not sooner – US forces should withdraw from Iraq.
Bracing for Stagnation
MUMBAI – As 2015 begins, the global economy remains weak.
The United States may be seeing signs of a strengthening recovery, but the eurozone risks following Japan into recession, and emerging markets worry that their export-led growth strategies have left them vulnerable to stagnation abroad.
With few signs that this year will bring any improvement, policymakers would be wise to understand the factors underlying the global economy’s anemic performance – and the implications of continued feebleness.
In the words of Christine Lagarde, the International Monetary Fund’s managing director, we are experiencing the “new mediocre.”
The implication is that growth is unacceptably low relative to potential and that more can be done to lift it, especially given that some major economies are flirting with deflation.
Conventional policy advice urges innovative monetary interventions bearing an ever expanding array of acronyms, even as governments are admonished to spend on “obvious” needs such as infrastructure.
The need for structural reforms is acknowledged, but they are typically deemed painful, and possibly growth-reducing in the short run.
So the focus remains on monetary and fiscal stimulus – and as much of it as possible, given the deadening effects of debt overhang.
And yet, the efficacy of such policy advice remains to be seen.
It is worth noting that the Japanese checked each of these boxes over the last two decades: They held interest rates low, introduced quantitative easing, and launched massive debt-financed spending on infrastructure.
Few would argue that Japan has recovered fully from its malaise.
An emerging narrative might better explain why stimulus efforts have been unsuccessful: As former US Treasury Secretary Larry Summers has argued, the world economy may be going through a sustained period of “secular stagnation.”
The causes of the stagnation very much depend on which economist one asks.
Summers emphasizes the inadequacy of aggregate demand, exacerbated by the inability of central banks to reduce nominal interest rates below zero.
The reasons for weak aggregate demand include aging populations that consume less and the growing concentration of wealth among the very rich, whose marginal propensity to consume is small.
The economists Tyler Cowen and Robert Gordon, on the other hand, argue that the problem is on the supply side.
In their view, the years following World War II were an aberration, with industrial countries’ growth helped by post-war reconstruction, rising education levels, higher workforce participation rates (owing to the entry of women), restored global trade, increasing investment, and the diffusion of technologies such as electricity, telephones, and automobiles.
Whatever the causes, growth started to slow in the 1970s, and adverse consequences like high unemployment rates among immigrants and the young were compounded by the growing realization that governments would struggle to deliver on their promises of social security.
These promises, notes the sociologist Wolfgang Streeck, had been made in the 1960s, when economies were surging and visions of a “Great Society” seemed affordable.
Promises have since been augmented with pension hikes and old-age health-care commitments for public-sector workers.
To meet their obligations, governments needed growth.
So, from the 1970s on, they began to spend to stimulate the economy.
Because of the supply-side problems, however, the spending translated into spiraling inflation.
Price stability needed to be restored, but the spending had to be maintained.
The ultimate solution was to finance spending not with the inflation tax, but with debt: first public debt, and then, as governments cut their deficits, private-sector debt.
In 2008, these elevated debt levels – in banks, businesses, households, and governments – sparked the financial crisis.
Today, debt is making it difficult for developed countries to resume pre-2008 growth rates, let alone restore the levels of GDP that would have been attained if the subsequent Great Recession had not happened.
Meanwhile, industrial countries’ overall debt/GDP ratios are continuing to grow.
In emerging markets, slow growth in the advanced economies has shut down a traditional development path: export-led growth.
As a result, emerging markets have had to rely once again on domestic demand.
This is always a difficult task, given the temptation to over-stimulate.
The abundance of liquidity sloshing around the world – the result of developed countries’ ultra-accommodative monetary policies – has made the task more difficult still, as the smallest sign of growth in an emerging economy can attract foreign capital.
If not properly managed, these flows can precipitate a credit and asset-price boom and drive up exchange rates.
When developed-country monetary policies are eventually tightened, some of the capital is likely to depart.
Emerging markets will have to ensure that they are not vulnerable.
To be sure, the world’s economic outlook could still take a turn for the better.
The US may become the world’s engine of growth.
Declining oil prices could provide a major boost, especially to oil-importing developed economies.
Technological advances could still come to the rescue.
But, overall, there is a palpable sense of gloom in the developed world, a feeling that growth is unlikely to take off in the foreseeable future.
If secular stagnation persists, these countries will have to undertake painful structural reforms, figure out how to restructure their promises (debts, social-security commitments, and pledges to keep taxes low), and distribute the resulting burden.
After the city of Detroit filed for bankruptcy in 2013, it had to make tough choices between servicing its pensioners or its debt, keeping its museums open or its police force intact.
As 2015 begins, similar difficult decisions may become increasingly common.
Out of the Asylum
Serbia &#45;&#45; long castigated as the land whose late president, Slobodan Milošević, launched a genocide in Yugoslavia &#45;&#45; is not accustomed to finding itself lauded for safeguarding human rights.
But in one area of human rights protection, much-maligned Serbia has taken an unprecedented step that puts ahead of all the rest of Central and Eastern Europe, including states that are already members of the European Union.
In September 2006, Serbia’s Ministry of Labor, Education, and Social Affairs made it official policy to integrate into society thousands of people who had been locked away in Dickensian state institutions because they have a mental disability.
With this historic move, Serbia adopted a practice that took hold in the rich, Western countries after World War II but was never applied in the Communist bloc.
It is anathema to the concept of a free society to segregate people solely on the basis of mental disability, to ignore their most-basic human rights, to bar them from access to education and employment, to deny them the freedom to choose where and how they live and with whom they can associate.
The policy change aimed at rectifying this grim reality in Serbia came when the Ministry agreed to apply country wide a pilot project that has, since 2003, established a range of community-based support services to enable persons with intellectual disabilities to leave the institutions where they were confined and begin living lives in the wider world.
That pilot project demonstrated that people with mental disabilities are capable of living as equal citizens when they receive appropriate assistance.
Based upon the project’s success, the Ministry has committed to purchase more than 130 apartments and homes to house people brought out of institutions and to establish day services to help them cope with the complexities of life beyond the walls that once confined them.
Funding for these reforms comes from the privatization of state assets &#45;&#45; not from aid from abroad.
To Serbia’s credit, the Ministry made its policy decision knowing that the change would require belt-tightening elsewhere in its budget, but it took the action because it concluded that protecting human rights was more important than saving a few dinars.
Hopefully, Serbia’s decision will inspire the other states of Central and Eastern Europe, including states that have won membership in the European Union, to follow its lead.
It is shocking that the EU has done so little to press its members, and candidate-members, to promote community living for people with mental disabilities.
None of the new EU member-states have concrete plans or financing mechanisms to develop networks of community-based alternatives on a national scale.
While there are pockets of high quality community-based services in most of the region’s countries, tens of thousands of people with mental disabilities are still living in institutions, and most of them have no prospect of ever leaving.
* Hungary continues to segregate its most disabled citizens and spent millions of dollars on the construction of a new institutional behemoth which sits empty because it does not meet EU fire and safety standards.
* Croatia is demonstrating that deinstitutionalization is not a question of money.
The Open Society Institute committed over $2 million to assist the government in closing a large institution for people with intellectual disabilities.
But, almost a year into the negotiations, the government is still not ready to commit to concrete action.
* In Romania last year, children were dying of starvation in one institution.
The government placed the blame on local authorities; the local authorities blamed the government for allocating inadequate resources; and inmates of the institutions still look out at the world through windows that are locked and barred.
There is an urgent need to change government policies so that providing services for people with mental disabilities in the community is the norm rather than the exception.
Such services must be accessible to everyone who needs them.
And governments must reallocate resources from institutions &#45;&#45; and the bureaucracies that have a vested interest in preserving their positions &#45;&#45; to organizations that support community-based living.
It is time for the rest of Central and Eastern Europe to catch up to Serbia.
Outsourcing in Africa
In the past 40 years, advanced computers and communications have transformed one part of the world after another - first, the US and Europe, then Japan, Korea, and Taiwan, and most recently, India, China, and Eastern Europe.
Is Africa next?
Despite civil wars, malnutrition, and the anguish of the AIDS epidemic, something remarkable is happening in black Africa: the stealthy rise of a high-technology sector.
If not quite representing an African "Silicon Valley," these shoots of high-tech industry nonetheless can and must be nurtured if Africa is to thrive.
Consider what is happening on several floors of a single high-rise office building in Accra, Ghana's capital.
There some 1,500 Africans process American health-insurance claims - working around the clock, in three shifts.
The Africans speak English, type at least 50 words a minute on a computer, take data from paper claim forms supplied by US health insurers via satellite in electronic form, put it into new digital forms, and ship them back to the US.
So connected are these Africans that their forms can be reviewed - as they fill them in - by an American supervisor 8,000 miles away.
Ghana is best known for producing cocoa and gold, but today Affiliated Computer Services (ACS), a Texas company that runs the outsourcing operation, is the country's largest private employer.
African "key punchers" earn $4 to $5 a day - four times the legal minimum wage - and receive health insurance, meals, and subsidized transport.
A small number of African engineers and professionals earn much more, and receive periodic training in advanced technologies.
ACS's employees are but the first Africans to benefit from the hottest trend in the global economy: outsourcing, or the shift of service jobs from high-wage to low-wage countries.
To be sure, the number of jobs moving to Africa is tiny compared to those going to Asia, Latin America, and Eastern Europe.
But the big news is that Africa is finally competing in the economic contest that is reshaping the world economy.
Still, Africa remains burdened by severe disadvantages, not the least of which is a terrible image.
"Big corporations don't even have Africa on the map when they consider outsourcing locations," says Sambou Makalou, a native of Mali who tries to persuade US employers to shift service jobs to Africa.
"There are real opportunities for outsourcing to Africa," he says, "but there are barriers, too."
African governments also must be willing to start small: expend a lot of effort to attract pilot projects in the hope of larger employment in the future.
With sensible reforms, many barriers can be removed or at least eased.
Start with the following:
· Better Governance : African governments often boast when they simply stop the corrosive effects of corruption and irrational business regulation.
But little attention is given to the high cost of telecommunications, unreliable electrical-power systems, and the poor transport infrastructure.
• Greater Competitiveness : African leaders have been slow to realize that they must woo foreign corporations with special services, training programs for workers, and even subsidized offices.
Asian countries attract many jobs by creating "industrial parks," with more reliable services, including ultra-reliable communications networks, offered at competitive prices.
By restructuring their secondary schools and universities to train graduates with skills demanded by multinational corporations, Asian countries also create more competitive workforces.
To be sure, Africa is a far better place to do business than five years ago.
The spread of mobile telephony has revolutionized ordinary life in a continent with the world's lowest penetration of fixed-line telephones.
Satellite links have vastly improved Internet access, and a new undersea cable that runs along the coast of Africa (SAT-3) promises to improve and reduce the cost of all types of communications.
The problem is that, although Africa's economic appeal is increasing, India and China are improving more quickly, widening the gap.
African cities are increasingly finding their way onto the short lists of corporate location experts, only to lose out to Asian cities.
Africans can start winning only if they move faster.
Surprisingly, wage competitiveness is a problem.
Although Africa is the world's poorest region on average, wages in the formal economy generally exceed those paid in China and India, where government keeps basic food, housing, and transport costs relatively low through subsidies and controls.
In urban Africa, costs - for food and transport in particular - are relatively high, which forces wages up.
The supply of African professionals and skilled workers, meanwhile, is tight; shortages also drive up wages.
Indeed, an Indian software programmer typically earns less than a comparable African programmer.
Even wages for routine data-entry tasks in Africa are usually no less than those paid in south Asia.
The odds that Africa one day will receive a fair share of outsourcing jobs are improving.
But there is a risk that the region will fall further behind.
When ACS decided to expand recently, it opened a new operation in India rather than in Ghana or another African country.
The message was sobering.
Even as hundreds of similar outsourcing centers spring up in Asia, Eastern Europe, and Latin America, the Accra center remains a rarity in Africa.
That is a shame, but it need not be Africa's fate.
The Not-So-High Costs of Brexit
BRUSSELS – The United Kingdom’s vote to “Brexit” the European Union is on course to become the year’s biggest non-event.
Beyond a weaker pound and lower UK interest rates, the referendum has not had much of a lasting impact.
Financial markets wobbled for a few weeks after the referendum, but have since recovered.
Consumer spending remains unmoved.
More surprising, investment has remained consistent, despite uncertainty about Britain’s future trade relations with the EU.
Have the costs of Brexit been overblown?
Not exactly.
In fact, the UK may well end up losing the predicted 2-3% of GDP from Brexit.
Other factors will also cushion the blow of Brexit.
Over the last two decades, the UK has transformed its economy to foster unprecedented specialization in services.
In the mid-1990s, goods exports were three times as important as services exports, and the majority of British exports went to the EU.
Nowadays, the UK exports mostly services – and mostly to non-EU markets.
As a result, the internal market for goods is far less important for the UK today than it is for other EU countries.
The value-added contained in British goods exports to the EU accounts for only about 5% of GDP – several times less than for, say, Germany.
Meanwhile, Britain’s non-EU exports account for about 7% of GDP.
The shift in UK goods exports away from the EU reflects a change in the sources of economic growth, with Asia, in particular, gaining primacy.
To some extent, other EU member states have also shifted their goods exports away from Europe, but the effect has been most pronounced in the UK.
The fact that the UK now relies more heavily on access to world markets than on access to the EU’s internal market surely contributed to the Brexit vote, as it minimized the sacrifice that the UK would have to make to regain control over hot-button issues like immigration.
The belief that the UK could secure superior access to world markets on its own than as part of the EU also helped.
This is where the Brexit bet becomes riskier.
To be sure, approving trade deals will be much easier for the UK than it is for the EU, which requires agreement from 30 parliaments (including some regional ones).
The political challenges that have impeded the approval of a relatively low-profile free-trade agreement with Canada exemplify this challenge.
But the UK will also have less leverage in negotiations than the EU does, especially in dealing with large emerging economies.
Similarly, the UK does not have to fear huge changes in its ability to export services to the EU, which currently accounts for about 40% of the UK total, because the EU’s internal services market already is far from open.
But there is one exception: financial services.
And it is a big one.
As it stands, financial services account for about one-third of Britain’s total services exports and two-thirds of the overall services surplus that the UK needs to pay for its deficit on goods.
The industry’s success is the result, at least partly, of the UK’s EU membership.
The specialization of the UK economy and its external accounts toward financial services (and services in general) began when capital movements were liberalized under the internal market program of the 1990s.
It was accelerated with the introduction of the common currency, which, combined with the elimination of obstacles to cross-border capital flows and a global credit boom, fostered the concentration of many types of wholesale financial services in the City of London.
The financial sector has a natural tendency to form clusters, and London – where English is spoken, the legal system is efficient, labor markets are flexible, and the regulatory regime is relatively streamlined – offered substantial advantages.
Add to that the EU’s “passporting” system, which enables London-based banks to sell their services directly throughout the EU, and the growth of the city’s financial-services sector makes perfect sense – as does the fact that citizens of London voted overwhelmingly against Brexit.
Yet the reality is that most of the advantages that have made London into a financial-services hub will remain even after Brexit.
And the loss of passporting might be offset by the creation of subsidiaries or “bridgeheads” within the EU, such as Dublin, Frankfurt, or Paris.
London’s financial-services industry could therefore survive Brexit, though it is unlikely that it will maintain its previous vigor.
Indeed, no matter what terms the UK negotiates with the EU, it will probably have to change its growth model, probably through a modest revival of manufacturing, among other things.
Given decades of decline in British manufacturing, this would be easier said than done.
But, if the country doesn’t manage such a rebalancing, the long-term cost of Brexit might turn out to be substantially higher than current estimates.
The expansion of the financial-services industry – which creates few, but very highly paid, jobs – has contributed to rising income inequality, which has been more pronounced in the UK than elsewhere in the EU.
And inequality helped fuel the widespread frustration with globalization and the so-called “establishment elites” that carried the Brexit campaign to victory.
In this sense, one of the major economic benefits of the UK’s EU membership led the British to reject the project.
The question is whether the economic changes that Brexit will necessitate will produce the benefits for British workers that the “Leave” campaign promised.
The answer remains far from clear.
The Greening of African Technology
JOHANNESBURG – Technological innovation offers Africa huge possibilities.
That is why I joined Africa’s movers and shakers last week at a meeting of the World Economic Forum in Kigali, the capital of Rwanda.
We were there to discuss how the digital economy can propel the kind of radical change the continent needs.
At the same time, though, we had to think about some old tools that our ancestors passed down to us – namely, how to think for the long term and how to work together.
These tools are a form of technology that we need to use now, so that future generations have a chance.
Climate change is the ultimate test of whether we can use the old and new technologies to safeguard our children’s future.
Africans must take decisive action to combat the threat of global warming, by reducing greenhouse-gas emissions and by helping one another to adapt to climate change.
If we fail to make progress in these areas now, future generations will judge our inaction as expensive, unjust, and immoral.
Africa is one of the regions most vulnerable to climate change.
Yet it accounts for only 2.3% of global CO2 emissions.
That is partly because two-thirds of Africans – 621 million people – do not have access to electricity.
To meet the double challenge of climate change and this energy deficit, African countries need to help themselves and one another.
Developed countries – the major contributors to global warming – must live up to the promises they made at the COP21 climate talks in Paris last December.
Alongside reacquainting ourselves with old-tech methods of thinking about the long run and working together, new technology is essential if Africa is to cope with climate change.
Innovations in biotechnology and farming methods are needed to deal with disease, pests, and drought.
New technology can also help Africa to leapfrog over dependence on fossil fuels and into a low-carbon future.
The continent has a great opportunity to develop new low-carbon energy strategies that build resilience and support growth that benefits everyone, reducing poverty faster.
We show how this can be done in the 2015 Africa Progress Report, “Power People Planet: Seizing Africa’s Energy and Climate Opportunities.”
Renewable sources will replace fossil fuels gradually.
It cannot happen overnight.
Africa needs a judicious and dynamic energy mix.
Most of all, it needs much more energy, now: Sub-Saharan Africa as a whole, excluding South Africa, currently generates less electricity than Spain.
The state of education in Africa is one telling consequence of the continent’s energy crisis.
I have worked in education most of my life, as a teacher and minister of education in Mozambique.
Experience has taught me that a country’s schools are the key to its success and prosperity.
Yet in many African countries, 80% of primary schools do not have electricity, severely compromising the quality of instruction.
Shortages of electricity also cost lives.
Almost four in five Africans rely for cooking on solid biomass, mainly wood and charcoal.
As a result, more than 600,000 people die each year from household air pollution.
Efficient cooking stoves would save them, liberate millions of girls and women from the chore of gathering firewood, and generate wide-ranging environmental benefits.
The steps that Africa’s leaders need to take are clear.
Long-term national interest must take precedence over short-term political goals, vested interests, and political patronage.
African leaders need to root out graft, make the governance of energy utilities – some of which have been centers of corruption and inefficiency – more transparent, strengthen regulations, and increase public spending on energy infrastructure.
They also need to redirect the $21 billion spent in Africa on subsidies for loss-making utilities and electricity consumption – which mainly benefit the rich – toward connection subsidies and renewable-energy investments that deliver energy to the poor.
There is also a clear course of action for the leaders of major CO2-emitting countries.
They need to put a proper price on their emissions by taxing them, instead of continuing to subsidize them by spending billions on fossil-fuel exploration.
G-20 countries must set a timetable for phasing out such subsidies.
And rich countries need to mobilize international development finance, which can play a key role in helping African countries meet their energy needs.
The fragmented, under-resourced and ineffective system for financing climate policy has failed Africa.
It needs wholesale reform.
Unfortunately, the world’s largest emitters have shown little commitment to the United Nations’ Green Climate Fund.
Corporate leaders have a responsibility to act as well.
They should demand a price on carbon, drive innovation, and seek opportunities to fund low-carbon development across Africa.
Natural gas and renewable energy sources, such as sun, water and wind, are an opportunity, not a risk, in Africa.
Millions of energy-poor, disconnected Africans earning less than $2.50 a day constitute an energy market worth $10 billion a year.
Some hope for rapid change may be glimpsed in the fact that Africa now leads the world in adopting many new technologies.
It is bypassing earlier ones and jumping straight into the digital age.
East Africa’s M-Pesa system for transferring money via mobile phones is spurring new microfinance services, such as peer-to-peer lending.
Commodity exchanges are enabling farmers to access real-time prices.
Let us put those timeless, old-tech skills of far-sightedness and collaboration together with new technology.
If we do, the current generation of African leaders has a unique opportunity to protect future generations from a climate disaster, deliver on the promise of energy for all, and build shared prosperity.
Can the Democrats and Republicans Heal Themselves?
WASHINGTON, DC – The contests to decide the nominees of America’s two main political parties, the Democrats and the Republicans, for the presidential election are all but over.
That leaves both parties facing the challenge of reuniting for the fall campaign – a feat that will be much harder to pull off this year than it was in most other presidential election years.
Though it is mathematically impossible for Bernie Sanders to win enough pledged delegates to capture the Democratic nomination, he is staying in the race, which means that Hillary Clinton cannot yet begin her healing effort.
But winning the support of the millions of voters who fervently back Sanders poses a serious challenge.
Sanders is not simply an adversary; he leads a movement that opposes what Clinton and the “establishment” stand for.
The contest between Clinton and Barack Obama in 2008 seemed to end amicably enough.
Though Clinton stayed in the race to the end, she toned down her rhetoric against Obama as the contest wound down.
That summer, she took the unusual step of going onto the convention floor to urge the party to nominate him by acclamation.
Yet the efforts in 2008 to unite the Democratic Party weren’t as successful as the conventional wisdom suggests.
It is one thing for candidates to decide that they must be gracious in defeat. Their followers can be harder to reconcile.
After 2008, tensions between some of Clinton’s and Obama’s strongest supporters lingered for years.
One way to unite party factions is for the nominee to select his rival as his running mate.
John F. Kennedy chose his formerly bitter opponent, Lyndon B. Johnson.
(That merger didn’t go well.)
But Clinton isn’t about to make Sanders her running mate.
Sanders is temperamentally unsuited for the role of subordinate, and their policy disagreements reflect deeply held views about the role of the federal government.
Obama probably chose Clinton to be his first Secretary of State for reasons that went beyond her considerable intelligence: It was better to have her in the tent than outside it.
Even so, Clinton’s loyalty was not absolute.
In her book Hard Choices, she took some shots at his handling of Syria’s civil war, and in her campaign she has sometimes distanced herself from his policies.
Yet Obama, once Sanders is out of the race, will surely campaign hard for Clinton.
It is clear that Sanders intends to challenge Clinton on some issues to be included in the party’s 2016 policy platform.
During the nomination campaign, he managed to pull her somewhat to the left on trade, the minimum wage, and mass incarceration.
But there’s only so far she can go in the general election without losing the votes of independents.
While Sanders’s proposals are popular, particularly among young people, much of his agenda – such as transforming Obamacare into a single-payer health system – isn’t politically feasible.
Likewise, Wall Street’s banking behemoths are unlikely to be broken up.
Moreover, at this point, Clinton and Sanders are exasperated by each other.
She and her husband, Bill, are annoyed with Sanders for continuing to campaign (even though she did the same in 2008) and for not toning down his critique of her record.
Candidates rarely forget such things.
Thirty years later, Jimmy Carter still spoke bitterly about an incident at the Democrats’ convention in 1980.
Carter, the incumbent president, was reduced to chasing his defeated challenger, Edward M. Kennedy, around the stage in pursuit of the traditional photo of former rivals with arms raised and hands clasped.
Instead of a beaming show of unity, Carter got only a grudging handshake.
The main reason why it could be hard for Clinton to win over Sanders’s supporters is that a great many of them don’t like her.
A third of them have said that they won’t vote for her.
In April, only 40% of Democrats gave her high marks for being honest and trustworthy, and only 50% of Democrats rated her favorably overall.
(Obama’s favorability rating in 2008 was 60%.)
Though Republicans relish the possibility that Clinton will be indicted for routing official business through a private email server when she was Secretary of State, prosecutors would have to prove that she intended to break the law, which is unlikely.
But the email row has highlighted some of the reasons people don’t like Clinton: To put it charitably, she’s been evasive in her responses to questions about what was undeniably a reckless act.
As a result, her standing has gone down during the campaign.
Clinton has a great many fervent supporters, of course, but her presidential campaigns have both suffered from a dearth of passion.
The greatest danger she faces in the election in November is that too many Democrats simply won’t bother to vote.
Her campaign is counting on Donald Trump to unite the party, and that might well happen; but she will have her work cut out, particularly among young and first-time voters, who have overwhelmingly backed Sanders.
The Republicans will also have a problem uniting around Trump, who is now the party’s presumptive nominee.
Most elected Republicans view him as too ill-informed and bombastic to be President.