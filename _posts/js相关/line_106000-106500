The failure of Abbas’s peaceful methods has made the alternative of violence look increasingly attractive.
Hamas also emerged as the moral victor after the latest – but surely not the last – military clash.
Far from intimidating the Palestinians by bombing Gaza and mobilizing troops, the Israelis made Hamas look heroic in its resistance.
Once again, Abbas looked feeble in comparison.
This is why he desperately needed his victory at the UN.
The diplomatic promotion of Palestine offered him a lifeline.
Did the Israelis really want a resurgence of Islamist violence in Gaza, the potential collapse of peaceful politics on the West Bank, and now the right of a recognized Palestinian state to take Israel to the International Criminal Court for war crimes?
If not, why are they so ham-fisted?
It appears that Israel is making the same mistake that others have made in the past.
It has been proven repeatedly that military intimidation of civilians does not break their morale and turn them against their own leaders, however terrible the regime.
On the contrary, shared hardship usually strengthens the ties between citizens and their rulers.
So it was in bombed German cities during World War II; so it was in Vietnam; and so it is turning out to be in Gaza.
But there is another way of looking at the situation.
To call the Israeli government clumsy is to miss the point.
Israel has few illusions about Palestinians toppling their own leaders.
In fact, a strengthened Hamas may play into the hands of the Israeli hardliners currently in power.
They can point to the violent, anti-Zionist, and, yes, anti-Semitic rhetoric of radical Islamists, and argue that no deal with the Palestinians is possible.
The threat of a large stick is the only language that the natives understand.
Keeping the Palestinians divided between Islamist revolutionaries and the more business-minded Fatah suits Israeli purposes admirably.
As long as Fatah keeps things more or less under control on the West Bank, and all Hamas can do is periodically lob missiles across the Israeli border or occasionally blow up a bus, Israel can easily live with the status quo.
Those Israelis who believe that a two-state solution cannot be achieved feel vindicated; those who simply do not want two states to coexist are equally well served.
From the current Israeli government’s perspective, then, the correct strategy is to keep the Palestinian government on the West Bank weak and off balance, without quite bringing it down, and to contain Hamas with periodic displays of military power (while destroying long-range missiles that can do serious damage to Israel).
Israeli policies are not genocidal, as some commentators, not always free from anti-Semitic animus, like to claim.
Many Palestinians have been killed under Israeli rule, but their number is not even close to the number of Muslim civilians who are still being tortured, murdered, and maimed by Muslim governments every day.
Israel is, however, a semi-imperial power, using traditional colonial methods: ruling by proxy, dividing potential rebels, rewarding obeisance, and punishing opposition.
Colonial history shows that this type of rule is fragile.
Humiliation is not a firm basis for long-term stability.
There comes a point when promises of independence no longer convince anyone.
Fomenting violent resistance by demoralizing those who might still listen to reason is an invitation to disaster.
The chances of a peaceful settlement vanish.
Violence is all that is left.
It is one thing for colonies to blow up on the other side of the world.
It is quite another if the colony is just next door, and the colonial power is surrounded by countries with limited sympathy for a mess that is largely of its own making.
The Arab Spring’s Unlikely Winner
PARIS – The war in Iraq – which led in 2003 to the fall of Saddam Hussein’s regime – had one clear winner: Iran.
The United States-led military intervention resulted in the weakening of the Middle East’s Sunni regimes, America’s traditional allies, and the strengthening of America’s principal foe in the region, the Islamic Republic.
Ten years later, we may be witnessing yet another ironic outcome in the region: At least for the time being, Israel seems to be the only clear winner of the “Arab Spring” revolutions.
Most Israelis would strongly object to this interpretation.
Their regional environment has become much more unstable and unpredictable.
Only a few days ago, Israel’s Iron Dome missile-defense system intercepted a rocket fired from Sinai that was aimed at the port of Eilat.
In contrast to the past, no Israeli border is now secure, especially the long frontier with Egypt.
No implicit alliance can be taken for granted.
All scenarios are open.
Can Israel remain an oasis of stability, security, modernity, and economic growth in such a volatile environment?
The answer, of course, is no.
Israel may be tempted to regard itself as some kind of latter-day Noah’s ark, but it is not.
Tel Aviv has become a cross between San Francisco, Singapore, and São Paulo, but it is still less than 300 kilometers from Damascus.
For the pessimists (or realists, depending on your perspective), Israel must remain on maximum alert to minimize the risks that it faces.
Above all, many Israelis (if not most) believe that this is no time to be imaginative and daring.
The resumption of the peace process with the Palestinian Authority can be only a fig leaf.
Israel simply cannot ignore the Americans in the way that the Egyptian army has as it massacres its Islamist opponents.
But a very different reading of the current situation is possible.
What started as a revolution in the eighteenth-century meaning of the term is becoming a reproduction of the religious wars that ravaged Europe from 1524 to 1648, pitting Catholics and Protestants against each other in the same way that Sunnis and Shia are pitted against each other today.
(In Egypt, however, we are seeing simply the return of a military police state.)
One may disagree with this Euro-centric interpretation, but what is clear is that the Muslim Middle East will be too preoccupied with internecine struggle to worry about the Palestinians or the existence of Israel.
War with Jews or Christians has necessarily taken a back seat (except where, as in Egypt and Syria, Christian minorities are perceived to be allied with the regime).
In some cases, there is explicit cooperation with Israel.
Because it is fighting for its own survival in a highly challenging environment, the Jordanian regime needs Israel’s security collaboration.
Indeed, Israeli and Jordanian forces are now working together to secure their respective borders against infiltration by jihadists from Iraq or Syria, while Egypt and Israel now share the same objective in Sinai.
So the paradox of the Arab revolutions is that they have contributed to Israel’s integration as a strategic partner (for some countries) in the region.
At this point, more Arab lives have been lost in Syria’s civil war alone than in all of the Arab-Israeli wars combined.
Of course, one should not draw the wrong conclusions from this.
Israel may have become, more than ever, a key strategic partner for some Arab regimes, or a de facto ally against Iran (as it is for Saudi Arabia).
But this does not imply that Israel’s neighbors have resigned themselves, in emotional terms, to its continued existence in their midst.
Nor does it mean that Israel can do whatever it wants, whenever and wherever it wants.
On the contrary, the Israeli government should not use the region’s turmoil as justification for doing nothing to resolve the conflict with the Palestinians.
Current conditions, though admittedly confusing, can be seen as opening a window of opportunity – a moment to consider making serious sacrifices for the sake of long-term survival.
Israel should be addressing the Arab world in the following terms: “You may not like me, and you may never like me, but I am not – and never should have been – your first concern.
Now it is clear that you have other priorities to worry about.”
The Arab quagmire may not be creating conditions for peace and reconciliation between Israelis and Palestinians.
But it has turned the “strategic truce” favored by many Arab leaders into the only conceivable alternative.
Arabs cannot be at war with themselves and with Israel at the same time.
The chaotic events unfolding in the Middle East will – and should – change the approach and perceptions of the protagonists.
Short-term considerations will not suffice.
Israeli leaders must adjust their long-term strategic thinking to the new Middle East that ultimately emerges from the current disarray.
That means not exploiting today’s opportunity to build more settlements on Palestinian land, or to expand existing ones, as Binyamin Netanyahu’s government appears determined to do.
Israel may well be the current winner in the Arab Spring; but, if it is wise, it will leave the spoils of victory on the ground.
Israel’s Wrong Friends
JERUSALEM – Israel has been welcoming some rather peculiar visitors of late.
The Dutch populist, Geert Wilders, is a frequent caller, telling sympathetic audiences that Israel is on the front line of the Western war against Islam.
And, in December, a delegation of European far-right politicians toured Jewish settlements on the occupied West Bank, pleasing their hosts by reassuring them that this was “Jewish land.”
Some of these “friends of Israel” represent political parties whose supporters, to put it mildly, have not traditionally been noted for their fraternal feelings towards Jews.
Heinz-Christian Strache, for example, leads the Freedom Party of Austria, which began, under its late leader, Jörg Haider, by actively courting former Nazis.
“More strength for our Viennese blood,” one of his election slogans, gives an idea of Strache’s typical tone.
His Belgian colleague, Filip Dewinter, represents a Flemish nationalist party tainted by wartime collaboration with the Nazis.
To be sure, nowadays even right-wing politicians in Europe are careful not to sound openly anti-Semitic.
Wilders, for one, is ostentatiously philosemitic, and all the New Rightists like to stress the importance of what they call “Judeo-Christian values,” which must be defended against “Islamofascism.”
Leftist and liberal critics of Israeli politics like to point out that anti-Zionism is not the same thing as anti-Semitism.
But it is just as true that being a friend of Israel is not necessarily the same thing as being a friend of the Jews.
Richard Nixon, for example, said of Jews that “you can’t trust the bastards,” but was a great admirer of Israel.
And, of course, the last 2,000 years have shown that anti-Semitism is perfectly compatible with the worship of a Jew called Jesus of Nazareth.
In the United States, some of the fiercest defenders of hardline Zionism are evangelical Christians who firmly believe that Jews who refuse to convert to Christianity will one day face terrible retribution.
Sometimes, the wrong friends can be useful.
When Theodor Herzl was making the rounds of Europe at the end of the nineteenth century, trying to gain support for the establishment of a state for the Jews, he was often rebuffed by rich and powerful Jewish grandees, who saw him as a troublemaker.
Instead, he found eager supporters among pious Protestants, for whom Jews belonged in their own holy land rather than in Europe.
Once the Jewish state was established, the earliest European friends of Israel were often people on the left, who admired the communal life on the kibbutzim, and saw Israel as a great socialist experiment, led by wise old left-wing idealists, such as David Ben-Gurion.
Residual guilt about the Holocaust bolstered this attitude.
Things began to change after the 1967 Six Day War, and even more after the 1973 “Yom Kippur” war, when it became clear that Israel was not going to let go of the Palestinian territories that it had conquered.
Later, when Israel began to build settlements all over the occupied territories, admiration even turned into active hostility from Europe’s left.
To many people on the right, however, the very things deplored by the European (and Israeli) left became reasons to admire Israel.
These new friends liked the ruthless use of force, the ethnic nationalism, the continued humiliation of the Palestinians.
Keen to revive a more militant form of nationalism in their own countries, politicians like Strache, Wilders, and Dewinter see Israel as a kind of model – a model discredited for a long time in Europe, owing to bad memories of fascism and Nazism.
Indeed, anti-Zionist leftists frequently attempt to discredit Israel by comparing its actions in Gaza and the West Bank to Nazi atrocities.
This is a cheap trick, aimed to give maximum offense.
Contrary to what the Nobel Prize-winning author José Saramago once said, the Israeli army’s attacks in Gaza are not comparable in any way to Auschwitz.
But the view, espoused by Israel’s new right-wing friends, that Israel is on the front line against Islamic fascism, is equally mendacious.
By comparing Islam in general – not only Islamist terrorism – to fascism, as the right-wing populists do, and to suggest that Europe faces a threat comparable to the Nazis, is not just wrong, but dangerous.
For, if it were true, any and all measures taken against Muslims, however brutal, would be justified, and Israel would indeed be a frontline state, resisting “Islamofacism” to prevent another Auschwitz.
This is certainly how many Israeli right-wing politicians explain things.
And they find eager parrots among some of Europe’s most retrograde political forces.
It is a view that carries the grave implication that a peaceful solution of the Israeli-Palestinian conflict is almost impossible.
The longer Israel, cheered on by the wrong European friends, continues to humiliate the Palestinians and occupy their lands, the more likely it will be that hatred and violence will stand in the way of compromise, without which there can be no peace.
There is another potential consequence, however.
False analogies with the past trivialize history.
If the Israelis, or the Palestinians, are like Nazis, then the horror of what the real Nazis did has been greatly diminished.
But exploiting history to justify current violence will not work forever.
Once people stop believing that Israel is defending the West against fascism, Israel will be blamed for all the violence in the Middle East.
And Jews everywhere else will be blamed by association.
In short, the wrong friends of Israel are even worse friends of the Jewish people.
Israel Votes for Violence
War and violence always have a direct effect on elections.
Wars account for dramatic shifts in voter preferences, and radical leaders and parties often poll much higher after a round of sharp violence than in normal times.
Minority ethnic groups are therefore often able to sway the balance of power between major competing forces. 
This appears to have been precisely what has happened in Israel’s recent election.
Benjamin Netanyahu’s right-wing Likud Party and the even harder right Avigdor Lieberman and his Yisrael Beiteinu (Israel is Our Home) party achieved a dominant result that saw Labor, the dominant party throughout Israel’s history, consigned to a lowly fourth place.
Throughout the campaign, Israeli leaders competed over who would deal more firmly (read: violently) with the Palestinians.
In the aftermath of Israel’s assault on Gaza, Palestinians hoped that Israel would choose a leader who would focus on the need to end the suffering, lift the siege, and begin rebuilding.
It appears that just the opposite has happened.
The last time that Israeli elections were so obviously affected by violence was in 1996, when polling results shifted wildly in the run-up to the vote, finally allowing Netanyahu a razor-thin win over acting Prime Minister Shimon Peres.
Competing against an older Peres (who had taken over after the assassination of Yitzhak Rabin) Netanyahu dyed his hair white to appear more mature, and then took advantage of a badly handled mini-war and the anger of Israel’s Arab voters.
Now Peres is Israel’s president, while Netanyahu heads Likud.
But not much has changed: badly handled wars, incomplete peace talks, and a boycott by Israel’s Arab voters made this 2009 election seem almost like a carbon copy of 1996, when Rabin’s assassination ended the Palestinian-Israeli talks at a crucial time and Peres’ ill-advised war on South Lebanon reduced his large lead almost to a tie with Netanyahu.
The anger of northern Israel’s Arab citizens at the killing of their brethren across the border led to a boycott that cost Peres the few thousand votes he needed to win.
Israel’s 2009 election is similar in many ways.
It follows two controversial wars (although the current nominees were not directly involved in the 2006 war with Hezbollah).
It also follows serious negotiations between Israeli Prime Minister Ehud Olmert and Palestinian President Mahmoud Abbas, which are said to have moved both sides much closer to each other.
But wars and violence move electorates to the hawkish right, and Israel’s operation in Gaza was no exception.
Many Palestinian citizens of Israel, disgusted by the large-scale casualties inflicted on their brethren – and believing that to vote would mean to endorse the political system responsible for the carnage – stayed home once again.
The most important element now is the new administration in the United States.
The decisive victory of a candidate who opposed the Iraq war and favors direct talks with Iran will no doubt have a major influence on US-Israel relations and the peace process.
The appointment of George Mitchell, who opposes Israel’s West Bank settlements, and Mitchell’s decision to open an office in Jerusalem, speaks volumes about what the new Israeli government should expect from the Obama administration.
The Arab world is also in a state of flux after an emotional 22 days of Israel’s televised bombardment of Gaza.
Millions of Arabs throughout the Middle East took to the streets, so angered by the inability of anyone to stop the bloodshed that a huge schism has been created.
Egypt, Jordan, Saudi Arabia, and the Palestinian Authority beat a hasty retreat from their moderate and accommodating positions.
The major stumbling block for the world in trying to relieve the suffering in Gaza is how to finesse the biggest bloc in the Palestinian Legislative Council, Ismael Hanieh’s Islamist list of Reform and Change.
This challenge has become more interesting with European countries’ willingness to deal with a united Palestinian government that includes Hamas’ Hanieh.
President Barack Obama’s pragmatism and refusal to embrace the Bush administration’s “war on terror” will also be a key determinant of the outcome.
But, beyond band-aid solutions for the deep injuries inflicted on Gaza, Palestinians’ biggest concern is to ensure that Israel’s attempt to split Gaza from the West Bank does not become permanent.
Egypt and the Palestinian Authority have been made to look bad in the eyes of the Arab world, owing to their refusal to make Egypt responsible for Gaza and possibly Jordan for the West Bank.
But that proposal was a trap that would have destroyed the possibility of an independent, contiguous Palestinian state.
Despite the election results, Palestinians still hope to re-establish momentum in resolving the remaining points of disagreement with Israel.
While an international consensus now supports a two-state solution, settling the status of Jerusalem and of Palestinian refugees will be the main obstacles facing the two sides.
The only hope now for resuming negotiations is the old “only Nixon could open up China” argument, meaning that only a truly hard-right Israeli leader would have the credibility to make peace with the Palestinians.
But it is now clear to historians that Richard Nixon was determined to make his overture to China from the moment he began his presidency.
Sadly, the signs that any of Israel’s potential prime ministers are truly prepared to take so bold a step are few.
Is Regulation Really for Sale?
LONDON – Relationships between London banks and their regulators are not especially warm just now.
The latest bonus rules issued by the Committee of European Banking Supervisors (soon to morph into the European Banking Authority), have left those sensitive souls on the trading floors feeling rather bruised and unloved. In the future, 70% of their bonuses will have to be deferred.
Imagine living on only $3 million a year, with the other $7 million paid only if the profits you earned turn out to be real?
It is a shocking turn of events.
Yet, in narratives of the financial crisis, regulatory capture is often an important part of the story.
Will Hutton, a prominent British commentator, has described the Financial Services Authority, which I chaired from 1997-2003 (the date things began to go wrong!) as a trade association for the financial sector.
Even more aggressive criticism has been advanced about American regulators – and, indeed, about Congress – alleging that they were in the pockets of investment banks, hedge funds, and anyone else with lots of money to spend on Capitol Hill.
How plausible is this argument?
Can benign regulation really be bought?
When I was a regulator, I would certainly have denied it.
I had never worked in the financial industry, and knew few people who did. (Full disclosure: I am now an independent Director of Morgan Stanley.)
My successors have all come from the financial sector, however, which, until recently, was regarded as a sign that they were street-wise.
Now we are not so sure.
The consultation processes on rules and regulations were highly structured, and much effort was devoted to ensuring balanced representations from providers and users of financial services.
We funded research for a Consumer Panel in an effort to ensure “equality of arms.”
Of course, regulatory staff had more informal links with the industry than with consumers.
But that is inevitable in any country.
The industry’s voice was more often heard in Parliament as well.
The most effective lobbyists were Independent Financial Advisers, who seemed to be especially active in the local Conservative Party associations.
Goldman Sachs could learn a lot from their tactics!
I have no first-hand knowledge of the legislative process in the United States.
But, as an outsider, I am amazed at the apparent intensity of lobbying, and at the amounts of money that firms and their associations spend.
Is it effective?
The media seem to think so, though with relations between government and industry still only a notch below open warfare, it is difficult to be sure.
An intriguing sidelight on the relationship between Congress and business is provided in a study by Ahmed Tahoun of the London School of Economics on “The role of stock ownership by US members of Congress on the market for political favors.”
Tahoun analyzed the relationship between stock owned by congressmen and contributions their political campaigns by the relevant firms, and found a powerful positive association.
In particular, Tahoun’s research shows that US congressmen systematically invest more in firms that favor their own party, and that when they sell stock, firms stop contributing to their campaigns.
Moreover, firms with more stock ownership by politicians tend to win more and bigger government contracts.
The data are not from financial firms alone, and Tahoun has not disaggregated them by sector.
But the results are of interest nonetheless. They suggest a less-than-healthy relationship between lawmakers’ political and pecuniary interests.
Regulators are typically not subject to those temptations.
They are not normally allowed to own stock in financial firms (at least in the jurisdictions that I know).
But can they nonetheless be captured?
I see two potential grounds for concern.
The first is the revolving door between the industry and regulatory bodies.
This is more prevalent in the US, where regulators’ salaries are very low, especially in the Securities and Exchange Commission and the Commodity Futures Trading Commission.
Turnover among senior – and not so senior – people in these agencies is very high.
The Fed folk are paid a little better, and stay rather longer.
The United Kingdom pays its regulators more, but there is still a lot of “in and out” activity, and more than there used to be.
Singapore and Hong Kong have a different model.
Their regulators are given market-related compensation packages, and continuity of senior staff is more effectively maintained.
My view is that the Asian financial centers have it right.
The second concern is what one might call intellectual capture.
While I would strongly argue that the FSA in my day did not favor firms unduly, it is perhaps true that we – and in this we were exactly like US regulators – were inclined to believe that markets were generally efficient.
If willing buyers and willing sellers were trading claims happily, then, as long as they were “professional” investors, there was no legitimate reason to interfere in their markets.
These people were “consenting adults in private,” and the state should avert its gaze.
We now know that some of these market emperors had no clothes, and that their activities, far from benign, could result in severe financial instability and generate serious losses for taxpayers, not to mention precipitating a global recession.
That has been a grave lesson for regulators and central banks.
So intellectual capture is a charge hard to refute.
But were regulators surrogate lobbyists for the financial industry?
I do not think so, and to argue as much devalues the efforts of many overworked and underpaid public servants around the world.
Japan’s Nationalist Turn
TOKYO – Japan has been in the news lately, owing to its dispute with China over six square kilometers of barren islets in the East China Sea that Japan calls the Senkakus and China calls the Diaoyu Islands.
The rival claims date back to the late nineteenth century, but the recent flare-up, which led to widespread anti-Japanese demonstrations in China, started in September when Japan’s government purchased three of the tiny islets from their private Japanese owner.
Prime Minister Yoshihiko Noda has said that he decided to purchase the islands for the Japanese central government to prevent Tokyo Governor Shintaro Ishihara from purchasing them with municipal funds.
Ishihara, who has since resigned from office to launch a new political party, is well known for nationalist provocation, and Noda feared that he would try to occupy the islands or find other ways to use them to provoke China and whip up popular support in Japan.
Top Chinese officials, however, did not accept Noda’s explanation, and interpreted the purchase as proof that Japan is trying to disrupt the status quo.
In May 1972, when the United States returned the Okinawa Prefecture to Japan, the transfer included the Senkaku Islands, which the US had administered from Okinawa.
A few months later, when China and Japan normalized their post-World War II relations, Japanese Prime Minister Kakuei Tanaka asked Chinese Premier Zhou Enlai about the Senkakus, and was told that rather than let the dispute delay normalization, the issue should be left for future generations.
So both countries maintained their claims to sovereignty.
Though Japan had administrative control, Chinese ships would occasionally enter Japanese waters to assert their legal position.
For China, this was the status quo that Japan upended in September.
In Beijing recently, Chinese analysts told me that they believe that Japan is entering a period of right-wing militaristic nationalism, and that purchasing the islands was a deliberate effort to begin eroding the post-WWII settlement.
While Chinese rhetoric is overheated, there is certainly a rightward shift in mood in Japan, though it would be difficult to describe it as militaristic.
A large group of students at Waseda University recently were polled on their attitudes toward the military.
While a significant number expressed a desire for Japan to improve its ability to defend itself, an overwhelming majority rejected the idea of developing nuclear arms and supported continued reliance on the US-Japan Security Treaty.
As one young professional told me, “we are interested in conservative nationalism, not militaristic nationalism.
No one wants to return to the 1930’s.”
And, of course, Japan’s Self Defense Forces are professional and under full civilian control.
Japan faces parliamentary elections in the near future, by August 2013 at the latest, but perhaps as early as the start of the year.
According to public-opinion polls, the governing Democratic Party of Japan, which came to power in 2009, is likely to be replaced by the Liberal Democratic Party, whose president, Shinzo Abe, would become prime minister – a position he has already held.
Abe has a reputation as a nationalist, and recently visited the Yasukuni Shrine, a Tokyo war memorial that is controversial in China and Korea.
In addition, Toru Hashimoto, the young mayor of Osaka, Japan’s second-largest city, has built a new party and also developed a reputation as a nationalist.
Japanese politics, it seems, is showing signs of two decades of low economic growth, which has led to fiscal problems and a more inward-looking attitude among younger people.
Undergraduate enrollment of Japanese students in US universities has fallen by more than 50% since 2000.
Thirty years ago, Harvard professor Ezra Vogel published Japan as Number 1: Lessons for America, a book that celebrated Japan’s manufacturing-fueled rise to become the world’s second-largest economy.
Recently, Vogel has described Japan’s political system as “an absolute mess,” with prime ministers replaced almost every year and the youngest generation’s expectations sapped by years of deflation.
Yoichi Funabashi, former Editor-in-Chief of the newspaper Asahi Shimbun, also is worried: “There’s a sense in Japan that we are unprepared to be a tough, competitive player in this global world.”
Despite these problems, Japan still has remarkable strengths.
Although China surpassed Japan as the world’s second-largest economy two years ago, Japan is a comfortable society with a much higher per capita income.
It has impressive universities and a high education level, well- managed global companies, and a strong work ethic.
It is a society that has reinvented itself twice in less than 200 years – in the nineteenth-century Meiji Restoration and after defeat in 1945.
Some analysts hoped that last year’s earthquake, tsunami, and nuclear catastrophe would spark a third effort at national reinvention, but that has not yet occurred.
Many younger Japanese have told me that they are “fed up” with stagnation and drift.
When asked about the rightward trend in politics, some young Diet (parliament) members said they hoped that it might produce a realignment among political parties that would lead to a more stable and effective national government.
If a moderate nationalism is harnessed to the yoke of political reform, the results could be good for Japan – and for the rest of the world.
But if Japan’s deepening nationalist mood leads to symbolic and populist positions that win votes at home but antagonize its neighbors, both Japan and the world will be worse off.
What happens in Japanese politics over the coming months will ripple far beyond the country’s shores.
Is Russia’s National Character Authoritarian?
NEW HAVEN – Russia’s aggression against Ukraine and the Russian public’s acquiescence in direct government control of news media have many people wondering if Russians are predisposed to authoritarianism.
It seems like a sensible question.
But I have learned from experience that we have to be very careful about drawing conclusions about national character from isolated events.
In 1989, I was invited to an economic conference in Moscow, then in the Soviet Union, sponsored jointly by the Soviet think tank IMEMO (now called the Primakov Institute of World Economy and International Relations) and the United States’ National Bureau of Economic Research.
Such joint conferences were part of a historic breakthrough, resulting from a thaw in US-Soviet relations.
The Soviet economists seemed enthusiastic about a transition to a market economy, and I was struck by how openly they spoke to us during coffee breaks or at dinner.
But, significantly, the Soviets expressed serious doubts at the conference that their public could ever allow free markets to function.
Individual market actions, they said, would strike the public as wrong, unfair, and intolerable.
I met one of the younger IMEMO economists, Maxim Boycko, and was impressed by his sincerity and intellect. (He later became Russian Deputy Prime Minister and Minister of State Property under President Boris Yeltsin, left the Russian government before Vladimir Putin came to power, and recently came to the US, where he is lecturer in economics at Harvard and Brown.)
We had a lively conversation.
I told him that many Americans also think capitalist practices are unfair.
Were attitudes in the two countries really different?
It appears no one had ever conducted a survey about such attitudes.
In 1989, however, it was possible to do just that.
We decided on the spot to carry out a careful questionnaire survey comparing attitudes toward free markets.
After laboring over subtleties of translation and possible extraneous associations that might bias respondents’ answers, we arrived at a set of virtually identical questionnaires in both Russian and English.
We administered the survey (with the help of Ukrainian survey expert Vladimir Korobov) in New York and Moscow in 1990 and published our results in the American Economic Review in 1991 and in the IMEMO journal MEIMO in 1992.
The differences we found in attitudes toward free markets were often small, and it was hard to make sense of them in terms of authoritarianism and democracy.
For example, we asked, “On a holiday, when there is a great demand for flowers, their prices usually go up.
Is it fair for flower sellers to raise their prices like this?”
Just as the IMEMO economists predicted, most (66%) of those who answered this question in Moscow thought it was unfair.
But there was a surprise: New York yielded virtually identical results (68% thought it was unfair).
So we decided last year to find out whether the same similarity between Moscow and New York persists today, or whether, given the revival of authoritarianism in Russia today, attitudes toward markets there had become more negative.
We administered the identical questionnaire in the two cities in 2015. We presented the results at the American Economic Association’s annual meeting this January.
In the flower question, we found very little change in attitude in Moscow (67% said raising prices on holidays was unfair).
In New York, by contrast, public opinion had become somewhat more pro-market (55% said raising prices was unfair).
For our 2015 survey, Boycko and I decided to examine attitudes toward democracy itself.
Fortunately, we were able to find a study conducted in 1990 by the political scientists James Gibson, Raymond Duch, and Kent Tedin (GDT), which asked questions in Moscow that, like ours, got past slogans to assess basic values.
Though they did not do a comparison with New York, we thought to add it in 2015.
Surprisingly, most of the results concerning democratic values do not support the idea that Russians prefer strong authoritarian government.
For example, GDT asked in 1990 if respondents agreed with the statement “The press should be protected by the law from persecution by the government.”
Only 2% disagreed in 1990; in 2015, Russians were substantially more likely to disagree (20% did), suggesting a decline in democratic values.
But the real surprise is our 2015 results in New York for the same question: 27% disagreed.
New Yorkers appear less supportive of a free press than Muscovites today!
The biggest difference of all between Moscow and New York came from the GDT statement “It is better to live in a society with strict order than to allow people so much freedom that they can bring destruction to the society.”
In 1990, 67% of the Muscovites agreed, and 76% agreed in 2015, while in New York in 2015 only 36% agreed.
Maybe this is important, but it is an outlier – the most extreme difference between Moscow and New York in our entire survey.
Overall, while there are differences, the results do not lend strong support to the idea that recent events have a simple explanation in terms of differences in deep attitudes toward free markets or authoritarianism.
It’s wrong to write Russia off as fundamentally different from the West.
In 1991, we concluded that the Russian national character was not an obstacle to creating a market economy in Russia – and were proven right.
We hope we are right again, and that national character will not prevent Russia from becoming a truly democratic society someday.
Is Russia’s Economic Crisis Over?
MOSCOW – Has Russia’s economic crisis ended?
That depends on who you ask.
Ask Prime Minister Vladimir Putin, or any official of his United Russia party, and you will be told, “Of course it is over.”
They will even produce proof in the form of an unemployment rate that does not rise, unprecedented increases in pensions, and strong growth in construction and metal-working.
Of course, all these comparisons are made with how things stood last month rather than with the country’s pre-crisis economic performance.
Then there is another “miracle” that the government is starting to trumpet, one discovered in August 2009: an increase in Russia’s population.
Unfortunately, in no month before or since have births outpaced deaths.
Ask a member of the opposition whether the crisis has ended, and you will be told that it is only just beginning.
Gazprom’s production is falling at a dizzying pace; the country’s single-industry “mono-towns” are dying.
There is truth in both views about the state of Russia’s economy, but because the government controls all the major television channels, it is succeeding in enforcing its view of the situation.
Indeed, the opposition has access only to a few newspapers and radio stations, leaving the Internet the sole remaining space of freedom in Russia.
But there you can read very pessimistic estimates of the country’s economic future.
So the Kremlin blinds its citizens with rosy scenarios, while the Internet over-dramatizes reality.
The truth, it is clear, is somewhere in the middle.
What is beyond dispute is that Russia’s economic health depends on external factors.
But, outside Russia, no responsible economists can even begin to say whether the crisis is truly over.
They know that relatively calm markets do not mean that strong economic growth is around the corner.
Russia ’s economy is now hostage to potential global growth.
It is clear why: the state budget depends almost totally on energy prices.
Now that oil price has reached $80 per barrel, Russia’s central bank can start buying foreign currency again.
Gold and foreign currency reserves are increasing, implying appreciation of the ruble.
But Russia’s budget for 2010 is still headed for a serious deficit, owing to high spending.
The rapid income growth of the early Putin years is a thing of the past.
While it persisted, expenditures swelled but were manageable – until, suddenly, energy prices collapsed.
The Kremlin, devoted to its key fetish –Putin’s approval ratings – proved completely unprepared to curtail public spending in the wake of falling state revenues.
The budget deficit, unsurprisingly, ballooned.
The late Yegor Gaidar, Russia’s first pro-reform prime minister, warned the government about the consequences of inflated oil prices, repeatedly arguing that excessive spending growth would undermine the political will for retrenchment when it became necessary.
Gaidar died last year, his unheeded warnings having come true, proving once again that no man is ever a successful prophet in his own country.
In recent months, Russia’s government finally brought inflation down to 8%.
Sometimes this is presented as another milestone demonstrating that the crisis is near its end.
But that is wrong.
Inflation fell as a result of the crisis, which reversed the direction of capital flows.
Whereas inward investment reached $20 billion in 2008, capital outflows totaled $20 billion in 2009.
The central bank buys less foreign currency, and thus issues fewer rubles, reducing inflation.
A far more inertial indicator is unemployment, which experts predict will grow in 2010.
The problem is that Russian labor is less mobile than in the Europe and the United States.
Russians prefer lower wages – or simply waiting with no wages at all – to moving in search of a new job.
The situation at carmaker AUTOVaz is a striking example.
Last year, output fell to 300,000 cars, from 800,000 in 2008.
Such a dramatic fall in sales would normally require massive layoffs or lower wages.
Yet, of the company’s 102,000 employees, only 27 favored layoffs.
As a result, wages were cut by half.
The state, which is seeking to rescue the domestic automobile industry, allocated to the firm more credits through state-owned banks.
But how long can such a situation last?
One day, it will no longer be possible to disguise unemployment through shorter working weeks, forced leaves of absence, and decreases in wages.
When that happens – and there is a strong probability that it will happen next year – the crisis will only just be beginning for Russia.
All over the world – in the US, Europe, and China – stimulus programs have paid off, as expected.
But it is not yet certain whether the engine of the global economy will be able to run without additional liquidity, possibly undermining fiscal stability worldwide.
Elsewhere, that will become clear in the first half of 2010; in Russia, signs of recovery, if they appear at all, will lag well behind the rest of the world.
Is Sadness a Disease?
NEW YORK – Sadness is one of the small number of human emotions that have been recognized in all societies and in all time periods.
Some of the earliest known epics, such as The Iliad and Gilgamesh , feature protagonists’ intense sadness after the loss of close comrades.
Likewise, anthropological work across a great range of societies clearly describes emotions of sadness that develop in response to frustration in love, humiliation by rivals, or the inability to achieve valued cultural goals.
Even primates display physiological and behavioral signs after losses that are unmistakably similar to sadness among humans.
There is little doubt that evolution designed people to have a propensity to become sad after such situations.
Depressive mental disorders also have been known for as long as written records have been kept.
Writing in the fifth century b.c., Hippocrates provided the first known definition of melancholia (what we now call “depression”) as a distinct disorder: “If fear or sadness last for a long time it is melancholia.”
The symptoms that Hippocrates associated with melancholic disorder – “aversion to food, despondency, sleeplessness, irritability, restlessness” – are remarkably similar to those contained in modern definitions of depressive disorder.
Like Hippocrates, physicians throughout history have recognized that the symptoms of normal sadness and depressive disorder were similar.
Depressive disorders differed from normal reactions because they either arose in the absence of situations that would normally produce sadness or were of disproportionate magnitude or duration relative to whatever cause provoked them.
Such conditions indicated that something was wrong with the individual, not with his environment.
Traditional psychiatry thus adopted a contextual approach to diagnosing a depressive disorder.
Whether a condition was diagnosed as disordered depended not just on the symptoms, which might be similar in normal sadness, and not just on the condition’s severity, for normal sadness can be severe and disordered sadness moderate, but on the degree to which the symptoms were an understandable response to circumstances.
The distinction between contextually appropriate sadness and depressive disorders remained largely unchanged for two and a half millennia.
But the psychiatric profession abandoned this distinction in 1980, when it published the third edition of its official diagnostic manual, the DSM-III.
The definition of Major Depressive Disorder (MDD) became purely symptom-based.
All conditions that display five or more of nine symptoms – including low mood, lack of pleasure, sleep and appetite difficulties, inability to concentrate, and fatigue – over a two-week period are now considered depressive disorders.
The sole exception is &quot;uncomplicated&quot; grief-related depression.
Symptoms otherwise meeting the DSM criteria are not considered disorders if they arise after the death of an intimate, do not last more than two months, and do not include certain particularly severe symptoms.
Yet, comparable symptoms that arise after, say, dissolution of a romantic relationship, loss of a job, or diagnosis of a life-threatening illness are not excluded from diagnosis of disorders.
The DSM-III’s confusion of normal intense sadness and depressive mental disorder, which persists to the present, emerged inadvertently from psychiatry’s response to challenges to the profession during the 1970’s.
A powerful group of research psychiatrists was dissatisfied with the definitions of depression and other common mental disorders in the earlier, psychoanalytically-influenced diagnostic manuals.
These earlier definitions separated feelings of sadness proportionate to contextual loss from those excessive to their contexts, and defined only the latter as disordered.
But they also assumed that unconscious, unresolved psychological conflicts caused depression.
In order to abolish this unwarranted psychoanalytic assumption, the researchers abandoned the attempt to distinguish natural from disordered conditions by context or etiology and assumed that all conditions that met the symptom-based criteria were disordered.
The new definition of depression has resulted in extensive medicalization of sadness.
Parents whose child is seriously ill, spouses who discover their partners’ extramarital affairs, or workers unexpectedly fired from valued jobs are defined as suffering mental disorders if they develop enough symptoms to meet the DSM criteria.
This is so even if the symptoms disappear as soon as the child recovers, the spouses reconcile, or a new job is found.
The medicalization of sadness has proven to be of tremendous benefit to the mental health and medical professions.
Millions of people now seek professional help for conditions that fall under the medicalized, overly inclusive definition of depression.
Indeed, depression is now the most commonly diagnosed condition in outpatient psychiatric treatment.
The medicalization of depression has proven to be even more profitable for pharmaceutical companies, whose sales of anti-depressant medications have soared.
While it is impossible to know what proportion of these people are experiencing normal sadness that would go away with the passage of time or a change in social context, it is almost certainly very high.
It would not be hard for psychiatry to develop a more adequate definition of depressive disorder that de-medicalizes natural emotions of sadness.
The diagnostic criteria could simply extend the current bereavement exclusion to cover conditions that develop after other losses and that are not especially severe or enduring.
Such a change would acknowledge what humans have always recognized: intense sadness after loss is a painful and perhaps inevitable aspect of the human condition, but it is not necessarily a mental disorder.
Is South Korea Turning Japanese?
SEOUL – South Korea’s recent economic performance has been disappointing.
After 40 years of astonishing 7.9% annual GDP growth, the average growth rate dropped to 4.1% in 2000-2010, and has stood at a mere 3% since 2011.
This has many wondering whether South Korea is headed for the kind of protracted deflation and stagnation that characterized Japan’s so-called “lost decades,” from which it is just beginning to emerge.
The similarities between South Korea today and Japan 20 years ago are undeniable.
And, in fact, on economic matters, South Korea has, for better or worse, often followed Japan’s example.
In this case, Japan’s example can save South Korea – if, that is, South Korea’s leaders take it as a lesson in what not to do.
Japan’s woes are rooted in real-estate and equity bubbles, which were fueled by monetary expansion aimed at stimulating domestic demand after the 1985 Plaza Accord drove up the yen’s value and hurt Japan’s exports.
In the early 1990s, the bubbles burst, leaving the private sector with a huge debt overhang.
Add to that sluggish productivity growth, weak demand, and rapid population aging, and Japan’s situation was dire.
At first, Japan’s authorities turned again to fiscal and monetary expansion.
Things have been looking up since Prime Minister Shinzo Abe took office in 2012 and launched his three-pronged recovery strategy, dubbed “Abenomics,” which entailed bold monetary easing, fiscal expansion, and structural reforms.
Stock prices have climbed more than 80%.
The yen’s depreciation – from ¥78 to ¥123 against the US dollar – has boosted exports of industrial products and, in turn, corporate profitability.
Consequently, employment and wages have also increased.
Now, Abe is preparing to augment these efforts with initiatives to address major drags on Japan’s economy.
So-called “Abenomics 2.0” entails efforts to raise the fertility rate (free preschool education, support for fertility treatments, and greater assistance for single-parent families) and to mitigate problems associated with population aging (boosting social security and providing more employment opportunities for retirees).
But Japan’s economy is by no means out of the woods.
On the contrary, GDP contracted by 0.1% last year, and is expected to grow by just 0.6% this year.
Moreover, despite continued purchases of ¥80 trillion per year in government bonds, the Bank of Japan has failed to achieve its 2% inflation target.
And Japan’s public debt-to-GDP ratio, at 240% (and rising), remains the highest in the world.
And Abenomics 2.0 may not succeed, not least because young people, unconvinced that they can support larger families, are increasingly delaying marriage and children.
Against this background, many believe that preventing the current population of 127 million from falling below 100 million – Abe’s official goal – will require Japan to accept more immigrants.
That is no small matter in a country that places such a high value on homogeneity.
Simply put, while Japan has some reason for hope, its position is not enviable.
And, if South Korea is not careful, it could end up in much the same place.
Employing many of the same development strategies – including export-oriented policies and a conglomerate-dominated industrial system – South Korea has been catching up with Japan for four decades.
South Korea ranks 26th on the World Economic Forum’s Global Competitiveness Index, whereas Japan ranks sixth.
Based on the gap in GDP per worker with that of the US, South Korea is more than 20 years behind Japan.
Nonetheless, the reality is that South Korea has been experiencing many of the same problems Japan did in the early 1990s, including high levels of household and corporate debt, labor- and financial-market inefficiencies, and low productivity in the service sector.
Given a fertility rate of just 1.2 births per woman – among the lowest in the world – South Korea’s labor force is set to shrink by a quarter by 2050, with people aged 65 and over accounting for 35% of the total population, up from 13% today.
This will put serious strain on public budgets.
If South Korea is to avoid Japan’s fate, it must take steps to reduce its household and corporate debt.
It also should continue to implement structural reforms aimed at strengthening its labor and financial markets, improving institutional quality, and boosting productivity in services and small and medium-size enterprises.
Taking a cue from Abenomics 2.0, South Korea would do well to provide a better environment for child rearing, including flexible working environments, affordable and high-quality childcare and after-school programs, and paid maternal and paternal leave.
Financial support, such as low-interest loans for newlyweds, could also promote marriage and childbirth.
Japan’s lost decades highlight the importance of treating economic ills with the right medicine, before they become chronic and difficult to cure.
If South Korea takes this lesson, and implements the right policies and reforms, being like Japan won’t have to mean sharing its economic fate.
Is the Bank Crisis Over?
MUNICH – As America’s various rescue plans take hold, stock markets are recovering somewhat.
The S&amp;P 500 price/earnings ratio is gradually climbing back to its long-term average of 16.
Bank shares in particular are rebounding, and some banks have even succeeded in repaying at least part of their government-provided capital.
But, as I point out in my new book Kasino-Kapitalismus , this may only be a temporary improvement in expectations rather than a sign of permanent recovery, as the size of the banks’ hidden losses on their balance sheets is probably enormous.
According to the International Monetary Fund’s most recent estimates, the total write-offs on financial claims in this crisis will be $4.05 trillion for the United States, Japan, the euro zone and the United Kingdom, of which the US alone will have to absorb $2.7 trillion.
But according to my calculations of Bloomberg data, just $1.12 trillion had actually been written off worldwide by February, 2009.
These frightening numbers raise doubts about the stability of the West’s financial system, and they dwarf all measures, such as “bad banks” and government guarantees, that attempt to solve a mere liquidity crisis.
The banking system is not primarily suffering from a temporary breakdown of the inter-bank market and a transitory decline in asset values that could be overcome simply by waiting for recovery.
Rather, the banking system is at the brink of insolvency, with a permanent loss in equity capital.
The prices of structured securities such as collateralized debt obligations have come down, because the institutional fraud of a multi-fold chain of securitizations has been detected.
Cash-back loans to NINJA (No Income, No Job, and No Assets) customers that included voluminous fees to brokers and were securitized and structured up to 60 times do not represent any value.
And if the structuring process created 70% triple-A rated paper out of what on average were B-value loans, there must have been fundamental flaws in the rating process, which will not disappear simply because the economy or the stock market recover.
Moreover, defaults on securitized credit card debt and commercial loans to companies that are driven to bankruptcy are still to come.
They will continue to deprive the banking system of its equity capital, with little chance of it being recouped in the near future.
Accounting rules are generous enough to allow banks to keep many losses under the carpet for the time being. But it is only a matter of time until banks are forced to reveal the truth.
Thus, there is no point in waiting for miracles.
That mistake was made by the Japanese, who tried, unsuccessfully, to muddle through, only to end up with 18 years of stagnation.
In today’s crisis, muddling through would be a recipe for a continuation of the crisis and secular stagnation of the type once described by Alvin Hansen, a contemporary of Keynes.
Hansen predicted that capitalism would suffer from a permanent underinvestment crisis.
Banks would scale down their balance sheets in proportion to their reported equity losses and exacerbate the credit crunch from which the world is already suffering today.
Bad banks that are constructed generously enough to provide banks with hidden equity injections are one way to avoid or mitigate the credit crunch.
But establishing them would be a bad idea, because to do so would imply that government subsidization of banks, thereby creating incentives for imprudent behavior in the long run.
After all, one reason for the banking crisis was that banks expected governments to bail them out in case of trouble.
A better way to help banks and prevent them from simply deleveraging their business would be to establish full transparency and provide fresh money from taxpayers.
But governments should not make gifts. Instead, they should become partners of private shareholders, endowing the banks temporarily with new equity capital until the crisis is over.
This rescue strategy has a double advantage.
It helps banks immediately, and it creates the right incentives for future behavior, as banks will know that the government will not prevent private equity capital from being destroyed in a crisis.
This type of rescue strategy also makes it possible to increase the required supervisory equity-asset ratios of banks in the midst of the crisis without risking a credit crunch.
If government becomes a partner, it may well endow the banks immediately with the equity required to sustain their business.
Banks would again trust each other, and the inter-bank market would be re-established.
Of course, from a political perspective, reforms such as these can best be carried out when the crisis is acute, not when Wall Street believes it can go back to business as usual.
The time for reform is now.
Is the Boss Overpaid?
Ever since 2001, when France enacted a law requiring listed companies to reveal their executives’ pay packages, newspapers have had a field day denouncing greedy bosses.
Not only are fixed salaries revealed, but so are bonuses, fees for serving on boards of directors, returns on stock options, pension packages, and other perks, such as corporate jets or chauffeur-driven cars.
But executive remuneration has usually faded from view once the journalistic spotlight shifts elsewhere – that is, until now.
This year, executive heads have started to roll.
In June, Antoine Zacharias, chairman and CEO of Vincy, France’s biggest public concessions and construction company, was obliged to resign when a majority of the board of directors judged his remuneration to be outrageous: €4.3 million in salary, a €13 million retirement bonus, a €2.2 million pension, and an estimated €173 million in stock options.
But the focus of debate was a €8 million exceptional bonus that he requested after successfully executing a financial operation at the end of his tenure.
More recently, Noel Forgeard, the French co-CEO of the Franco-German aeronautical and defence company EADS, was forced to resign under a cloud of suspicion: he sold his EADS shares in March, before the company announced a costly delay in production of the Airbus A380.
Whether Forgeard acted illegally is still under investigation, but, with the announcement causing the share price to plummet by 26% overnight – wiping out €5.5 billion of the company’s value – his position became untenable.
Such events have brought old questions back to the fore in almost every rich country: Are bosses being paid too much?
Should laws governing stock options be reformed?
Although the circumstances are different, the fundamental issues are always the same, for they touch on questions of legitimacy and morality.
If remuneration is perceived as unjust, trust in the capitalist system will suffer.
The French debate about executive compensation is particularly striking in this respect, because managers’ salaries are in fact lower than those paid to their German, British, and American counterparts, and their remuneration has grown in step with corporate share prices, increasing six-fold in 25 years.
Moreover, like managers everywhere, their responsibility is great, making their positions less secure, while companies must compete for the relatively few good ones, driving up their price.
But critics argue that the best managers are not necessarily the best paid, that the market for them is not transparent, and that boards of directors are often partial to their presidents when setting compensation.
Likewise, they insist that mergers and acquisitions, which make big companies bigger, should not be motivated by salary considerations, and that “golden parachutes” should not be granted to failed managers.
More fundamentally, they claim that it is simply immoral that bosses should earn as much in a day as their employees do in a year.
No manager is a superstar, a Tiger Woods or Michael Schumacher of the boardroom.
Stock options, too, often stir passionate criticism.
Allowing managers to buy shares at prices fixed in advance was intended to align their interests with those of other shareholders by giving them a personal stake in building the value of the company.
But, for some managers, stock options have created an incentive to inflate profits and hide losses, thereby enriching themselves artificially while jeopardizing their companies and other shareholders.
The question is not specific to France.
Jacques Chirac, more cautiously, stated that stock options should be legally “encadrés” (framed).
In all other areas, legislation cannot serve as a substitute for the exercise of common sense, discernment, and responsibility by a company’s board of directors.
But if we must have laws to bolster our ethics, their guiding principle should be that remuneration is always linked to the performance and services it is intended to compensate.
Only measures that ensure that companies reward true merit will be considered legitimate by employees, shareholders, and the public.
Is the European Dream Over?
NEW YORK – Were the Euroskeptics right after all?
Was the dream of a unified Europe – inspired by fears of another European war, and sustained by the idealistic hope that nation-states were obsolete and would give way to good Europeans – a utopian dead end?
On the surface, Europe’s current crisis, which some people predict will tear apart the European Union, is financial.
Jacques Delors, one of the architects of the euro, now claims that his idea for a single currency was good, but that its “execution” was flawed, because the weaker countries were allowed to borrow too much.
But, fundamentally, the crisis is political.
When sovereign states have their own currencies, citizens are willing to see their tax money go to the weakest regions. That is an expression of national solidarity, a sense that a country’s citizens belong together and are prepared, in a crisis, to sacrifice their own interests for the collective good.
Even in nation-states, this is not always self-evident.
Many northern Italians fail to see why they should pay for the poorer south.
Affluent Flemings in Belgium resent having to support unemployed Walloons.
Still, on the whole, just as citizens of democratic states tolerate the government that won the last election, they usually accept economic solidarity as a part of nationhood.
Since the EU is neither a nation-state nor a democracy, there is no “European people” to see the EU through hard times.
Rich Germans and Dutch do not want to pay for the economic mess in which the Greeks, Portuguese, or Spanish now find themselves.
Instead of showing solidarity, they moralize, as though all of the problems in Mediterranean Europe were the result of native laziness or its citizens’ corrupt nature.
As a result, the moralizers risk bringing the common roof down on Europe’s head, and confronting the nationalist dangers that the EU was created to prevent.
Europe must be fixed politically as much as financially.
It is a cliché, but nonetheless true, that the EU suffers from a “democratic deficit.”
The problem is that democracy has only ever worked within nation-states.
Nation-states need not be monocultural, or even monolingual.
Think of Switzerland or India.
They need not be democracies, either: China, Vietnam, and Cuba come to mind.
But democracy does require that citizens have a sense of belonging.
Is this possible in a supra-national body like the EU?
If the answer is no, it may be best to restore the sovereignty of individual European nation-states, give up on the common currency, and abandon a dream that is threatening to become a nightmare.
This is what the more radical Euroskeptics in Britain think, having never shared the EU dream to begin with.
It is easy to dismiss this as typical British chauvinism – the insular attitude of a people living in splendid isolation.
But, in Britain’s defense, its citizens have had a longer and more successful democratic history than have most continental Europeans.
Still, even if disbanding Europe were possible, it would come at enormous cost.
Abandoning the euro, for example, would cripple the continent’s banking system, affecting both Germany and the affluent north and the distressed countries in the south.