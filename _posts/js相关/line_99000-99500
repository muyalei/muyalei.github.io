The pioneers of microelectronics tried many strategies to supplant vacuum tubes, and they delivered a host of semiconductors and chip designs: germanium, silicon, aluminum, gallium arsenide, PNP, NPN, CMOS, and so on.
Some of these research efforts were never implemented, but many found their way into specialized devices.
The diversity of options allowed widespread adoption, paving the way for the digital revolution.
As with the microelectronics program, government incentives don’t have to line the road all the way to commercial success.
At some point, companies will be ready to sell products, and market demand can take over.
The US Department of Defense was the only customer for integrated circuits in 1962, but by the end of the decade consumers were buying transistor radios and pocket calculators in droves.
Likewise, state-sponsored demand should not take the form of subsidies to specific technologies or companies; the government has no business gambling taxpayer money on particular ventures.
Assuming that risk is the job of venture capitalists and others in finance, not public officials.
But there is little risk in offering a contract for a job well done: there is no payout if the problem remains unsolved.
And those payouts are modest compared to the research and development efforts they stimulate.
A program offering rewards of $1-5 billion in contracts or deployment commitments can generate many times that value in private-sector R&amp;D. Innovators and their investors are willing to bet big on these opportunities, because they know that the eventual reward in revenue from a global customer base will far exceed the initial investment.
That makes state-sponsored demand a very efficient mechanism for generating innovation.
Because of the multiplier effect, small governments and states, and even large cities, can successfully sponsor the kind of demand that fosters a world-class innovation epicenter.
Certain Scandinavian countries, Chinese provinces, and the city-state of Singapore, for example, are ideally positioned to try this approach.
Some years ago, I calculated how many units of product need to be sold to launch a technology.
The number is actually quite modest: If you can move between 100,000 and one million units of a disruptive product, you can establish the technology standards for that category and in time become the global leader of a new industry.
Government sponsorship ensures that a certain number of people will adopt your product.
At the start, it need not be that many.
The economic planners and policymakers who are chasing Silicon Valley’s taillights are learning that they cannot always replicate the entrepreneurial culture and finance mechanisms that flourish there now.
But they have forgotten how it all started: guaranteed demand, which stimulates the most ambitious kind of innovation.
The lesson is a simple one: Don’t try to build another Silicon Valley.
Instead, build a Demand Mountain, and the innovators will come.
Supply Side, Demand Side, or Innovation Side?
NEW YORK – It has become impossible to deny the so-called secular stagnation gripping the world’s most developed economies: Wealth is piling up, but real wages are barely rising and labor force participation has been on a downward trend.
Worse yet, policymakers have no plausible idea about what can be done about it.
Behind this stagnation is the slowdown in productivity growth since 1970.
The wellspring of such productivity gains – indigenous innovation – has been badly clogged since the late 1960s (mostly in established industries) and was even more so by 2005.
Ronald Reagan and Margaret Thatcher viewed the stagnation that was gripping economies by the 1970s from the supply side.
They pushed through tax cuts on profits and wages to boost investment and growth, with debatable results.
But today, with tax rates much lower, cuts of that size would result in huge increases in fiscal deficits.
And with debt levels already high and large deficits ahead, such supply-side measures would be reckless.
So now the best and brightest view things from the demand side, using the theory built by John Maynard Keynes in 1936.
When “aggregate demand” – the level of real expenditure on final domestic goods that households, businesses, the government, and overseas buyers are willing to make – falls short of output at full employment, output is limited to the demand. And innovation won’t happen.
But the demand-siders’ conception of the economy is strange.
For them, private investment demand is autonomous, governed by forces that Keynes dubbed “animal spirits.”
Consumer demand is essentially autonomous, too, because the so-called induced part is yoked to autonomous investment through the “propensity to consume.”
Thus, government measures are the sole way to boost employment and growth when autonomous demand falls short and jobs are lost.
This conception grasps neither growth nor recovery.
In healthy economies, a contractionary demand shock sets off two types of responses fueling recovery.
Adaptations to emerging opportunities are one such response.
When firms hit by reduced demand contract operations, the space they give up becomes available for use by entrepreneurs with better ways of running the business – or with better businesses.
Some of the employees they let go will start firms (and hire employees) of their own.
With every recession, many shops on Main Street disappear; and, over time, new shops – generally more successful – appear.
The other response is indigenous innovation – new ideas springing from the brows of various businesspeople.
When firms hit by reduced demand stop hiring for a time, some people who would have joined established firms use their situation to dream up new products or methods and organize startups to develop them.
The growing number of aspiring innovators toiling in home garages may self-produce some of their capital goods.
More important, the accumulation of new startups will gradually generate rising investment demand – induced demand! – and growth, too.
Some may doubt this. Can new products and methods fare well in the market if demand is deficient?
As an innovator said to me amid the financial crisis, his objective was to take over a market – it mattered little that the targeted market was only 90% of its former size.
Can capital be raised where incomes are depressed?
Small firms and startups must always struggle for credit, and the Great Recession that followed the 2008 financial crisis made it harder for them.
Yet the recession did not prevent droves of such firms from finding financing in Silicon Valley, London, and Berlin. No wonder Germany, the United States, and the United Kingdom are more or less recovered.
In the US, total factor productivity growth set records in the 1930s, when the economy fell into and then grew out of the Great Depression.
Recovery has fallen woefully short in two kinds of economies.
France and Italy are lacking young people who want to be new entrepreneurs or innovators, and those few who do are impeded by entrenched corporations and other vested interests.
Greece has no lack of would-be entrepreneurs and innovators, but it lacks a system of angel and venture capital.
Some Greeks have formed startups, though not in Greece.
The demand-siders say that innovation only makes recovery harder, because it enables firms to meet existing demand with fewer employees.
Thus, they call for annual public-sector investment up to the level needed for full employment.
But such infrastructure investment would go far beyond what would ever have been undertaken had the economy been left to regain high employment through the workings of adaptive or innovative activity.
Indeed, such investment is costly beyond the expense because it preempts the adaptation and innovation that would have brought higher employment and faster growth.
Moreover, as long as Western innovation remains narrowly confined, a demand-side commitment to a large, sustained flow of infrastructure investment – and, likewise, a supply-side commitment to a similar flow of private investment – must bring ever-diminishing returns, until, ineluctably, the economy reaches its near-stationary state.
Supplying more of the same old goods never “creates its own demand,” as Keynes thought.
But supplying new goods can.
It is the impediments to adaptation and innovation – not fiscal austerity – causing our stagnation.
And only renewed dynamism – not more fiscal irresponsibility – offers any hope of a durable way out.
Innovation Is Not Enough
CAMBRIDGE – We seem to be living in an accelerated age of revolutionary technological breakthroughs.
Barely a day passes without the announcement of some major new development in artificial intelligence, biotechnology, digitization, or automation.
Yet those who are supposed to know where it is all taking us can’t make up their minds.
At one end of the spectrum are the techno-optimists, who believe we are on the cusp of a new era in which the world’s living standards will rise more rapidly than ever.
At the other end are the techno-pessimists, who see disappointing productivity statistics and argue that the new technologies’ economy-wide benefits will remain limited.
Then there are those – the techno-worriers? – who agree with the optimists about the scale and scope of innovation but fret about the adverse implications for employment or equity.
What distinguishes these perspectives from one another is not so much disagreement about the rate of technological innovation.
After all, who can seriously doubt that innovation is progressing rapidly?
The debate is about whether these innovations will remain bottled up in a few tech-intensive sectors that employ the highest-skilled professionals and account for a relatively small share of GDP, or spread to the bulk of the economy.
The consequences of any innovation for productivity, employment, and equity ultimately depend on how quickly it diffuses through labor and product markets.
Technological diffusion can be constrained on both the demand and supply sides of the economy.
Take the demand side first.
In rich economies, consumers spend the bulk of their income on services such as health, education, transportation, housing, and retail goods.
Technological innovation has had comparatively little impact to date in many of these sectors.
Consider some of the figures provided by the McKinsey Global Institute’s recent report Digital America.
The two sectors in the United States that have experienced the most rapid productivity growth since 2005 are the ICT (information and communications technology) and media industries, with a combined GDP share of less than 10%.
By contrast, government services and health care, which together produce more than a quarter of GDP, have had virtually no productivity growth.
Techno-optimists, such as the McKinsey authors, look at such numbers as an opportunity: There remain vast productivity gains to be had from the adoption of new technologies in the lagging sectors.
The pessimists, on the other hand, think that such gaps may be a structural, lasting feature of today’s economies.
For example, the economic historian Robert Gordon argues that today’s innovations pale in contrast to past technological revolutions in terms of their likely economy-wide impact.
Electricity, the automobile, airplane, air conditioning, and household appliances altered the way that ordinary people live in fundamental ways.
They made inroads in every sector of the economy.
Perhaps the digital revolution, impressive as it has been, will not reach as far.
On the supply side, the key question is whether the innovating sector has access to the capital and skills it needs to expand rapidly and continuously.
In advanced countries, neither constraint typically binds much.
But when the technology requires high skills – technological change is “skill-biased,” in economists’ terminology – its adoption and diffusion will tend to widen the gap between the earnings of low- and high-skill workers.
Economic growth will be accompanied by rising inequality, as it was in the 1990s.
The supply-side problem faced by developing countries is more debilitating.
The labor force is predominantly low-skilled.
Historically, this has not been a handicap for late industrializers, so long as manufacturing consisted of labor-intensive assembly operations such as garments and automobiles.
Peasants could be transformed into factory workers virtually overnight, implying significant productivity gains for the economy.
Manufacturing was traditionally a rapid escalator to higher income levels.
But once manufacturing operations become robotized and require high skills, the supply-side constraints begin to bite.
Effectively, developing countries lose their comparative advantage vis-à-vis the rich countries.
We see the consequences in the “premature deindustrialization” of the developing world today.
In a world of premature deindustrialization, achieving economy-wide productivity growth becomes that much harder for low-income countries.
It is not clear whether there are effective substitutes for industrialization.
The economist Tyler Cowen has suggested that developing countries may benefit from the trickle-down of innovation from the advanced economies: they can consume a stream of new products at cheap prices.
This is a model of what Cowen calls “cellphones instead of automobile factories.”
But the question remains: What will these countries produce and export – besides primary products – to be able to afford the imported cellphones?
In Latin America, economy-wide productivity has stagnated despite significant innovation in the best-managed firms and vanguard sectors.
The apparent paradox is resolved by noting that rapid productivity growth in the pockets of innovation has been undone by workers moving from the more productive to the less productive parts of the economy – a phenomenon that my co-authors and I have called “growth-reducing structural change.”
This perverse outcome becomes possible when there is severe technological dualism in the economy and the more productive activities do not expand rapidly enough.
Disturbingly, there is evidence that growth-reducing structural change has been happening recently in the United States as well.
Ultimately, it is the economy-wide productivity consequences of technological innovation, not innovation per se, that lifts living standards.
Innovation can co-exist side-by-side with low productivity (conversely, productivity growth is sometimes possible in the absence of innovation, when resources move to the more productive sectors).
Techno-pessimists recognize this; the optimists might not be wrong, but to make their case, they need to focus on how the effects of technology play out in the economy as a whole.
Our Collective Brain
CAMBRIDGE – Imagine a game of survival that pits a troop of capuchin monkeys against you and your work colleagues.
Both teams would be parachuted into a remote African forest, without any equipment: no matches, knives, shoes, fish hooks, clothes, antibiotics, pots, ropes, or weapons.
After one year, the team with the most surviving members would be declared the victor.
Which team would you bet on?
You might assume that the humans, given our superior intelligence, are the team to beat.
But do you or your colleagues know how to make bows and arrows, nets, water containers, and shelters?
Do you know which plants are toxic?
Can you start a fire without matches?
Can you make fish hooks or natural glues?
Do you know how to protect yourself from big cats and snakes at night?
The answer to most, if not all, of these questions is probably “no,” meaning that your team would likely lose to a bunch of monkeys – probably pretty badly.
This raises an obvious question.
If we cannot survive as hunter-gatherers in Africa, the continent where our species evolved, how did humans achieve such immense success relative to other animals and spread to nearly all of the earth’s major ecosystems?
Here’s a key piece of the answer: We are a cultural species.
Our unique psychological capacities allow us to learn from one another over generations, facilitating a cumulative cultural evolutionary process that produces increasingly complex and sophisticated technologies, languages, bodies of knowledge, conceptual toolkits, and adaptive heuristics.
The power of this process arises not from raw individual intelligence, but from the reinterpretation of the serendipitous insights and mistakes that our intelligence produces.
This means that the rate of innovation will depend, at least in part, on the size and interconnectedness of the pool of minds contributing to the cultural evolutionary process.
All other things being equal, larger and more socially interconnected groups will produce a greater number of fancier tools, technologies, and techniques, even if their individual members are less inventive than those comprising a smaller, more isolated group.
This finding is supported by both tightly controlled laboratory experiments and historical case studies.
About 10,000 years ago, for example, rising oceans transformed Tasmania from an Australian peninsula into an island.
On the mainland, technological progress continued unimpeded.
But in Tasmania, groups of hunter-gatherers began to lose – or failed to develop – a wide range of useful technologies: bone tools, fitted cold-weather clothing, boomerangs, spear-throwers, and durable boats.
When the Dutch arrived in the seventeenth century, Tasmanians had the simplest technology ever encountered by European explorers.
To understand humans’ social nature, it is crucial to understand how culture has driven our genetic evolution in ways that shape not only our physiology and anatomy, but also our social psychology, motivations, inclinations, and perceptions.
From this long process, in which surviving and thriving meant acquiring and adhering to the local social rules, we emerged as potent social learners.
The foundation of our ability to form cooperative communities, organizations, and societies arises not from innate cooperative tendencies, but from the specifics of the social norms that we learn, internalize, and enforce on others.
While our innate motivations do play a role, they are harnessed, extended, and suppressed by social norms, which form the institutional skeleton that allows our innate inclinations to operate.
This novel view of human nature and society generates some important insights.
First, as a cultural species, humans acquire ideas, beliefs, values, and social norms from others in their communities, using cues of prestige, success, sex, dialect, and ethnicity.
We pay particular attention – especially under conditions of uncertainty, time pressure, and stress – to domains involving food, danger, and norm violations.
Changing people’s behavior begins with an understanding of our cultural nature, not our rationality.
Second, we gradually internalize the social norms that we acquire through a culture-driven process of self-domestication.
(We acquire our standards for judging and punishing others through the same process.)
These internalized norms become the motivations that guide our actions.
This means that people’s preferences, desires, and motivations are not fixed, and thus that well-designed programs or policies can change what is automatic, intuitive, and obvious.
Third, the most potent social norms harness aspects of our evolved psychology.
Social norms for fairness toward foreigners, for example, are much harder to sustain and diffuse than those that demand that mothers care for their children.
Fourth, our ability to innovate depends on the size of our collective brain, which depends on the ability of social norms to encourage people to generate, share, and recombine novel ideas and practices.
Fifth, there is a fundamental link between institutions and psychology.
Because different societies have different norms, institutions, languages, and technologies, they also have different ways of reasoning, mental heuristics, motivations, and emotional reactions.
The imposition of imported institutions often creates psychological and social mismatches that tend to lead to poor outcomes.
Finally, humans lack a certain degree of rationality, making us terrible at designing effective institutions and organizations – at least for now.
I am hopeful that as we obtain deeper insights into human nature and cultural evolution, this can be improved.
Until then, we should take a page from cultural evolution’s playbook and design systems that use variation and selection to make institutions compete.
That way, we can dump the losers and keep the winners.
By examining the rich interaction and co-evolution of psychology, culture, biology, history, and genetics, we have the possibility to gain important insights into human psychology.
This scientific road has rarely been traveled.
It promises an exciting journey into unexplored intellectual territory, as we seek to understand the peculiarity of our species.
In Praise of Euroskepticism
BRUSSELS &#45;&#45; The EU has no coherent strategy on many issues.
It has only sketchy economic policies toward Russia; ambitions, but no game plan, to become a player in the Middle East; and, despite its original leadership on the Kyoto Protocol, no successor program on climate change.
And the biggest question of all – how to engage with China, India, and other giants of the future – has received virtually no attention from EU-level policymakers.
These issues require attention now, and an integral part of the EU’s search for new global strategies should be to invite, rather than avoid, criticism of its activities.
If the EU is to lift its gaze from its navel to the horizon, it must reconcile the very different views that exist across Europe of its place in the world and its own best interests.
That means engaging with those shades of political opinion that the European Commission and the European Parliament consider “Euroskeptical.”
The counter-pressure, of course, is that EU officialdom feels unloved and unappreciated.
There is an almost embattled culture among many senior officials, who fear that fanning the flames of dissent among Europe’s voters could one day knock European unity off course.
Euroskepticism represents everything the Eurocrats dislike.
They worry that politicians and journalists who oppose their strategies for closer political and economic union could yet tip the balance of public opinion against the EU.
Euroskeptic politicians elected to the European Parliament are often treated with the disdain that true believers reserve for the infidel.
Yet it is ludicrous to think that Euroskeptics represent a silent majority that could rise up and destroy the EU. Popular support for the European project has barely faltered over the last 25 years, and has even begun to strengthen of late.
At the beginning of the 1980’s, when Europe was faltering and the media catchword was “Eurosclerosis,” 50% of people polled for the Eurobarometer surveys viewed membership as positive for their country. About 19% said its effects were negative, and the rest didn’t know.
Today, overall support for the EU stands at 57%, and the share of people unhappy with it has dropped to 15%.
There are now no EU countries where Euroskeptics are in the majority, and the widespread impression that citizens in Western and Eastern Europe alike are turning their backs on the EU is wrong. The reality is that even though voters may find the EU remote, most appreciate the need for Europe to unite in a world where China, India, and other fast-developing countries are set to challenge it.
Reassured by this groundswell of support, the Eurocrats should be fostering a much more pluralistic approach to EU policymaking and debate.
The Commission should be organizing public debates that give equal prominence to dissenting views.
Eurocrats must learn that Euroskepticism is fundamentally healthy, because it invites closer examination of the policy options open to Europe, and thus increases the involvement of ordinary people in the EU’s policymaking process.
And greater involvement quickly leads to better understanding of the issues at stake, and the reasons why some policies have been adopted that challenge or even override the sovereign powers of individual countries.
For half a century, Europe’s integrationists have sought unquestioning acceptance of their efforts.
That demand must be abandoned.
It will probably take several generations before a workable EU-wide political system emerges, but the first step is for the EU to encourage people to have their say, however uncomfortable that may be.
Why Europe?
PRINCETON – What is the point of Europe?
The threat of an explosive disintegration of the eurozone – and with it of the European Union – is receding.
But the confused outcome of Italy’s recent parliamentary election, with an upper house dominated by a party that campaigned on an anti-EU platform and a pro-European majority in the Chamber of Deputies, has revived the fundamental debate about the purpose of European integration.
Europeans find it hard to find a positive way of describing the exercise in which they have been engaged for the past six decades.
One common interpretation is that integration makes people better off.
Unity is supposed to be a foundation of prosperity.
The Common Market was defended at the outset in terms of the gains that would follow from increased trade.
The case for capital-market integration, and then for a single currency, was similar.
All of this recalls some powerful arguments that were made in the nineteenth century about national integration and unification.
In particular, the two countries whose problems drove much of the need for twentieth-century European integration – Germany and Italy – were culturally and politically highly diverse.
In both countries, early-nineteenth-century romantic nationalism gave way to a sober obsession with economic forces after the failed revolutions of 1848.
The great Florentine liberal statesman, Bettino Ricasoli, concluded that Tuscany was simply financially unviable on its own.
This sort of economic nationalism in Germany and Italy briefly produced coalitions of interests that supported the drive to national unification under Bismarck and Cavour.
But the credibility of the national project seemed to crumble when growth faltered, leading to the emergence of movements that championed the aggressive, confrontational, and violent assertion of cultural identity.
Mario Monti is the twenty-first-century descendant of those nineteenth-century patriots who argued for the economic necessity of national unity.
Now it is European unity that is needed for economic reasons.
This vision of Europe is not idealistic; it is simply concerned with how Europeanization can benefit Italians.
And, like its nineteenth-century precursor, it is vulnerable to severe backlashes, especially when it appears to bring only pain and suffering.
Indeed, when today’s Europeans peer into the future, they see only prolonged recession and austerity.
Europe means nothing but sacrifice: northern Europeans paying for southern Europe’s woes through large transfers, or southern Europeans repaying onerous – and maybe impossible – levels of debt.
A variant of the economic argument for European unity is the claim that enhanced integration makes it easier to finance debt, because interest rates are lower.
A reduction in borrowing costs constituted a powerful motive in the 1990’s for southern European governments to join the monetary union.
But the costs of moving into a non-defaulting environment are high.
Here, another historical parallel is helpful.
France in the ancien régime repeatedly imposed semi-default on its creditors by reducing interest rates and extending maturities.
In the 1780’s, a new consensus against such measures emerged.
But the impossibility of raising revenue then triggered the French Revolution, with the revolutionaries demanding confiscatory taxes and impositions on the wealthy elite.
The alternative to thinking about European integration simply as a way of generating wealth and prosperity frequently analogizes it to a marriage.
In the late 1980’s, for example, then-European Commission President Jacques Delors, raising the prospect of a two-speed Europe, suggested that one or two countries might need a “different kind of marriage contract.”
The marriage analogy was used initially to signal that the European relationship was an exclusive one.
Europeans had a unique relationship with which no one –&#160;especially the United States – should interfere.
As Dominique Strauss-Kahn, then France’s finance minister, put it in 1997, “People who are married do not want others in the bedroom.”
But marriage can be a fraught institution (as Strauss-Kahn may know better than most).
The British economic journalist Martin Wolf thinks of Europe as a marriage kept together only by the high cost of divorce.
Others see it as a sham marriage.
Traditional marriage vows entail a commitment that binds the partners through changing circumstances: for richer and for poorer, in sickness and in health.
Even if the marriage does not make the partners better off, they still need to stick with it.
So neighbors who have a quarrelsome or violent past are not always well advised to reconcile by marrying.
The problem was that the Europeans did not understand what marriage really meant and why they should want to get married.
Enthralled by promises of material well-being and security, they had exaggerated expectations of romantic wedded bliss.
The unhappy marriage analogy for Europe’s current malaise, while depressing, is helpful.
At least it tells Europeans that they are not stuck together only for material reasons.
But, until that lesson is really learned, Europe must brace itself for more setbacks and backlashes, which means that it must still answer the fundamental question: Why stick it out together, especially at a time when more and more Europeans are choosing not to get married at all?
Insecuritization
BRUSSELS – There is no shortage of analyses of what went wrong in the world’s capital markets over the past 18 months.
What is clear is that a complex set of relationships, interactions, events, and omissions on the part of many different actors, rather than any single factor, was to blame.
I am convinced, for example, that over the years there has been too much “regulatory capture” by the supply side of the financial services market, with its well-organized and powerful lobbies.
By contrast, there has been too little engagement on the demand side.
That is an imbalance of which legislators must be much more conscious.
A second problem for regulators, supervisors, and, indeed, credit rating agencies was scarce resources.
When investment banking markets were booming – and the private sector easily recruited up top talent – regulators and supervisors found it difficult to get the budgets to keep up with innovation and police the markets.
In the future, governments will have to commit the necessary resources to ensure more robust oversight of risk management in financial institutions.
Capital markets must be subject to much more detailed and frequent hands-on supervisory inspections.
In Europe, crisis management mechanisms must be put in place to manage their deeply integrated nature, as 80% of Europe’s banking assets held in cross-border banking groups.
A third problem – particular relevant to banks, risk managers, and traders – has been misaligned incentives.
Incentive structures have been overwhelmingly aligned to short-term performance.
In firms where this was most pronounced, there has been almost total destruction of shareholder value.
As a consequence, a wholly unacceptable long-term burden has been imposed on taxpayers.
Privatizing banks’ profits and socializing their losses is not acceptable in democratic societies.
The structure and timing of performance pay in banks must be more closely aligned to long-term shareholder interests and financial stability.
Incentives for brokers and credit rating agencies have been even more perverse.
In the United States, brokers were selling mortgages without checking whether the borrower had the means to repay.
They had no stake beyond the immediate “sale.”
Financed via Special Purpose Entities, mortgages were parceled up in debt packages and securitized entities in which neither originators nor sponsors retained any material long-term stake but paid credit rating agencies to award a nice little ribbon marked AAA.
When the packages were unwrapped, most of their contents turned out to consist of pools of toxic assets for which there was no proper due diligence, no evidence of capacity to repay, and little cushion to cope with a market downturn.
That’s why I have proposed much tougher measures in the revised Capital Requirements Directive amendments now being considered by the European Parliament.
This will require thorough independent due diligence on securitizations, proper cash-flow sensitivity analysis, and less reliance on credit rating agencies paid by issuers.
Originators or managers of these securitizations will be required to retain a meaningful stake in each tranche of the issue.
I was pilloried for this proposal when I initially put it forward.
I am therefore glad to see that a G-30 advisory group has now supported this principle, and that it is gaining increased traction in the US.
But some banking industry lobbyists have sought amendments in the European Parliament that would totally neuter the proposal’s effectiveness.
Even more irresponsible are attempts to undermine a requirement for adequate due diligence on securitization positions prior to investing – with some amendments containing wording that would make it virtually impossible for supervisors to monitor compliance.
Mortgage assets and leveraged loans created in huckster shops, carved up and buried in “CDO squareds” (securitizations wrapped in other securitizations), and characterized by progressively more obscure, more contingent, and more complex orders of priority for allocating cash flows have no place in capital markets.
The opaqueness, wholly unnecessary complexity, and near impossibility of undertaking independent due diligence on these structures’ underlying risk have undermined trust in the securitization market.
Financial institutions – and their trade bodies – are doing themselves no favors by vigorously opposing meaningful reform.
Is it any wonder that the valuation of securitized investments has become so challenging, that mark-to-market valuation on securitized assets has become meaningless, depressed, or both, and that the securitization market itself has seized up?
Rather than restoring the trust and confidence in capital markets needed for recovery, those European Union members and banking federations that submitted “wrecking amendments” to the due diligence and securitization proposals are reinforcing the suspicion that is now embedded within them.
If successful, they will impair the revival of a transparent, responsible, and vibrant securitization market – a market that, if properly managed, can contribute meaningfully to sustainable, long-term economic growth.
Inside Africa’s Consumer Revolution
JOHANNESBURG – Nowadays, Africa’s economic potential – and the business opportunities that go with it – is widely acknowledged.
Poverty and unemployment are still more widespread than in other emerging markets, but accelerating growth since 2000 has made Africa the world’s second-fastest-growing region (after emerging Asia and equal to the Middle East).
With rapid economic growth have come more prosperous consumers – and vice versa: 45% of Africa’s total GDP growth in the 2000’s (before the financial crisis erupted in 2008) came from consumer-related sectors of the economy.
It is expected that, by 2020, more than half of African households – almost 130 million – will have discretionary income to spend (or save), up from 85 million today.
Moreover, Africa has the world’s fastest-growing population – and the youngest, with more than half under 20 years old, compared to 28% in China.
The United Nations estimates that the continent will account for more than 40% of global population growth through 2030, with the working-age population expected to surpass that of China by 2040.
Given these trends, the continent’s consumer industries are expected to grow a further $410 billion by 2020 – more than half the total revenue increase that all businesses are expected to generate in Africa by the end of the decade.
But, for many companies entering Africa or seeking to expand there from a local base, the challenge now is to obtain a better understanding of the market and its consumers.
In one of the first studies of its kind, the McKinsey Africa Consumer Insights Center surveyed 13,000 individuals from 15 cities in ten of the continent’s 54 countries in 2011 and 2012.
The ten countries – Algeria, Angola, Egypt, Ghana, Kenya, Morocco, Nigeria, South Africa, Sudan, and Tunisia – accounted for 81% of Africa’s private consumption in 2011.
But, throughout the continent, market opportunities for consumer-facing companies are concentrated more in cities than in particular countries.
Indeed, with 40% of its population living in cities, Africa is more urbanized than India (30%), and nearly as urbanized as China (45%).
By 2016, more than 500 million Africans will live in urban centers, and the number of cities with more than one million people is expected to reach 65, up from 52 in 2011 (on par with Europe and higher than India and North America).
This development is critically important for consumer companies.
Urban household spending in Africa is increasing twice as fast as rural spending, with urban per capita incomes, on average, 80% higher than those of countries as a whole.
Befitting the continent’s strong macro trends, the survey found a high degree of optimism among urban African consumers: 84% of respondents expect their households to be better off in two years.
Sub-Saharan Africans are the most optimistic – 97% of Ghanaians, for example, expect to be much better off in two years. (For North Africans, however, that figure drops to only 10-15%, which is unsurprising given the uncertainty generated by the region’s recent political turmoil.)
Overall, consumers are increasing their spending across most retail categories.
Up to 30% of the more optimistic consumers in some countries say that they are shopping more frequently and purchasing new and more expensive products.
And half of all respondents claim to make daily sacrifices to save for major expenditures.
This suggests that companies offering cheap, poor-quality, unbranded products are unlikely to succeed in the long term.
For apparel consumers, for example, quality is second only to price when choosing a store, and second only to fashion when choosing a specific item.
And, in both North and Sub-Saharan Africa, brand loyalty is strong, averaging 58%.
But quality and brand must be delivered at the right price.
Even though Africans value brands and product quality, affordability remains crucial.
To succeed, companies should work to reach consumers’ price points through a combination of product reengineering (such as removing low-value-added features), smaller package sizes, and low-cost operating models.
Moreover, timing is crucial when choosing where to play.
Demand for consumer products typically follows an S-curve.
As incomes rise, categories reach a takeoff point where demand accelerates by 3-5 times.
At higher levels of income, markets become saturated and growth slows.
Different products and categories enter the “hot zone” at different moments: those with low price points, such as snacks and beverages, typically take off relatively early; beauty products somewhat later; and luxury goods, such as branded fashion, later still.
Not surprisingly, in most African markets, few categories have entered the slower-growth “chill-out” zone.
This is where understanding opportunities at a city level is vital.
Country-level planning and resource allocation is still the rule for most businesses operating in Africa, resulting in inefficient allocation of human and capital resources.
By creating detailed profiles of the most promising urban opportunities, companies could target their investments more effectively.
Identifying growth hot spots is only the start.
Substantial differences among and within Africa’s countries imply the need for a much deeper and finer-grained understanding of consumer preferences and affordability profiles by product category.
Likewise, many markets are still in early stages of development, and must be built through concerted consumer education and trial.
Here, Africa’s youth merit special attention: the survey found that the 16-34 age group already accounts for 53% of income in urban centers.
Young people’s consumption habits are quite different from their elders’.
They are more than twice as likely to search for information online and to seek products and stores that reflect the “right image.”
They are also more educated, with 40% of 16-24 year olds having completed high school, compared with only 27% of the 45-and-older group.
These characteristics point to a major change in African consumption habits as this cohort ages, its incomes increase, and its behaviors and decision criteria become the societal norm.
Many companies – particularly multinational firms accustomed to old and aging populations in the advanced countries – will have to adapt accordingly.
Inside Iran’s Nuclear Reasoning
MELBOURNE – Is Iran really hell-bent on becoming a nuclear-armed state?
Or will it settle for nuclear capability, able to make weapons but choosing not to?
Does the difference matter?
Few international questions involve higher stakes than these.
An immediate concern, if deep pessimism about Iran’s intentions prevails, is a preventive Israeli strike, leading to another major Middle East war – with catastrophic consequences for the global economy likely.
No one should underestimate the difficulty of assessing Iran’s real intentions.
Mixed signals from competing power centers don’t help; nor does the recurring contrast between Iranian officials’ usually-strident public pronouncements and often-moderate private discourse.
Pessimists and skeptics have plenty to point to in Iran’s long record of obstruction and brinkmanship in addressing legitimate international concerns about its nuclear programs.
That said, too many policymakers and commentators have rushed to judgment, insisting that Iran is irrevocably determined to build nuclear weapons, or that it wants a break-out capability that is just as dangerous.
But in my many off-the-record discussions with senior officials in Iran and elsewhere over the last few years, I have heard five such reasons stated with clarity and consistency, and they deserve to be taken seriously.
The first reason is concern that Israel will perceive the existence of one or two Iranian bombs as an existential threat, demanding a pre-emptive military attack – with or without US support, but in either case with resources that Iran knows it cannot match.
Iranians think such an attack unlikely if they do not cross the red line of actual weaponization.
Second, it is well understood that there is zero tolerance in Russia and China for an Iranian bomb, and all the rope that that these powers have so far given Iran in the Security Council will run out if Iran weaponizes.
The writing on this wall became even clearer after the most recent round of sanctions negotiations.
Third, following from this, there is a clear perception in Iran that acquiring an actual bomb would lead to impossibly stringent economic sanctions.
Financial sanctions, direct and indirect, already are biting – including on  the Revolutionary Guard and its significant economic interests – but have been tolerable in the context of asserting Iran’s “right to enrich” under the NPT.
Once in obvious breach of the NPT, universal participation in a much tougher sanctions regime is seen in Iran as inevitable.
Fourth, Iranians acknowledge that any regional hegemony bought with nuclear weapons is likely to be short-lived.
There is skepticism about the capacity of Egypt, Saudi Arabia, or Turkey to move quickly to build bombs of their own, and a belief that they would be under much international pressure, especially from the US, not to do so.
But there is also a clear view that Arab-Persian, Sunni-Shia, or more straightforward regional power anxieties would make a nuclear-arms race inevitable.
Finally, there is a religious reason: weapons of mass destruction simply violate the precepts of Islam.
Few in the West are likely to find this line very compelling, but it has echoed strongly in every conversation that I have ever had with Iranian officials, senior or minor.
And it is not without plausibility: Iran did not, after all, respond in kind when it was bombarded with chemical weapons by Iraq.
None of this suggests that Iranian intentions can be taken on trust.
There is too much history, and there are too many continuing grounds for suspicion, for that.
Any agreement involving an end to sanctions and diplomatic isolation would need to be accompanied by intrusive monitoring, inspection, and verification arrangements, covering not only all sensitive stages of the nuclear fuel cycle, but also any suspected weapons design or engineering facilities.
The international community requires real confidence that there would be enough lead time – 12 months or so – in which to respond to any evidence of real intent to move to weaponization.
Frustrations will continue, like those over the last year as creative efforts by Security Council members – and more recently by Brazil and Turkey – to find interim confidence-building solutions were rebuffed, largely because the leaders of last year’s democratic movement refused to support a compromise-inclined President Mahmoud Ahmadinejad.
But there is a solid foundation of rationality on which to build in keeping the door open for negotiations.
Iran is an extraordinarily complex country.
But, just as we cannot afford to underestimate the forces of extremism that persist there, we also fail at our peril to comprehend the currents of restraint and good sense that run within the country, including at high policymaking levels.
America’s Healthy Path to Fiscal Health
BERKELEY – Over the last five years, the growth of health-care spending in the United States has slowed dramatically – to the lowest rate in the past 50 years.
The slowdown is not a surprise.
It is a predictable result of the recession and slow recovery that have left millions of Americans without health insurance and dampened household spending.
But the size of the slowdown is surprising, as is the fact that it started several years before the 2008 recession – and not only in the private insurance system, but also in Medicare and Medicaid, the two major government health programs.
(Medicare provides health coverage for retirees, and Medicaid provides coverage for low-income Americans and their children and those with disabilities.)
What explains this slowdown in health-care spending?
How much of it is attributable to the weak economy, and how much is the result of changes in provider and consumer behavior?
Two recent studies offer different answers, but both predict that at least some of the slowdown will persist even after the economy recovers.
That would be good news for the US economy, which currently devotes nearly 18% of GDP to health care, by far the largest share among developed countries.
It would also be good news for America’s fiscal position, because Medicare and Medicaid are the two largest contributors to the long-term federal budget deficit.
The growth of health-care spending declined or remained unchanged in real (inflation-adjusted) terms each year between 2002 and 2011, falling to 3-3.1% in 2009-2011, the lowest rates on record since reporting began in 1960.
Recent data indicate that after a slight acceleration in 2012, the growth of real health-care spending in 2013 has fallen back to its 2009-2011 average.
As a result of the recession and lagging recovery, health-care spending has also slowed significantly since 2009 throughout the OECD.
Indeed, for the first time on record, real health-care spending stalled on average in the OECD in 2010, as developed countries, reeling from budgetary constraints, clamped down on health programs.
Growth in health-care spending was slower in every OECD country in that year, with the exception of Germany.
A new study by Drew Altman, a respected health-care expert and President of the Henry J. Kaiser Family Foundation, concludes that slower growth in real GDP, along with a lower inflation rate, accounts for more than three-quarters of the slowdown in health-care spending in the US after 2001.
The weak economy has caused people to postpone consumption of health-care services and has encouraged states and employers to restrain their spending on health.
But important cost-containing changes in the private health-care system, including more cost-sharing in private insurance plans and tighter controls in managed care, have also contributed to the slowdown.
Altman conjectures that, overall, the growth in health-care spending between 2008 and 2012 was about one percentage point lower than predicted by deteriorating macroeconomic conditions alone.
If this reduction continues after the economy recovers – as seems likely, given the cost-containment incentives in the Affordable Care Act (commonly known as Obamacare) – the US stands to spend $2 trillion less on health care over the coming decade.
Based on the relationship between changes in real per capita health-care spending and changes in unemployment rates at the state level, the recent Economic Report of the President concludes that the recession and lackluster recovery account for less than 20% of the slowdown in health-care spending since 2007 – and for an even smaller share of the slowdown that began in 2002.
And difficult macroeconomic conditions explain little (if any) of the slowdown in Medicare spending per enrollee since 2001.
That is not unexpected, because the largely retired Medicare population is less vulnerable to macroeconomic fluctuations than is the working-age population.
The Council of Economic Advisers, whose members write the president’s report, surmise that structural changes – including stronger incentives for efficiency by hospitals and providers, more cost-sharing in insurance policies, and the substitution of generic drugs for branded drugs – explain most of the deceleration in per capita spending growth.
They also suggest that payment reforms contributed to the slowdown in Medicare’s spending growth after 2001, and that early responses to new Medicare regulations in the Affordable Care Act may have caused a further decline after 2010.
The long-term effect on the federal budget implied by a sustained reduction in the growth of Medicare and Medicaid spending to the rates of the last several years would be profound.
These programs currently claim 21% of the budget, with Medicare accounting for two-thirds of that amount.
Even a small reduction in the growth of these programs would save billions of dollars.
Based on the unexpected slowdown in spending growth during the last few years, the Congressional Budget Office recently cut its ten-year projections for these programs by 3.5%, reducing the ten-year deficit by $382 billion.
Trends in the US budget reflect an inconvenient truth: If the growth of spending on health-care programs cannot be slowed, stabilizing the federal debt at a sustainable level will require deep cuts in spending on other priorities and increases in taxes on the middle class.
The recent slowdown in the growth of health-care spending is a promising sign that America’s budgetary tradeoffs may turn out to be less difficult than expected.
Why Turkey is Thriving
NEW YORK – A recent visit to Turkey reminded me of its enormous economic successes during the last decade.
The economy has grown rapidly, inequality is declining, and innovation is on the rise.
Turkey’s achievements are all the more remarkable when one considers its neighborhood.
Its neighbors to the west, Cyprus and Greece, are at the epicenter of the eurozone crisis.
To the southeast is war-torn Syria, which has already disgorged almost 400,000 refugees into Turkey.
To the east lie Iraq and Iran.
And to the northeast lie Armenia and Georgia.
If there is a more complicated neighborhood in the world, it would be difficult to find it.
Yet Turkey has made remarkable strides in the midst of regional upheavals.
After a sharp downturn in 1999-2001, the economy grew by 5% per year on average from 2002 to 2012.
It has remained at peace, despite regional wars.
Its banks avoided the boom-bust cycle of the past decade, having learned from the banking collapse in 2000-2001.
Inequality has been falling.
And the government has won three consecutive general elections, each time with a greater share of the popular vote.
There is nothing flashy about Turkey’s rise, which has been based on fundamentals, rather than bubbles or resource discoveries.
Indeed, Turkey lacks its neighbors’ oil and gas resources, but it compensates for this with the competitiveness of its industry and services.
Tourism alone attracted more than 36 million visitors in 2012, making Turkey one of the world’s top destinations.
Even a short stay in Ankara allows one to see these underlying strengths.
The airport, highways, and other infrastructure are first class, and a high-speed intercity rail network links Ankara with other parts of the country.
Much of the advanced engineering is homegrown.
Turkish construction firms are internationally competitive and increasingly win bids throughout the Middle East and Africa.
Turkey’s universities are rising as well.
Ankara has become a hub of higher education, attracting students from Africa and Asia.
Many top programs are in English, ensuring that Turkey will attract an increasing number of international students.
And the country’s universities are increasingly spinning off high-tech companies in avionics, information technology, and advanced electronics, among other areas.
To its credit, Turkey has begun to invest heavily in sustainable technologies.
The country is rich in wind, geothermal, and other renewable energy, and will most likely become a global exporter of advanced green innovations.
Waste-treatment facilities are not typically tourist attractions, but Ankara’s novel integrated urban waste-management system has rightly attracted global attention.
Until a few years ago, the waste was dumped into a fetid, stinking, noxious landfill.
Now, with cutting-edge technology, the landfill has been turned into a green zone.
The private waste-management company ITC receives thousands of tons of solid municipal waste each day.
The waste is separated into recyclable materials (plastics, metals) and organic waste.
The organic waste is processed in a fermentation plant, producing compost and methane, which is used to produce electricity in a 25-megawatt power plant.
The electricity is returned to the city’s power grid, while the heat exhaust is piped to the facility’s greenhouses, which produce tomatoes, strawberries, and orchids.
Turkey’s diversified, innovative base of industry, construction, and services serves it well in a world in which market opportunities are shifting from the United States and Western Europe to Africa, Eastern Europe, the Middle East, and Asia.
Turkey has been deft in seizing these new opportunities, with exports increasingly headed south and east to the emerging economies, rather than west to high-income markets.
This trend will continue, as Africa and Asia become robust markets for Turkey’s construction firms, information technology, and green innovations.
So, how did Turkey do it?
Most important, Prime Minister Recep Tayyip Erdoğan and his economics team, led by Deputy Prime Minister Ali Babacan, have stuck to basics and looked to the long term.
Erdoğan came to power in 2003, after years of short-term instability and banking crises.
The International Monetary Fund had been called in for an emergency rescue.
Step by step, the Erdoğan-Babacan strategy was to rebuild the banking sector, get the budget under control, and invest heavily and consistently where it counts: infrastructure, education, health, and technology.
Smart diplomacy has also helped.
Turkey has remained a staunchly moderate voice in a region of extremes. It has kept an open door and balanced diplomacy (to the extent possible) with the major powers in its neighborhood.
This has helped Turkey not only to maintain its own internal balance, but also to win markets and keep friends without the heavy baggage and risks of divisive geopolitics.
No doubt, Turkey’s ability to continue on a rapid growth trajectory remains uncertain.
Any combination of crises – the eurozone, Syria, Iraq, Iran, or world oil prices – could create instability.
Another global financial crisis could disrupt short-term capital inflows.
A dangerous neighborhood means inescapable risks, though Turkey has demonstrated a remarkable capacity during the last decade to surmount them.
Moreover, the challenge of raising educational quality and attainment, especially of girls and women, remains a priority.
Fortunately, the government has clearly acknowledged the education challenge and is pursuing it through school reforms, increased investments, and the introduction of new information technologies in the classroom.
Turkey’s successes have deep roots in governmental capacity and its people’s skills, reflecting decades of investment and centuries of history dating back to Ottoman times.
Other countries cannot simply copy these achievements; but they can still learn the main lesson that is too often forgotten in a world of “stimulus,” bubbles, and short-term thinking.
Long-term growth stems from prudent monetary and fiscal policies, the political will to regulate banks, and a combination of bold public and private investments in infrastructure, skills, and cutting-edge technologies.
Instability from Rigidity
Everyone wants economic stability, and many are reluctant to abandon today what gave them stability yesterday.
But trying to obtain stability from rigidity is illusory.
The stability of the international financial system today depends on the willingness of countries with rigid exchange rates to allow greater flexibility.
In the aftermath of the international financial crisis of 1997-1998, many emerging markets found themselves – through currency depreciation, rapid productivity gains, or both – highly competitive.
Countries that ran significant current-account surpluses, built up large reserves, and fixed (or heavily managed) their exchange rates in order to support the first two objectives appeared to secure external stability.
The irony is that the crisis of 1997-1998 was one in which a particular system of exchange-rate pegs failed when capital flowed out.
Yet, in many ways, accumulating reserves worked better than anyone could have imagined – countries found that they could withstand considerable shocks and growth was impressive both domestically and globally.
So, within a few years, many countries concluded that their pegs could work fine if supported by large enough war chests of official reserves.
A new type of order emerged in the world’s exchange rate system.
There were, of course, some less desirable spillover effects on others.
If a considerable fraction of the world economy wants to run a current-account surplus (by 2006, this included much of emerging Asia, most oil exporters, and Japan), an equal share of the world economy must run a deficit.
In the period after 1998, the United States provided almost the entire required deficit.
As long as US assets were attractive to residents of surplus countries (or there was an acceptable chain of investments from surplus countries that ended in the US), these accumulations of reserves were sustainable.
The IMF worried a great deal about what would happen when this chain broke – and the eventual break was, of course, more a matter of arithmetic than economics.
The US current-account deficit can persist above roughly 3% of GDP only if unrealistic assumptions are made about the share of US assets that the rest of the world is willing to hold.
The policy plans announced by China, the euro area, Japan, Saudi Arabia, and the US in the spring of 2007 – in the context of the IMF’s Multilateral Consultation on global imbalances – represent the international community’s response to the rising risks.
The US is to reduce its deficit, with the surplus countries proposing sensible steps to bring down their surpluses in ways that support global growth.
The sense of urgency in these discussions has increased in recent months, as the global situation has grown more complex.
Specifically, problems in the US housing sector have, since summer, undermined confidence in securitized assets.
The net result has been to shift global portfolio preferences in ways that have affected some exchange rates significantly.
The dollar has depreciated in a way that helps global adjustment and fortunately does not disrupt the US government securities market; long-term rates are in fact down from July, so adjustment has been “orderly.”
Yet the pattern of exchange-rate movements in the rest of the world has been largely unrelated to existing current-account positions.
In fact, currencies of surplus countries with heavily managed exchange rates have actually depreciated in real effective terms since the summer, creating inflationary pressure and frustrating global adjustment.
This has also shifted the burden of adjustment disproportionately onto countries with floating currencies, such as the euro and the Canadian and Australian dollar.
The lack of adjustment of surplus countries with inflexible exchange rate-regimes means that as the US deficit falls, a counterbalancing deficit develops elsewhere in the world – along with real effective exchange rate appreciation.
Knowing what to do in this increasingly complex and volatile situation is the easy part: look at the Multilateral Consultation policy plans and “just do it.”
This would help maintain confidence that the adjustment process will remain orderly and free of new global imbalances or protectionism.
Implementing the policy commitments from the multilateral consultation is also needed to avoid a loss of confidence in the dollar.
The risks to global growth will increase as long as adjustment remains uneven.
The politics is not so simple, but we need cooperation between countries to reduce these risks, and we need it now.
David Cameron’s European Spaghetti Bowl
WASHINGTON, DC – British Prime Minister David Cameron’s “Europe” speech, delivered on January 23, was powerful, polished, contained a bold vision, and offered good arguments.
In particular, he got three things right.
But translating those arguments into institutional reality will be a nearly impossible challenge.
First, Cameron is correct to emphasize the urgent need for a renewal of popular support for the European Union.
The percentage of Europeans who believe that the EU is “a good thing” is dropping steadily.
Democracies require real debate.
Yet too many decisions about the future of Europe and the eurozone are made in highly technocratic settings, with most citizens not really understanding what is going on, let alone feeling that policymakers care.
One can debate whether a referendum is the most appropriate vehicle for asking for their consent, but ask one must.
As Cameron put it: “There is a gap between the EU and its citizens which has grown dramatically in recent years and which represents a lack of democratic accountability and consent that is – yes – felt particularly acutely in Britain.”
Addressing the political challenge head on is much better than trying to evade the debate.
Second, Cameron was right to say that “the European Union that emerges from the eurozone crisis … will be transformed beyond recognition by the measures needed to save the eurozone.”
He did not disagree that the eurozone needs more integration, but correctly noted that the required degree of political integration is beyond the comfort zone of British citizens and of others in the EU.
Finally, Cameron argues that the EU is not an end in itself.
Rather, it must deliver better economic performance for its citizens by emphasizing the challenge of competitiveness, particularly with respect to the new emerging countries.
His speech stressed the economic weakness of many EU members (though some – such as Germany and the Nordic countries – are actually doing reasonably well in the global marketplace).
As a conservative, Cameron lays the blame for economic weakness on the size of the state and a high degree of market regulation, though some Nordic countries with large government spending and strong financial and environmental regulations are in better shape than the UK, which has had less of both.
But he is right that a debate on economic performance is needed, and that it will be crucial to reform Europe in a way that maximizes its prospects in global competition.
It is normal for conservatives to argue for less government and to place greater trust in free markets, and for social democrats and greens to argue for public policies that deliver less income inequality, more public goods (such as a clean environment and public transport), and more regulation to help markets function with greater stability and distribute benefits more evenly.
The competitiveness debate should indeed be part of the debate about Europe’s renewal.
But Cameron’s vision for Europe’s institutional future is difficult to translate into workable specifics.
He argues for a Europe “à la carte,” at least for those outside the eurozone.
He entertains the possibility that the UK and other EU countries that have opted out of the eurozone could each negotiate a specific and special “deal” with the EU, picking and choosing among its various dimensions those that suit them best and cost them the least.
Thinking about the consequences that such a Europe would have on EU institutions, one must ask how the European Commission, the European Parliament, and the Council of Ministers would function.
Would there be one set of sub-institutions for every country that has made a special deal with the Union – say, a Commission for the eurozone and Sweden, and another for the eurozone and the UK?
And would the European Parliament become fragmented in similar fashion?
Would the European Council have a diverse set of memberships?
How many temporary or permanent opt-outs can there be?
How will Europe’s citizens, who already have enough trouble with the complexities of European governance, be able to comprehend such a “spaghetti bowl” structure?
And yet Cameron is right to believe that not all EU members will want or be able to be part of a more integrated eurozone.
There will have to be some flexibility if the EU is not to shrink, becoming a smaller eurozone.
British membership is important to many in Europe.
One way to overcome the dilemma might be to articulate an institutional future in which there would be essentially just two types of countries within the EU and the single market: those in the eurozone and those with national currencies.
There would have to be two sets of EU institutions, one for the eurozone and another for non-eurozone countries, although they would overlap.
This is already the case in some areas: consider the EU-wide Ecofin and the eurozone-only Eurogroup of Finance Ministers.
Something similar could be created for the European Parliament, and so on.
It would be complex, but it could be made manageable; we should discuss how.
A new European treaty would not allow cherry-picking, but would give each member state a chance to join, or commit to, either the politically more integrated eurozone or the less integrated second group.
There would be clear rules and decision-making mechanisms for both sets of countries, subject to democratic votes by a two-tier European Parliament.
Many details would have to be worked out.