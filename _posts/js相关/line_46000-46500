In each country where conflict is present or emerging (Bolivia, Guatemala, El Salvador, Paraguay, and Ecuador) the hard-left will push hard, the democracies will look the other way, and Obama will either give in (as at the OAS) and pay a domestic political price, or step back from Latin America, for fear of appearing isolated.
A magnificent opportunity for a new start in US-Latin American relations will have been missed.
Cultivating Energy
From climate change to volatile oil prices, all signs point to a looming global energy crisis.
Confronting the growing challenge means that humanity can no longer afford to ignore the inexhaustible resource found in the organic material that the sun provides each day through photosynthesis.
Solar energy enables plants to absorb carbon gas and thereby produce not only oxygen, but also matter that the animal kingdom uses for food – and that our machines can use for energy. 
Since the Neolithic (or late Stone Age) period, humans have been cultivating this “biomass” in order to feed itself.
Yet, even in today’s world, its energy potential is ignored.
Beginning with the industrial revolution, humans sought energy from coal, and later from oil and natural gas, but this leads to the exhaustion of non-renewable resources. 
Existing alternatives for diversifying energy production are limited.
Nuclear energy presents a number of disadvantages, owing to concerns about safety and disposal of radioactive waste.
Hydroelectric power is already widely used, while wind and solar energy are structurally sporadic and disparately available.
Biomass, on the other hand, has several advantages.
Supplies of it are large and available throughout the world.
Moreover, the technology necessary to convert it into energy – including high-yield burning, gas conversion, and liquefaction into synthetic fuel – has long been mastered.
Widely used during World War II, this technology has since advanced considerably. 
Biomass energy, however, is the victim of unfair competition from fossil fuels.
Oil’s price reflects its extraction, refining, and distribution costs, but not that of creating the raw material.
Millions of years and 200 tons of plant matter are necessary to produce one liter of oil, whereas just 15 kilograms of plant matter are required to make one liter of synthetic fuel.
After the oil glut, with oil below $20 a barrel, interest in developing energy from biomass ebbed, attractive only to “green” militants and those interested in fundamental science.
Yet the potential is immense.
The planet’s biomass – forests, pastureland, savannas, and crops – make up productive capital that generates a 10% “return” every year.
Like a battery that runs out and is then recharged by the sun, this supply is renewable indefinitely, as long as it is managed properly.
The annual return on this capital is currently estimated at 60 billion tons, yet only two billion tons is consumed for food purposes and 10 billion tons for energy. 
Increasing the responsible use of this energy source would contribute to the fight against climate change by reducing the amount of carbon in the atmosphere and diminishing the amount of fossil fuel required to produce energy.
Moreover, its abundance in southern countries promises to facilitate their economic development.
Considered the “energy of the poor” until today, biomass could become a source of wealth if it is grown and harnessed with the support of the international community. 
Thus, “energy crops” could be developed to produce biofuel.
Residue from forest, agricultural, and agro-industrial activities could be collected and converted.
For example, the six million tons of waste produced annually by Niger could theoretically be used to meet that country’s entire energy needs. 
However, in many places, energy cropping would certainly compete with food crops.
Long-term estimates project that over a 50-year time horizon, most of the planet’s arable land would have to be used to feed the world and for forest conservation.
Thus, areas dedicated to energy production, particularly biofuel, may not reach the level that societies would wish.
But, while such competition would reveal new global scarcities, it would also bring higher prices, thereby encouraging producers to increase yields and productivity.
Thus, while cultivating energy would create new constraints, it would also open new possibilities for many economic actors.
The farmer and the forest worker could become more involved in the market, the mine engineer could begin to take an interest in crop fields, the banker in plant shares, etc.
But, in order to prepare for a scaling up of energy cropping, new policies must be implemented, both in northern and southern countries, in terms of agriculture, land and water management, protection of biodiversity, fuel taxes, and information and awareness-raising. 
The ancient Egyptians and the Incas practiced a religion of the Sun, believing it to be at the beginning of all life on Earth.
Science has since proven this to be the case.
Nowadays, when it has become more important than ever that we embrace renewable resources, we should use the Sun to cultivate our energy, just as our ancestors used it to cultivate their food.
Curing Hereditary Breast Cancer
In developed countries, breast cancer affects about one in ten women, and in many of these countries the disease is on the increase.
But, whatever the reason (or reasons) for the rise in their occurrence, we also know that between 5% and 10% of breast cancers are due to an inherited defect that affects the BRCA1 or BRCA2 genes.
Women carrying a mutated BRCA1 or BRCA2 gene have roughly an 80% risk of developing breast cancer.
A mutation in these genes also leads to an increased risk of developing ovarian tumors.
When the BRCA1 and BRCA2 genes were discovered more than a decade ago, there were high hopes for novel and targeted therapies.
Disappointingly, no new treatments have yet arisen.
As a result, many women with a high level of mutated BRCA1 or BRCA2 genes face the tragic choice of having their breasts and ovaries surgically removed to pre-empt cancer.
Recently, my research group, along with researchers in London, provided some real hope for carriers of mutated BRCA1 or BRCA2 genes.
Both research teams describe how the use of a chemical inhibitor can kill tumor cells that have either a BRCA1 or BRCA2 gene defect causing hereditary breast cancer.
This new treatment targets only the tumor cells and is unlikely to affect other healthy cells in the body.
The discovery could also work to prevent hereditary breast cancer cells from growing into tumors.
The chemical inhibitors used in this treatment target the enzyme polymerase (PARP1), which is normally involved in the repair of DNA single-strand breaks – a common form of spontaneous DNA lesions.
Chemical inhibition of the PARP1 protein results in reduced occurrence of these single-strand break repairs.
Unrepaired single-strand breaks are not very toxic to cells.
However, these breaks disrupt and damage the DNA when they are copied as DNA replicates.
The damage arising when copying the DNA is repaired with recombination, involving the BRCA1 and BRCA2 proteins. But cells with mutated BRCA1 or BRCA2 genes are unable to undergo recombination and are therefore much more sensitive to an increased level of unrepaired single-strand breaks.
The normal cells of women carrying the BRCA1 or BRCA2 mutations can still recombine, because they retain one functional allele—or alternative form—of the gene.
Only those cells losing this remaining functional allele of the BRCA1 or BRCA2 gene will become tumors.
Thus, only the tumor cells will have a non-functional recombination pathway and rely completely on PARP to repair single-strand breaks before copying the DNA.
In our research, we exploit this requirement to specifically target the BRCA1 or BRCA2-defective cancer cells with inhibitors of PARP.
This treatment is unlikely to cause many side effects; prolonged treatments with PARP inhibitors are well tolerated in mice.
We have shown that PARP inhibitors are effective at killing BRCA2-defective breast cancer cells, and that the tumors they cause can fully regress and disappear following treatment with a PARP inhibitor.
The next step is to investigate how efficient this treatment is in human patients.
We are now initiating clinical trials to determine how efficient these PARP inhibitors are in the treatment of metastasized breast tumors.
But caution is in order.
BRCA1 and BRCA2-defective tumors are characterized by a high degree of genetic instability.
It is possible that highly metastasized breast tumors might have acquired additional genetic changes causing resistance to treatment with PARP inhibitors.
Therefore, we suggest that PARP inhibitors might be more useful in the prophylactic treatment of women carrying the gene responsible for this form of inherited breast cancer.
The reason is simple: cells that have recently lost the functional BRCA1 or BRCA2 allele and that will later grow into tumors will also be unable to undergo recombination.
This means that early cancerous cells should be sensitive to PARP inhibitors.
However, unlike fully developed tumors, they are not likely to have acquired many genetic changes and are therefore unlikely to have gained resistance to PARP inhibitors.
Treating women carrying BRCA1 or BRCA2 mutations with PARP inhibitors to kill cancer cells before they grow into tumors is a new and hopeful concept in cancer prevention.
However, the usefulness of this treatment relies on the fact that PARP1 inhibitors are completely non-toxic to humans.
It will also take longer to validate a PARP inhibitor for use as a prophylactic treatment, because the treatment cannot be proven effective in a short time.
Thus, while the use of PARP inhibitors to treat established tumors may be feasible within a few years, we could have to wait at least a decade before a prophylactic treatment for inherited breast cancer is widely available.
The Return of the Currency Crash
CAMBRIDGE – Currency-market volatility has been around for decades, if not centuries.
Wide gyrations in exchange rates became a staple of international financial markets after the Bretton Woods system broke down in the early 1970s, and mega-depreciations were commonplace later in the decade and through much of the 1980s, when inflation raged across much of the world.
Even through much of the 1990s and early 2000s, 10-20% of countries worldwide experienced a large currency depreciation or crash in any given year.
And then, suddenly, calm prevailed.
Excluding the mayhem associated with the global financial crisis of late 2008 and early 2009, currency crashes were few and far between from 2004 to 2014 (see figure).
But recent developments suggest that the dearth of currency crashes during that decade may be remembered as the exception that proves the rule.
The near-disappearance of currency crashes in the 2004-2014 period largely reflect low and stable international interest rates and large capital flows to emerging markets, coupled with a commodity price boom and (mostly) healthy growth rates in countries that escaped the global financial crisis.
In effect, many countries’ main concern during those years was avoiding sustained currency appreciation against the US dollar and the currencies of other trade partners.
That changed in 2014, when deteriorating global conditions revived the currency crash en masse.
Since then, nearly half of the sample of 179 countries shown in the figure have experienced annual depreciations in excess of 15%.
True, more flexible exchange-rate arrangements have mostly eliminated the drama of abandoning pre-announced pegged or semi-pegged exchange rates.
But, thus far, there is little to suggest that the depreciations have had much of a salutary effect on economic growth, which for the most part has remained sluggish.
The average cumulative depreciation versus the US dollar has been almost 35% from January 2014 to January 2016.
For many emerging markets, where depreciations have been considerably greater, weakening exchange rates have aggravated current problems associated with rising foreign-currency debts.
Moreover, in an interconnected world, the effects of currency crashes do not end in the country where they originate.
Back in 1994, China reformed its foreign-exchange framework, unified its system of multiple exchange rates, and, in the process, devalued the renminbi by 50%.
It has been persuasively argued that the Chinese devaluation resulted in a loss of competitiveness for Thailand, Korea, Indonesia, Malaysia, and the Philippines, which had pegged (or semi-pegged) their currencies to the US dollar.
Their cumulative overvaluation, in turn, helped set the stage for the Asian crisis that erupted in mid-1997.
Overvalued exchange rates have been among the best leading indicators of financial crises.
So one cannot help but wonder if we are facing a repeat of what happened from 1994 to 1997 – only this time with the roles reversed.
Since early 2014, the renminbi has depreciated by a mere 7.5% against the dollar, compared to the euro’s roughly 25% depreciation in this period, not to mention even faster currency weakening in many emerging markets.
For a manufacturing-based economy such as China’s, the overvaluation-growth connection should not be underestimated.
China’s announcement last August of its intent to allow modest depreciation and eventually move the renminbi toward greater exchange-rate flexibility triggered a roller-coaster ride in financial markets.
To provide reassurance, policymakers issued statements to the effect that China would move only gradually in that direction.
But perhaps the cautionary tale from the Asian crises is that gradualism on this front carries its own risks.
Of course, the potential beggar-thy-neighbor effects of the spike in currency crashes in the past two years are not unique to China.
They may also apply to any country that has maintained a comparatively fixed exchange rate (a category that includes major oil producers).
What distinguishes the Chinese case from others is the sheer size of its economy relative to world GDP, as well as its effects on numerous countries across regions, from suppliers of primary commodities to countries that depend on Chinese funding or direct investment.
The broader point is a simple one: Emerging markets now account for around 60% of world GDP, up from about 35% in the early 1980s.
Restoring global prosperity requires a much broader geographical base than it did back then.
The return of the currency crash may make achieving it all the more difficult.
How to Fight Currency Manipulation
WASHINGTON, DC – Is it appropriate to use trade agreements to discourage countries from using large-scale intervention in the foreign-exchange market to hold down their currencies’ value?
That is the question of the day in American economic-policy circles.
In recent years, Japan, South Korea, and China have manipulated their currencies to keep them undervalued.
This boosted their exports, limited imports, and led to large current-account surpluses.
But such intervention adversely affects trading partners and is barred under existing international rules.
Unfortunately, those rules have proved completely ineffective.
Now a new opportunity to address the issue has emerged: The Trans-Pacific Partnership – the mega-regional free-trade agreement involving the United States, Japan, and ten other countries in Latin America and Asia.
With the TPP close to being finalized, South Korea and China are watching intently, and other countries may want to join.
US President Barack Obama correctly argues that this is an occasion to set the rules for trade and investment in the twenty-first century.
Yet the US Treasury Department and the US Trade Representative steadfastly refuse to include any language prohibiting currency manipulation in the TPP, for five main reasons – none of which fits the facts.
The first argument is that the International Monetary Fund can deal with instances of currency manipulation.
The IMF does have up-to-date guidelines that define and seek to prevent currency manipulation.
These were adopted not only with America’s assent, but at its insistence, at a time (the mid-2000s) when China’s renminbi was greatly undervalued, contributing to the loss of millions of US manufacturing jobs.
Unfortunately, the IMF cannot enforce its guidelines, because currency manipulators are able to stall action.
This has been the entrenched and continuing pattern, including when I was the IMF’s chief economist (from early 2007 to August 2008).
The second argument made by the US Treasury and the Trade Representative is that no sufficiently precise currency rules can be negotiated.
But there is nothing wrong with the IMF guidelines – both the 2007 and 2012 versions – negotiated by the Treasury itself.
Recognizing this, Congressman Sander Levin – the senior Democrat on the House Ways and Means Committee, which has jurisdiction over international trade – proposes that a TPP currency chapter be based on the IMF guidelines.
These guidelines identify when a country, despite running a large current-account surplus, is pursuing long-term, large-scale purchases of foreign assets, thereby blocking exchange-rate appreciation – exactly the problem we want to prevent.
(I have worked with Levin on some of these issues, but here I am speaking only for myself.)
The third argument against putting anti-manipulation provisions in the TPP is that they would imperil America’s ability to implement monetary stimulus.
But this reflects a thorough misunderstanding of the issue.
A well-designed currency chapter in the TPP would not impede US monetary independence.
Conventional monetary policy operates by altering short-term interest rates, which includes the central bank buying and selling short-term government debt.
No intervention in the foreign-exchange market – buying and selling foreign currency – is involved.
Similarly, the quantitative easing (QE) that has defined many major central banks’ monetary policy in recent years does not involve buying or selling foreign assets.
Under QE, the Federal Reserve buys – and announces that it will buy – assets; the only difference is that these assets are longer-maturity US government debt instruments and mortgage-backed securities of various kinds, all denominated in US dollars.
The fourth argument is that no major country is currently manipulating its exchange rate (the renminbi has appreciated since the mid-2000s), so there is nothing to worry about.
But there is also nothing to stop China or any other country from resuming large-scale currency-market intervention if and when it chooses.
And the lack of diplomatic tension around exchange rates today makes this a good moment to raise the topic.
The final reason cited in support of excluding a currency chapter from the TPP is that the countries negotiating the deal would never agree.
But this argument does not hold up when the participating countries are examined one by one.
Canada, Australia, and New Zealand, developed economies with floating exchange rates, do not want to encourage currency manipulation.
Chile, a middle-income country that has long had sound and responsible macroeconomic policies, does not favor currency manipulation.
Mexico and Peru have much to fear from other countries becoming currency manipulators again.
Likewise, Japan, now running its own version of QE, worries about potential currency manipulation by other countries, such as South Korea and China.
Malaysia and Singapore, having built up a substantial stock of foreign-exchange reserves, should also now be more concerned about currency manipulation by their trading partners.
Vietnam has much more serious TPP issues to resolve, particularly concerning labor rights.
And Brunei Darussalam, with a population of less than 500,000, is unlikely to object.
Currency manipulation is a real problem that causes significant damage.
The TPP deal – if it establishes a dispute-resolution mechanism that can quickly dismiss frivolous claims and home in on genuine cases – may offer the best chance to fix it.
The Currency Manipulation Charade
NEW HAVEN – As the US Congress grapples with the ever-contentious Trans-Pacific Partnership – President Barack Obama’s signature trade legislation – a major stumbling block looms.
On May 22, the Senate avoided it, by narrowly defeating – 51 to 48 – a proposed “currency manipulation” amendment to a bill that gives Obama so-called “fast-track” authority to negotiate the TPP.
But the issue could be resurrected as the debate shifts to the House of Representatives, where support is strong for “enforceable currency rules.”
For at least a decade, Congress has been focusing on currency manipulation – a charge leveled at countries that purportedly intervene in foreign-exchange markets in order to suppress their currencies’ value, thereby subsidizing exports.
In 2005, Senators Charles Schumer, a liberal Democrat from New York, and Lindsey Graham, a conservative Republican from South Carolina, formed an unlikely alliance to defend beleaguered middle-class US workers from supposedly unfair competitive practices.
Stop the currency manipulation, went the argument, and America’s gaping trade deficit would narrow – providing lasting and meaningful benefits to hard-pressed workers.
A decade ago, the original Schumer-Graham proposal was a thinly veiled anti-China initiative.
The ire that motivated that proposal remains today, with China accounting for 47% of America’s still outsize merchandise trade deficit in 2014.
Never mind that the Chinese renminbi has risen some 33% against the US dollar since mid-1995 to a level that the International Monetary Fund no longer considers undervalued, or that China’s current-account surplus has shrunk from 10% of GDP in 2007 to an estimated 2% in 2014.
China remains in the crosshairs of US politicians who believe that American workers are the victims of its unfair trading practices.
While this argument has great emotional and political appeal, it is deeply flawed, because the United States has an insidious saving problem.
America’s net national saving rate – the sum total of household, business, and government saving (adjusted for the depreciation of aging capacity) – currently stands at 2.5% of national income.
While that is better than the negative saving rates of 2008-2011, it remains well short of the 6.3% average of the final three decades of the twentieth century.
Lacking in saving and wanting to grow, America must import surplus savings from abroad.
And to attract that foreign capital, it has no choice but to run equally large balance-of-payments deficits.
So it is no coincidence that the US economy has a chronic current-account deficit.
While this shortfall has narrowed from a peak of 5.8% of GDP in 2006 to 2.4% in 2014, it still leaves the US heavily dependent on surplus foreign savings in order to grow.
This is where the trade deficit comes into play.
The US does not just pluck surplus foreign savings out of thin air.
To attract the capital it needs, America must send dollars overseas through foreign trade.
And it is here that the currency manipulation argument falls apart.
In 2014, the US ran trade deficits with some 95 countries.
In other words, America does not suffer from a small number of bilateral trade deficits that can be tied to charges of currency manipulation by countries like China, Japan, Malaysia, or Singapore.
Rather, the US suffers from a multilateral trade imbalance with many countries, and this cannot be remedied through the imposition of bilateral penalties such as tariffs.
Without fixing its savings problem, restricting trade with a few so-called currency manipulators would simply redistribute the US trade deficit to its other trading partners.
In effect, America’s trade balance is like a water balloon – applying pressure on one spot would simply cause the water to slosh elsewhere.
Moreover, this approach could easily backfire.
For example, assuming that there is no increase in domestic US saving, penalizing a low-cost producer like China for currency manipulation would most likely cause the Chinese piece of America’s trade deficit to be reallocated to higher-cost producers.
That would be the functional equivalent of a tax hike on middle-class families – precisely the constituency that so concerns Congress.
Further complications would arise from putting the verdict on currency manipulation – presumably dependent on some type of “fair value” metric – in the hands of politicians.
This is also the twist that underscores the ultimate congressional hypocrisy.
The charge of currency manipulation is nothing but a foil for the US to duck responsibility for fixing America’s saving problem.
Lacking any semblance of a strategy to boost savings – not just a long-term fix to the federal government’s budget deficit, but also meaningful incentives for personal saving – US politicians have turned to yet another quick fix.
In the end, there is no way around it: If Congress does not like trade deficits, it needs to address America’s saving problem and stop fixating on misplaced concerns over currency manipulation.
None of this is to argue that the US should ignore unfair trading practices.
As a member of the World Trade Organization, the US has ample opportunity to use that body’s dispute-resolution mechanism to adjudicate major problems with its trading partners.
And it has enjoyed success with this approach.
What Congress cannot do is pretend that wrong-footed trade policy is the answer to its inability or unwillingness to refocus its domestic policy agenda.
Of course, it is always easier to blame others than to look in the mirror.
But history has not been kind to major trade blunders.
Just as the Smoot-Hawley Tariff Act of 1930 sparked a global trade war that may well have put the “great” in the Great Depression, Congressional enactment of enforceable currency rules today could spark retaliatory actions that might devastate the free flow of trade that a sluggish global economy desperately needs.
The US Senate was wise in rejecting this dangerous option.
We can only hope that similar wisdom prevails in the House of Representatives.
Currency manipulation legislation is one tragedy that can and should be avoided.
The Myth of Currency Manipulation
TOKYO – This month, the Japanese yen’s exchange rate against the US dollar fell below ¥125, a 13-year low, before rebounding to nearly ¥122 following a statement by Bank of Japan Governor Haruhiko Kuroda that he did not expect further depreciation.
But, as Kuroda later clarified, Japan’s monetary policymakers do not seek to predict, much less control, exchange-rate movements.
Instead, the BOJ’s goal – like that of any effective central bank – is to ensure the right combination of employment and inflation.
Of course, a country’s monetary policy does affect exchange rates in the short term.
But it does so only in relation to monetary policy in other relevant countries.
In the case of Japan today, the exchange rate is being determined less by its own monetary expansion than by America’s move toward monetary tightening, following a period during which massive quantitative easing (QE) by the US Federal Reserve put upward pressure on the yen.
A country can also influence the short-term exchange rate by intervening directly in the foreign-exchange market.
But such interventions are complicated – not least because they must account for the relationship between the country’s monetary-policy approach and that of other relevant countries.
Moreover, if, for example, the United States aims for ¥100 per dollar, while Japan aims for ¥120 per dollar, the result could be not only rising tension between the US and Japan; incompatible exchange-rate targets could also trigger broader market volatility, with spillover effects on other economies.
Given this, monetary policy remains the most effective driver of exchange-rate movements.
The key to ensuring a satisfactory exchange-rate balance is for countries to pursue policies aimed at ensuring a desirable combination of domestic inflation and employment.
If, for example, meeting domestic inflation and employment targets requires greater monetary expansion – which will place downward pressure on the local currency, bolstering the economy’s international competitiveness – other countries may have to pursue their own monetary expansion to maintain optimal domestic inflation and employment rates.
That is precisely what happened after the global economic crisis.
The US, in an effort to prevent deflation and stem rising unemployment, initiated a massive QE program, with the United Kingdom following suit.
At first, the Bank of Japan hesitated to adjust its monetary policy accordingly, allowing the yen to appreciate – a decision that drove the country’s long-stagnant economy into recession.
Fortunately, when Prime Minister Shinzo Abe came to power in 2013, he recognized the need for monetary expansion, making it one of the three “arrows” of his strategy – dubbed Abenomics – for economic reform and recovery.
Thanks to this change in approach, Japan was able to arrest the yen’s appreciation and move toward stronger growth, without undermining the ability of the US or the UK to advance their own monetary-policy objectives.
The capacity for such adjustments is the hallmark of the flexible exchange-rate system; indeed, for more than four decades, it has proved time and again to be the key to global macroeconomic stability.
As long ago as the period following World War I, countries that adopted an independent monetary policy recovered faster than those that remained locked into the gold standard.
Yet some economists and journalists fear that countries, in attempting to gain an advantage in global markets, will engage in competitive devaluations, triggering large-scale inflation in the process.
Such concerns have even made their way into debates about the mega-regional free-trade agreements – namely, the Transatlantic Trade and Investment Partnership between the US and the European Union, and the Trans-Pacific Partnership – that are currently being negotiated.
Many are now calling for the inclusion of enforceable provisions prohibiting so-called “currency manipulation.”
Including such provisions would be a mistake – not least because exchange-rate issues are intrinsically irrelevant to trade deals.
In fact, such an approach – which has the potential to derail agreements that would bring considerable benefits to the economies involved – is based on a fallacy.
Unless countries are using direct intervention to pursue contradictory exchange-rate goals, a “currency war” that generates widespread inflation is highly unlikely.
If each country tailors its monetary policy to domestic macroeconomic objectives, exchange rates will settle naturally in a state of Pareto (or maximum) efficiency.
The economist Jeffrey Frankel has called currency manipulation a chimera, declaring that “linking efforts to prevent currency manipulation to trade agreements has always been a bad idea, and it still is.”
He is right.
Doing so would controvert the most fundamental rule of a flexible exchange-rate regime: that each economy can set – and pursue – its own monetary-policy goals.
Lessons from the Fiscal Cliff
CAMBRIDGE – One of the many things I learned from Milton Friedman is that the true cost of government is its spending, not its taxes.
To put it another way, spending is financed either by current taxes or through borrowing, and borrowing amounts to future taxes, which have almost the same impact on economic performance as current taxes.
We can apply this reasoning to the United States’ unsustainable fiscal deficit.
As is well known, closing this deficit requires less spending or more taxes.
The conventional view is that a reasonable, balanced approach entails some of each.
But, as Friedman would have argued, the two methods should be considered polar opposites.
Less spending means that the government will be smaller.
More taxes mean that the government will be larger.
Hence, people who favor smaller government (for example, some Republicans) will want the deficit closed entirely by cutting spending, whereas those who favor larger government (for example, President Barack Obama and most Democrats) will want the deficit closed entirely by raising taxes.
As the economist Alberto Alesina has found from studies of fiscal stabilization in OECD countries, eliminating fiscal deficits through spending cuts tends to be much better for the economy than eliminating them through tax increases.
A natural interpretation is that spending adjustments work better because they promise smaller government, thereby favoring economic growth.
For a given size of government, the method of raising tax revenue matters.
For example, we can choose how much to collect via a general income tax, a payroll tax, a consumption tax (such as a sales or value-added tax), and so on.
We can also choose how much revenue to raise today, rather than in the future (by varying the fiscal deficit).
A general principle for an efficient tax system is to collect a given amount of revenue (corresponding in the long run to the government’s spending) in a way that causes as little distortion as possible to the overall economy.
Usually, this principle means that marginal tax rates should be similar at different levels of labor income, for various types of consumption, for outlays today versus tomorrow, and so on.
From this perspective, a shortcoming of the US individual income-tax system is that marginal tax rates are high at the bottom (because of means testing of welfare programs) and the top (because of the graduated-rate structure).
Thus, the government has moved in the wrong direction since 2009, sharply raising marginal tax rates at the bottom (by dramatically increasing transfer programs) and, more recently, at the top (by raising tax rates on the rich).
One of the most efficient tax-raising methods is the US payroll tax, for which the marginal tax rate is close to the average rate (because deductions are absent and there is little graduation in the rate structure).
Therefore, cutting the payroll tax rate in 2011-2012 and making the rate schedule more graduated (on the Medicare side) were mistakes from the standpoint of efficient taxation.
Republicans should consider these ideas when evaluating tax and spending changes in 2013.
Going over the “fiscal cliff” would have had the attraction of seriously cutting government spending, although the composition of the cuts – nothing from entitlements and too much from defense – was unattractive.
The associated revenue increase was, at least, across the board, rather than the unbalanced hike in marginal tax rates at the top that was enacted.
But the most important part of the deal to avert the fiscal cliff was the restoration of the efficient payroll tax.
I estimate that the rise by two percentage points in the amount collected from employees corresponds to about $1.4 trillion in revenue over ten years.
This serious revenue boost was not counted in standard reports, because the payroll-tax “holiday” for 2011-2012 had always been treated legally as temporary.
It is true that some macroeconomic modelers, including the Congressional Budget Office, forecasted that going over the cliff would have caused a recession.
But those results come from Keynesian models that always predict that GDP expands when the government gets larger.
Entirely absent from these models are the negative effects of more government and uncertainty about how fiscal problems will be resolved.
Another recession in the US would not be a great surprise, but it can be attributed to an array of bad government policies and other forces, not to cutting the size of government.
Indeed, it is nonsense to think that cuts in government spending should be avoided in the “short run” in order to lower the chance of a recession.
If a smaller government is a good idea in the long run (as I believe it is), it is also a good idea in the short run.
Why Give Corporations a Tax Break?
BERKELEY – US President Barack Obama has called for additional revenue as part of a balanced plan to reduce future budget deficits.
But he is also proposing a significant cut in the corporate tax rate.
To many, this approach seems inconsistent: Shouldn’t the corporate tax rate be raised, not lowered, so that corporations contribute their “fair share” to deficit reduction?
The answer is no.
After its 1986 tax overhaul, the United States had one of the lowest corporate tax rates among OECD countries.
Since then, these countries have been slashing their rates in order to attract foreign direct investment and discourage their own companies from shifting operations and profits to low-tax foreign locations.
In the most recent and audacious move, the British government has embarked on a three-year plan to reduce its corporate tax rate from 28% to 20% – one of the lowest in the OECD – by 2015.
The US now has the highest corporate tax rate of these countries.
Even after incorporating various deductions, credits, and other tax-reducing provisions, the effective average and marginal corporate tax rates in the US – what corporations actually pay – are higher than the OECD average.
Cutting the rate to a more competitive level would encourage more domestic investment by US corporations, and would also make the US more attractive to foreign investors.
Capital has become increasingly mobile, and differences in national corporate tax rates have a growing influence on where multinational companies locate their operations and report their income.
Higher investment in the US by both domestic and foreign companies would boost economic growth, while the resulting increase in capital –&#160;new businesses, factories, equipment, and research –would improve productivity.
That should, in turn, boost real wages over time (although the link between productivity growth and wage growth has weakened during the last two decades).
The pro-growth rationale for reducing the US corporate tax rate is compelling, and explains why Obama has proposed cutting it from 35% to 28% (roughly the weighted average rate of the other developed countries).
But a rate cut would be costly in terms of foregone revenues: each percentage point would reduce corporate-tax revenues by about $100 billion over the next decade.
Moreover, recent studies indicate that a significant share of the corporate-tax burden falls on capital, so a reduction in corporate taxes would weaken the progressivity of the tax system at a time when income inequality is at an all-time high.
For these reasons, Obama is championing a “revenue-neutral” reform that would leave corporate-tax revenues unchanged, with the proposed rate cut financed by limiting deductions, credits, and loopholes, which would broaden the tax base.
These features add complexity to the tax code, raise the cost of tax compliance, and reduce corporate-tax revenues.
They also affect business decisions about what to invest in, how to finance investments, which form of business organization to adopt, and where to produce – reflecting sizeable differences in the effective tax rates behind these choices.
As a result, broadening the corporate tax base will not be easy.
Within the corporate sector, the three largest domestic tax preferences are the manufacturing production deduction, the credit for research and development, and accelerated depreciation of capital.
Manufacturing companies are the major beneficiaries of these preferences, and Obama has proposed strengthening the first two.
Instead, he suggests reforming the third by tightening allowances for accelerated depreciation (as several other developed countries have done) in order to offset some of the revenue losses.
But reducing the overall corporate rate would increase after-tax returns on past investments, while limiting accelerated depreciation would lower after-tax returns on new investments.
And even eliminating accelerated depreciation would not broaden the tax base enough to finance a rate cut to 28%.
Likewise, while limiting the deductibility of net interest for corporations, as many other developed countries have done, would broaden the tax base and discourage excessive reliance on debt financing, it would increase the tax burden on major investments in physical capital, which are often debt-financed.
Reducing the tax preferences for non-corporate business entities (such as partnerships) that pass their income through to their owners’ individual returns would also broaden the tax base subject to the corporate-income tax.
Pass-through companies now account for more than 80% of net business income (by far the highest share in the developed countries).
Several of these entities are very large and profitable, and enjoy the same legal benefits as corporations.
Economic logic suggests that businesses of similar size and engaged in similar activities should not pay different tax rates based solely on their organizational form.
The fact that a large share of business income is currently taxed as personal income makes it difficult to separate corporate tax reform from personal tax reform, as Obama and members of Congress would prefer to do.
Moreover, keeping the two areas of reform separate rules out the approach adopted by several other developed countries, which have offset some of the revenue losses from cutting corporate tax rates by increasing taxes on corporate equity income at the personal shareholder level.
This approach also addresses concerns about the regressive effects of a cut in the corporate rate.
It is both more progressive and more effective: with highly mobile capital, it is far easier to collect taxes from individual citizens and resident shareholders than from multinational companies.
According to a recent study, restoring tax rates on dividends and capital gains to their pre-1997 levels of 28% could finance a reduction in the US federal corporate tax rate from 35% to 26%.
This change would both reduce the incentive for corporations to shift investments abroad and increase the progressivity of the US tax system.
Similarly, a modest carbon tax or value-added tax, with credits or subsidies to offset the regressive effects on low-income households, could generate enough revenue both to pay for a significant reduction in the corporate tax rate and to make a meaningful contribution to deficit reduction.
There is no inconsistency between a progressive, balanced deficit-reduction plan and lowering the corporate tax rate.
Of all taxes, corporate taxes are the most harmful to economic growth – without which meaningful deficit reduction is far more difficult to achieve.
Cyber Insecurity
CAMBRIDGE – In August 2008, Russian troops moved into Georgia.
Observers dispute who fired first, but there was a little noticed dimension of the conflict that will have major repercussions for the future.
Computer hackers attacked Georgian government Web sites in the weeks preceding the outbreak of armed conflict.
The Russia-Georgia conflict represents the first significant cyber attacks accompanying armed conflict.
Welcome to the twenty-first century.
Cyber threats and potential cyber warfare illustrate the increased vulnerabilities and loss of control in modern societies.
Governments have mainly been concerned about hacker attacks on their own bureaucracy’s information technology infrastructure, but there are social vulnerabilities well beyond government computers.
In an open letter to the US president in September 2007, American professionals in cyber defense warned that “the critical infrastructure of the United States, including electrical power, finance, telecommunications, health care, transportation, water, defense, and the Internet, is highly vulnerable to cyber attack. Fast and resolute mitigating action is needed to avoid national disaster.”
In the murky world of the Internet, attackers are difficult to identify.
In today’s interconnected world, an unidentified cyber attack on non-governmental infrastructure might be severely damaging.
For example, some experts believe that a nation’s electric power grid may be particularly susceptible.
The control systems that electric power companies use are thought vulnerable to attack, which could shut down cities and regions for days or weeks.
Cyber attacks may also interfere with financial markets and cause immense economic loss by closing down commercial Web sites.
Some scenarios, including an “electronic Pearl Harbor,” sound alarmist, but they illustrate the diffusion of power from central governments to individuals.
In 1941, the powerful Japanese navy used many resources to create damage thousands of miles away.
Today, an individual hacker using malicious software can cause chaos in far-away places at little cost to himself.
Moreover, the information revolution enables individuals to perpetrate sabotage with unprecendented speed and scope.
The so-called “love bug virus,” launched in the Phillipines in 2000, is estimated to have cost billions of dollars in damage.
Terrorists, too, can exploit new vulnerabilities in cyberspace to engage in asymmetrical warfare.
In 1998, when America complained about seven Moscow Internet addresses involved in the theft of Pentagon and NASA secrets, the Russian government replied that phone numbers from which the attacks originated were inoperative.
The US had no way of knowing whether the Russian government had been involved.
More recently, in 2007, China’s government was accused of sponsoring thousands of hacking incidents against German federal government computers and defense and private-sector computer systems in the US.
But it was difficult to prove the source of the attack, and the Pentagon had to shut down some of its computer systems. 
In 2007, when Estonia’s government moved a World War II statue commemorating Soviet war dead, hackers retaliated with a costly denial-of-service attack that closed down Estonia’s access to the internet.
There was no way to prove whether the Russian government, a spontaneous nationalist response, or both aided this transnational attack.
In January 2008, President George W. Bush signed two presidential directives that called for establishing a comprehensive cyber-security plan, and his 2009 budget requested $6 billion to develop a system to protect national cyber security.
President-elect Barack Obama is likely to follow suit.
Just recently, Donald Kerr, the US deputy director of national intelligence, warned that “major losses of information and value for our government programs typically aren’t from spies....In fact, one of the great concerns I have is that so much of the new capabilities that we’re all going to depend on aren’t any longer developed in government labs under government contract.”
Kerr described what he called “supply chain attacks” in which hackers not only steal proprietary information, but go further and insert erroneous data and programs in communications hardware and software – Trojan horses that can be used to bring down systems.
All governments will find themselves exposed to a new type of threat that will be difficult to counter.
Governments can hope to deter cyber attacks just as they deter nuclear or other armed attacks.
But deterrence requires a credible threat of response against an attacker.
And that becomes much more difficult in a world where governments find it hard to tell where cyber attacks come from, whether from a hostile state or a group of criminals masking as a foreign government.
While an international legal code that defines cyber attacks more clearly, together with cooperation on preventive measures, can help, such arms-control solutions are not likely to be sufficient. Nor will defensive measures like constructing electronic firewalls and creating redundancies in sensitive systems.
Given the enormous uncertainties involved, the new cyber dimensions of security must be high on every government’s agenda.
Cyber War and Peace
CAMBRIDGE – Two years ago, a piece of faulty computer code infected Iran’s nuclear program and destroyed many of the centrifuges used to enrich uranium.
Some observers declared this apparent sabotage to be the harbinger of a new form of warfare, and United States Secretary of Defense Leon Panetta has warned Americans of the danger of a “cyber Pearl Harbor” attack on the US.
But what do we really know about cyber conflict?
The cyber domain of computers and related electronic activities is a complex man-made environment, and human adversaries are purposeful and intelligent.
Mountains and oceans are hard to move, but portions of cyberspace can be turned on and off by throwing a switch.
It is far cheaper and quicker to move electrons across the globe than to move large ships long distances.
The costs of developing those vessels – multiple carrier task forces and submarine fleets – create enormous barriers to entry, enabling US naval dominance.
But the barriers to entry in the cyber domain are so low that non-state actors and small states can play a significant role at low cost.
In my book The Future of Power, I argue that the diffusion of power away from governments is one of this century’s great political shifts. &amp; Cyberspace is a perfect example.
Large countries like the US, Russia, Britain, France, and China have greater capacity than other states and non-state actors to control the sea, air, or space, but it makes little sense to speak of dominance in cyberspace.
If anything, dependence on complex cyber systems for support of military and economic activities creates new vulnerabilities in large states that can be exploited by non-state actors.
Four decades ago, the US Department of Defense created the Internet; today, by most accounts, the US remains the leading country in terms of its military and societal use.
But greater dependence on networked computers and communication leaves the US more vulnerable to attack than many other countries, and cyberspace has become a major source of insecurity, because, at this stage of technological development, offense prevails over defense there.
The term “cyber attack”covers a wide variety of actions, ranging from simple probes to defacing Web sites, denial of service, espionage, and destruction.
Similarly, the term “cyber war” is used loosely to cover a wide range of behaviors, reflecting dictionary definitions of war that range from armed conflict to any hostile contest (for example, “war between the sexes” or “war on drugs”).
At the other extreme, some experts use a narrow definition of cyber war: a “bloodless war” among states that consists solely of electronic conflict in cyberspace.
But this avoids the important interconnections between the physical and virtual layers of cyberspace.
As the Stuxnet virus that infected Iran’s nuclear program showed, software attacks can have very real physical effects.
A more useful definition of cyber waris hostile action in cyberspace whose effects amplify or are equivalent to major physical violence.
In the physical world, governments have a near-monopoly on large-scale use of force, the defender has an intimate knowledge of the terrain, and attacks end because of attrition or exhaustion.
Both resources and mobility are costly.
In the cyber world, by contrast, actors are diverse (and sometimes anonymous), physical distance is immaterial, and some forms of offense are cheap.
Because the Internet was designed for ease of use rather than security, attackers currently have the advantage over defenders.
Technological evolution, including efforts to “reengineer” some systems for greater security, might eventually change that, but, for now, it remains the case.
The larger party has limited ability to disarm or destroy the enemy, occupy territory, or use counterforce strategies effectively.
Cyber war, though only incipient at this stage, is the most dramatic of the potential threats.
Major states with elaborate technical and human resources could, in principle, create massive disruption and physical destruction through cyber attacks on military and civilian targets.
Responses to cyber war include a form of interstate deterrence through denial and entanglement, offensive capabilities, and designs for rapid network and infrastructure recovery if deterrence fails.
At some point, it may be possible to reinforce these steps with certain rudimentary norms and arms control, but the world is at an early stage in this process.
If one treats so-called “hacktivism” by ideological groups as mostly a disruptive nuisance at this stage, there remain four major categories of cyber threats to national security, each with a different time horizon: cyber war and economic espionage are largely associated with states, and cyber crime and cyber terrorism are mostly associated with non-state actors.
For the US, the highest costs currently stem from espionage and crime, but over the next decade or so, war and terrorism could become greater threats than they are today.
Moreover, as alliances and tactics evolve, the categories may increasingly overlap.
In the view of Admiral Mike McConnell, America’s former director of national intelligence, “Sooner or later, terror groups will achieve cyber-sophistication.
It’s like nuclear proliferation, only far easier.”
The world is only just beginning to see glimpses of cyber war – in the denial-of-service attacks that accompanied the conventional war in Georgia in 2008, or the recent sabotage of Iranian centrifuges.
States have the greatest capabilities, but non-state actors are more likely to initiate a catastrophic attack.
A “cyber 9/11” may be more likely than the often-mentioned “cyber Pearl Harbor.”
It is time for states to sit down and discuss how to limit this threat to world peace.
Can Cyber Warfare Be Deterred?
CAMBRIDGE – Fear of a “cyber Pearl Harbor” first appeared in the 1990s, and for the past two decades, policymakers have worried that hackers could blow up oil pipelines, contaminate the water supply, open floodgates and send airplanes on collision courses by hacking air traffic control systems.
In 2012, then-US Secretary of Defense Leon Panetta warned that hackers could “shut down the power grid across large parts of the country.”
None of these catastrophic scenarios has occurred, but they certainly cannot be ruled out.
At a more modest level, hackers were able to destroy a blast furnace at a German steel mill last year.
So the security question is straightforward: Can such destructive actions be deterred?
It is sometimes said that deterrence is not an effective strategy in cyberspace, because of the difficulties in attributing the source of an attack and because of the large and diverse number of state and non-state actors involved.
We are often not sure whose assets we can hold at risk and for how long.
Attribution is, indeed, a serious problem.
How can you retaliate when there is no return address?
Nuclear attribution is not perfect, but there are only nine states with nuclear weapons; the isotopic identifiers of their nuclear materials are relatively well known; and non-state actors face high entry barriers.
None of this is true in cyberspace where a weapon can consist of a few lines of code that can be invented (or purchased on the so-called dark web) by any number of state or non-state actors.
A sophisticated attacker can hide the point of origin behind the false flags of several remote servers.
While forensics can handle many “hops” among servers, it often takes time.
For example, an attack in 2014 in which 76 million client addresses were stolen from JPMorgan Chase was widely attributed to Russia.
By 2015, however, the US Department of Justice identified the perpetrators as a sophisticated criminal gang led by two Israelis and an American citizen who lives in Moscow and Tel Aviv.
Attribution, however, is a matter of degree.
Despite the dangers of false flags and the difficulty of obtaining prompt, high-quality attribution that would stand up in a court of law, there is often enough attribution to enable deterrence.
For example, in the 2014 attack on SONY Pictures, the United States initially tried to avoid full disclosure of the means by which it attributed the attack to North Korea, and encountered widespread skepticism as a result.
Within weeks, a press leak revealed that the US had access to North Korean networks.
Skepticism diminished, but at the cost of revealing a sensitive source of intelligence.
Prompt, high-quality attribution is often difficult and costly, but not impossible.
Not only are governments improving their capabilities, but many private-sector companies are entering the game, and their participation reduces the costs to governments of having to disclose sensitive sources.
Many situations are matters of degree, and as technology improves the forensics of attribution, the strength of deterrence may increase.
Moreover, analysts should not limit themselves to the classic instruments of punishment and denial as they assess cyber deterrence.
Attention should also be paid to deterrence by economic entanglement and by norms.
Economic entanglement can alter the cost-benefit calculation of a major state like China, where the blowback effects of an attack on, say, the US power grid could hurt the Chinese economy.
Entanglement probably has little effect on a state like North Korea, which is weakly linked to the global economy.
It is not clear how much entanglement affects non-state actors.
Some may be like parasites that suffer if they kill their host, but others may be indifferent to such effects.
As for norms, major states have agreed that cyber war will be limited by the law of armed conflict, which requires discrimination between military and civilian targets and proportionality in terms of consequences.
Last July, the United Nations Group of Government Experts recommended excluding civilian targets from cyberattacks, and that norm was endorsed at last month’s G-20 summit.
It has been suggested that one reason why cyber weapons have not been used more in war thus far stems precisely from uncertainty about the effects on civilian targets and unpredictable consequences.
Such norms may have deterred the use of cyber weapons in US actions against Iraqi and Libyan air defenses.
And the use of cyber instruments in Russia’s “hybrid” wars in Georgia and Ukraine has been relatively limited.
The relationship among the variables in cyber deterrence is a dynamic one that will be affected by technology and learning, with innovation occurring at a faster pace than was true of nuclear weapons.
For example, better attribution forensics may enhance the role of punishment; and better defenses through encryption may increase deterrence by denial.
As a result, the current advantage of offense over defense may change over time.
Cyber learning is also important.
As states and organizations come to understand better the importance of the Internet to their economic wellbeing, cost-benefit calculations of the utility of cyber warfare may change, just as learning over time altered the understanding of the costs of nuclear warfare.
Unlike the nuclear age, when it comes to deterrence in the cyber era, one size does not fit all.
Or are we prisoners of an overly simple image of the past?
After all, when nuclear punishment seemed too draconian to be credible, the US adopted a conventional flexible response to add an element of denial in its effort to deter a Soviet invasion of Western Europe.
And while the US never agreed to a formal norm of “no first use of nuclear weapons,” eventually such a taboo evolved, at least among the major states.
Deterrence in the cyber era may not be what it used to be, but maybe it never was.
The Politics of Moral Hazard
BRUSSELS – It is an old and never-ending contest.
On one side are the moral-hazard scolds, claiming that one of the major responsibilities confronting policymakers is to establish incentives that demonstrate that imprudent behavior does not pay.
On the other side are the partisans of financial stability, for whom confidence in the financial system is too precious to be endangered, even with the best possible intentions.
Cyprus is the latest battleground between the two camps.
On March 25, after the decision had been taken to wind up the country’s second-largest bank, and to impose large losses on uninsured depositors in the process, Eurogroup President Jeroen Dijsselbloem, the Dutch finance minister, declared that a healthy financial sector requires that “where you take on the risks, you must deal with them.”
The aim, he added, should be to create an environment in which Europe’s finance ministers “never need to consider a direct recapitalization” of a bank by the European Stability Mechanism. He was apparently reading from a textbook on moral hazard.
Immediately after this declaration, however, prices of European bank stocks plunged, and Dijsselbloem was accused by many (including some of his colleagues) of having poured oil on a burning fire.
Within hours, he issued a statement indicating that “Cyprus is a specific case with exceptional challenges,” and that “no templates are used” in the approach to the European crisis.
This is not convincing.
Markets learn from a current crisis which principles will be applied in the next one.
And letting them learn is precisely what the fight against moral hazard is about.
European policymakers have been agonizing over the same dilemma throughout the Cyprus crisis.
The burden of bailing out the country’s ailing financial institutions was too heavy for an already-indebted Cypriot state, and the International Monetary Fund was adamant that it would not pretend otherwise.
So, in mid-March, Cyprus was heading for a precipitous retrenchment of its banking system, resulting in the loss of a very large part of the country’s financial wealth.
For the IMF and Germany, which pushed for such an outcome, the rationale was the need to prevent moral hazard.
Cypriot President Nicos Anastasiades, reportedly with some support from European institutions, desperately tried to avoid this fate – in the name of financial stability.
The solution found during the night of March 15 – a one-time tax on deposits – was defensible from the Cypriot viewpoint.
Preserving domestic financial stability required limiting taxation of large deposits, because a substantial proportion belonged to foreign account-holders.
Avoiding a massive withdrawal of foreign capital therefore implied taxing all deposits below the €100,000 ($130,000) threshold.
Absent a foreign bailout, no other solution was on offer.
But this solution was detrimental to financial stability in the rest of Europe, because it signaled that the €100,000 threshold below which deposits are guaranteed was not sacrosanct.
Legally, of course, this guarantee is only worth the solvency of the guarantor – in this case the near-bankrupt Cypriot state.
But its abrogation would nonetheless be symbolically powerful, sparking anxiety throughout Europe.
The obvious way out of this dilemma would have been for Cyprus’s eurozone partners to assume the cost of the tax on deposits below €100,000.
Doing so would have cost them an estimated €1.3 billion, or roughly 0.01% of their GDP – a ridiculously low price to pay for financial stability.
It would not have created much moral hazard: large depositors would have been taxed, and the Cypriot government would still have suffered the strictures of an IMF/eurozone program – bitter enough medicine.
But, at a time when northern European citizens are full of resentment against banks and seething with anger over transfers to the south, German Chancellor Angela Merkel and her peers did not want to ask their taxpayers to pay for a partner country’s mistakes.
The March 15 agreement was not politically viable, and was overwhelmingly rejected by the Cypriot parliament.
So, ten days after the ill-fated solution was proposed, the Eurogroup ministers changed course and adopted the approach that they had tried to avoid.
Banks are being precipitously resolved.
The consequences are already visible: to avoid a complete meltdown, Cyprus has been forced to introduce capital controls – which everyone had thought were illegal and unthinkable within the eurozone.
As a result, investors and depositors have learned that the erection of financial barriers within the currency area is indeed a genuine risk.
And the Cypriots are so angry at Europe that a deliberate exit from the eurozone has become a distinct possibility.
Ultimately, the true contest is less between moral hazard and financial stability than it is between financially sensible and politically acceptable solutions.
In Europe, as elsewhere, financial policy used to be the remit of specialists – central bankers, regulators, and supervisors.
Not anymore: the experts have lost their legitimacy.
Nowadays, angry citizens are in charge, and politics is driving financial policy.
But politics in Europe is national, and what one national parliament regards as the only possible solution another national parliament regards as entirely unacceptable.
Europe has not yet found a response to this problem, and it is not on the way to finding one.
Europe’s Perpetual Crisis
ATHENS – The Cyprus bailout deal is a watershed in the unfolding eurozone crisis, because responsibility for resolving banks’ problems has been shifted from taxpayers to private investors and depositors.
But imposing major losses on Cypriot banks’ depositors violates the deposit-insurance guarantee that forms part of the proposed European banking union, while the imposition of capital controls further erodes the monetary union’s foundations.
So, is Europe chasing its tail?
Germany and the other countries of the eurozone core are signaling that debt mutualization within the monetary union is out of the question, and that bailouts of countries or financial institutions will be balanced by “bail-ins” of their creditors.
Increased uncertainty concerning the safety of deposits will push up interest rates and deepen Europe’s recession, and may also trigger capital outflows from the eurozone’s weaker peripheral economies to the core.
The implications of this shift may be far-reaching.
The German model for resolving the debt crisis and returning to internal or external balance relies on fiscal consolidation and structural reforms for the deficit countries.
But, if all countries simultaneously attempt to improve their fiscal or external balances by cutting spending and raising taxes, all will fail, because each country’s austerity implies less demand for other countries’ output, in turn perpetuating both domestic and external imbalances.
“Bailing in” creditors will exacerbate these trends.
Moreover, a deep and prolonged recession implies vanishing support for reforms, as governments fail to convince citizens that current sacrifice will ensure a better future.
Privatization, market liberalization, the opening of closed professions, and government downsizing involve conflicts with powerful vested interests, such as businesses in protected industries, public-sector unions, or influential lobbies.
Resolving such conflicts requires social alliances, which are invariably undermined by discontent, civil disorder, and political instability.
The recent Italian election has shown how toxic the association of austerity policies with the pursuit of reform has become.
Anti-austerity anger swept away the reform agenda of Mario Monti’s previous technocratic government, leaving Italy, its future uncertain, to continue muddling through.
The same scenario seems to be emerging in Greece, where the depth of the austerity-induced recession, with output down by 25% over five years and unemployment at 27%, is paralyzing a reform-minded center-right government.
The gaps in the strategy are clear.
First, the eurozone authorities misread the real causes of the debt crisis, which stemmed mainly from a growing competitiveness gap between the core and periphery countries.
The resulting private-sector imbalances culminated in banking problems that were eventually transferred to sovereigns.
Greece’s fiscal profligacy was the exception rather than the rule.
Indeed, in contrast to the United States, eurozone authorities were slow to consolidate the banking system after the global financial crisis erupted in 2008, and failed to sever the ties between sovereigns’ and banks’ balance sheets.
Nor did they push strongly for structural reforms.
Instead, they emphasized harsh austerity, which was to be pursued everywhere.
Second, the effects of austerity were exacerbated by the choice to pursue nominal, rather than structural, fiscal-deficit targets.
Countries with a stronger fiscal position (that is, smaller structural deficits) should be encouraged to adopt more expansionary policies in order to contribute to lifting overall demand.
Moreover, the European Investment Bank’s lending capacity could be increased substantially, and European Union structural funds mobilized, to finance investment projects in the peripheral economies.
Third, the European Central Bank’s announcement last August of its “outright monetary transactions” program – through which it guarantees eurozone members’ sovereign debt, subject to policy conditionality – has contributed significantly to subduing financial turbulence in the eurozone.
But the OMT scheme has not been reinforced by a reduction in key interest rates, which would boost inflation in core countries with external surpluses and thus help to close the competitiveness gap with the periphery.
Crucially, monetary-policy measures do not address the underlying problem of lack of demand.
Last, but not least, the eurozone authorities misread the confidence factor.
In theory, simultaneous fiscal consolidation and supply-side reform facilitates economic recovery, because it increases confidence among consumers and investors, thereby inducing higher spending and production.
But this does not necessarily work in an imperfectly functioning monetary union, such as the eurozone, where the continual appearance of systemic flaws erodes confidence; in such circumstances, the result may be hoarding and capital outflows, rather than increased spending.
The eurozone’s flaws reflect its conceptual distance from the US, which is the only model of a well-functioning monetary union.
Europe’s history rules out emulating the US model.
But, to make the eurozone work, monetary unification should extend to the fiscal and financial fields, thereby creating an integrated economic union.
The longer that European authorities postpone the introduction of Eurobonds, an effective banking and fiscal union, and lender-of-last-resort status for the ECB, the longer the crisis will last.
By effectively defaulting on a deposit-insurance guarantee through its actions in Cyprus, the eurozone backtracked on the planned banking union.
Pursuing a strategy that simultaneously deepens recession and weakens confidence will not resolve the debt crisis.
As funding problems recur in the recession-hit economies, governments may resist “bailing in” and the associated losses.
Civil unrest and political destabilization could erupt into financial and social crises that ultimately threaten the monetary union’s survival.
In short, the “solution” to the Cyprus crisis is no solution at all for the eurozone.
Unless the authorities embrace a growth strategy – and do so quickly – the eurozone’s prospects will become increasingly bleak.