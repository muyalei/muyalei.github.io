While such benefits may not appear to be “stimulus,” their mounting effect better serves the objective of raising expectations of future demand and growth.
But the concerns of serious people, whether on the left or the right, are not so different.
Will economic growth accelerate sufficiently to boost job and income growth?
Can the barriers that exclude many Americans from recovery and future prosperity be removed?
Federal infrastructure spending and corporate-tax reform should top the list of policies capable of attracting bipartisan agreement, because they promise significant long-term productivity, income, and employment gains, while also supporting short-term growth.
A commitment to a multi-year federal infrastructure-spending program, for example, could increase demand, private investment, and employment, even though projects may not be immediately available.
And such a program, normally proposed by Democrats, can and should be crafted to secure Republican support as well.
To that end, an infrastructure program should give states and localities a key role in selecting the projects to be funded, and these governmental units should have “skin in the game” by funding part of the costs.
Policymakers should also give serious consideration to regulatory reforms that would reduce the expense of new projects and assure their timely completion.
An infrastructure program oriented in this way – as opposed to a grab bag of politically expedient shovel-ready projects – should be able to muster conservative support.
And, done properly, federally funded infrastructure projects should provide substantial benefits to lower-income Americans.
Better transport infrastructure, for example, would not only create jobs, but would also reduce the costs of commuting to work.
Corporate-tax reform also offers a good opportunity for bipartisan agreement, especially given that Obama and congressional leaders of both parties have expressed interest.
While gains from fundamental tax reform – say, replacing the current tax system with a broad-based consumption tax – are large, on the order of 0.5-1 percentage point per year of economic growth for a decade, corporate-tax reform would also boost growth.
Reducing the tax rate for companies substantially, while eliminating targeted business-tax preferences and broadening the corporate-tax base, would increase both investment and workers’ wages.
Allowing multinational companies to repatriate overseas profits without paying additional US tax would also bolster investment and job creation at home.
Given that recent research shows that much of the burden of corporate taxation is borne by workers in the form of lower wages, Democrats should embrace tax reform as a way to support income growth.
One could add to such a reform further support for low-income Americans by increasing the Earned Income Tax Credit for single workers.
Given their policy objectives, conservatives should support a well-crafted federal infrastructure program, and liberals should support corporate-tax reform.
But changes in the political process would help move matters ahead.
Because the payoffs from infrastructure spending and tax reform do not fit neatly within the five-year or ten-year budget window used by America’s fiscal scorekeepers, measuring more completely the benefits from such policies is vital to attracting political support.
Moreover, any increase in spending on infrastructure or any revenue loss from tax reform should be offset elsewhere.
For example, future growth in Social Security benefits or the home-mortgage-interest tax deduction could be scaled back for more affluent individuals, as progressive indexation, proposed by conservatives in the US, and the adjustment of mortgage-interest tax deductions in the United Kingdom, started during the Thatcher administration, attest.
Clearly, the economy is Americans’ top concern.
Its leaders must respond with a policy agenda focused on reviving growth now and sustaining it in the future.
But that can happen only if enough legislators in both parties, and the president, remove their intellectual and political blinders and reach the long-term compromises needed to create jobs and increase incomes.
The time for a Pact for America has arrived.
Economists on the Refugee Path
NEW HAVEN – Today’s global refugee crisis recalls the period immediately after World War II.
By one contemporary estimate, there were more than 40 million refugees in Europe alone.
These “displaced persons,” as they were called at the time, were forced to flee their homes because of violence, forced relocation, persecution, and destruction of property and infrastructure.
The dire postwar situation led to the creation in 1950 of the United Nations High Commissioner for Refugees, which was expected to serve only a temporary mandate, protecting displaced people for three years.
But the problem never went away.
On the contrary, the UNHCR is not only still with us; it is sounding an alarm.
In its 2015 mid-year report, the agency put the number of “forcibly displaced” people worldwide at 59.5 million at the end of 2014, including 19.5 million internationally displaced, which they define as true refugees.
Some countries – Afghanistan, Azerbaijan, Colombia, Central African Republic, Democratic Republic of Congo, Iraq, Myanmar, Nigeria, Pakistan, Somalia, South Sudan, Sudan, Syria, and Ukraine – each accounted for more than a half-million forcibly displaced people at the end of 2014.
The report noted that the total number had certainly grown substantially since.
Unfortunately, the report underscores the incompleteness of our understanding of the refugee problem.
In fact, throughout history, the fate of refugees seeking asylum in another land has largely been unstudied.
Historians record wars, and they mention diasporas, but they rarely show much interest in how refugee crises arose or were resolved.
To the extent that history is written by the victors, that is not surprising.
The knowledge that one’s country terrorized a minority to the point that its members had to flee, or that a substantial share of one’s forebears arrived in defeat and panic, is not exactly an inspiring source of national identity.
So the stories, unheard and untold, are lost.
That is why we need more research on what can and should be done for refugees in the long term.
The UNHCR has been doing an important job in protecting refugees, but it cannot possibly address their needs alone.
Its budget of $7 billion in 2015 may seem large, but it amounts to only about $100 per displaced person – not enough to cover even essentials like food and shelter.
As President of the American Economic Association for 2016, I felt a moral obligation to use our annual meeting earlier this month as a setting in which to bring attention to serious economic problems.
And the refugee crisis, whatever else it may be, is an economic problem.
But a dearth of papers addressing it had been submitted to the meeting.
So I decided to create a session entitled Sixty Million Refugees, and invited some of our discipline’s most distinguished scholars on migration.
I asked them to describe the dimensions of the refugee problem in economic terms, and to propose some sensible policies to address it.
One of the papers, by Timothy J. Hatton of the University of Essex and Australian National University, examined refugee flows around the world, to see what drives them.
Hatton confronts a popular argument against admitting refugees: that asylum-seekers are not really desperate, but are just using a crisis as a pretext for admission to a richer country.
He finds that, contrary to some expectations, refugee flows are driven largely by political terror and human rights abuses, not economic forces.
People in fear for their lives run to the nearest safe place, not the richest.
There is no escape from the moral imperative to help them.
Semih Tumen of the Central Bank of Turkey presented evidence regarding the impact of the 2.2 million Syrian refugees on the labor market in the border region.
Tumen’s paper, too, takes on an argument frequently used to oppose admitting refugees: that the newcomers will take locals’ jobs and drive down wages.
He found that in the formal sector, jobs for locals actually increased after the influx of refugees, apparently because of the stimulative effect on the region’s economy.
If further research backs up this finding, countries might actually welcome the inflow of labor.
Another paper, by Susan F. Martin of Georgetown University, described the arbitrariness of our current refugee procedures, calling for “legal frameworks based on the need for protection, rather than the triggering causes of the migration.”
But formulating such rules requires some careful economic thought.
The framers of a refugee system need to consider the rules’ incentive effects on the migrants themselves and on the governments of their countries of origin.
For example, we do not want to make it too easy for tyrants to drive unwanted minorities out of their country.
Finally, Jeffrey D. Sachs of Columbia University detailed a major new system for managing refugees.
Sachs is concerned with how such a system’s rules will shape the world’s economies in the longer run.
He wants such a system to prevent encouraging a brain drain by enforcing a commitment to admitting low-skilled and desperate immigrants, not just those who are highly useful to the host country.
Moreover, the rate of flow must be regulated, and economists need to develop a way to ensure equitable burden sharing among countries.
Under today’s haphazard and archaic asylum rules, refugees must take enormous risks to reach safety, and the costs and benefits of helping them are distributed capriciously.
It does not have to be this way.
Economists can help by testing which international rules and institutions are needed to reform an inefficient and often inhumane system.
Economics in Denial
PARIS – In an exasperated outburst, just before he left the presidency of the European Central Bank, Jean-Claude Trichet complained that, “as a policymaker during the crisis, I found the available [economic and financial] models of limited help.
In fact, I would go further: in the face of the crisis, we felt abandoned by conventional tools.”
Trichet went on to appeal for inspiration from other disciplines – physics, engineering, psychology, and biology – to help explain the phenomena he had experienced.
It was a remarkable cry for help, and a serious indictment of the economics profession, not to mention all those extravagantly rewarded finance professors in business schools from Harvard to Hyderabad.
So far, relatively little help has been forthcoming from the engineers and physicists in whom Trichet placed his faith, though there has been some response.
Robert May, an eminent climate change expert, has argued that techniques from his discipline may help explain financial-market developments.
Epidemiologists have suggested that the study of how infectious diseases are propagated may illuminate the unusual patterns of financial contagion that we have seen in the last five years.
These are fertile fields for future study, but what of the core disciplines of economics and finance themselves?
Can nothing be done to make them more useful in explaining the world as it is, rather than as it is assumed to be in their stylized models?
George Soros has put generous funding behind the Institute for New Economic Thinking (INET).
The Bank of England has also tried to stimulate fresh ideas.
The proceedings of a conference that it organized earlier this year have now been edited under the provocative title What’s the Use of Economics?
Some of the recommendations that emerged from that conference are straightforward and concrete.
For example, there should be more teaching of economic history.
We all have good reason to be grateful that US Federal Reserve Chairman Ben Bernanke is an expert on the Great Depression and the authorities’ flawed policy responses then, rather than in the finer points of dynamic stochastic general equilibrium theory.
As a result, he was ready to adopt unconventional measures when the crisis erupted, and was persuasive in influencing his colleagues.
Many conference participants agreed that the study of economics should be set in a broader political context, with greater emphasis on the role of institutions. Students should also be taught some humility.
The models to which they are still exposed have some explanatory value, but within constrained parameters.
And painful experience tells us that economic agents may not behave as the models suppose they will.
But it is not clear that a majority of the profession yet accepts even these modest proposals.
The so-called “Chicago School” has mounted a robust defense of its rational expectations-based approach, rejecting the notion that a rethink is required.
The Nobel laureate economist Robert Lucas has argued that the crisis was not predicted because economic theory predicts that such events cannot be predicted.
So all is well.
And there is disturbing evidence that news of the crisis has not yet reached some economics departments.
Stephen King, Group Chief Economist of HSBC, notes that when he asks recent university graduates (and HSBC recruits a large number of them) how much time they spent in lectures and seminars on the financial crisis, “most admitted that the subject had not even been raised.”
Indeed, according to King, “Young economists arrive in the financial world with little or no knowledge of how the financial system operates.”
I am sure they learn fast at HSBC.
(In the future, one assumes, they will learn quickly about money laundering regulations as well.)
But it is depressing to hear that many university departments are still in denial.
That is not because students lack interest: I teach a course at Sciences Po in Paris on the consequences of the crisis for financial markets, and the demand is overwhelming.
We should not focus attention exclusively on economists, however.
Arguably the elements of the conventional intellectual toolkit found most wanting are the capital asset pricing model and its close cousin, the efficient-market hypothesis.
Yet their protagonists see no problems to address.
On the contrary, the University of Chicago’s Eugene Fama has described the notion that finance theory was at fault as “a fantasy,” and argues that “financial markets and financial institutions were casualties rather than causes of the recession.”
And the efficient-market hypothesis that he championed cannot be blamed, because “most investing is done by active managers who don’t believe that markets are efficient.”
This amounts to what we might call an “irrelevance” defense: Finance theorists cannot be held responsible, since no one in the real world pays attention to them!
Fortunately, others in the profession do aspire to relevance, and they have been chastened by the events of the last five years, when price movements that the models predicted should occur once in a million years were observed several times a week.
They are working hard to understand why, and to develop new approaches to measuring and monitoring risk, which is the main current concern of many banks.
These efforts are arguably as important as the specific and detailed regulatory changes about which we hear much more.
Our approach to regulation in the past was based on the assumption that financial markets could to a large extent be left to themselves, and that financial institutions and their boards were best placed to control risk and defend their firms.
These assumptions took a hard hit in the crisis, causing an abrupt shift to far more intrusive regulation.
Finding a new and stable relationship between the financial authorities and private firms will depend crucially on a reworking of our intellectual models.
So the Bank of England is right to issue a call to arms. Economists would be right to heed it.
The Global Economy’s Hesitation Blues
NEW HAVEN – Economic slowdowns can often be characterized as periods of hesitation.
Consumers hesitate to buy a new house or car, thinking that the old house or car will do just fine for a while longer.
Managers hesitate to expand their workforce, buy a new office building, or build a new factory, waiting for news that will make them stop worrying about committing to new ideas.
Viewed from this perspective, how worried should we be about the effects of hesitation today?
Hesitation is often like procrastination.
One may have vague doubts and feel a need to mull things over; meanwhile, other issues intrude on thought and no decision is taken.
Ask people why they procrastinate, and you probably won’t get a crisp answer.
So how does such behavior become sufficiently widespread to bring about an economic slump?
In fact, the reasons for postponing activities that would stimulate the economy may be difficult to discern.
One thinks first of feedback from others who are hesitating.
Income effects and crowd psychology may amplify individual vacillation.
But there must have been some initial factor that started the feedback cycle – some underlying source of hesitation.
Loss of economic “confidence” is one possible cause.
Published confidence indices, available since the 1950s, are based on polls that ask consumers or businesspeople about their perceptions of business activity and expectations of future income and employment.
“Uncertainty” about economic policy is another possible source of hesitation.
If businesspeople don’t know what regulations, taxes, or worse, nationalizations, will be coming, they may dither.
The idea is an old one, expressed during the Great Depression of the 1930s; but it was not measured well, at least until recently.
In a 2015 working paper, the economists Scott R. Baker, Nicholas Bloom, and Steven J. Davis constructed Economic Policy Uncertainty (EPU) indices for a dozen countries using digital news archives.
The indices (covering Canada, China, France, Germany, India, Italy, Japan, Russia, South Korea, Spain, the United Kingdom, and the United States) were created by counting the number of newspaper articles in each country and each month that had the trifecta of terms “economy” (E), policy” (P) and “uncertainty” (U).
The index each month was the total number of articles with those three words, divided by the total number of articles in the targeted newspapers each month.
Native speakers in each country were consulted on the appropriate translations of the three words.
The indices spanned decades, and in two countries, the US and the UK, went all the way back to 1900.
The US index correlates with implied equity-price volatility in the options markets (VIX).
They found that their EPU index foreshadows economic contractions in the 12 countries, and that for the two countries with long-term indices, the EPU values were high during the Great Depression.
But do contractions cause uncertainty, they ask, or does uncertainty cause contractions?
Given that we know that people are highly reactive to each other, the causality most likely runs both ways, in a feedback loop.
The deeper and more interesting question concerns what initiates this uncertainty.
To answer it requires impressionistic characterizations of the extant stories and ideas that might influence public thinking – or avoidance of thinking – about the economy.
As for the Great Depression, one wonders if the high degree of EPU was linked to social trends after the excesses of the 1920s, fueling fear of Communism and, in the United States, of the New Deal.
One wonders if fear of fascist regimes, and of a coming war, prolonged the depression after Hitler came to power in 1933.
The attention devoted to Johannes Steele’s 1934 book The Second World War, which predicted that eponymous event, indicates that fear of war must have been talked about enough to underpin some hesitation.
To people who lived through World War I, the thought of a sequel must have seemed nightmarish.
Of course, whether the Great Depression was really prolonged by these stories or ideas cannot be proved.
How do we know which stories were affecting people’s thinking?
On the other hand, we can be fairly certain that some of these stories really do affect perceived economic uncertainty.
Psychologists have shown that people display an “affect heuristic,” or a tendency to tag memories with emotions and to let those emotions affect decision-making, even when the decision is unrelated to what caused the emotions.
A mismatch of emotions can cause executive dysfunction, a failure to act, hesitation.
Some kinds of stories circulating today – related to growing nationalism or fear of challenges by immigrants to traditional cultural values – might underpin greater hesitation.
The Brexit vote in the United Kingdom last month has been viewed worldwide with extraordinary alarm as a signal of political instability.
The rising incidence of terrorism has added a vivid emotional edge to such developments.
Will these fears fuel enough economic hesitation to bring on another worldwide recession?
Any answer at this time would be impressionistic and imprecise.
Given the importance of the consequences, however, we should not shrink from considering how such fears are affecting economic decision-making.
Nobel Economics Versus Social Democracy
OXFORD – Of the elites who manage modern society, only economists have a Nobel Prize, whose latest recipients, Oliver Hart and Bengt Holmström, have just been announced.
Whatever the reason for economists’ unique status, the halo conferred by the prize can – and often has – lend credibility to policies that harm the public interest, for example by driving inequality and making financial crises more likely.
But economics does not have the field entirely to itself.
A different view of the world guides the allocation of about 30% of GDP – for employment, health care, education, and pensions – in most developed countries.
This view about how society should be managed – social democracy – is not only a political orientation; it is also a method of government.
Standard economics assumes that society is driven by self-seeking individuals trading in markets, whose choices scale up to an efficient state via the “invisible hand.”
But this doctrine is not well founded in either theory or practice: its premises are unrealistic, the models it supports are inconsistent, and the predictions it produces are often wrong.
The Nobel Prize in economics was endowed by Sweden’s central bank, the Riksbank, in 1968.
The timing was not an accident.
The new prize arose from a longstanding conflict between the interests of the better off in stable prices and the interests of everybody else in reducing insecurity by means of taxation, social investment, and transfers.
The Royal Swedish Academy of Sciences awarded the prize, but Sweden was also an advanced social democracy.
During the 1950s and 1960s, the Riksbank clashed with Sweden’s government over the management of credit.
Governments gave priority to employment and housing; the Riksbank, led by an assertive governor, Per Åsbrink, worried about inflation.
As recompense for restrictions on its authority, the Riksbank was eventually allowed to endow a Nobel Prize in economics as a vanity project for its tercentenary.
Within the Academy of Sciences, a group of center-right economists captured the process of selecting prizewinners.
The laureates comprised a high-quality sample of economics scholarship.
An analysis of their influence, inclinations, and biases indicates that the Nobel committee kept up an appearance of fairness through a rigid balance between right and left, formalists and empiricists, Chicago School and Keynesian.
But our research indicates that professional economists, on the whole, are more broadly inclined toward the left.
The prize kingmaker was Stockholm University economist Assar Lindbeck, who had turned away from social democracy.
During the 1970s and 1980s, Lindbeck intervened in Swedish elections, invoked microeconomic theory against social democracy, and warned that high taxation and full employment led to disaster.
His interventions diverted attention from the grave policy error being made at the time: deregulation of credit, which led to a deep financial crisis in the 1990s and anticipated the global crisis that erupted in 2008.
Lindbeck’s concerns were similar to those of the International Monetary Fund, the World Bank, and the US Treasury.
These actors’ insistence on privatization, deregulation, and liberalization of capital markets and trade – the so-called Washington Consensus – enriched business and financial elites, led to acute crises, and undermined emerging economies’ growth.
In the West, the priority accorded to the individualist self-regarding norms underlying the Washington Consensus created a nurturing environment for growth in corruption, inequality, and mistrust in governing elites – the unintended consequences of rational-choice, me-first premises.
With the emergence in advanced economies of disorders previously associated with developing countries, Swedish political scientist Bo Rothstein has petitioned the Academy of Sciences (of which he is a member) to suspend the Nobel Prize in economics until such consequences are investigated.
Social democracy is not as deeply theorized as economics.
It constitutes a pragmatic set of policies that has been enormously successful in keeping economic insecurity at bay.
Despite coming under relentless attack for decades, it remains indispensable for providing the public goods that markets cannot supply efficiently, equitably, or in sufficient quantity.
But the lack of formal intellectual support means that even nominally social-democratic parties do not entirely understand how well social democracy works.
Unlike markets, which reward the wealthy and successful, social democracy is premised on the principle of civic equality.
This creates a bias for “one-size-fits-all” entitlements; but there have long been ways to manage this constraint.
Because economics appears to be compelling, and because social democracy is indispensable, the two doctrines have mutated to accommodate each other – which is not to say that their marriage is a happy one.
As with many unhappy marriages, divorce is not an option.
Many economists have responded to the failure of their discipline’s core premises by retreating into empirical investigation.
But the resulting validity comes at the cost of generality: randomized controlled trials in the form of local experiments cannot replace an overarching vision of the social good.
A good way to begin acknowledging this would be to select Nobel Prize recipients accordingly.
The Economist’s Concubine
LONDON – In recent decades, economics has been colonizing the study of human activities hitherto considered exempt from formal calculus.
What critics call “economics imperialism” has given rise to an economics of love, of art, of music, of language, of literature, and of much else.
The unifying idea underlying this extension of economics is that whatever people do, whether it is making love or making widgets, they aim to achieve the best results at the least cost.
These benefits and costs can be reduced to money.
So people are always looking for the best financial return on their transactions.
This is contrary to the popular separation of activities in which it is right (and rational) to count the cost, and those in which people do not (and should not) count the cost.
To say that affairs of the heart are subject to cold calculation is, say the critics, to miss the point.
But cold-hearted calculation, reply the economists, is exactly the point.
The pioneer of the economic approach to love was the Nobel laureate Gary Becker, who spent most of his career at the University of Chicago (where else?).
In his seminal paper, “A Theory of Marriage,” published in 1973, Becker argued that selecting a partner is its own kind of market, and marriages occur only when both partners gain.
It’s a very sophisticated theory, relying on the complementary nature of male and female work, but which tends to treat love as a cost-reducing mechanism.
More recently, economists such as Columbia University’s Lena Edlund and University of Marburg’s Evelyn Korn, as well as Marina Della Giusta of Reading University, Maria Laura di Tommaso of the University of Turin, and Steiner Strøm of the University of Oslo, have applied the same approach to prostitution.
Here, the economic approach might seem to work better, given that money is, admittedly, the only relevant currency.
Edlund and Korn treat wives and prostitutes as substitutes.
A third alternative, working in a regular job, is ruled out by assumption.
According to the data, prostitutes make a lot more money than women working in ordinary jobs.
So the question is: why is there such a high premium for such low skills?
On the demand side is the randy male, often in transit, who weighs the benefits of going with prostitutes against the costs of getting caught.
On the supply side the prostitute will require higher earnings to compensate for her higher risk of disease, violence, and blighted marriage prospects.
“If marriage is a source of income for women,” write Edlund and Korn “then the prostitute has to be compensated for foregone marriage market opportunities.”
So the premium reflects the opportunity cost to the prostitute of performing sex work.
There is a ready answer to the question of why competition does not drive down sex workers’ rewards.
They have a “reservation wage”: If they are offered less, they will choose a less risky line of work.
What warrant does the state have to interfere with the contracts that are struck within this market of willing buyers and sellers?
Why not decriminalize the market altogether, as many sex workers want?
Like all markets, the sex market needs regulation, particularly to protect the health and safety of its workers.
And, as in all markets, criminal activity, including violence, is already illegal.
But on the other side, there is a strong movement to ban buying sex altogether.
The so-called Sex Buyer Law, criminalizing the purchase, though not the sale, of sexual services has been implemented in Sweden, Norway, Iceland, and Northern Ireland.
The enforced reduction of demand is expected to reduce supply, without the need to criminalize the supplier.
There is some evidence that it has had the intended effect.
(Though supporters of the so-called Nordic System ignore the effect of criminalizing the purchase of sex on the earnings of those who supply it, or would have supplied it.)
The movement to ban buying sex has been strengthened by the growth of international trafficking in women (as well as drugs).
This may be counted as a cost of globalization, especially when it involves an influx into the West from countries where attitudes toward women are very different.
But the proposed remedy is too extreme.
The premise of the Sex Buyer Law is that prostitution is always involuntary for women – that it is an organic form of violence against women and girls.
But I see no reason to believe this.
The key question concerns the definition of the word “voluntary.”
True, some prostitutes are enslaved, and the men who use their services should be prosecuted.
But there are already laws on the books against the use of slave labor.
I would guess that most prostitutes have chosen their work reluctantly, under pressure of need, not involuntarily.
If men who use their services are criminalized, then so should people who use the services of supermarket checkout employees, call-center workers, and so on.
Then there are some prostitutes (a minority, to be sure) who claim to enjoy their work.
And, of course, there are male prostitutes, gay and straight, who are typically ignored by feminist critics of prostitution.
In short, the view of human nature of those who seek to ban the purchase of sex is as constricted as that of the economists.
As St. Augustine put it, “If you do away with harlots, the world will be convulsed with lust.”
Ultimately, all arguments against prostitution based on notions of inequality and coercion are superficial.
There is, of course, a strong ethical argument against prostitution.
But unless we are prepared to engage with that – and our liberal civilization is not – the best we can do is to regulate the trade.
Secular Stagnation for Free
CAMBRIDGE – Something is definitely rotten in the state of capitalism.
Despite unprecedentedly low interest rates, investment in most advanced countries is significantly below where it was in the years prior to the 2008 crisis, while employment rates remain stubbornly low.
And even investment in the pre-crisis period was unimpressive, given low prevailing interest rates.
For some reason, achieving a level of investment that would generate full employment seems to require negative real (inflation-adjusted) interest rates, which is another way of saying that people have to be paid to invest.
But in a world of low inflation and zero nominal interest rates, getting to the required negative real rate may be a challenge.
This is the ailment that Larry Summers, recalling a 1938 paper by Alvin Hansen, has dubbed “secular stagnation.”
The policy consequences of this state of affairs remain open to debate (the issues are well summarized in an e-book edited by Coen Teulings and Richard Baldwin).
For Keynesians, the answer is unconventional monetary policy (for example, quantitative easing), fiscal stimulus, and a higher target inflation rate.
But, as Summers and others point out, lax monetary policies may trigger asset bubbles, and prolonged fiscal stimulus may end in a debt crisis.
Moreover, the Keynesians’ preferred policies address only the consequences of secular stagnation, not its causes – about which there is even less agreement.
For some, the problem is a savings glut associated with slower demographic growth, rising life expectancy, and static retirement thresholds – a combination that forces people to save more for their old age.
But, as Barry Eichengreen points out, the rise in savings appears to be too small to explain this.
For others, the problem is lower investment demand, caused partly by the fact that machines are now much cheaper and that technological progress has slowed since 1970.
Economists like Robert Gordon and Tyler Cowen argue that the technological breakthroughs of the past, including piped water, air conditioning, and commercial air travel, had a greater social impact – giving rise to the suburban lifestyle of cars and shopping malls, for example – than many of today’s advances.
This assessment bothers optimists like Joel Mokyr or Erik Brynjolfsson and Andrew McAfee, who do not believe that technological progress has slowed. Instead, they argue that the traditional concept used to measure economic output and growth, gross domestic product, understates that progress.
After all, our lives have been made dramatically more productive thanks to Google, Wikipedia, Skype, Twitter, Facebook, YouTube, Waze, Yelp, Hipmunk, Pandora, and many other companies.
But all deliver their services for free, which means that the benefits they provide are not counted in GDP.
As Edward Glaeser has argued, it is hard to believe that the median family in the United States, which supposedly is worse off than in 1970, would be willing to give up its cell phones, Internet access, and new health technologies in order to return to that halcyon era.
Thus, the GDP numbers must be excluding much progress.
The fact that so much innovation is given away for free does not only create a measurement problem for economists; it is also a real problem for those trying to find investment opportunities.
In the good old days of the post-World War II boom, if you wanted an air conditioner, a car, or a newspaper, you had to buy one, making it possible for producers to earn money by providing them.
Information-intensive products – typical of today’s technologically advanced economies – are different.
Because the cost of providing an extra copy is almost nil, it is hard to charge for them.
Broadcast radio and television were the first to confront this problem, because they could not prevent those with a receiver from getting the signal.
They had to develop an advertising-based model, making it possible for others to pay for the benefits received by the consumer.
This is supposedly what makes Google so profitable, though I have trouble believing that the enormous benefits I receive as an assiduous and happy user are paid for by my rather infrequent Internet purchases.
So we live in a world where much of the progress that new technology permits is embodied in products that must be given away for free.
A somewhat haphazard sub-set of potential products can, with the right business model, be profitable – say, through advertising or by selling the information that they passively collect from users.
But many others, like Wikipedia and public radio, have trouble making ends meet.
Free products also depress the value of close substitutes.
While it may require charging $100 per ticket to recover the costs of a $1 million theater play, some filmmakers can make money on a $200 million film by selling $10 tickets to consumers who are unwilling to wait a few weeks until their cable TV provider offers it.
The e-book mentioned above, which prompted this column, is available to you, the reader, for free (as is this column).
No wonder so many people have trouble making ends meet.
But the Center for Economic Policy Research, which published the e-book, and Project Syndicate, which distributes this column, are both (at least to some extent) donor-funded.
This may not be a coincidence.
To harness the possibilities of new technology, we may need non-market forms of payment for valuable contributions.
The traditional capitalist model may have made Bill Gates rich, but his foundation now finances valuable technological breakthroughs in unprofitable ways.
As with negative real interest rates, but in a more targeted and efficient manner, we may have to pay to make valuable investments happen.
Missing the Economic Big Picture
BERKELEY – I recently heard former World Trade Organization Director-General Pascal Lamy paraphrasing a classic Buddhist proverb, wherein China’s Sixth Buddhist Patriarch Huineng tells the nun Wu Jincang: “When the philosopher points at the moon, the fool looks at the finger.”
Lamy added that, “Market capitalism is the moon.
Globalization is the finger.”
With anti-globalization sentiment now on the rise throughout the West, this has been quite a year for finger-watching.
In the United Kingdom’s Brexit referendum, “Little Englanders” voted to leave the European Union; and in the United States, Donald Trump won the presidency because he convinced enough voters in crucial states that he will “make America great again,” not least by negotiating very different trade “deals” for the country.
Let us orient ourselves by considering what the economic-policy moon looks like today, particularly with respect to growth and inequality.
For starters, technological innovation in areas such as information processing, robotics, and biotechnology continues to accelerate at a remarkable pace.
But annual productivity growth in North Atlantic countries has fallen from the 2% rate to which we have been accustomed since 1870 to about 1% now.
Productivity growth is an important economic indicator, because it measures the year-on-year decline in resources or manpower needed to achieve the same level of economic output.
Northwestern University economist Robert J. Gordon maintains that all of the true “game-changing” innovations that have fueled past economic growth – electric power, flight, modern sanitation, and so forth – have already been exhausted, and that we should not expect growth to continue indefinitely.
But Gordon is almost surely wrong: game-changing inventions fundamentally transform or redefine lived experience, which means that they often fall outside the scope of conventional measurements of economic growth.
If anything, we should expect to see only more game changers, given the current pace of innovation.
Measures of productivity growth or technology’s added value include only market-based production and consumption.
But one’s material wealth is not synonymous with one’s true wealth, which is to say, one’s freedom and ability to lead a fulfilling life.
Much of our true wealth is constituted within the household, where we can combine non-market temporal, informational, and social inputs with market goods and services to accomplish various ends of our own choosing.
While standard measures show productivity growth falling, all other indicators suggest that true productivity growth is leaping ahead, owing to synergies between market goods and services and emerging information and communication technologies.
But when countries with low-growth economies do not sufficiently educate their populations, nearly everyone below the top income quintile misses out on the gains from measured economic growth, while still benefiting from new technologies that can improve their lives and wellbeing.
As economist Karl Polanyi pointed out in the 1930s and 1940s, if an economic system promises to create shared prosperity but only seems to serve the top 20% of earners, it has disappointed the vast majority of economic participants’ expectations.
And market capitalism, for its part, has not delivered the ever-more affordable 1980s lifestyle that so many back then expected it would.
Instead, during the past 30 years, an “overclass” has emerged, one that exercises even more relative economic power than Gilded Age robber barons did.
The factors contributing to its rise and undue power, however, remain unclear.
Elsewhere, China, India, and some Pacific Rim countries have matched, or will soon match, North Atlantic countries’ productivity and prosperity.
The rest of the world is no longer falling further behind the North Atlantic, but nor is it closing the productivity and prosperity gap, implying that these countries will continue to lag behind indefinitely.
The aforementioned features are all constituent parts of our proverbial market capitalist moon.
As it develops and interacts with social, political, and technological forces, it creates elation alongside distress.
Globalization is one piece in a larger puzzle: while it is important that we determine the best way to manage the global trade system, doing so cannot substitute for the much larger challenge of managing market capitalism itself.
By focusing on individual free-trade agreements, whether proposed or already existing, or on closing national borders to immigrants, we are looking at the finger and missing the moon.
If we are to get a grip on the global economy’s trajectory, is time to look up.
Economics and Its Critics
MUNICH – There is much to criticize in economics nowadays.
For example, the profession focuses far too little on political issues and far too much on beating students to death with mathematics.
But much current criticism of the profession is based on misunderstanding and ignorance.
Consider Adam Smith’s concept of the “invisible hand,” which implies that a market equilibrium is efficient if perfect competition prevails and well-defined property rights exist.
Contrary to what many critics suppose, mainstream economists do not assume that these ideal conditions are always present.
On the contrary, economists tend to use these conditions as a benchmark for analyzing market failures.
Like sniffer dogs, they search the economy for such defects and ponder how they can be corrected through intelligent state intervention.
In this respect, economists are like doctors, who have to know what a healthy body looks like before they can diagnose disease and prescribe treatment.
A good doctor does not intervene arbitrarily in the body’s processes, but only in cases where there is objective proof of a disease and an effective treatment can be prescribed.
Environmental regulation addresses a particularly striking example of market failure.
Markets are generally efficient if companies’ revenues correctly reflect all the benefits that their output bestows on third parties, while their costs reflect all the harms.
In this case, maximizing profit leads to maximizing social welfare.
But if production entails environmental damage for which companies do not pay, incentives are distorted; companies may turn a profit, but they function inefficiently in economic terms.
So the state “corrects” firms’ incentives by levying fines or issuing bans.
Another malady that economists sometimes diagnose might be called “Keynes disease.”
If demand is too weak, it can lead to a sharp drop in employment (because wages and prices are rigid in the short term).
The disease can be cured with injections of public, debt-financed stimulus – like giving a cardiac patient doses of nitroglycerine to keep his heart going.
Contrary to what many think, there is no fundamental bias against this medicine in mainstream economics today.
But stimulus cannot be seen as a universal remedy.
Many ailments that may afflict an economy are chronic, not acute, and thus call for other types of treatment.
Trying Keynesian therapy to resolve, say, the structural problems currently affecting the countries of southern Europe would be like trying to cure a broken leg with heart medicine.
Nitroglycerine addresses the risk of circulatory collapse.
In economic terms, that is what was needed following the 2008 global financial crisis.
But long-term use of such medication can be fatal.
Here and elsewhere, ideology causes conceptual confusion.
For example, Smith viewed competition as a basic condition of the invisible hand’s operation, because monopolies and oligopolies exploit consumers and restrict production.
But only competition among providers of similar products is beneficial.
Competition among providers of complementary goods or services is harmful, and can be even worse than a monopoly.
(That is why train drivers and pilots, for example, should be forced into monopoly unions that represent all of the other employees of their respective companies.)
The market failures that initially give rise to public-sector intervention tend to recur internationally, which means that competition between states is usually not efficient, either.
Examples include competition between welfare states to deter economic migrants, the race to the bottom in taxation, and regulatory rivalry in the banking and insurance sectors.
Competition, contrary to what many on the right believe, is not always good.
Of course, ideology often overwhelms terminology on the left as well.
Consider “neoliberalism,” a term of derision for many because it has come to be viewed as a doctrine of deregulation and pure laissez-faire.
But in Europe, at least, neoliberalism has a very different meaning.
It was coined by Alexander Rüstow, who in 1932 proclaimed the end of old liberalism and called for a new liberalism featuring a strong state that lays down a solid legal framework within which firms operate.
Homo economicus, the rationally acting egoist who populates economists’ models, has recently attracted criticism as well, because all too often he does not represent the real behavior of individuals.
Behavioral experiments have shown conclusively the limited predictive value of this artificial construct.
But homo economicus was never intended to be used for forecasting; its real purpose is to make it easier to distinguish between market failures and mental failures.
Economists seek to detect collective irrationality, and economic models that assume individual rationality facilitate that.
By ensuring that policies respond to flaws in the rules of the game, not to individuals’ fallibility or irrationality, this “methodological individualism” saves us from dictatorial paternalism.
Banks that grant risky loans on too little equity illustrate the analytical value of homo economicus particularly clearly.
Their profits are privatized, but any losses exceeding their equity are dumped on their creditors, or, even better for them, on the taxpayers.
This asymmetry turns banking into a casino: The house always wins.
Banks choose particularly risky investment projects, which may be profitable but are economically damaging.
The problem is not caused by human irrationality; on the contrary, it arises precisely because bankers are acting rationally.
As we know from environmental regulation, preaching common sense or ethics to bankers will not help; but changing bankers’ incentives – by, say, requiring higher equity-asset ratios – would work wonders.
Economists’ New World Order
Most academic economics rely on concepts laid down at the beginning of the twentieth century by the British economist Alfred Marshall, who said that “nature does not make leaps.”
Yet we economists find ourselves increasingly disturbed by the apparent inadequacy of the neo-Marshallian toolkit that we have built to explain our world.
The central bias of this toolkit is that we should trust the market to solve the problems we set it, and that we should not expect small (or even large) changes to have huge effects.
A technological leap that raises the wages of the skilled and educated will induce others to become skilled and educated, restoring balance so that inequality does not grow too much.
So a country where labor productivity is low will become an attractive location for foreign direct investment, and the resulting increase in the capital-labor ratio will raise productivity.
Wherever one looks, using Marshall’s toolkit, one sees economic equilibrium pulling things back to normal, compensating for and attenuating the effects of shocks and disturbances.
Marshall’s economics has had a marvelous run, and has helped economists make sense of the world.
Yet there is a sense that progress and understanding will require something new – an economics of virtuous circles, thresholds, and butterfly effects, in which small changes have very large effects.
Perhaps this has always been so.
By the standards of centuries ago, we live in a world of unbelievable wealth.
Within two generations human literacy will be nearly universal.
Yet three centuries ago there was also technological progress, from the mechanical clock and the watermill to the cannon and the caravel, and on to strains of rice that can be cropped three times a year in Guangzhou and the breeding of merino sheep that can flourish in the hills of Spain.
But these innovations served only to increase the human population, not raise median standards of living.
Today, if we divided up equally what we produce worldwide, would it give us a standard of living ten times that of our pre-industrial ancestors?
Twenty times?
A hundred times?
Does the question even have meaning?
David Landes likes to tell the story of Nathan Meyer Rothschild, the richest man in the world in the first half of the nineteenth century, dead in his fifties of an infected abscess.
If you gave him the choice of the life he led as the finance-prince of Europe or a life today low-down in the income distribution but with thirty extra years to see his great-grandchildren, which would he choose?
No doubt, we live today in an extraordinarily unequal world.
There are families today near Xian, in what was the heartland of the Tang Dynasty Empire, with two-acre dry wheat farms and a single goat.
There are other families throughout the world that could buy that wheat farm with one day’s wages.
Marshall’s economics – the equilibrium economics of comparative statics, of shifts in supply and demand curves, and of accommodating responses – is of almost no help in accounting for this.
Why, worldwide, did median standards of living stagnate for so long?
Why has the rate of growth undergone an acceleration that is extraordinarily rapid over so short a period?
Where is the economics of invention, innovation, adaptation, and diffusion?
Not in Marshall.
And why is today’s world so unequal that it is hard to find any measures of global distribution that do not show divergence at least up until the 1980’s?
It has been generations since economists Robert Solow and Moses Abramovitz pointed out that Marshall’s toolkit is a poor aid for understanding modern economic growth.
The real sources of growth are not to be found in supplies and demands and the allocation of scarce resources to alternative uses, but in technological and organizational change – about which economists have too little to say.
Economic historians like Ken Pomeranz rightly point out that before the Industrial Revolution, differences in median standards of living across the high civilizations of Eurasia were relatively small.
A peasant in the Yangtze Valley in the late seventeenth century had a different style of life than his or her contemporary peasant in the Thames Valley, but not one that was clearly better or worse.
Two centuries later that was no longer the case: by the end of the nineteenth century, median living standards in Britain and other countries to which the Industrial Revolution had spread were, for the first time in recorded history, light-years above any neo-Malthusian benchmark of subsistence.
The early industrial-era economic accomplishments occurred despite the loss of a substantial proportion of national income to support a corrupt, decadent, and profligate aristocracy. They occurred despite a tripling of the population, which put extraordinary Malthusian pressure on the economy underlying natural resource base, and despite the mobilization of an unprecedented proportion of national income for nearly a century of intensive war against France, a power with three times Britain’s population.
How, exactly, did these accomplishments occur?
What were the small differences that turned out to matter so much?
Economists are now awakening to the realization that the most interesting questions they face were always beyond the reach of Marshall’s toolkit.
Clearly, economics – if it is to succeed and progress – must be very different in a generation from what it is today.
Economists vs. Economics
CAMBRIDGE – Ever since the late nineteenth century, when economics, increasingly embracing mathematics and statistics, developed scientific pretensions, its practitioners have been accused of a variety of sins.
The charges – including hubris, neglect of social goals beyond incomes, excessive attention to formal techniques, and failure to predict major economic developments such as financial crises – have usually come from outsiders, or from a heterodox fringe.
But lately it seems that even the field’s leaders are unhappy.
Paul Krugman, a Nobel laureate who also writes a newspaper column, has made a habit of slamming the latest generation of models in macroeconomics for neglecting old-fashioned Keynesian truths.
Paul Romer, one of the originators of new growth theory, has accused some leading names, including the Nobel laureate Robert Lucas, of what he calls “mathiness” – using math to obfuscate rather than clarify.
Richard Thaler, a distinguished behavioral economist at the University of Chicago, has taken the profession to task for ignoring real-world behavior in favor of models that assume people are rational optimizers.
And finance professor Luigi Zingales, also at the University of Chicago, has charged that his fellow finance specialists have led society astray by overstating the benefits produced by the financial industry.
This kind of critical examination by the discipline’s big names is healthy and welcome – especially in a field that has often lacked much self-reflection.
I, too, have taken aim at the discipline’s sacred cows – free markets and free trade – often enough.
But there is a disconcerting undertone to this new round of criticism that needs to be made explicit – and rejected.
Economics is not the kind of science in which there could ever be one true model that works best in all contexts.
The point is not “to reach a consensus about which model is right,” as Romer puts it, but to figure out which model applies best in a given setting.
And doing that will always remain a craft, not a science, especially when the choice has to be made in real time.
The social world differs from the physical world because it is man-made and hence almost infinitely malleable.
So, unlike the natural sciences, economics advances scientifically not by replacing old models with better ones, but by expanding its library of models, with each shedding light on a different social contingency.
For example, we now have many models of markets with imperfect competition or asymmetric information.
These models have not made their predecessors, based on perfect competition, obsolete or irrelevant.
They have simply made us more aware that different circumstances call for different models.
Similarly, behavioral models that emphasize heuristic decision-making make us better analysts of environments where such considerations may be important.
They do not displace rational-choice models, which remain the go-to tool in other settings.
A growth model that applies to advanced countries may be a poor guide in developing countries.
Models that emphasize expectations are sometimes best for analyzing inflation and unemployment levels; at other times, models with Keynesian elements will do a superior job.
Jorge Luis Borges, the Argentine writer, once wrote a short story – a single paragraph – that is perhaps the best guide to the scientific method.
In it, he described a distant land where cartography – the science of making maps – was taken to ridiculous extremes.
A map of a province was so detailed that it was the size of an entire city.
The map of the empire occupied an entire province.
In time, the cartographers became even more ambitious: they drew a map that was an exact, one-to-one replica of the whole empire.
As Borges wryly notes, subsequent generations could find no practical use for such an unwieldy map.
So the map was left to rot in the desert, along with the science of geography that it represented.
Borges’s point still eludes many social scientists today: understanding requires simplification.
The best way to respond to the complexity of social life is not to devise ever-more elaborate models, but to learn how different causal mechanisms work, one at a time, and then figure out which ones are most relevant in a particular setting.
We use one map if we are driving from home to work, another one if we are traveling to another city.
Yet other kinds of maps are needed if we are on a bike, on foot, or planning to take public transport.
Navigating among economic models – choosing which one will work better – is considerably more difficult than choosing the right map.
Practitioners use a variety of formal and informal empirical methods with varying skill.
And, in my forthcoming book Economics Rules, I criticize economics training for not properly equipping students for the empirical diagnostics that the discipline requires.
But the profession’s internal critics are wrong to claim that the discipline has gone wrong because economists have yet to reach consensus on the “correct” models (their preferred ones of course).
Let us cherish economics in all its diversity – rational and behavioral, Keynesian and Classical, first-best and second-best, orthodox and heterodox – and devote our energy to becoming wiser at picking which framework to apply when.
Economizing Life and Death
Have you ever sat at the deathbed of a statistical life?
“Statistical lives” are what politicians save, or let die, or kill, when they decide on resource allocations for health care.
Health care is not the only area where political decisions are matters of life and death.
Environmental programs to reduce air pollution, educational efforts to publicize the adverse effects of smoking, traffic measures that lower the risk of car accidents: many policies save lives – and omit other lives that would have been saved if the money had been spent otherwise.
So, if you have ever sat at somebody’s deathbed, the answer may very well be yes: you sat at the deathbed of a statistical life.
Even so, we say that John died from cancer, not that he died from a policy decision to stop payment for cancer screening.
We say that Mary died in a car accident, not that she was a casualty of the Road Traffic Act.
In short, we do not usually identify policy decisions as the causes of individual deaths.
This would be quite different if the identities of future victims were known at the time such decisions are taken.
Imagine that they were known, and that the individual victims of policy decisions would somehow stare into the faces of decision makers just as if they were being held at gunpoint.
Policy making, I am sure, would suddenly halt.
In fact, the analogy of holding victims at gunpoint is misleading, because in public decision-making we can hardly claim that everything is all right as long as we don’t pull the trigger.
Given that everything that happens is somehow a consequence of decision-making, the distinction between killing someone and letting her die is unconvincing.
So perhaps decision makers, faced with the victims of previous policies and the future victims of current ones, would simply be happy that at last they could allocate resources in an optimally efficient way.
That seems unlikely.
Indeed, the thought experiment of turning statistical lives into identifiable lives highlights an important point about policy-making: much, if not all, of the appeal of “efficient” resource allocation depends on the anonymity of the victims.
Full anonymity explains why efficiency rules – say, leaving the most “expensive” patients untreated when resources are scarce – meet with no protest.
Such anonymity also holds for those who are left untreated in “triage” – the sorting of casualties when natural or man-made disasters strike.
But, for the same reason, efficiency rules often do meet with protest when they are used or proposed for rationing medical services in everyday medicine.
It is part of the everyday life of many citizens – even part of their identities – that they suffer from an expensive health problem.
Under an efficiency regime, they might as well bear a target on their foreheads.
What about young and healthy citizens?
Many will develop expensive health problems in the future.
But their future is unknown, as is the fate of future disaster victims.
Why should they not fully embrace efficient resource allocation?
Many statistical lives – your own, perhaps – could be saved by excluding future payment for some expensive medical treatment (say, hemodialysis) for those who are now healthy and reallocating the funds to cheap but effective prevention programs.
Since there is no fairness problem here, would it not simply be irrational to reject efficiency?
After all, saving statistical lives does save individuals.
Whether or not you see a distinction between statistical lives and individual lives depends on whether you accord value not only to when you die, but also to how you die.
Dying is hard. But it is our fate as humans, and it is usually accepted with dignity when the hour comes.
Nevertheless, as long as we see a chance to escape death, we run from it, and we expect those who take care of us to look for the escape routes.
So here is a difference: when you die from lack of medical care, there is an escape route.
It is clearly marked, but nobody helps you get to it.
They stand idly by, abandoning you to death.
By contrast, when you die from the absence of prevention policies, you may be dying sooner than you otherwise would, but you are not being left to die.
This is why sitting beside, and even lying on, the deathbed of a statistical life may be more tolerable after all.
Perhaps a maximally extended life expectancy is of higher value to you than living in a society where doctors do not leave curable patients to die if they cannot pay for the required treatment out of their own pockets.
But there is nothing irrational in deciding otherwise.
It all depends on a value judgment – one of the many value judgments societies must make with respect to modern medicine.
The higher the technical capabilities, and the costs, of modern medicine become, the more contested this particular value judgment will be.
An Even More Dismal Science
BERKELEY – For the past 25 years, a debate has raged among some of the world’s leading economists.
At issue has been whether the nature of the business cycle underwent a fundamental change after the end of the “30 glorious years” that followed World War II, when the economy was characterized by rapid growth, full employment, and a bias toward moderate inflation.
Three positions have been staked out.
First out of the gate, in 1991, was Larry Summers, with his seminal paper, “How Should Long-Term Monetary Policy Be Determined?”
Summers was unconvinced that the underlying economic reality had changed, so his focus was technical – an attempt to guard against a repetition of the inflationary disturbances of the 1970s that marked the end of the glory years.
His prescription was to strengthen the technocratic independence of central banks.
Politicians should set goals, but they should avoid micromanaging the economy or imposing strict rules that would inevitably fail in unexpected circumstances.
Technocrats were far better placed to carry the policy forward, Summers argued, guided by a target of 2-3% annual inflation.
The debate continued with Paul Krugman’s 1998 paper, “It’s Baaack: Japan’s Slump and the Return of the Liquidity Trap” and his book The Return of Depression Economics, published the following year. Krugman made the case that central banks had already succeeded in anchoring inflation expectations to low levels, but had nonetheless failed to put the economy back on track.
The economy in Europe and the United States, Krugman argued, had fallen from glory and returned to a pre-World War II pattern of “depression economics,” in which its dominant features were shortages of aggregate demand, risks of deflation, financial crises, and liquidity traps.
Then Ken Rogoff entered the fray with a comment on Krugman’s paper.
In Rogoff’s view, what Krugman described as a long-term return to “depression economics” was a temporary condition, the consequence of failures to regulate properly and curb debt accumulation.
This phenomenon, which he identified as the cause of the economic turbulence, inevitably ended in catastrophe, which could be resolved only through painful deleveraging and heterodox government-enforced debt write-downs.
Other prominent economists – including Joseph Stiglitz, Ben Bernanke, and Martin Feldstein – contributed to the debate as well. But, for the most part, they have not staked out their own positions as much as sat in Schroedingerian superposition, sometimes writing as if they believed that the post-war glory years had never ended, at other times making arguments that echo those of Krugman, Summers, or Rogoff.
Today, a degree of consensus has emerged.
There is no longer much point in questioning whether the glory days are over.
The models and approaches developed to understand the post-war business cycle and its bias toward moderate inflation are worse than useless today.
Disagreement among economists nowadays reflects different positions not so much on the state of the economy, but on whether macroeconomic policy can provide an effective cure.