But insights into the changing moral landscape, in which issues like animal rights, abortion, euthanasia, and international aid have come to the fore, have not come from religion, but from careful reflection on humanity and what we consider a life well lived.
In this respect, it is important for us to be aware of the universal set of moral intuitions so that we can reflect on them and, if we choose, act contrary to them.
We can do this without blasphemy, because it is our own nature, not God, that is the source of our morality.
Going “Soft” on Iran
BRUSSELS – 2010 will be a crucial and uncertain year for the Islamic Republic of Iran – and for its relations with the European Union.
The domestic hostility towards the regime that erupted in the aftermath of the disputed presidential elections last June has not died away, but has become stronger and more determined.
The Ashura riots of last December and the violent suppression of protests during the recent anniversary to mark the 31st anniversary of the Islamic Revolution were some of the fiercest to date.
The regime’s sharp crackdown ahead of the anniversary did not stop thousands from marching in the streets, despite the threat of swift retribution.
The likelihood of more arrests, trials, and bloodshed is a concern for many in the international community.
More ominously, following riots the regime put 16 opposition members on trial for taking part in the demonstrations, with prosecutors indicating that some would be charged with the offense of mohareb , or “making a war against God” – a capital crime.
The heavy-handed approach adopted by the regime is causing friction among even its loyalists.
A former member of Iran’s parliament, Javad Ettaat, argues that the “government is contravening the principles of Islam by using an iron fist against protesters.”
Mohammad Taghi Khalaji, a cleric and devoted follower of Ayatollah Khomeini, was arrested on January 12 after saying at a Tehran mosque that Iran’s leaders should repent for their actions.
Moreover, an Iranian diplomat in Oslo, Mohammed Reza Heydari, resigned in protest against the regime’s behavior after the December riots.
Other Iranian diplomats also are reportedly resigning from their posts and seeking asylum abroad.
The European Parliament has been paying close attention to the deteriorating situation in Iran.
There has been pressure to impose targeted sanctions aimed at impeding the financial operations of Iran’s Revolutionary Guard, which holds a virtual monopoly over strategic industries such as banking, defense and construction.
Many European companies have profited from investing in such firms, which means deciding on the terms of sanctions could prove cumbersome.
On the issue of Iran’s nuclear ambitions, the Iranian government’s equivocal position also is a source of growing concern.
Many European lawmakers are worried by the prospect of a nuclear-armed Iran on Europe’s doorstep, and are not convinced by the regime’s claim that it seeks only nuclear energy.
It is critical, therefore, that the EU demonstrate its commitment to the Iranian people through actions, rather than words – a complaint that many Iranians level against Western powers – by taking a tougher stance against the regime.
Targeted sanctions aimed at the Revolutionary Guard would be an important step, but so is clearly expressing solidarity with the millions of Iranian men and women who are fighting for a democratic and pluralist society.
Europe should stand with Iran's civil society, and the European Parliament has already paid tribute to the courage of all those Iranian men and women who are defending their basic freedoms and democratic principles.
A concrete demonstration of its commitment is the request to make better use of the European Instrument for Democracy and Human Rights.
Eighty MEPs, including the Parliament’s former president, Hans-Gert Pöttering, and former Belgian Prime Minister Guy Verhofstadt, are urging the Parliament to honor its commitment to human rights by remembering the life of Neda Agha Soltan, the young woman who was killed last June in Tehran while standing up for her rights.
We believe that the European Parliament should commemorate her sacrifice by hanging a poster of her image on the external wall of the Parliament’s premises in Brussels, beside the poster of Aung San Suu Kyi, the leader of Burma’s democratic opposition.
Agha Soltan has become the symbol of the desire for freedom of a people that Europe must help.
This simple act could demonstrate the importance of Europe’s soft power, which frightens the Islamic Republic more than the threat of military force by keeping the media spotlight on the regime’s human rights record and emphasizing its growing isolation.
It would also foster stronger ties between Iran’s civil society and the outside world, while setting an example to the international community that the EU is committed to the principles enshrined in its own Charter of Fundamental Rights.
Europe’s policy for Iran is not regime change, but when human rights and democracy are at stake, we cannot simply close our eyes.
Going to the Dogs
GAINESVILLE, FLORIDA – There are about 70 million dogs living in human homes in the United States. That’s 10 million more dogs than children under the age of 15.
The pattern in other Western nations is similar.
Roughly 40% of house dogs are allowed to sleep on their owners’ beds. 
How did dogs achieve such an intimate position in our lives?
One theory is that, in the thousands of years that dogs have lived with humans, they have become attuned to human ways of thinking.
Certainly dogs have a remarkable sensitivity to human behavior.
Dogs are able to follow human pointing gestures to find hidden food, and they can indicate successfully to their owners by their own pointing actions where a hidden toy is located.
Under certain circumstances, dogs understand that a human who cannot see them (because, for example, she is blindfolded) is less likely to respond to begging with a tasty treat than a person whose vision is not obscured.
Dogs are also more likely to obey a command to leave something desirable alone if their master stays in the room than if he steps out.
And yet attempts to view canine smarts as cut from the same cloth as human intelligence gloss over a lot of the details about how dogs and humans operate.
Evolution doesn’t ever build the same form of intelligence twice – even though similar problems may lead to similar solutions.
As most owners of puppies know, it takes time and care for a dog to learn the ways of humans.
We don’t literally raise our hackles when angry, or sniff each other’s backsides when making new friends.
And dogs don’t gesture with their forepaws or use an elaborate grammatical language when trying to explain things.
In our own research, we have found that people remain somewhat mysterious to dogs for the first five months of life, and dogs at our local pound lag considerably behind house dogs when it comes to understanding human beings.
Recent research by Alexandra Horowitz at Barnard College in New York accentuates the “talking past each other” that sometimes goes on between humans and dogs.
Horowitz asked owners to forbid their dogs to take a biscuit and then briefly leave the room.
When the owners returned after a few moments away, some were told that their dogs had been naughty and eaten the forbidden food.
Others were told their dog had been good and left the biscuit alone.
If the dog had misbehaved, the owner was given a moment to berate his pet for its misdeed.
The owners were then asked whether their dog looked guilty.
The twist in this tale is that only half of the owners were correctly informed.
Half of the time, Horowitz told the owner of a dog that had actually left the biscuit alone that his dog had taken the treat.
And half the time the owner of a naughty dog was told that his dog had been good.
The point of this deception was that when Horowitz asked each owner whether his dog looked guilty, she could consider whether the owner’s report of “guilty looks” actually had to do with the facts of the matter – whether the dog had taken the forbidden treat – or whether it reflected nothing more than whether the owner had chastised his hound.
The results showed very clearly that a dog’s “guilty looks” came about solely because it was being scolded: the look had nothing to do with whether the dog had really committed an offense.
This does not mean that we should not chastise our dogs (or praise them).
Nor does it mean that we should not love our dogs – or sometimes be frustrated by them.
All it means is that, if we want to live harmoniously with another species in our most intimate places, we must recognize that some of the time our preferred modes of reasoning are not theirs.
We must try to understand dogs on their own terms, and help them to understand us.
Emerging Markets Should Go for the Gold
CAMBRIDGE – Are emerging-market central banks overweight in dollars and underweight in gold?
Given a slowing global economy, in which emerging markets are probably very grateful for any reserves they retain, this might seem an ill-timed question.
But there is a good case to be made that a shift in emerging markets toward accumulating gold would help the international financial system function more smoothly and benefit everyone.
Just to be clear, I am not siding with those – usually American far-right crackpots – who favor a return to the gold standard, in which countries fix the value of their currencies in terms of gold.
After all, the gold standard’s last reign ended disastrously in the 1930s, and there is no reason to believe that a return to it would turn out any differently.
No, I am just proposing that emerging markets shift a significant share of the trillions of dollars in foreign-currency reserves that they now hold (China alone has official reserves of $3.3 trillion) into gold.
Even shifting, say, up to 10% of their reserves into gold would not bring them anywhere near the many rich countries that hold 60-70% of their (admittedly smaller) official reserves in gold.
For some time, the rich countries have argued that it is in everyone’s collective interest to demonetize gold.
Sure, we hold a lot of gold, these countries say, but that is a vestige of the pre-World War II gold standard, when central banks needed a stockpile.
Indeed, back in 1999, European central banks, seeing no reason to keep holding so much gold, entered a pact to start reducing their stocks in an orderly fashion.
The sales made sense at the time for most of the participating countries: The real backing for their debt was the tax reach of their governments, their high levels of institutional development, and their relative political stability.
The 1999 pact has been revisited periodically, though since the most recent edition in 2014, most rich countries have taken a long pause, still leaving them with extremely high gold reserves.
Emerging markets have remained buyers of gold, but at a snail’s pace compared to their voracious appetite for US Treasury bonds and other rich-country debt.
As of March 2016, China held just over 2% of its reserves in gold, and the share for India was 5%. Russia is really the only major emerging market to increase its gold purchases significantly, in no small part due to Western sanctions, with holdings now amounting to almost 15% of reserves.
Emerging markets hold reserves because they do not have the luxury of being able to inflate their way out of a financial crunch or a government debt crisis.
Simply put, they live in a world where a large fraction of international debt – and an even larger share of global trade – is still denominated in hard currency.
So they hold reserves of such currencies as a backstop against fiscal and financial catastrophe.
Yes, in principle, it would be a much better world if emerging markets could somehow pool their resources, perhaps through an International Monetary Fund facility; but the trust required to make such an arrangement work simply is not yet there.
Why would the system work better with a larger share of gold reserves?
The problem with the status quo is that emerging markets as a group are competing for rich-country bonds, which is helping to drive down the interest rates they receive.
With interest rates stuck near zero, rich-country bond prices cannot drop much more than they already have, while the supply of advanced-country debt is limited by tax capacity and risk tolerance.
Gold, despite being in nearly fixed supply, does not have this problem, because there is no limit on its price.
Moreover, there is a case to be made that gold is an extremely low-risk asset with average real returns comparable to very short-term debt.
And, because gold is a highly liquid asset – a key criterion for a reserve asset – central banks can afford to look past its short-term volatility to longer-run average returns.
True, gold does not pay interest, and there are costs associated with storage.
But these costs can be managed relatively efficiently by holding gold offshore if necessary (many countries hold gold at the New York Federal Reserve); and, over time, the price can go up.
It is for this reason that the system as a whole can never run out of monetary gold.
I don’t want to create the impression that by shifting into gold, emerging markets would somehow benefit at the expense of advanced economies.
After all, the status quo is that advanced-economy central banks and treasuries hold vastly more gold than emerging markets do, and a systematic shift by emerging markets will bid up its price.
But this is not a systemic problem; and, in fact, a rise in gold prices would close part of the gap between demand and supply for safe assets that has emerged due to the zero lower bound on interest rates.
There has never been a compelling reason for emerging markets to buy into the rich-country case for completely demonetizing gold. And there isn’t one now.
Golden Rules for the Eurozone
LONDON – The European Monetary Union, as many of its critics maintain, looks a lot like the pre-1913 gold standard, which imposed fixed exchange rates on extremely diverse economies.
But is that resemblance as bad as it sounds, or as the euro’s critics insist?
The appeal of the historic gold standard lay in an institutional capacity to build confidence.
A completely fixed exchange rate rules out monetary-policy initiative, and consequently makes adjustment to large external imbalances very difficult to carry out.
And the burden is unequal, because there is much more pressure on deficit countries to adjust via deflation than on creditor countries to allow higher inflation.
Pessimists are especially worried by the unpleasant gold-standard analogies and lessons.
They foresee years and even decades of slow growth in Europe.
Politically, too, the process of adjustment by deflation in deficit countries is so unpleasant and difficult that many pessimists think it will ultimately prove to be unsustainable.
But critics of the euro should take the gold-standard analogy more seriously.
Like any system in the real world, it was more complex, more interesting, and also filled with more real policy possibilities than textbook caricatures suggest.
First, there was no automatic deflationary pressure following from some alleged peculiarity of the adjustment mechanism.
The question of overall deflationary – or inflationary – impact depended (and still depends) on the total quantity of money.
Thus, in periods after large new gold discoveries – for example, following the California Gold Rush of 1849, and again in the 1890’s, when new mining techniques opened up South African, Alaskan, and Australian reserves – the classical gold standard had a mild inflationary bias.
In an era of paper money, however, the link to a physical stock of some precious metal – or, indeed, some other commodity – does not exist, and there should be no reason why a central bank cannot aim at an overall inflation rate.
In fact, almost all modern central banks, including the European Central Bank, do precisely that.
The second lesson to be learned from the gold standard concerns the extent and limits of capital-market integration.
In the early 1990’s, policymakers, market participants, and economists alike simply assumed that the European Community’s “1992 program” – the legislative framework for the single market, and thus for a single capital market – would create a new reality, within which the single currency would work its magic.
From this followed an official obligation to treat all types of risk in the monetary union – bank risk or government risk – as identical.
But the history of the gold standard, and of other large common-currency areas, was more complex.
Despite the theoretical possibility of capital being sent over vast distances to other parts of the world, much capital remained local.
Creditors and banks often preferred to do business with known borrowers, and where local jurisdictions could settle any disputes.
In particular, a critical part of the gold standard was that individual national central banks set their own interest rates, with the aim of influencing the direction of capital movements.
This became the central feature of the gold-standard world: a country that was losing gold reserves would tighten interest rates in order to attract money.
The gold-standard rules look very different from the modern practice of monetary union, which relies on a single uniform interest rate.
That one-size-fits-all approach meant that interest rates in southern European countries were too low before 2009, and too high in northern Europe.
A gold-standard rule would have produced higher rates for the southern European borrowers, which would have attracted funds to where capital might be productively used, and at the same time acted as a deterrent against purely speculative capital flows.
Since the 2008 financial crisis erupted, there has been something of a renationalization of financial behavior in Europe.
Up to the late 1990’s and the advent of monetary union, most European Union sovereign debt was domestically held: in 1998, the overall ratio of foreign-held debt was only one-fifth.
That ratio climbed rapidly in the aftermath of the euro’s introduction.
In 2008, on the eve of the crisis, three-quarters of Portuguese debt, one-half of Spanish and Greek debt, and more than two-fifths of Italian debt was held by foreigners, with foreign banks holding a significant proportion, especially in the case of Greece, Portugal, and Italy.
One consequence of the ECB’s large-scale long-term refinancing operation (LTRO) has been that Italian banks are once again buying Italian government bonds, and Spanish banks are buying Spanish bonds.
German Economics Minister Philipp Rösler has made the fascinating suggestion that members of the European System of Central Banks should set their own interest rates (though, interestingly, he made this suggestion explicitly as a party politician, not as a government minister).
Autonomous interest-rate determination would penalize banks that have borrowed in southern Europe from their national central banks.
Meanwhile, the German Bundesbank would have lower rates, but southern European banks would be unlikely to have access to that credit for use in their own markets.
There are also signs that individual central banks are using the leeway that they have within the existing framework in order to carry out important policy shifts.
The Bundesbank has stated that it will no longer accept bank securities as collateral from banks that have undergone a government recapitalization.
The new collateral requirements, together with tentative talk of autonomous interest rates, represents a remarkable incipient innovation.
In the aftermath of the crisis, some policymakers are beginning to see that a monetary union is not necessarily identical with unfettered capital mobility.
Recognition of diverse credit quality is a step back into the nineteenth-century world, and at the same time forward to a more market-oriented and less distorting currency policy.
Different interest rates in different countries might open the door to a more stable eurozone.
Good and Bad Capitalism
PARIS – The reality of market exchange – direct transactions between merchants and customers – appeared gradually 3,000 or 4,000 years ago.
In this novel social relationship, the customer was free to buy whatever he wanted, whenever and from whomever he chose, often bargaining with the seller about the price.
Because of these features, the free market is part of a basic freedom that is rooted in everyday life.
It remains dominant today, as all efforts to establish an alternative, even totalitarianism, failed.
Indeed, it has been 20 years since the former communist countries of Eastern Europe rejoined the world of market exchange, a step taken as early as 1946 by social democrats around the world.
For several thousand years, the free market was comprised of individuals: craftsmen, traders, and consumers.
Capitalism when it arose three centuries ago was simply the same activity on a larger scale.
Because of steam engines and electricity, a large number of people were enabled to work together, and corporations could attract a large number of small savers, who became capitalists.
This system is fantastic.
By the time of the French Revolution, the standard of living had hardly doubled since the Roman Empire. Today, it is 150 times higher.
But capitalism is also cruel.
At its inception, people were compelled to work 17 hours a day without a day off or retirement. It was a form of slavery.
Thanks to democracy, social struggle, and workers’ unions, together with the political efforts of social democracy, the inhumanity of the system was partly softened.
Nevertheless, left to itself, the system is unstable.
It undergoes a crisis about once a decade.
The twentieth century’s worst crisis, between 1929 and 1932, caused 70 million workers in Great Britain, the United States, and Germany to lose their jobs (with no unemployment benefits) in less than six months.
Prosperity became the main weapon that ensured the West’s victory over Soviet communism.
The people of Eastern Europe were eager to embrace this kind of capitalism.
Capitalism’s political success, however, came at the very moment when the system was starting to deteriorate.
High salaries drove growth but reduced earnings.
Shareholders organized themselves into pension funds, investment funds, and hedge funds. Because of their pressure, employment fell, reducing the share of wages in total national income by 10% over the past 30 years.
In developed nations, the number of the working poor reached 10-15% of the workforce, with another 5-10% of unemployed workers and 5-10% dropping out of&nbsp; the labor market altogether.
Moreover, over the past 25 years, a severe financial crisis – regional or global – has erupted every four or five years.
Annual growth fell below 3% on average.
Today’s crisis was triggered by widespread concealment of bad loans within pools of securities sold all over the world.
The spread of bankruptcies triggered a severe credit crunch, which triggered a deep recession and with it a brutal rise in unemployment.
Capitalism’s three stabilizing devices lost their efficacy.
While rich countries reacted more quickly and more wisely in stimulating their economies than in 1929, and the hemorrhaging of banks was stanched, this has not been enough to boost growth.
We are now in a strange period in which governments, bankers, and journalists herald the end of the crisis just because large banks are no longer failing every week.
But nothing has been solved, and unemployment continues to rise.
Even worse, the banking sector is trying to take advantage of publicly financed rescue packages to protect its privileges, including immorally huge bonuses and extravagant freedoms to create speculative financial assets with no links to the real economy.
Indeed, the so-called end of the crisis looks more like a reconstruction of the mechanisms that caused it.
Everywhere, economic activity is painfully stabilizing at 5% to 10% below 2007 levels.
The root of the crisis remains the fall in purchasing power on the part of the middle and lower classes, and the collapse of speculative bubbles created by the wealthy classes’ greed for more.
But if we are to have a system where nearly everybody can become better off, the wealthy cannot become ever wealthier at the same time.
Otherwise, we can expect a long period of stagnation, punctuated by periodic financial crises.
In these circumstances, a majority of European voters have recently shown, once again, that they favor the right and its tendency to support the fortune seekers.
A bleak future awaits us.
Good and Bad Deficits
LONDON – “Deficits are always bad,” thunder fiscal hawks.
Not so, replies strategic investment analyst H. Wood Brock in an interesting new book, The American Gridlock.
A proper assessment, Brock argues, depends on the “composition and quality of total government spending.”
Government deficits incurred on current spending for services or transfers are bad, because they produce no revenue and add to the national debt.
Deficits resulting from capital spending, by contrast, are – or can be – good.
If wisely administered, such spending produces a revenue stream that services and eventually extinguishes the debt; more importantly, it raises productivity, and thus improves a country’s long-run growth potential.
From this distinction follows an important fiscal rule: governments’ current spending should normally be balanced by taxation.
To this extent, efforts nowadays to reduce deficits on current spending are justified, but only if they are fully replaced by capital-spending programs.
Indeed, reducing current spending and increasing capital spending should be carried out in lock step.
Brock’s argument is that, given the state of its economy, the United States cannot return to full employment on the basis of current policy.
The recovery is too feeble, and the country needs to invest an additional $1 trillion annually for ten years on transport facilities and education.
The government should establish a National Infrastructure Bank to provide the finance by borrowing directly, attracting private-sector funds, or a mixture of the two.
(I have proposed a similar institution in the United Kingdom.)
The distinction between capital and current spending (and thus between “good” and “bad” deficits) is old hat to any student of public finance.
But we forget knowledge at such an alarming rate that it is worth re-stating it, particularly with deficit hawks in power in the UK and Europe, though fortunately not (yet) in the US.
According to proposals agreed at an informal European Council meeting on January 30, all EU members are to amend their constitutions to introduce a balanced-budget rule that caps annual structural deficits at 0.5% of GDP.
This ceiling can be raised only in a deep depression or other exceptional circumstances, allowing for counter-cyclical policy so long as it is agreed that the additional deficit is cyclical, rather than structural.
Otherwise, violations would automatically trigger fines of up to 0.1% of GDP.
The UK is one of two EU countries (alongside the Czech Republic) that refused to sign this “fiscal compact,” acceptance of which is required to gain access to European bailout funds.
But Britain’s government has the identical aim of reducing its current deficit of 10% of GDP to near zero in five years.
An argument commonly heard in support of such policies is that the “bond vigilantes” will demand nothing less.
And the finances of some European governments (and Latin American governments in the recent past) have been so parlous that this reaction is understandable.
But that is not true of the US or the UK, which both have large fiscal deficits.
And most countries were adhering to reasonably tight fiscal discipline before the crisis of 2008 undermined their banks, cut their tax revenues, and forced up their sovereign debt.
At the same time, we should not attribute current enthusiasm for fiscal retrenchment to such contingencies.
At its heart lies the belief that all government spending above a necessary minimum is wasteful.
Europe has its own Tea Party crackpots who loathe the welfare state and want it abolished or radically pared, and who are convinced that all state-sponsored capital spending is a “boondoggle” – just so many roads, bridges, and railway lines to nowhere that soak up their money in corruption and inefficiency.
Those who believe this are unfazed by the corruption and waste that characterizes much private-sector spending.
And they prefer the total waste of letting millions of people sit idle (Brock reckons that 16% of the American workforce is unemployed, underemployed, or too discouraged to seek work) to the possibly partial waste of programs that put them to work, nurture their skills, and equip the country with assets.
One can criticize details of Brock’s case: a deeper understanding of Keynes would have given him a more persuasive response to the objection that, if state-financed projects were worth doing, the private sector would be doing them.
Before long, we will have to provide answers to these questions, because the pre-slump fiscal rules that the Europeans are vainly trying to strengthen were not up to the job.
We are far from having worked out a post-recession theory of macroeconomic policy, but certain elements are clear.
In the future, fiscal and monetary policy will have to work together: neither on its own can stabilize inherently unstable market economies.
Monetary policy will have to do much more than it did before 2008 to restrain financial markets’ “irrational exuberance.”
And we need a new, unambiguous system of fiscal accounting that distinguishes between tax-funded government spending and public spending that pays for itself.
Above all, we need to recognize that the state’s role goes beyond maintaining external security and domestic law and order.
He is right to do so, however much today’s deficit hawks seem, by their behavior, to prove the opposite.
Goodbye to “Globalization”
FLORENCE – The term “globalization” first swept the world in the 1990’s and reached its highpoint of popularity in 2000 and 2001.
In 2001, for instance, Le Monde contained more than 3,500 references to mondialisation.
But then the figure steadily fell – more than 80% by 2006.
Since the outbreak of the financial crisis in 2007, the word’s usage in major newspapers such as the New York Times and the Financial Times has fallen still further.
Globalization is on its way out.
A brief history of the concept, and a comparison with another term that also became discredited by overuse, helps to explain what happened.
The twentieth century’s two most important conceptual innovations, “totalitarianism” and “globalization,” were originally Italian.
The first term defined the tumultuous middle of the twentieth century, the latter its benign ending.
“Totalitarianism” finally disintegrated in 1989, and globalization prevailed.
Both terms originated as criticisms that were supposed to undermine and subvert the political tendencies they described.
But both ended up being just as frequently and enthusiastically used by the respective tendencies’ proponents.
“Totalitarianism” began its conceptual life in 1923 as a criticism or parody by the liberal writer Giovanni Amendola of the megalomaniacal pretensions of Benito Mussolini’s new regime.
In the course of a few years, it had become the proud self-definition of Italian fascism, endorsed by Mussolini’s education minister, Giovanni Gentile, who became the official philosopher of fascism, and then incorporated in a ghost-written article by Mussolini himself in the Encyclopedia of Fascism.
In both the hostile and the celebratory use of the word, totalitarianism was intended to describe a movement that embraced all aspects of life in what purported to be a coherent philosophy of politics, economics, and society.
Fascists liked to think of themselves as imbued with total knowledge and total power.
Today, few know where the term “globalization” originated.
The Oxford English Dictionary gives as the earliest reference to its current usage an academic article from 1972.
The word had been used earlier, but in a rather different sense.
It was a diplomatic term conveying the linkage between disparate policy areas (for example, in negotiating simultaneously on financial and security matters).
The OED etymology ignores the non-English origins of the term, which can be found in the inventive linguistic terminology of continental European student radicalism.
In 1970, the radical left-wing Italian underground periodical Sinistra Proletaria carried an article entitled “The Process of Globalization of Capitalist Society,” which was a description of IBM, an “organization which presents itself as a totality and controls all its activities towards the goal of profit and ‘globalizes’ all activity in the productive process.”
Because IBM, according to the article, produced in 14 countries and sold in 109, it “contains in itself the globalization (mondializzazione) of capitalist imperialism.”
This obscure left-wing publication is the first known reference to globalization in its contemporary sense.
Since then, the term has had ups and downs. It became increasingly faddish in the 1990’s, but mostly as a term of abuse.
In the late 1990’s and early 2000’s, anti-globalization demonstrations targeted the World Trade Organization, the International Monetary Fund, the World Economic Forum, and McDonald’s.
Globalization was seen at this time – as in the vision of the 1960’s Italian leftists – as the exploitation of the world’s poor by a plutocratic and technocratic elite.
But in the 2000’s, the meaning of globalization shifted and began to take on a semi-positive note, in large part because it increasingly looked as if the major winners of globalization included many rapidly growing emerging markets.
Indeed, countries that had previously been described as “under-developed” or “Third World” were becoming incipient global hegemons.
Moreover, many former critics began to recognize global connectedness as a way of solving global problems such as climate change, economic crisis, and poverty.
Historians have started to project globalization backwards.
It is no longer seen only as a story of the capital-market-driven integration of the last two decades of the twentieth century, or even of an “early wave of globalization” in the nineteenth century, when the gold standard and the Atlantic telegram seemed to unite the world.
Instead, the wider and deeper historical vision is of a globalization that encompasses the Roman empire and the Song dynasty, and goes back to the globalization of the human species from a common African origin.
The terms that we use to describe complex political and social phenomena and processes have odd ambiguities.
Some concepts that are designed as criticisms are quickly inverted to become celebratory.
By 2011, anti-globalization rhetoric had largely faded, and globalization is thought of as not something to be neither fought nor cheered, but as a fundamental characteristic of the human story, in which disparate geographies and diverse themes are inextricably intertwined.
In short, globalization has lost its polemical bite, and with that loss, its attractions as a concept have faded.
Goodbye to the Dollar?
You can’t treat your customers as badly as the United States has done lately if they can go elsewhere.
Over the past six years, the value of the trade-weighted dollar has fallen by more than a quarter, as the US has continued to rack up historically unprecedented trade deficits.
With a soft economy, a badly compromised financial system, and serious concerns about rising inflation, the long-term dollar trend is downward, however the current crisis ends.
And it is not over.
The Federal Reserve’s bailout of the financial system is unlikely to stand up unless banks find fresh capital, and lots of it.
Ultra-rich sovereign wealth funds have the cash to rescue US banks. But they are unlikely to want to do so at this point, even if the US political system allowed it.
Instead, as the credit crunch and housing price decline continue, an epic mortgage bailout appears increasingly likely, possibly costing US taxpayers a trillion dollars or more.
The problem is that after so many years of miserable returns on dollar assets, will global investors really be willing to absorb another trillion dollars in US debt at anything near current interest rates and exchange rates?
US debt hardly looks like a bargain right now, even without the sinking dollar.
Far-flung military misadventures continue to stretch the country’s fiscal resources, with costs potentially running into many trillions of dollars, according a recent study by Linda Bilmes and Joseph Stiglitz. 
Next year will almost certainly see a massive rise in US corporate defaults, even though many firms entered the recession with relatively strong balance sheets.
State and municipal finances are in even worse shape.
With tax revenues collapsing due to falling home prices and incomes, dozens of US municipalities could well go into receivership, as New York City did in the 1970’s.
US municipal bonds are already trading at huge risk premia, and the first big government default hasn’t even hit yet.
Of course, if the dollar were to fall off its perch as the world’s dominant currency any time soon, the euro would be the only serious alternative.
The Yuan may well supplant the dollar in the second half of this century.
But China’s draconian capital controls and massive financial repression currently disqualify it from anchoring the global economic system.
Fortunately for the dollar, the euro, too, seems to have its problems.
European banks remain balkanized, with a patchwork of national regulators seeking to promote their own champions.
European governments’ debt may all be denominated in euro, but German and Italian debt are hardly the same thing, so the government euro-bond market lacks the depth and liquidity of the US Treasury Bill market.  
Moreover, international investors can buy and sell real estate far more easily in the US than in most of Europe.
And the absence of a Europe-wide fiscal policy creates significant uncertainty about how the European Central Bank would finance itself if it suddenly faced large losses on junk bank debt after a big bailout.
But the euro does have growing strengths.
At current market exchange rates, the European Union is now larger economically than the US.
New central and eastern European members are bringing enormous dynamism and flexibility.
At the same time, the ECB has gained considerable credibility from its handling of the global credit crisis.
Indeed, if the euro zone can persuade Great Britain to become a full-fledged member, thereby acquiring one of the world’s two premier financial centers (London), the euro might really start to look like a viable alternative to the dollar.
In 1971, as the dollar collapsed towards the end of the post-World War II fixed exchange-rate system, US Treasury Secretary John Connally famously told his foreign counterparts that “the dollar is our currency, but your problem.”
And the dollar’s exalted global status has survived ever since, despite many episodes of neglect and abuse.
World currency standards have enormous inertia.
The British pound only forfeited its role to the US dollar after more than 50 years of industrial decline and two world wars.
But it could happen a lot faster this time.
As central bankers and finance ministers ponder how to intervene to prop up the dollar, they should also start thinking about what to do when the time comes to pull the plug.
Good Governance Begins At Home
The whole sorry Wolfowitz affair looks like it is finally drawing to a close.
It is hard to believe that he will stay on much longer at the World Bank, and it is time to start thinking more closely about the future of that institution.
From the first, I was critical of the way he was chosen because I have long opposed the “old boy” agreement between the United States and Europe, by which the US always appoints the head of the World Bank and Europe the head of the IMF.
This unspoken arrangement dates from the founding of the Bretton Woods institution at a time when colonialism was still alive, and makes no sense in the twenty-first century.
There are reports that European leaders have told the US that if they get Wolfowitz to step down quickly and quietly, they will be allowed to choose Wolfowitz’s successor.
It’s easy to see why the US and Europe want to stick to business as usual, but such a deal would amount to a wasted opportunity.
I can think of no better way to restore confidence in these two venerable institutions than to finally open up the way their presidents are selected.
One of the lessons of the Wolfowitz debacle is that it does actually matter how stakeholders and employees feel about the Bank’s leadership.
The world was prejudiced against him from the start because of his involvement in the Iraq War.
But people were willing to give him a chance.
Some said that perhaps he would be another Robert McNamara, the US defense secretary who helped mire America in the Vietnam War, but used his service to the Bank as penance.
At first, there was reason for hope: Wolfowitz was forceful in arguing for debt forgiveness and an end to agricultural subsidies.
But he also hired old friends and political allies – many of whom did not have experience in development – and sealed himself off from his staff, alienating the very people whose support he needed.
As we learned from the case of Larry Summers at Harvard, relationships inside institutions (not just with donors and funders) matter.
In this respect, Wolfowitz, while by all accounts an intelligent and pleasant person, did not do himself any favors.
Worse, Wolfowitz did not seem to have a grand vision for the Bank. Instead of a development strategy, there was simply an expansion of the anti-corruption agenda initiated by his predecessor, James Wolfensohn.
As the World Bank’s Chief Economist under Wolfensohn, I had argued that failing to deal with corruption risked undermining growth and poverty alleviation.
By the time I left the Bank, these ideas were widely accepted, and I was pleased that Wolfowitz supported continuing the Bank’s efforts.
But the fight against corruption was always to be only one part of a more comprehensive development agenda that was required.
Indeed, aid effectiveness could be undermined just as much by incompetence as by corruption.
Sadly, the anti corruption agenda of the Bank became politicized.
There was a push to give money to Iraq – a country rife with corruption – while other countries were accused of corruption without adequate hard evidence or specific details.
And here, too, an opportunity was lost.
The aims of the campaign were laudable, but it generated hostility and ill will, undermining its effectiveness.
The World Bank, in its efforts to support democracy and good governance, must insist on the highest standards of due process: charges of corruption should be treated seriously, and the evidence turned over to national authorities for use in open, transparent, and independent proceedings.
This is something for Wolfowitz’s successor to bear in mind.
If anti-corruption campaigns are to be seen as effective, they must be fair and transparent.
The same is true of the selection of the World Bank’s president.
There is still a chance to snatch victory from the jaws of defeat.
What has been a sad and sorry saga could have a happy ending if Wolfowitz’s successor is chosen in an open, transparent process.
This, one hopes, is the silver lining in the cloud now hanging over the World Bank.
Goodluck Nigeria
LAGOS – The bombs that exploded in Abuja, Nigeria’s capital, as the country was celebrating its golden jubilee earlier this month are a disturbing portent of the unprecedented political territory that the country is entering.
The death last May of Umaru Yar’Adua, Nigeria’s president, upended the informal agreement between members of the ruling People’s Democratic Party (PDP) to rotate power between northern Muslims and their southern, mainly Christian counterparts.
Yar’Adua’s deputy, Goodluck Jonathan, from the oil-rich Niger Delta in the south, overcame resistance from members of the late president’s cabinet and was sworn in as Yar’Adua’s successor, as stipulated by the constitution.
In September, he told Nigerians of his intention to run for another presidential term in 2011.
President Jonathan’s announcement triggered furious protests from his northern rivals, including Ibrahim Babangida, a former military dictator who reminded him that Olusegun Obasanjo, a southerner, had served as president from 1999, when military rule ended, to 2007, with northern support.
Yar’Adua had completed only three years of his first four-year term when he died, and it was expected that all southerners, including Jonathan, would unite behind another northerner for next year’s vote.
But resentment of northerners’ perceived dominance of national politics runs deep in the south, particularly in the Niger Delta, where 50 years of uncontrolled oil production has resulted in polluted farmlands and deepening poverty.
The ethnic minority groups that inhabit the area complain that the current revenue-allocation formula, which leaves Nigeria’s oil-producing states with only 13% of oil revenue, is grossly unfair and insufficient compensation for the damaged ecology they endure.
In January 2006, the Movement for the Emancipation of the Niger Delta (MEND), a violent organization led by angry Delta youth, began to attack oil installations and the soldiers guarding them.
MEND and other local groups are demanding that the country return to “true federalism” in the spirit of 1960, and that 50% of oil revenue be retained by the region’s inhabitants.
Ken Saro-Wiwa, a writer and founder of the Movement for the Survival of the Ogoni People (MOSOP), a grassroots movement in Ogoniland, had called for this as well, before he was hanged by General Sani Abacha’s junta in 1995.
Leading voices in the region have come out strongly in Jonathan’s support, and have asked him to ignore northern politicians who insist that the PDP’s power rotation arrangement be respected.
Delta leaders point out that 2011 is the ‘minorities’ turn to govern the country after being sat upon by the larger ethnic groups since the end of colonial rule in 1960.
It is not yet clear whether Goodluck Jonathan will be able to translate this sectional support into enough votes in the party primaries and beyond to retain the presidency.
He has the advantage of a massive war chest, given that Nigeria’s leaders have always done with the public treasury what they liked.
But General Babangida also has deep pockets.
Besides, PDP’s powerful governors, in control of 28 of the country’s 36 states, see Jonathan as an upstart who came from the middle of nowhere to become president.
The powers of the Nigerian presidency are extensive, and Jonathan’s handlers have been dropping loud hints that they will deploy them to whip the governors – including the northerners – into line.
Northern PDP leaders, still pressuring the region’s large group of presidential contenders, including Babangida, to agree on who will fight it out with Jonathan, are already looking beyond the primaries.
They are threatening to take the northern vote to another party if they lose the PDP ticket.
This could have far-reaching consequences for the PDP and the country. The PDP, in power since military rule ended in 1999, is widely disliked.
Corruption is widespread, and PDP politicians have been unable to deliver the prosperity and improved social services that Nigerians looked forward to following the return of democracy.
Indeed, the PDP has been able to retain power only by rigging successive elections, most spectacularly in 2007, when the outgoing Obasanjo foisted Yar’Adua on the party hierarchy.
The poorly resourced opposition could benefit if the expected northern backlash divides the PDP.
Nuhu Ribadu, the respected former chairman of the Economic and Financial Crimes Commission, has announced his intention to contest the presidency as the candidate of one of the opposition parties.
A Muslim northerner, Ribadu enjoys the support of youth and democrats nationwide.
The latter are regaining confidence in the political process, following the recent appointment of a no-nonsense academic as head of the election commission.
Muhammadu Buhari, whom Babangida replaced as military head of state in 1985, is also expected to run, as the nominee of the Congress of Progressive Change.
Doubts linger about whether longtime northern PDP leaders, used to cutting midnight deals with their southern counterparts, would break ranks and support Ribadu next year.
Conservative northerners also view Buhari, an ascetic politician popular with the region’s poor, with unease.
Even if they overcome their reservations and back Ribadu or Buhari, and either candidate goes on to beat Jonathan at the polls, angry Delta youths could respond with fresh violence against oil workers, disrupting production.
Other trouble spots – central Nigeria, where ethnic tensions are simmering, and the far north, the stomping ground of Boko Haram, a violent Muslim sect – could get sucked into election-related violence.
With industries collapsing because of constant power outages, unemployment soaring, and cynical politicians forcing their impoverished followers into ethnic and religious laagers, Nigeria’s 2011 elections are shaping up to be a perfect storm.
In the past, Nigeria has always managed to weather its political tempests.
Will it do so again?
Good Policies for Great Countries
NEW YORK – We are in a protracted period of international transition, one that began more than two decades ago with the Cold War’s end.
That era of strategic rivalry between the United States and the Soviet Union gave way to one in which the US possessed far greater power than any other country and enjoyed an unprecedented degree of influence.
That American unipolar moment has given way to a world better described as non-polar, in which power is widely distributed among nearly 200 states and tens of thousands of non-state actors ranging from Al Qaeda to Al Jazeera and from Goldman Sachs to the United Nations.
But what distinguishes historical eras from one another is less the distribution of power than the degree of order between and within states.
Order never just emerges; it is the result of conscious efforts by the most powerful entities in the world.
While the US remains the world’s most powerful single country, it cannot maintain, much less expand, international peace and prosperity on its own.
It is over-extended, dependent upon massive daily imports of dollars and oil, and its armed forces are engaged in demanding conflicts in Afghanistan and Iraq.
The US lacks the means and the political consensus to take on much more in the way of global responsibility. It also lacks the means to compel others to follow its lead.
Moreover, contemporary problems – for example, thwarting the spread of materials and weapons of mass destruction, maintaining an open world economy, slowing climate change, and combating terrorism – cannot be managed, much less solved, by any single country.
Only collective efforts can meet common challenges; the more global the response, the more likely that it will succeed.
In short, the US requires partners if the twenty-first century is to be an era in which the majority of people around the world enjoy relative peace and satisfactory standards of living.
But the partnerships that prevailed in the Cold War  – between the US, Western Europe, and several Asian countries, including Japan, South Korea, and Australia – are no longer adequate.
These countries lack the resources and often the will to manage most of the world’s problems.
So the old partners need new ones.
Emerging powers have the potential to fill this need.
The question is what China, India, Brazil, and others are prepared to do with their growing strength.
What makes a country great is not the size of its territory, population, army, or economy, but how it uses its power to shape the world beyond its borders.
Countries that are strong but still developing tend to regard foreign policy as little more than a hand-maiden of domestic policy and a means to gain access to markets and resources essential for rapid development.
This outlook is understandable, but shortsighted.
Rising powers can neither insulate nor isolate themselves from what happens beyond their borders.
Whether or not they acknowledge it, they have a stake in world order.
Consider China, by many measures the most significant emerging country.
It wants to maintain preferred access to Iran’s energy resources, but if conflict results from Iran’s nuclear aspirations, China will be paying much more for those resources.
The prospect of a threat to the stability of the greater Middle East and to the flow of oil should give China an incentive to support robust sanctions against Iran.
But it is not clear whether China’s leaders will recognize this and act in their country’s own long-term self interest.
The point is not to single out China. Similar questions apply to India and Brazil.
And it is not just the developing and emerging countries that must reconsider their approach to the world. The US must do so as well.
While much has been said and written about America’s call for China to become a global stakeholder, China will not simply sign on as a pillar of an American-defined world.
It wants to help set the rules and build the institutions for enforcing them.
It is up to the US to work with China and others to do this, and this requires America’s openness to others’ preferences and their having a larger role.
The empowerment of the G-20 is a step in the right direction, but many more changes are needed, including restructuring the UN, the International Monetary Fund, and the World Bank so that they, too, reflect the new distribution of power.
In return, new arrangements should call on emerging countries to contribute more to addressing climate change, paying for peacekeeping and state-building, promoting free trade, and sanctioning those who support terror or develop weapons of mass destruction.
This era’s major states, developed and emerging alike, have the ability to reach accord on today’s defining issues.
Their willingness to do so will determine when and how this period of global transition ends and what succeeds it.
Good Times Down Latin America’s Way
MEXICO CITY – For Latin America, 2011 was, in Frank Sinatra’s terms, a very good year –&nbsp;and 2012 doesn’t look like being so bad either.
For a region not always accustomed to things going well, this is a somewhat strange state of affairs.
Three elections were held in Latin America in 2011.
Two – in Argentina and Peru – went well; the other – in Nicaragua – was marred by egregious fraud and heavy-handed government intervention in favor of the incumbent.
Still, two out of three is not bad in a region where, previously, if elections were held at all, disputes about the outcomes were the norm.
In economic terms, high commodity prices fueled strong growth in South America in 2011, and the modest US recovery benefited nearby countries.
In Chile, Peru, Argentina, Uruguay, Bolivia, and, to a lesser extent, Brazil and Colombia, voracious Chinese and Indian demand for raw materials and food boosted foreign reserves, enabled heavy government spending, and sustained high levels of imports.
All this led to average growth rates well in excess of 4%.
But it also led to new doubts about the wisdom of reliance on commodity exports.
Chilean economist and politician Carlos Ominami, in his tell-all memoir Secretos de la Concertación, wondered what would happen if China's economy slowed or its real-estate bubble burst.
By the end of the year, this seemed to be happening: commodity prices and growth rates were dropping, and 2012, while still promising strong economic performance, will not match this year's success.
Sustained lower prices may bring chickens home to roost.
The outliers were Venezuela, despite high oil prices, and the Caribbean Basin: Mexico, Central America, and the islands.
These countries export manufactured goods to the US, on which they also rely for tourism and remittances; they lack either the geography or the geology to become great commodity exporters (or, like Mexico, they export all of their oil to the US).
But even the outliers enjoyed decent growth this year.
If the US avoids a new slowdown, they may do better than South America in 2012.
All told, with the exception of 2009, the entire region will have experienced a full decade of uninterrupted growth – something not witnessed since the 1970’s.
The boom fueled expansion of Latin America’s middle classes.
Between 1950 and 1980, most Latin American countries’ middle classes comprised between one-quarter and one-third of the population.
Then came the debt crisis of the 1980’s, the extreme &nbsp;structural reforms and financial collapses of the 1990’s, and a new global downturn in 2001.
Such traumatic events plunged these countries into the so-called “middle-income trap”: unable to grow nor to continue broadening their middle classes.
But, by the second half of the 2000’s, everything changed: prolonged macroeconomic stability, competent center-left or center-right governments, sensible social policies, and global economic growth allowed countries like Mexico, Brazil, Chile, Uruguay, and even Argentina to take the next giant step.
By 2008 or so, around 55% of these countries’ populations belonged to the middle class, by whatever definition one used.
Access to credit, more jobs, remittances, the commodity boom, and conditional cash transfers enabled millions to purchase a home, a car, and a better life.
This was not a middle class modeled on North Atlantic precedents, and its members’ status is precarious and reversible; moreover, their standard of living is well below that of their counterparts in wealthier countries.
But a middle class it is.
These middle-income sectors make up an even larger part of the electorate, since their turnout rates are higher than those of the poor.
Political candidates must engage them, occasionally pander to them, and tailor their message to them, all of which steers leaders and parties toward moderate positions.
There are no guarantees that this will endure, but it is one of the region’s most impressive achievements in recent years.
Latin America will witness two important elections in 2012, in Venezuela and Mexico, and one non-election, in Cuba.
In Venezuela, President Hugo Chávez’s opponents will unite behind a single candidate for October’s presidential election.
But everything depends on Chávez’s health, which, like that of Fidel Castro in Cuba a closely guarded state secret.
Will Chávez’s cancer allow him to run (he is as formidable a campaigner as he is a terrible economic manager), win, and govern until 2030?
Will he be a stand-in for his more radical brother (and designated successor), Adán?
Or will he be too ill to participate?
In that case – and most importantly – would he, Adán, and the entire “Bolivarian” elite accept defeat at the polls?
In Cuba, there will be no elections, but matters may come to a head next year.
Raúl Castro’s economic reforms have either not been implemented, or are not delivering the expected results; the island continues to depend on Venezuelan subsidies, remittances from Miami, and European tourists.
Cuba’s octogenarian ruling brothers cannot last forever.
Something may have to give on the island, especially if their Venezuelan benefactor is no longer in power.
Then there is Mexico, which will hold only its fourth democratic election in its history in a context of rampant organized crime, appalling violence, and rising skepticism about President Felipe Calderón’s war on drugs.
With three contending parties, a terrible electoral law, no run-off, and condiderable frustration with 12 years of center-right, often ineffective governments, the outcome is highly uncertain.
That said, Mexico’s political institutions have survived hard times, the middle class rejects extremism, and the US is close by.
One would prefer to see Mexico’s presidential candidates offer platforms with ideas and proposals that respond to the challenges facing the country, but this substance deficit occurs everywhere now, almost all the time.
For a region that has suffered so long from frustration and despair over its failures, these are among the best of times.
Latin America should count its blessings, and remember that nothing lasts forever.
The Tinkerer’s Apprentice
BERLIN – The best inventions are never finished.
When the German engineer Karl Benz invented the first petroleum-powered automobile, he did not just create an engine with wheels; he set in motion an industry that revolutionized the way society was structured.
Similarly, the English computer scientist Tim Berners-Lee did not only build the world’s first Web site. He laid the groundwork for the World Wide Web.
Neither could have anticipated the impact of what he was doing.
If there is one lesson that economic policymakers should heed in 2015 and beyond, it is this: Just as invention is dynamic, so are the industries it creates.
As we learned in 2014, it is a lesson that has yet to sink in entirely.
When Google was launched, people were amazed that they were able to find out about almost anything by typing just a few words into a computer.
The engineering behind it was technically complicated, but what you got was pretty rough: a page of text, broken up by ten blue links.
It was better than anything else, but not great by today’s standards.
So our co-founders Larry Page and Sergey Brin – like all other successful inventors – kept iterating.
They started with images.
After all, people wanted more than just text.
This first became apparent after the 2000 Grammy Awards, where Jennifer Lopez wore a green dress that, well, caught the world’s attention.
At the time, it was the most popular search query we had ever seen.
But we had no surefire way of getting users exactly what they wanted: J­Lo wearing that dress.
Google Image Search was born.
Maps are another great example.
When people search Google for an address, they do not want a link to Web sites that mention the street.
They usually want to know how to get there.
So we built a map that was clickable, draggable, and easy to explore.
Maps have become such an integral part of Google that most users probably cannot imagine it without them.
It has been the same with many of our changes.
Our searches have gotten better over time.
Google the weather where you live and you will get the forecast for the next few days as the top result, saving you time and effort.
But Google’s efforts to provide direct answers to questions have fueled complaints at the European Commission.
Companies like Expedia, Yelp, and TripAdvisor argue that Google searches are depriving their Web sites of valuable traffic, putting their businesses at a disadvantage.
Instead of us providing you with images, maps, the weather, news, or translated versions of foreign-language sites, they would rather go back to ten blue links.
A few years ago, a lawyer for one of our competitors drew a picture of a coastline with a little island offshore.
He added a dotted line, explaining that this was the only ferry connecting the island to the mainland.
His point was that Google was just like the ferry: the only way to navigate the Internet.
In reality, there are many ways to get around on the Web.
For news, you might go directly to your favorite news service.
If you want to buy something, you might go directly to Zalando or Amazon, where you can research models and prices, get reviews, and pay for your purchase all at once.
The real point is that the economic landscape in which we are operating is not only competitive; it is changing constantly.
This year, our industry reached an important milestone.
For the first time, people are spending more time on mobile devices than on their desktop computers.
Time spent on desktops has now fallen to just 40%.
And people use mobile devices very differently from the way they use desktops.
Seven out of every eight minutes spent on a mobile phone is spent within an app, and the most popular app in the world is Facebook.
Many people look at Facebook, Google, Apple, and Amazon, among others, as companies that no competitor could ever beat.
I am less certain.
History is full of examples that show that size and past success guarantee nothing.
Great companies can be surpassed swiftly.
Just a few years ago, companies like Yahoo, Nokia, Microsoft, and Blackberry seemed unrivaled.
They have all since been disrupted by a new wave of tech companies – Google among them.
Google works very differently from other companies that have been dubbed “gatekeepers” and that are regulated accordingly.
We are not a ferry, a railroad, a telecommunications network, or an electricity grid with only one line serving you and no competitors allowed.
No one is stuck using Google.
People have choices, and they exercise them all the time.
We know that if we cease to be useful, our users will leave.
The barriers to entry are negligible, because competition is just one click away.
Someone in a garage somewhere is gunning for us, and 2015 could be the year that they make their move.
I know, because not long ago we were in that garage.
And I know that the next Google will not do what Google does, just as Google did not do what AOL did.
The upheavals resulting from momentous technological change are rarely expected.
The telegraph disrupted the postal service.
Radio and television shook up the newspaper industry.
Airplanes ended the age of ocean liners.
Inventions are always dynamic; that is why the future will always be as exciting as the past.
Education Without Borders
LONDON – As the third anniversary of the start of Syria’s civil war approaches, there is a race against time to deliver a groundbreaking education project to the conflict’s hardest-hit victims – hundreds of thousands of child refugees.
A shocking three million Syrian children have now been displaced. More than one million of them have fled Syria and are languishing in camps in neighboring countries, particularly Lebanon, Jordan, and Turkey.
These children are now suffering a third winter away from their homes, schools, and friends.
Many are separated from their families, and thousands more join the ranks of displaced persons every day in what is becoming the largest humanitarian catastrophe of our time.
But a pathbreaking initiative in Lebanon, involving teachers, aid agencies, and education charities has opened a small window of hope.
Amid the chaos of camps, makeshift huts, and destitution, the fight for an important new principle of international aid has begun: even in times of conflict, children must have access to education.
A century and a half ago, the Red Cross established the norm that health care could – and should – be provided even in conflict zones.