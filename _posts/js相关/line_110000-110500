Perhaps the fiscal observation is a coincidence.
After all, it would be foolish to read too much into two historical data points.
It would be even more foolish to believe that just because American politicians have failed to dislodge the US dollar from its paramount status over the last 40 years, they could not accomplish the job with another few decades of effort.
It is not an eternal law of nature that the dollar shall always be number one.
The pound sterling had the top spot in the nineteenth century, only to be surpassed by the dollar in the first half of the twentieth century.
The day may come when the dollar, too, succumbs to a rival. But today is not that day.
Absent America
CAMBRIDGE – The US Congress has now carelessly blocked a long-awaited reform of the International Monetary Fund.
That would be bad enough if it were an isolated episode. But this is just the latest in a series of self-inflicted blows since the turn of the century that have needlessly undermined the United States’ claim to global leadership.
The IMF reform would have been an important step in updating the allocations of quotas, which determine member states’ monetary contributions and voting power.
The US was not being asked to contribute more money or lose its voting weight, which has always given it a unique veto power.
Instead, the proposed increase in quotas for China, India, Brazil, and other emerging economies would have come largely at the expense of European countries.
The change in IMF quotas is a partial and overdue response to the newcomers’ rising economic weight and Europe’s outdated dominance.
Indeed, the principle of matching representation to countries’ contributions – sometimes known as the Golden Rule (“He who has the gold, rules”) – is probably one of the reasons that the IMF has usually been more effective than other international organizations (for example, the United Nations General Assembly).
To be sure, US President Barack Obama has tried to exercise global leadership.
He pushed for the agreement to reform the IMF at the G-20 summit in Seoul in November 2010 (the first meeting to be hosted by a non-G-7 country), and he prevailed over understandable European reluctance to cede power.
But congressional rejection of an international agreement that the president had painstakingly persuaded the rest of the world to accept is not a new pattern.
It goes back a century, to President Woodrow Wilson’s inability in 1919 to persuade a myopically isolationist Congress to approve the League of Nations.
Since then, Congress has rejected the International Trade Organization (1948), the SALT II nuclear agreement (1979), and the Kyoto Protocol (1997), among others.
A history of trying to reopen international negotiations that the executive has already concluded is also the reason why Congress has to give Obama so-called trade promotion authority (which entails fast-track congressional votes on trade agreements).
Otherwise, America’s trading partners will not negotiate seriously in ongoing regional and global trade negotiations.
Commentators have been warning since the 1980’s that the US may lose its global hegemony for economic reasons – budget deficits, a declining share of global GDP, and the switch from net international creditor to net debtor – with the historical hypothesis of imperial overreach gaining renewed attention.
But the main problem seems to be a lack of will rather than a thin wallet.
Or perhaps it would be more accurate to describe the problem as one of wild swings in US domestic politics between excessive isolationism and excessive foreign intervention in response to short-term events, and untempered by any longer-term historical perspective.
These days, after a decade of war in Iraq and Afghanistan at an estimated cost of $4 trillion (including the medical care that veterans will need for the rest of their lives), the pendulum has apparently swung back in the direction of isolationism.
One had hoped that the shortsighted members of Congress who foolishly shut down the US government three months ago had become aware of the damage caused to America’s credibility and global leadership.
Most visibly, the Obama administration had to cancel its participation at the Asia-Pacific Economic Cooperation (APEC) summit in Bali in October, impeding progress on the US-led Trans-Pacific Partnership.
It was widely reported that Asian countries concluded from Obama’s absence that they should cultivate ties with China instead.
The growing power of China and other major emerging-market countries is a reality.
That is precisely why it is so important that the US support a greater role for these countries in international institutions such as the IMF, the G-20, and APEC.
The rise of China could go well or badly, depending in part on whether the status quo powers make room for the newcomer – a risk to international stability first noted by Thucydides, who traced the cause of the Peloponnesian War to Sparta’s response to the rising power of Athens.
Likewise, failure to accommodate Germany’s rise contributed a century ago to the outbreak of World War I.
Though Chinese President Xi Jinping’s call for “a new type of great power relations” may sound anodyne, the phrase apparently demonstrates awareness of the “Thucydides trap.”
It signals China’s openness to working with other countries to avoid a repetition of the tragedies of 431 BC and 1914 AD.
It is only sensible to take him up on his offer.
The continuing potential for US global leadership, despite America’s move from global creditor to debtor, has partly been a matter of luck.
In the Asia-Pacific region, historical and territorial frictions among Japan, Korea, and China have ensured that America’s presence remains more welcome than it otherwise would be.
Meanwhile, Europe’s fiscal follies have been even more egregious than America’s.
Asians are acutely aware that the IMF has intervened in the euro crisis with much greater support than it provided during the Asian financial crisis of 1997-98, and they understandably feel entitled to a larger say in how the Fund is run.
But the emerging-market countries have been so disunited that in 2011 they failed to support a common candidate for IMF Managing Director.
As a result, though the three previous incumbents were Europeans who did not complete their terms in office, another European, Christine Lagarde, won the top spot yet again.
(Lagarde has done a good job, rather than kowtowing to Europe, but that is beside the point.)
Latent global demand for enlightened US leadership, which first appeared at the end of World War I, can survive budgetary constraints and even misguided military interventions. What it cannot survive is an abdication of interest by the US Congress.
Market Failure and Political Failure
PARIS – Markets can fail.
But, as has been demonstrated in areas like air pollution, traffic congestion, spectrum allocation, and tobacco consumption, market mechanisms are often the best way for governments to address such failures.
So why are such mechanisms now in retreat?
Consider markets for emissions allowances, in which firms that can cheaply cut air pollution trade with those that cannot.
A decade ago, the idea that such markets could achieve desired environmental goals at relatively low cost was widely recognized and implemented.
Today, however, politics is killing “cap and trade.”
In the United States, the highly successful cap-and-trade system for sulfur-dioxide emissions has effectively vanished.
In Europe, the Emissions Trading System (ETS), the world’s largest market for carbon allowances, has become increasingly irrelevant as well.
On both sides of the Atlantic, market-oriented environmental regulation has in effect been superseded over the last five years by older “command-and-control” approaches, by which the government dictates who should use which technologies, in what amounts, to reduce which emissions.
Cap and trade was originally supposed to be a Republican idea in the US: its backers were those who considered themselves pro-market, not those who considered themselves pro-regulation.
Most environmental organizations initially opposed it, with many believing it immoral for corporations to be able to pay for the right to pollute.
Indeed, it was Ronald Reagan’s administration that pioneered the use of cap and trade to phase out leaded gasoline in the 1980’s.
George H. W. Bush’s administration used it to reduce SO2 emissions from power plants in the 1990’s, and his son’s administration sought to use it to reduce SO2 and other emissions further in the 2000’s.
The problem is not that cap and trade is an ivory-tower theory that cannot work in the real world; on the contrary, its performance surpassed expectations.
In the 1980’s, it enabled lead to be phased out more rapidly than predicted and at an estimated annual savings of $250 million relative to the command-and-control approach.
Similarly, emissions of SO2 were curbed at a much lower cost than even cap-and-trade proponents had predicted before 1995.
As recently as 2008, the Republican candidate for US president, Senator John McCain, had sponsored legislative proposals to use cap and trade to address emissions of carbon dioxide and other greenhouse gases.
But Republican politicians now seem to have forgotten that this approach was once their policy.
In 2009, they worked to defeat climate-change legislation by relying on anti-regulation rhetoric that demonized their own creation.
This left only less market-friendly alternatives – especially after court cases upheld the validity of the 1970 Clean Air Act.
Though such alternatives are less efficient, they are again the operative regime.
Likewise, the European Union adopted the ETS in 2003 as a cost-effective way to achieve the commitments it had made under the 1997 Kyoto Protocol.
The ETS rapidly became the world’s largest system for putting a market price on environmental damage.
But now it has been pushed aside by other kinds of regulation. 
European directives require that 20% of energy must come from renewables by 2020.
But, while policymakers have helped drive down the price of emissions permits in the ETS by mandating and subsidizing renewable energy, the supply of permits has not been reduced.
As a result, demand now falls short of any binding constraint.
Indeed, the price of permits fell below three euros a ton in April 2013, rendering the emissions-trading market almost irrelevant.
This, in turn, has encouraged greater reliance on highly polluting coal – the worst energy source, from the standpoint of global warming. That would not have happened if the price mechanism still underpinned climate-change policy.
Moreover, the EU’s renewables policy has also proved to be ruinously expensive.
All of this should give pause to the European Council when it meets in March to consider how to extend the 2020 goals to 2030.
There is a fascinating parallel between the evolution of American political attitudes toward market mechanisms in environmental regulation and Republican hostility to “Obamacare” (the 2010 Affordable Care Act).
The core of Obamacare is an attempt to ensure that all Americans have health insurance, via the individual mandate.
But it is a market-oriented program insofar as health insurers and health-care providers remain private and compete against one other.
This was originally a conservative approach.
The two major alternatives to it are much further removed from the marketplace: a “single payer” system, as in Canada (or America’s Medicare system for the elderly), with the government providing health insurance, or “socialized medicine,” as in the United Kingdom (or the US Veterans Health Administration), with the government providing health care directly.
The approach taken by Obamacare was proposed in conservative think tanks such as the Heritage Foundation and enacted in Massachusetts by Republican Governor Mitt Romney.
But, by the time Obama adopted it, it had become anathema to Republicans, forcing Romney, the party’s presidential candidate in 2012, to run against his own record.
The market failure in the case of air pollution is what economists call an “externality”: those who pollute do not bear the entire cost.
The market failure in the case of health care is what economists call “adverse selection”: insurers may not provide insurance, especially to patients with pre-existing conditions, if they fear that healthy customers have already taken themselves out of the risk pool.
But, again, government attempts to address market failures can themselves fail.
In the case of the environment, command-and-control regulation is inefficient, discourages innovation, and can have unintended consequences (like Europe’s growing reliance on coal).
In the case of health care, a national monopoly can forestall innovation and provide inadequate care with long waits.
In general, the best government interventions target failures precisely – using cap and trade to put a price on air pollution, for example, or relying on the individual mandate to curtail adverse selection in health insurance – while letting market forces do the rest more efficiently than bureaucrats can.
African Leaders’ Eyes on the Prize
CAMBRIDGE – On October 14, the Mo Ibrahim Prize Committee announced that for the second year in a row it had not found anyone to whom to award its Prize for Achievement in African Leadership. Why is that important?
The prize is given to a recently retired African head of state or government who was democratically elected, stepped down at the end of his or her constitutionally mandated term, and demonstrated exceptional leadership.
The winner receives $5 million paid over ten years, followed by $200,000 annually for life, making it the world’s most valuable annual award.
The Mo Ibrahim Foundation supports other important activities, particularly the annual Ibrahim Index of African Governance (IIAG), which was also released on October 14.
But I am especially intrigued by the prize.
It is a fascinating social-policy experiment, which deserves to be more widely known.
Critics of the Ibrahim Prize argue that it makes Africa look bad, because in four out of seven years it has not been awarded to anyone.
It has also been argued that leaders should not have to be “bribed” into being good.
The good will be good, and the bad will be bad, regardless of the prize.
I don’t buy these criticisms.
Yes, other parts of the world also suffer from governance problems.
And more people should be aware that many African countries have made substantial progress over the last decade, particularly with respect to economic growth, health, and education.
But those are not arguments against highlighting the important role of leadership in African countries’ success.
Given the abundant attention received by Africa’s truly awful leaders, it is useful to focus on its good ones.
And the money that comes with the Ibrahim Prize is enough that it could affect leaders’ behavior.
The Ibrahim Prize was awarded in 2007, 2008, and 2011 to Presidents Joaquim Chissano of Mozambique, Festus Mogae of Botswana, and Pedro Verona Pires of Cape Verde, respectively.
Botswana and Cape Verde are two of the small-population countries that are consistently placed near the top in rankings of African governance, human development, and economic performance.
Mozambique is different: larger and historically in much worse shape, it suffered a terrible civil war from 1977 to 1992.
Even after two decades of strong political and economic improvement, it still ranks low on most development indicators.
What defines good leadership is a notoriously complicated question.
Should leadership be evaluated according to criteria like economic prosperity, public health, respect for human rights, personal security, and peace?
Or are the proper criteria the leader’s character and competence, including his or her ability to inspire the country, choose good officials, formulate good policies, and implement them?
In a word, is leadership a matter of outcomes or inputs?
Successful outcomes are obviously the ultimate objective.
But it is not useful to rely solely or primarily on outcomes to judge a leader.
Many factors beyond a leader’s control can block his or her country’s progress.
Even if good leadership means a demonstrated ability to prevail in the face of intransigent domestic political opposition, coup attempts, and invasions, surely no leader can be held responsible for the effects of droughts, floods, or other natural disasters.
Admittedly, a leader’s integrity and competence are more difficult to measure than outcomes (such as per capita income, life expectancy, infant mortality, literacy, and crime).
But some of the component indicators of the IIAG (such as rule of law, bureaucratic red tape, and fiscal policy) are more directly under government control.
In any case, one would not expect prize committees or historians to judge leaders solely by quantitative criteria.
Few Americans thought Harry Truman had been a good president immediately after he left office, but now he is rated very high.
In Mexico, Carlos Salinas looked good at the time, but is now viewed poorly, while the accomplishments of his successor, Ernesto Zedillo, now appear bold, historic, innovative, and valuable.
The list of eligible candidates for the Ibrahim Prize begins with those who were democratically elected and left office constitutionally within the preceding three years.
In a typical year, there may be as few as three candidates who meet these qualifications.
The question is then whether any candidate demonstrated the necessary level of excellence in office.
In 2009, 2010, 2012, and now 2013, the prize committee decided that none had.
Does that mean that the prize has failed to meet the objective of encouraging good leadership in Africa?
Consider a ruler who comes to power with good intentions and great abilities.
Assume that he accomplishes much for his country during his first term (or his first two or three terms if the constitution allows it). But he stays too long (Uganda’s Yoweri Museveni comes to mind).
He forces through constitutional changes so that he can run for more terms.
Then he starts rigging elections and suppressing opposition.
He or members of his family nurture large overseas bank accounts.
Such leaders’ personalities may have changed.
They may now regard themselves as indispensable.
They have been corrupted by power, like the porcine elite in George Orwell’s Animal Farm.
At this point, they are unlikely to be influenced by the money that comes with the Ibrahim Prize.
But now consider a leader who would prefer to serve honestly throughout his term and depart voluntarily. This path might leave a retirement with few resources for him and his family, little in the way of prestige or a platform from which to speak, and perhaps persecution by his successors.
It is precisely such a leader for whom the Ibrahim Prize could make the difference, influencing him to continue on the high road.
If the experiment works, however, the main fruits will lie in the future.
The Ibrahim Prize was established only in 2007, which means that the candidates have served most of their terms in office at a time when the prize could not have influenced their behavior.
If it does have the desired effect, we should start seeing winners in more years.
Sovereign Debt at Square One
CAMBRIDGE – Argentina and its bankers have been barred from making payments to fulfill debt-restructuring agreements reached with the country’s creditors, unless the 7% of creditors who rejected the agreements are paid in full – a judgment that is likely to stick, now that the US Supreme Court has upheld it.
Though it is hard to cry for Argentina, the ruling in favor of the holdouts is bad news for the global financial system and sets back the evolution of the international regime for restructuring sovereign debt.
Why is it so hard to feel sympathy for a developing country that can’t pay its debts?
For starters, in 2001, Argentina unilaterally defaulted on its entire $100 billion debt, an unusual step, rather than negotiating new terms with its creditors.
When, in 2005, the government finally got around to negotiating a debt swap, it could almost dictate the terms – a 70% “haircut.”
In the intervening decade, President Cristina Fernández de Kirchner and her late husband and predecessor, Néstor Kirchner, have pursued a variety of spectacularly bad economic policies.
The independence of the central bank and the statistical agency have been severely compromised, with Fernández forcing the adoption, for example, of a consumer price index that grossly understates the inflation rate.
Contracts have been violated and foreign-owned companies have been nationalized.
And when soaring global prices for Argentina’s leading agricultural commodities provided a golden opportunity to boost output and raise chronically insufficient foreign-currency earnings, Fernández imposed heavy tariffs and quotas on exports of soy, wheat, and beef.
Some might counter that the holdout hedge funds that sued Argentina deserve no sympathy, either.
Many are called “vulture funds” because they bought the debt at a steep discount from the original creditors, hoping to profit subsequently through court decisions.
But the problem with the Argentine debt case has little to do with the moral failings of either the plaintiffs or the defendant.
The problem is the precedent that the case establishes for resolving future international debt crises.
The most common reaction to the recent rulings is pro-holdout.
After all, the judge is only enforcing the legal contract embodied in the original bonds, isn’t he?
As President Calvin Coolidge supposedly said of the American loans to the World War I allies, “They hired the money, didn’t they?”
If only the world were so simple.
If only a regime of consistent enforcement of all loan contracts’ explicit terms were sufficiently practical to be worth pursuing.
But we have long since recognized the need for procedures to rewrite the terms of debt contracts under extreme circumstances.
The British Joint Stock Companies Act of 1856, for example, established the principle of limited liability for corporations.
Indentured servitude and debtors’ prisons have also been illegal since the nineteenth century.
And individuals and corporations can declare bankruptcy.
There will always be times when it is impossible for a debtor to pay.
As for corporate bankruptcy, it is recognized that a poor legal system is one that keeps otherwise viable factories shuttered while assets are frittered away in expensive legal wrangling, leaving everyone – managers, workers, and shareholders – worse off.
A good legal system permits employment and production to continue in cases where the economic activity is still viable; divides up the remaining assets in an orderly and generally accepted way; and makes these determinations as efficiently and speedily as possible, while discouraging future carelessness by imposing costs on managers, shareholders, and – if necessary – creditors.
No such body of law exists at the international level.
Some believe that this vacuum is the primary difficulty with the international debt system.
Ambitious proposals to redress it, such as a Sovereign Debt Restructuring Mechanism (SDRM) housed at the International Monetary Fund, have always run into political roadblocks.
But incremental steps had been slowly moving the system in the right direction since the 1980s.
In the international debt crisis that began in 1982, IMF country adjustment programs went hand in hand with “bailing in” creditor banks through “voluntary” coordinated loan rollovers.
Eventually, it was recognized that a debt overhang was inhibiting investment and growth in Latin America, to the detriment of debtors and creditors alike.
Subsequent programs to deal with emerging-market crises featured an analogous combination of country adjustment and “private sector involvement.”
Voluntary debt exchanges worked, roughly speaking, with investors accepting haircuts.
After Argentina’s unilateral default in 2001, many investors saw more clearly the need to allow explicitly for less drastic alternatives ahead of time, and so incorporated so-called “collective action clauses” into debt contracts.
If the borrower runs into trouble, CACs make it possible to restructure debt with the agreement of a substantial majority of creditors (usually around 70%).
The minority is then bound by the agreement.
Such incremental steps gave rise to a loose system of debt restructuring.
To be sure, it still had many deficiencies.
Restructuring often came too late and provided too little relief to restore debt sustainability.
But it worked, more or less.
By contrast, the US court rulings’ indulgence of a parochial instinct to enforce written contracts will undermine the possibility of negotiated re-structuring in future debt crises.
Time will run out for Argentina at the end of July.
Unable to pay all of its debts, perhaps it will be forced to default on all of them.
The more likely outcome is that it will manage to come to some accommodation that the holdouts find more attractive than the deal accepted by the other creditors.
Either way, future voluntary debt-workout agreements have just become more difficult to reach, which will leave debtors and creditors alike worse off.
The Subsidy Trap
CAMBRIDGE – Few policies place good economics so directly at odds with good politics as subsidies for food and energy.
The issue of unaffordable subsidies is now front and center for three of the world’s most important new leaders: Egyptian President Abdel Fattah el-Sisi, Indonesian President-elect Joko “Jokowi” Widodo, and Indian Prime Minister Narendra Modi.
Sisi is confronting the need to cut subsidies better than might have been expected.
Modi, by contrast, is doing worse than expected – even torpedoing a long-anticipated Word Trade Organization agreement.
With Jokowi, it is too soon to tell.
In July, Sisi accomplished what few leaders in North Africa or the Middle East have: he sharply cut longstanding fuel subsidies and allowed prices to rise by 41-78%.
Surprisingly, few protests materialized.
Egypt’s food subsidy program, which costs more than $5 billion a year, is in urgent need of reform as well.
The price of bread has been kept so low that it is often fed to animals.
Past attempts to reduce such subsidies in North African countries have brought unrest and even toppled governments.
But the Sisi government appears to be making progress here as well.
Bread subsidies have already been cut by 13%.
Sisi had little choice.
Even with subsidy cuts, the current government is targeting a budget deficit of 10% of GDP in the coming fiscal year (compared to 14% otherwise).
Still, few expected Sisi, who took office in a fragile political environment, to move faster than Modi, who was elected with a whopping democratic majority amid hopes for sweeping economic reform.
In Indonesia, when Jokowi takes office in October, he will inherit a long history of fuel subsidies that, at $21 billion a year (up to 20% of government spending), the country can no longer afford.
Outgoing President Susilo Bambang Yudhoyono took a first courageous step by raising fuel prices a year ago.
Jokowi’s advisers favor cutting the remaining subsidies, and he has already forthrightly said that he plans to do so gradually, over a four-year period.
Economists feel confident in opposing commodity subsidies because agricultural and energy markets tend to approach the ideal of perfect competition, with a large number of consumers on the demand side and producers on the supply side.
Where competition is imperfect, government, not large private monopolies, is usually the reason.
Critics of the invisible hand point out that, left to themselves, private markets can fail in a number of ways.
For example, income inequality and environmental externalities are two of the most prominent justifications for government intervention.
What is striking about food and fossil-fuel subsidies is that they are often promoted in the name of the environment or equity, but usually do little to achieve these goals, and often have the opposite effect.
Less than 20% of Egyptian food subsidies benefit poor people.
Gasoline subsidies in most countries benefit the middle class, while the poor walk or take public transportation.
In India, less than 0.1% of rural subsidies for Liquefied Petroleum Gas go to the poorest quintile, while 52.6% go to the wealthiest.
Worldwide, far less than 20% of fossil-fuel subsidies benefit the poorest 20% of the population.
Food and energy subsidies can also distort public policy, as Modi’s government, seeking to protect India’s agricultural subsidies, has shown.
Indeed, its veto of a WTO compromise has derailed the most important progress in multilateral trade negotiations of the last ten years.
Agricultural subsidies sometimes seek to benefit consumers at the expense of producers, especially in poor countries, and sometimes seek to benefit producers at the expense of consumers, especially in rich countries.
India’s policies try to do both.
As a result, India has accomplished the extraordinary feat of rationing grain to consumers at artificially low prices, while simultaneously suffering excess supply, because farmers are paid high prices.
(Farmers are also subsidized via agricultural inputs – electricity, water, and fertilizer – to the detriment of the environment.)
The government has purchased huge stockpiles of rotting rice and wheat, while the limited amount available to consumers is allocated in ways that are corrupt and inconsistent with the stated goal of helping the poor.
The government would like to keep its subsidies and stockpiles.
But it knows that this would violate WTO rules.
Unable to obtain a permanent change in these rules, Modi vetoed the WTO’s eagerly anticipated Trade Facilitation Agreement.
Once subsidies are in place, they are extraordinarily difficult to remove.
When world commodity prices rise, as they often have over the last decade, citizens who are accustomed to the domestic price being set in the market are more likely to accept the reality that officials cannot insulate them from the shock.
But people who are accustomed to administratively established food and energy prices hold the government responsible.
That is a strong reason not to adopt such subsidies in the first place.
But it does not necessarily mean that, once subsidies are in place, keeping them is a savvy politician’s best option.
If the alternative to raising the price is shortages or rationing, angry protesters may mobilize anyway.
Similarly, the procrastinating leader is unlikely to benefit if ever-widening gaps force an even bigger retail-price rise when the day of reckoning comes.
Ideally, other, more efficient means of supporting incomes at the bottom will be instituted at the same time that food and energy subsidies are cut.
Developing countries have learned a lot about efficient transfer mechanisms, from policy innovations, such as the conditional cash transfers of Mexico’s Progresa-Oportunidades program or Brazil’s Bolsa Família, and from technological innovations such as India’s Unique Identification system.
But in countries where the adjustment does not come until a budget crisis forces it, there may be no money for transfers to cushion the pain.
The savvy politician should probably announce the unpleasant adjustment as soon as he takes office.
Jokowi and Sisi seem to have adopted this approach.
Modi, despite his huge electoral mandate and hype about market reforms, has fallen short.
Why the ECB Should Buy American
CAMBRIDGE – The European Central Bank needs to ease monetary policy further.
Eurozone-wide inflation, at 0.8%, is below the target of “close to 2%,” and unemployment in most countries remains high.
Under current conditions, it is hard for the periphery countries to reduce their costs to internationally competitive levels, as they need to do.
If inflation in the eurozone as a whole is below 1%, the periphery countries are condemned to suffer painful deflation.
The question is how the ECB can ease policy, given that short-term interest rates are already close to zero. Most of the talk in Europe concerns proposals to undertake quantitative easing (QE), following the path taken by the US Federal Reserve and the Bank of Japan.
This would mean expanding the money supply by buying member countries’ government bonds – a realization of ECB President Mario Draghi’s “outright monetary transactions” scheme, announced in August 2012 in the midst of growing uncertainty about the euro’s future (but never used since then).
But QE would present a problem for the ECB that the Fed and other central banks do not face.
The eurozone has no centrally issued and traded Eurobond that the central bank could buy.
(And the time to create such a bond has not yet come.)
By purchasing bonds of member countries, the ECB would be taking implicit positions on their individual creditworthiness.
That idea is not popular with the eurozone’s creditor countries.
In Germany, ECB purchases of bonds issued by Greece and other periphery countries are widely thought to constitute monetary financing of profligate governments, in violation of the treaty under which the ECB was established.
The German Constitutional Court believes that the OMT scheme exceeds the ECB’s mandate, though it has temporarily tossed that political hot potato to the European Court of Justice.
The legal obstacle is not merely an inconvenience; it also represents a valid economic concern about the moral hazard that ECB bailouts present for members’ fiscal policies in the long term.
That moral hazard – a subsidy for fiscal irresponsibility – was among the origins of the Greek crisis in the first place.
Fortunately, interest rates on Greek and other periphery-country debt have fallen sharply over the last two years.
Since he took the helm at the ECB, Draghi has brilliantly walked the fine line required to “do whatever it takes” to keep the eurozone intact.
(After all, there would be little point in upholding pristine principles if doing so resulted in a breakup, and fiscal austerity alone was never going to return the periphery countries to sustainable debt paths.)
At the moment, there is no need to support periphery-country bonds, especially if it would flirt with illegality.
What, then, should the ECB buy if it is to expand the monetary base?
For several reasons, it should buy US treasury securities.
In other words, it should go back to intervening in the foreign-exchange market.
For starters, there would be no legal obstacles.
Operations in the foreign-exchange market are well within the ECB’s remit.
Moreover, they do not pose moral-hazard issues (unless one thinks of the long-term moral hazard that the “exorbitant privilege” of printing the world’s international currency creates for US fiscal policy).
Finally, ECB purchases of dollars would help push down the euro’s exchange rate against the dollar.
Such foreign-exchange operations among G-7 central banks have fallen into disuse in recent years, partly owing to the theory that they do not affect exchange rates except when they change money supplies.
But in this case we are talking about an ECB purchase of dollars that would change the euro money supply.
The increase in the supply of euros would naturally lower their price.
Monetary expansion that depreciates the currency is more effective than monetary expansion that does not, especially when, as is the case now, there is very little scope for pushing short-term interest rates much lower.
Depreciation of the euro would be the best medicine for restoring international price competitiveness to the periphery countries and reviving their export sectors.
Of course, they would devalue on their own had they not given up their currencies for the euro ten years before the crisis (and if it were not for their euro-denominated debt).
If abandoning the euro is not the answer, depreciation by the entire eurozone is.
The euro’s exchange rate has held up remarkably during the four years of crisis.
Indeed, the currency appreciated further when the ECB declined to undertake any monetary stimulus at its March 6 meeting.
Thus, the euro could afford to weaken substantially.
Even Germans might warm up to easy money if it meant more exports.
Central banks should and do choose their monetary policies primarily to serve their own economies’ interests.
But proposals to coordinate policies internationally for mutual benefit are fair.
Raghuram Rajan, the governor of the Reserve Bank of India, has recently called for the advanced economies’ central banks to take emerging-market countries’ interests into account via international cooperation.
ECB foreign-exchange intervention would fare well in this regard.
This year, the emerging economies are worried about a tightening of global monetary policy, not the policy loosening that three years ago fueled talk of “currency wars.”
As the Fed tapers its purchases of long-term assets, including US treasury securities, it is a perfect time for the ECB to step in and buy some itself.
Britain’s Populist Fantasies
LONDON – The election of Jeremy Corbyn as the new leader of the British Labour Party is a reminder that life is rich with paradox.
Globalization – the web of travel, technology, trade, and information that binds the world ever more closely together – is hardly a new phenomenon.
But politics in many developed democracies has lately been disrupted by populist insurgencies seeking to exit this shared reality.
What these groups do not seem to recognize is that the alternative they wish for is a fantasy.
From Syriza in Greece to the National Front in France, voters across Europe are being encouraged to believe in a virtual reality shaped by prejudice and uninformed nostalgia.
In the United States, this mood first emerged several years ago, fueling the rise of the Tea Party and now enabling the splenetic presidential campaigns of Donald Trump and other Republican candidates who promise to seal America off from the twenty-first century.
(The promise is to some extent literal: By building walls along the country’s northern and southern borders, the candidates would defend the American dream from outside contamination.)
The United Kingdom is the latest victim of this fantasy-driven populism.
On the right, we have already suffered the rise of the anti-European, anti-immigrant UK Independence Party, led by the cigarette-smoking, beer-swilling joker Nigel Farage, in whom Britain has found its own version of Silvio Berlusconi, if you can imagine such a thing.
Now the British left has embraced a similar folly.
The Labour Party’s defeat in May’s general election brought about the resignation of its leader, Ed Miliband, a courteous and intelligent figure who, having abandoned the middle ground once controlled by former Prime Minister Tony Blair, had failed to convince even his own party that he could run the country.
The campaign to choose his successor proceeded throughout the summer.
On the whole, the search was a pretty dismal business.
Three respectable, if uninspiring, former ministers vied for the position, but struggled to find a compelling message that connected the party of the left with modern Britain.
Unsure of the right approach, they wavered somewhere between moderation and left-wing nonsense.
Such indecisiveness was not a problem for Corbyn, whose principal distinction in more than three decades in parliament has been voting against his own party more than 500 times on the grounds that its proposals were not socialist enough.
In fact, Corbyn made it onto the ballot only because a few MPs wanted to show that the Labour Party welcomed debate.
But his passionate advocacy of old-fashioned socialism quickly caught on, breathing new life – and drawing tens of thousands of new members – into a party that had been losing adherents in droves.
So what exactly are Corbyn’s proposals?
At home, he would nationalize industries, especially in energy, and raise taxes, especially on business and the wealthy.
Any semblance of fiscal prudence would go out the window, with cuts in health, welfare, and education spending being reversed.
Trade unions would regain the power they enjoyed before Margaret Thatcher’s reforms in the 1980s.
And public-sector workers would become the principal beneficiaries of the country’s spending programs.
In foreign policy, Corbyn would slash defense spending and abandon the UK’s nuclear deterrent.
He would blame virtually anything that went wrong in the world on America, which is, in his view, morally equivalent to Russia.
If a leader like the late Hugo Chávez, the architect of Venezuela’s “socialist revolution,” emerges, Corbyn would probably be on the next plane to meet him.
Despite his radical views, Corbyn won the battle to lead Labour – and hence Britain’s parliamentary opposition, with nearly 60% of the vote.
But Labour will not win a general election under Corbyn – a reality that has caused some Conservatives to respond to his victory as though they had won the lottery.
In my view, however, no good will come from this insurrection for anyone.
First, Corbyn will not be swept out of his job by an early display of public distaste and hostility.
On the contrary, at the outset, he may be able to galvanize many alienated young voters against a government that has earned wary respect but is not much liked.
Second, without effective and responsible opposition, governments can become arrogant, careless, and too focused on their own supporters.
In this case, leaders of the Conservative Party’s far-right component are likely to think that they can dispense with offering disciplined support to Prime Minister David Cameron and his policies, because Labour can never win under Corbyn, anyway.
Third, at some time over the next year, the UK will face a referendum over its membership in the European Union.
While no one knows the position Corbyn will take on this issue, one can speculate that he, like some of the trade-union bosses who support him, might decide that the EU is a rich man’s club, thereby precluding the much-needed cross-party consensus in favor of continued membership.
Fourth, Corbyn, who shares many of the political views of the Scottish nationalists, will make it more difficult to manage the question of Scotland’s place in the UK.
Making common cause with the nationalists in policy matters will complicate the question of how best to deal with their constitutional aspirations.
Fifth, there is a danger that the Conservative government, faced with irrational populist forces on both the left and the right, will shrink from its duty to stand up for good values and good sense.
But it is vital that, amid all the make-believe, there are still those who hammer home the simple truth that, no matter how much people wish for it, a country cannot decide simply to stop the world and get off.
Corbyn’s election underscores how many Britons are refusing to accept reality.
It is up to Cameron to end their dangerous reverie.
Taking Corbynomics Seriously
LONDON – Fiscal austerity has become such a staple of conventional wisdom in the United Kingdom that anyone in public life who challenges it is written off as a dangerous leftist.
Jeremy Corbyn, the current favorite to become the next leader of Britain’s Labour Party, is the latest victim of this chorus of disparagement.
Some of his positions are untenable.
But his remarks on economic policy are not foolish, and deserve proper scrutiny.
Corbyn has proposed two alternatives to the UK’s current policy of austerity: a National Investment Bank, to be capitalized by canceling private-sector tax relief and subsidies; and what he calls “people’s quantitative easing” – in a nutshell, an infrastructure program that the government finances by borrowing money from the Bank of England.
The first idea is neither extreme nor new.
There is a European Investment Bank, a Nordic Investment Bank, and many others, all capitalized by states or groups of states for the purpose of financing mandated projects by borrowing in the capital markets.
The rationale for this type of institution derives from what that great socialist theorist Adam Smith called the state’s responsibility for the “erection and maintenance” of those “public works and institutions,” which, while of great advantage to society, would not profit private enterprise.
In other words, the state should always have an investment function.
Delegating that function to a dedicated institution may have advantages for the presentation of the public accounts.
Today’s particular economic circumstances provide a second reason for establishing a National Investment Bank.
In slump or even semi-slump conditions, a higher-than-normal proportion of private savings are held in cash or its nearest equivalent (short-term treasury bills).
A National Investment Bank could draw out these “idle savings” by issuing bonds for infrastructure development.
Offering a small premium on government securities, such bonds would likely attract long-term investors like pension funds, which otherwise face zero or even negative real returns.
For example, with a fiscal outlay of €21 billion ($23.3 billion), the European Investment Bank is set to finance investments worth at least €315 billion by 2017.
“People’s quantitative easing” is a more unorthodox – and a more interesting – version of this idea.
Under conventional quantitative easing (QE), the central bank buys government securities from banks or corporations and relies on the extra cash that it “prints” to stimulate private spending.
But studies suggest that much of this money goes into speculative activity, risking asset bubbles, rather than being channeled into productive investment.
An alternative would be to distribute the central bank’s newly issued money directly to housing associations, local councils, or national or regional investment banks – any organization that could carry out infrastructure projects.
This is what Corbyn proposes.
This idea of monetary financing of fiscal deficits (borrowing from the central bank, rather than from the bond markets) has a reputable pedigree.
In a lecture to the Cass Business School in February 2012, Adair Turner, former Chairman of the UK Financial Services Authority, proposed it as an option if further borrowing from the markets were politically or financially impossible.
Corbyn’s proposal, unlike orthodox monetary financing, would not add to the national debt – a major advantage.
Orthodox QE – let’s call it “monetization one” – is intended to be reversed, with taxation used to raise the money to redeem the government bonds held by the central bank.
The expectation of future tax hikes could drive people to save part of the new money, rather than spend it.
Unorthodox QE (“monetization two”) avoids this problem, because the central bank’s borrowing will not be repaid; central-bank assets net out against government liabilities.
That is why it should not be excluded a priori.
There is a strong case for monetization two in the eurozone, which faces zero growth and deflation.
Indeed, while the QE program unveiled by the European Central Bank in January consists mainly of sovereign-debt purchases, the ECB will also buy debt issued by the European Commission and the European Investment Bank – key elements of monetization two.
It will thus help to finance infrastructure investment.
But it is hardly the case that the UK economy, currently growing at close to 3% a year, needs a further QE program of any kind right now.
The government can borrow all it wants from the bond markets at near-zero interest rates.
Outsourcing such borrowing power to a National Investment Bank is merely a way to signal that any additional borrowing will be used for investment, not for current spending.
There are two solid arguments for activating such an institution in the UK today.
First, the share of private investment in GDP is still below its pre-crash level of around 11% of GDP.
This suggests that investors lack confidence in the durability of the recovery.
Second, depending on the institution’s mandate, a state-led investment program offers a way to rebalance the British economy away from private speculative activity to long-term investment in sustainable growth, and away from the south-east to the midlands and the north of England.
In short, it offers a way to address the problem of “private affluence and public squalor” that John Kenneth Galbraith identified in the 1950s.
Corbyn should be praised, not castigated, for bringing to public attention these serious issues concerning the role of the state and the best ways to finance its activities.
The fact that he is dismissed for doing so illustrates the dangerous complacency of today’s political elites.
Millions in Europe rightly feel that the current economic order fails to serve their interests.
What will they do if their protests are simply ignored?
Jeremy Lin and the Political Economy of Superstars
CAMBRIDGE – The biggest news around Cambridge in recent weeks has been Jeremy Lin, the Harvard economics graduate who has shocked the National Basketball Association by rising overnight from “nowhere” to become a genuine star, leading a losing New York Knicks team to an unlikely string of victories.
Lin’s success is delicious, partly because it contradicts so many cultural prejudices about Asian-American athletes.
Flabbergasted experts who overlooked Lin have been saying things like “he just didn’t look the part.”
Lin’s obvious integrity and graciousness has won him fans outside the sport as well.
The whole world has taken note, with Lin being featured on the cover of Sports Illustrated for two consecutive issues. The NBA, which has been trying to build brand recognition and interest in China, is thrilled.
I confess to being a huge Lin fan.
Indeed, my teenage son has been idolizing Lin’s skills and work ethic ever since Lin starred on the Harvard team.
But, as an economist observing the public’s seething anger over the “one percenters,” or individuals with exceptionally high incomes, I also see a different, overlooked facet of the story.
What amazes me is the public’s blasé acceptance of the salaries of sports stars, compared to its low regard for superstars in business and finance.
Half of all NBA players’ annual salaries exceed $2 million, more than five times the threshold for the top 1% of household incomes in the United States.
Because long-time superstars like Kobe Bryant earn upwards of $25 million a year, the average annual NBA salary is more than $5 million.
Indeed, Lin’s salary, at $800,000, is the NBA’s “minimum wage” for a second-season player.
Presumably, Lin will soon be earning much more, and fans will applaud.
Yet many of these same fans would almost surely argue that CEOs of Fortune 500 companies, whose median compensation is around $10 million, are ridiculously overpaid.
If a star basketball player reacts a split-second faster than his competitors, no one has a problem with his earning more for every game than five factory workers do in a year.
But if, say, a financial trader or a corporate executive is paid a fortune for being a shade faster than competitors, the public suspects that he or she is undeserving or, worse, a thief.
Economists have long studied the economics of superstars in fields where a company can lever enormously the decisions of a small number of individuals, making them valuable in a way that someone who can, say, chop down trees like the legendary Paul Bunyan, is not.
But the political economy of what levels of income differences countries will tolerate remains uncharted territory.
Of course, there is a certain logic to the public’s disdain for superstar compensation outside of professional sports and entertainment.
This is especially the case in some areas of finance that are essentially zero-sum games, in which one person’s gain is another’s loss.
There are other areas, such as technology, in which someone like Apple’s late founder, Steve Jobs, arguably delivers real innovation and quality, rather than just employing lawyers and lobbyists to maintain a monopoly position.
As a basketball fan, I would not describe the sport as a zero-sum game, even though one team wins and one team loses. The best players have huge creative flair.
But so do some “street ball” players who excel in slam-dunk theatrics; perhaps because they are not tall enough to compete, they make almost nothing.
Do fans tolerate outsize sports incomes because players are role models?
Many certainly are, but not all high-paid sports celebrities are exemplary citizens.
Michael Vick, a star quarterback in the US National Football League, served time in prison for running a vicious dog-fighting operation, and arrests of players on charges ranging from illegal possession of drugs and weapons to domestic battery have been a regular occurrence.
And, back on the field or court, serious infractions occur all the time.
Think of Zinedine Zidane’s infamous head butt in the 2006 football World Cup.
In the NBA itself, a star player, Ron Artest, was suspended for the remainder of the 2004 season after going into the stands and brawling with heckling fans during a game. (Artest has now changed his name to Metta World Peace, perhaps in response.)
Moreover, sports teams surely lobby governments as aggressively as any big business.
Professional sport is a legislated monopoly in most countries, with top teams extracting free stadiums and other privileges from host cities.
Indeed, Lin’s story, it should be remembered, grew out of a huge labor dispute between the NBA’s billionaire owners and its millionaire players over division of the league’s nearly $4 billion in annual revenues – more than many countries’ national income.
As the late University of Chicago economist Sherwin Rosen postulated, globalization and changing communication technologies have increasingly made the economics of superstars important in a variety of fields.
That is certainly true in sports and entertainment, but it is also the case in business and finance.
I wish Lin a long and successful career as a superstar, though he will have already had a huge cultural impact even if his success proves meteoric.
One can hope that, as Asian-Americans continue to break barriers in other arenas – they remain under-represented among corporate CEOs, for example – these rising superstars will be greeted with similar acclaim.
If the public is not happy about high superstar incomes, the obvious remedy is to improve the tax system, including for powerful sports-team owners, many of whom benefit from huge tax breaks in their day jobs. Who knows?
With a more level playing field, superstars outside sports and entertainment might find themselves a bit better appreciated.
Jihad or Murder?
It is remarkable that some of the most critical concepts of Muslim religious terminology have now become part of the international language of current affairs.
Questions drawn from Islamic theology are discussed freely by the world public, engaging specialists and non-specialists, Muslims and non-Muslims.
Theological disputation has moved far from Islam’s religious academies.
For example, the term jihad, commonly translated as “holy war,” has become nearly ubiquitous.
Though conceived in early Muslim history as a means of spreading God’s word, Muslim scholars today distinguish between two kinds of jihad – one being an internal struggle against temptation, and the other a physical conflict against an aggressor who threatens the survival or the fundamental rights of a Muslim community.
In this context, there is widespread rejection of the fundamentalists’ use of the term. 
Numerous Muslim scholars have raised their voices to challenge the terrorists’ defense of suicide bombings or attacks on civilians, offering long citations from centuries of religious jurisprudence.
In itself, this approach represents a worthy expression of collective conscience in opposition to the terrorists. 
But many among the public and in the media want more.
Muslim intellectuals are being encouraged to press the religious argument against fundamentalist violence in order to deprive the terrorists of their most fearsome and potent arguments.
If Muslim scholars can somehow disprove these arguments, it is thought, then the terrorists’ ability to sustain their violent underground will be reduced.
Is this right?
A quick survey of the history of religious conflict shows that theological controversies have never been resolved by theological arguments.
Looking more closely, one finds that while these controversies were often framed in religious terms, they were not at all about religion.
The range of opposing interpretations of religious texts is virtually unlimited, and disputes are seldom resolved by rational argument.
In earlier times, such controversies were decided by political authorities, which used military force to impose one particular point of view at the expense of all others.
Muslim history is full of such cases.
Recently, when Saddam Hussein invaded Kuwait, he found scholars who raised theological arguments on his behalf.
The coalition confronting him had no difficulty finding religious arguments that led to precisely the opposite conclusion.
Today, it is clear that fundamentalists and their supporters are completely closed off to even the most elaborate theological refutation of their views, even when produced by distinguished religious authorities.
The first reflex of the fundamentalists is to withdraw from the mainstream, to build around themselves a shell that is impervious to any logic other than their own.
The most essential questions that humans face today – those that engender the deepest conflicts – have nothing to do with theology.
They concern disputes over territory, political power, definitions of rights, and distribution of wealth.
The means of discussing these questions is known to all and is expressed in all religions and all languages.
The evils most deeply resented – in all societies – are injustice, despotism, corruption, and poverty.
We all understand what these mean, and how certain people must live with them on a daily basis.
Why, then, do we follow the fundamentalists to the very heart of their madness?
Allowing them to frame these problems in religious terms legitimizes the perspective that they are attempting to impose, particularly in their own societies.It also allows them to camouflage their very worldly thirst for power.
Repeatedly, the Muslim religious establishment has been urged to issue statements denying fundamentalists the right to use religious terms like jihad.
But experience has proven that this approach leads nowhere.
In fact, debates about the use of religious terms lend credibility to fundamentalist efforts to apply these ideas to conditions in the modern world.
Such debates concede that these religious concepts are generally valid, even when, as in the fundamentalists’ case, they simply do not apply.
As a result, the entire discussion could easily backfire.
Invariably, fundamentalists dismiss religious critiques of their views as evidence that religious authorities have been corrupted by hostile influences.
In this way, the terrorists oppose the “purity” and “authenticity” of their arguments to the compromises presumably forced upon religious establishments.
Speaking to Muslims exclusively in their own religious terms also excludes them from broad ethical frameworks that defend essential human values, most notably the protection of innocent civilians.
These values are the foundation upon which all religious and cultural traditions rest.
To be sure, it is important to understand the discourse of those who are making war on societies – their own societies first and foremost.
But adopting the terrorists’ interpretation of events conceals the reality of this conflict.
Instead of fighting on behalf of political and religious liberty, we risk engaging in a conflict with the false images that the terrorists have created.
Worse still, we would bring this conflict into our own societies, where different religious and cultural traditions are now inextricably mingled.
There is simply no need to look to theology to call a crime by its proper name.
The revulsion provoked by the murder of innocents is deeply felt by all, and it is reprehensible by any standard, religious or not.
It may even be that religious language does not adequately express the repulsion we all feel toward the terrorists’ actions.
No feeling of victimhood can justify, under any conditions, such crimes against innocents, and no theology can accept the negation of the human essence that we all share.
Big Data for Poor Students
WASHINGTON, DC – Countries need skilled and talented people to generate the innovations that underpin long-term economic growth.
This is as true in developed as it is in developing economies.
But it will not happen without investment in education and training.
If we are to end poverty, reduce unemployment, and stem rising economic inequality, we must find new, better, and cheaper ways to teach – and on a vast scale.
This goal may seem to be beyond even wealthier countries’ means; but the intelligent collection, analysis, and use of educational data could make a big difference.
And, fortunately, we live in an age in which information technology gives us the right tools to broaden access to high-quality, affordable education.
Big data – high-volume, complex data sets that businesses use to analyze and predict consumer behavior – can provide teachers and companies with unprecedented amounts of information about student learning patterns, helping schools to personalize instruction in increasingly sophisticated ways.
The World Bank Group and its private-sector lending arm, the International Finance Corporation (IFC), are trying to harness this potential to support national education systems.
A recently launched initiative, called the Systems Approach for Better Education Results (SABER), collects and shares comparative data on educational policies and institutions from countries around the world.
In the private sector, the ability to collect information about teacher-student interaction, and interaction between students and learning systems, can have a profound impact.
In Kenya, for example, Bridge International Academies is using adaptive learning on a large scale.
An IFC client founded by three American entrepreneurs, Bridge runs 259 nursery and primary schools, with monthly tuition averaging $6.
It is a massive learning laboratory for students and educators alike.
Bridge tests different approaches to teaching standard skills and concepts by deploying two versions of a lesson at the same time in a large number of classrooms.
The lessons are delivered by teachers from standardized, scripted plans, via tablets that also track how long the teachers spend on each lesson.
Exam results are recorded on the teacher’s tablet, with more than 250,000 scores logged every 21 days.
From these data, Bridge’s evaluation team determines which lesson is most effective and distributes that lesson throughout the rest of the Academy’s network.
We know that a host of issues can cause a student’s performance to decline – scorching summer heat in classrooms without air conditioning, problems at home, or poor-quality teachers, to name a few.
But when one gathers results on a large scale, variables flatten out, and the important differences emerge.
That is the great value of big data.
Another case is SABIS, a provider of K-12 education in the United States, Europe, Asia, the Middle East, and North Africa.
SABIS mines large data sets to ensure high standards and enhance academic performance for more than 63,000 students.
Continuous tracking of annual student academic performance yields more than 14 million data points that are used to shape instruction, achieve learning objectives, and ensure consistency across the company’s network of schools in 15 countries.
Knewton, an adaptive learning platform that personalizes digital courses using predictive analytics, is another company at the forefront of the data revolution.
With tailored content and instruction, even classrooms without private-school resources can provide individual learning.
As a result, teachers spend their time in the most effective way possible – solving problems with students – instead of delivering undifferentiated lessons.
These benefits do not come without risk.
We are only beginning to grapple with how big data’s tremendous potential for learning can be harnessed while protecting students’ privacy.
In some cases, data-collection technology is outpacing our ability to decide how it should be collected, stored, and shared.
No matter how rigorously data are secured, there is still a need for a clear licensing structure for its use.
In many developing countries, there are no regulations for data privacy at all.
The interface between data and education holds the promise of new educational products for improved learning, with large potential benefits, especially for the poor.
To realize those benefits – and to do so responsibly – we must ensure that data collection is neither excessive nor inappropriate, and that it supports learning.
The private sector, governments, and institutions such as the World Bank Group need to formulate rules for how critical information on student performance is gathered, shared, and used.
Parents and students deserve no less.
From War to Work (Transisi Pasca-Konflik)
OXFORD – Jelas sekali bahwa konflik menghasilkan banyak efek negatif yang berdampak luas, terutama pada pekerjaan.
Namun pemahaman yang berlaku mengenai kaitan antara konflik dan pekerjaan tidak sepenuhnya mengakui kerumitan hubungan tersebut – sebuah kelemahan yang meremehkan kebijakan ketenagakerjaan yang efektif di negara-negara rentan.
Kebijaksanaan konvensional yang berlaku adalah konflik memusnahkan lapangan kerja.
Selain itu, sebab pengangguran bisa memacu lebih banyak konflik, ketika pemuda pengangguran mendapat pengakuan dan ganjaran ekonomis dari tindak kekerasan, penciptaan lapangan kerja harus menjadi bagian pokok dalam kebijakan pasca-konflik.
Tapi, meski asumsi-asumsi tersebut jelas terdengar logis, seperti saya uraikan dalam sebuah makalah yang diterbitkan tahun 2015, mereka tidak sepenuhnya akurat.
Asumsi pertama – bahwa konflik kekerasan memusnahkan lapangan kerja – mengabaikan fakta bahwa setiap konflik itu unik.
Beberapa konflik, seperti perang saudara di Sri Lanka tahun 2008-2009, terpusat di daerah yang relatif kecil, sehingga sebagian besar wilayah negara – dan perekonomiannya – tidak terkena dampak.
Bahkan konflik-konflik endemik, seperti konflik yang berulang di Kongo, belum tentu berpengaruh besar pada net employment.
Bagaimanapun juga, pekerjaan yang hilang, misalnya di sektor publik atau pengekspor komoditas dapat diimbangi (offset) dengan lapangan kerja baru di pemerintahan dan pemberontak bersenjata, produksi informal menggantikan impor, dan tindakan ilegal seperti produksi obat-obatan terlarang dan penyelundupan.
Sama halnya, asumsi kedua – bahwa pengangguran adalah penyebab utama konflik kekerasan – juga tidak memperhitungkan perbedaan krusial.
Pertama, sektor formal hanya berkontribusi sedikit pada total pekerjaan di mayoritas negara yang dilanda konflik.
Mayoritas warga bekerja di sektor informal, umumnya melakukan pekerjaan dengan status, produktivitas, dan pendapatan rendah yang bisa mengarah pada ketidakpuasan dan mendorong pemuda mengikuti gerakan-gerakan penuh kekerasan, sama seperti efek pengangguran.