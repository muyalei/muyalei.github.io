This was a story not of a “bubble”; rather, the boom was a triumph of capitalist enterprise in a new millennium.
These stories were so powerful because a huge number of people were psychologically – and financially – invested in them.
Most families owned a house, so they were automatically participating in the boom.
And many homeowners, eager to participate even more in the boom and feel like savvy capitalists, bought more expensive houses than they normally would.
With the abrupt end of the boom in 2006, that ego-boosting story also ended.
We were not all investing geniuses after all.
It was just a bubble, we learned.
Our confidence in ourselves, and hence in our futures, took a hit, discouraging economic risk-taking.
Then the financial crisis erupted, scaring the entire world.
A story of opportunity and riches turned into one of corrupt mortgage lenders, overleveraged financial institutions, dimwitted experts, and captured regulators.
The economy was careening like a rudderless ship, and the sharp operators who had duped us into getting on board – call them the 1% – were slipping away in the only lifeboats.
By early 2009, the plunge in stock markets around the world reached its nadir, and fear of a deep depression, according to the University of Michigan Consumer Sentiment Survey, was at its highest level since the second oil crisis in the early 1980’s.
Stories of the Great Depression of the 1930’s were recalled from our dimmest memories – or from our parents’ and grandparents’ memories – and retold.
To understand why economic recovery (if not that of the stock market) has remained so weak since 2009, we need to identify which stories have been affecting popular psychology.
One example is the rapid advance in smartphones and tablet computers.
Apple’s iPhone was launched in 2007, and Google’s Android phones in 2008, just as the crisis was beginning, but most of their growth has been since then. Apple’s iPad was launched in 2010.
Since then, these products have entered almost everyone’s consciousness; we see people using them everywhere – on the street and in hotel lobbies, restaurants, and airports.
This ought to be a confidence-boosting story: amazing technologies are emerging, sales are booming, and entrepreneurship is alive and very well.
But the confidence-boosting effect of the earlier real-estate boom was far more powerful, because it resonated directly with many more people.
This time, in fact, the smartphone/tablet story is associated with a sense of foreboding, for the wealth that these devices generate seems to be concentrated among a tiny number of tech entrepreneurs who probably live in a faraway country.
These stories awaken our fears of being overtaken by others on the economic ladder.
And now that our phones talk to us (Apple launched Siri, the artificial voice that answers your spoken questions, on its iPhones in 2010), they fuel dread that they can replace us, just as earlier waves of automation rendered much human capital obsolete.
I had the pleasure of meeting with Abe on this trip.
He sticks to the script, telling a story of taking aggressive and definitive action against an economic malaise that has plagued Japan for decades.
He inspires confidence; I felt it immediately.
Abe is also described as reviving national patriotism, even nationalism.
Though I heard none of this from him in my meeting, I think it may be a central part of his story, too.
Nationalism, after all, is intrinsically bound up with individual identity.
It creates a story for each member of the nation, a story about what he or she can do as part of a successful country.
Some of Abe’s most controversial steps, such as visiting the Yasukuni Shrine despite Chinese and Korean objections, only increase the story’s impact.
Still, it is not easy for national leaders, even those with Abe’s talents, to manage such stories, just as it is hard for film producers to make a blockbuster every time.
No leader can consistently shape the narratives that affect the economy.
But that does not rule out the need to try.
Booming Until It Hurts?
NEW HAVEN – In recent months, concern has intensified among the world’s financial experts and news media that overheated asset markets – real estate, equities, and long-term bonds – could lead to a major correction and another economic crisis.
The general public seems unbothered: Google Trends shows some pickup in the search term “stock market bubble,” but it is not at its peak 2007 levels, and “housing bubble” searches are relatively infrequent.
But the experts’ concern is notable and healthy, because the belief that markets are always efficient can survive only when some people do not completely believe it and think that they can profit by timing the markets.
At the same time, this heightened concern carries dangers, too, because we do not know whether it will lead to a public overreaction on the downside.
The words “nearly all” are too strong, though the headline evinces the newfound concern.
It is not entirely clear why the alarms are sounding just now, after five years of general expansion in markets since they hit bottom in early 2009.
Why aren’t people blithely expecting more years of expansion?
It seems that this thinking is heavily influenced by recent record highs in stock markets, even if these levels are practically meaningless, given inflation.
Notably, just a month ago the Morgan Stanley Capital International All Country World Index broke the record that it reached on October 31, 2007.
The International Monetary Fund announced in June a new Global Housing Watch website that tracks global home prices and ratios.
The site shows a global index for house prices that is rising, on a GDP-weighted basis, as fast as during the boom that preceded the 2008 crisis, though not yet reaching the 2006 record level.
There is also the US Federal Reserve’s announcement that, if the economy progresses as expected, the last bond purchase from the round of quantitative easing that it began in September 2012 will be in the month after the Federal Open Market Committee’s October 2014 meeting.
That kind of news story seems also to affect observers’ thinking, though it is not really much in the way of news, given that everyone has known that the Fed would end the program before long.
The problem is that there is no certain way to explain how people will react to such a policy change, to any signs of price overheating or decline, or to other news stories that might be spun as somehow important.
We simply do not have much well-documented history of big financial crises to examine, leaving econometricians vulnerable to serious error, despite studying time series that are typically no more than a few decades long.
Until the recent crisis, economists were talking up the “great moderation”: economic fluctuations were supposedly becoming milder, and many concluded that economic stabilization policy had reached new heights of effectiveness.
As of 2005, just before the onset of the financial crisis, the Harvard econometricians James Stock (now a member of President Barack Obama’s Council of Economic Advisers) and Mark Watson concluded that the advanced economies had become both less volatile and less correlated with each other over the course of the preceding 40 years.
That conclusion would have to be significantly modified in light of the data recorded since the financial crisis.
The economic slowdown in 2009, the worst year of the crisis, was nothing short of catastrophic.
In fact, we have had only three salient global crises in the last century: 1929-33, 1980-82, and 2007-9.
These events appear to be more than just larger versions of the more frequent small fluctuations that we often see, and that Stock and Watson analyzed.
But, with only three observations, it is hard to understand these events.
All seemed to have something to do with speculative price movements that surprised most observers and were never really explained, even years after the fact. They also had something to do with government policymakers’ mistakes.
For example, the 1980-82 crisis was triggered by an oil price spike caused by the Iran-Iraq war.
But all of them were related to asset-price bubbles that burst, leading to financial collapse.
Those who warn of grave dangers if speculative price increases are allowed to continue unimpeded are right to do so, even if they cannot prove that there is any cause for concern.
The warnings might help prevent the booms that we are now seeing from continuing much longer and becoming more dangerous.
Is Economics a Science?
NEW HAVEN – I am one of the winners of this year’s Nobel Memorial Prize in Economic Sciences, which makes me acutely aware of criticism of the prize by those who claim that economics – unlike chemistry, physics, or medicine, for which Nobel Prizes are also awarded – is not a science.
Are they right?
One problem with economics is that it is necessarily focused on policy, rather than discovery of fundamentals.
Nobody really cares much about economic data except as a guide to policy: economic phenomena do not have the same intrinsic fascination for us as the internal resonances of the atom or the functioning of the vesicles and other organelles of a living cell.
We judge economics by what it can produce.
As such, economics is rather more like engineering than physics, more practical than spiritual.
There is no Nobel Prize for engineering, though there should be.
True, the chemistry prize this year looks a bit like an engineering prize, because it was given to three researchers – Martin Karplus, Michael Levitt, and Arieh Warshel – “for the development of multiscale models of complex chemical systems” that underlie the computer programs that make nuclear magnetic resonance hardware work.
But the Nobel Foundation is forced to look at much more such practical, applied material when it considers the economics prize.
The problem is that once we focus on economic policy, much that is not science comes into play.
Politics becomes involved, and political posturing is amply rewarded by public attention.
The Nobel Prize is designed to reward those who do not play tricks for attention, and who, in their sincere pursuit of the truth, might otherwise be slighted.
Why is it called a prize in “economic sciences,” rather than just “economics”?
The other prizes are not awarded in the “chemical sciences” or the “physical sciences.”
Fields of endeavor that use “science” in their titles tend to be those that get masses of people emotionally involved and in which crackpots seem to have some purchase on public opinion. These fields have “science” in their names to distinguish them from their disreputable cousins.
The term political science first became popular in the late eighteenth century to distinguish it from all the partisan tracts whose purpose was to gain votes and influence rather than pursue the truth.
Astronomical science was a common term in the late nineteenth century, to distinguish it from astrology and the study of ancient myths about the constellations.
Hypnotic science was also used in the nineteenth century to distinguish the scientific study of hypnotism from witchcraft or religious transcendentalism.
There was a need for such terms back then, because their crackpot counterparts held much greater sway in general discourse. Scientists had to announce themselves as scientists.
In fact, even the term chemical science enjoyed some popularity in the nineteenth century – a time when the field sought to distinguish itself from alchemy and the promotion of quack nostrums.
But the need to use that term to distinguish true science from the practice of imposters was already fading by the time the Nobel Prizes were launched in 1901.
Similarly, the terms astronomical science and hypnotic science mostly died out as the twentieth century progressed, perhaps because belief in the occult waned in respectable society.
Yes, horoscopes still persist in popular newspapers, but they are there only for the severely scientifically challenged, or for entertainment; the idea that the stars determine our fate has lost all intellectual currency.
Hence there is no longer any need for the term “astronomical science.”
Critics of “economic sciences” sometimes refer to the development of a “pseudoscience” of economics, arguing that it uses the trappings of science, like dense mathematics, but only for show.
For example, in his 2004 book Fooled by Randomness, Nassim Nicholas Taleb said of economic sciences: “You can disguise charlatanism under the weight of equations, and nobody can catch you since there is no such thing as a controlled experiment.”
But physics is not without such critics, too.
In his 2004 book The Trouble with Physics: The Rise of String Theory, The Fall of a Science, and What Comes Next, Lee Smolin reproached the physics profession for being seduced by beautiful and elegant theories (notably string theory) rather than those that can be tested by experimentation.
Similarly, in his 2007 book Not Even Wrong: The Failure of String Theory and the Search for Unity in Physical Law, Peter Woit accused physicists of much the same sin as mathematical economists are said to commit.
My belief is that economics is somewhat more vulnerable than the physical sciences to models whose validity will never be clear, because the necessity for approximation is much stronger than in the physical sciences, especially given that the models describe people rather than magnetic resonances or fundamental particles.
People can just change their minds and behave completely differently.
They even have neuroses and identity problems, complex phenomena that the field of behavioral economics is finding relevant to understanding economic outcomes.
But all the mathematics in economics is not, as Taleb suggests, charlatanism.
Economics has an important quantitative side, which cannot be escaped.
The challenge has been to combine its mathematical insights with the kinds of adjustments that are needed to make its models fit the economy’s irreducibly human element.
The advance of behavioral economics is not fundamentally in conflict with mathematical economics, as some seem to think, though it may well be in conflict with some currently fashionable mathematical economic models.
And, while economics presents its own methodological problems, the basic challenges facing researchers are not fundamentally different from those faced by researchers in other fields.
As economics develops, it will broaden its repertory of methods and sources of evidence, the science will become stronger, and the charlatans will be exposed.
Parallels to 1937
NEW HAVEN – The depression that followed the stock-market crash of 1929 took a turn for the worse eight years later, and recovery came only with the enormous economic stimulus provided by World War II, a conflict that cost more than 60 million lives.
By the time recovery finally arrived, much of Europe and Asia lay in ruins.
The current world situation is not nearly so dire, but there are parallels, particularly to 1937.
Now, as then, people have been disappointed for a long time, and many are despairing.
They are becoming more fearful for their long-term economic future.
And such fears can have severe consequences.
For example, the impact of the 2008 financial crisis on the Ukrainian and Russian economies might ultimately be behind the recent war there.
According to the International Monetary Fund, both Ukraine and Russia experienced spectacular growth from 2002 to 2007: over those five years, real per capita GDP rose 52% in Ukraine and 46% in Russia.
That is history now: real per capita GDP growth was only 0.2% last year in Ukraine, and only 1.3% in Russia.
The discontent generated by such disappointment may help to explain Ukrainian separatists’ anger, Russians’ discontent, and Russian President Vladimir Putin’s decision to annex Crimea and to support the separatists.
There is a name for the despair that has been driving discontent – and not only in Russia and Ukraine – since the financial crisis.
That name is the “new normal,” referring to long-term diminished prospects for economic growth, a term popularized by Bill Gross, a founder of bond giant PIMCO.
The despair felt after 1937 led to the emergence of similar new terms then, too.
“Secular stagnation,” referring to long-term economic malaise, is one example.
The word secular comes from the Latin saeculum, meaning a generation or a century.
The word stagnation suggests a swamp, implying a breeding ground for virulent dangers.
In the late 1930s, people were also worrying about discontent in Europe, which had already powered the rise of Adolph Hitler and Benito Mussolini.
The other term that suddenly became prominent around 1937 was “underconsumptionism” – the theory that fearful people may want to save too much for difficult times ahead.
Moreover, the amount of saving that people desire exceeds the available investment opportunities.
As a result, the desire to save will not add to aggregate saving to start new businesses, construct and sell new buildings, and so forth.
Though investors may bid up prices of existing capital assets, their attempts to save only slow down the economy.
“Secular stagnation” and “underconsumptionism” are terms that betray an underlying pessimism, which, by discouraging spending, not only reinforces a weak economy, but also generates anger, intolerance, and a potential for violence.
In his magnum opus&nbsp;The Moral Consequences of Economic Growth, Benjamin M. Friedman showed many examples of declining economic growth giving rise – with variable and sometimes long lags – to intolerance, aggressive nationalism, and war.
He concluded that, “The value of a rising standard of living lies not just in the concrete improvements it brings to how individuals live but in how it shapes the social, political, and ultimately the moral character of a people.”
Some will doubt the importance of economic growth.
Maybe, many say, we are too ambitious and ought to enjoy a higher quality of life with more leisure.
Maybe they are right.
But the real issue is self-esteem and the social-comparison processes that psychologist Leon Festinger observed as a universal human trait.
Though many will deny it, we are always comparing ourselves with others, and hoping to climb the social ladder.
People will never be happy with newfound opportunities for leisure if it seems to signal their failure relative to others.
The hope that economic growth promotes peace and tolerance is based on people’s tendency to compare themselves not just to others in the present, but also to what they remember of people – including themselves – in the past.
According to Friedman, “Obviously nothing can enable the majority of the population to be better off than everyone else.
But not only is it possible for most people to be better off than they used to be, that is precisely what economic growth means.”
The downside of the sanctions imposed against Russia for its behavior in eastern Ukraine is that they may produce a recession throughout Europe and beyond.
That will leave the world with unhappy Russians, unhappy Ukrainians, and unhappy Europeans whose sense of confidence and support for peaceful democratic institutions will weaken.
While some kinds of sanctions against international aggression appear to be necessary, we must remain mindful of the risks associated with extreme or punishing measures.
It would be highly desirable to come to an agreement to end the sanctions; to integrate Russia (and Ukraine) more fully into the world economy; and to couple these steps with expansionary economic policies.
A satisfactory resolution of the current conflict requires nothing less.
A Requiem for Technocracy
When I was a graduate student in the humanities in the 1970s, my mentors thundered against the coming technocratic state.
Politicians, I was told, would soon listen only to experts who would sacrifice human values for the sake of efficiency, while ordinary citizens’ voices would be drowned out.
If only more of that scenario were true.
Today, issues about which facts really matter – for example, the safety of genetically modified foods, the hazards of extracting shale oil and gas, and the impact of global warming – are debated without regard for scientific evidence or in ways that use distorted and cherry-picked information to promote a chosen position.
Politicians and activists portray these issues as social struggles or morality plays: big businesses against small farmers, oppressors versus liberators, or conspirators seeking to deceive innocent citizens.
For example, after a recent World Health Organization report warned that the Fukushima nuclear disaster in Japan had only slightly increased local residents’ risk of developing certain kinds of cancers, the environmental organization Greenpeace, deeming the figures too low, denounced the report as “a political statement to protect the nuclear industry.”
Similarly, Robert F. Kennedy, Jr., an American environmental activist, has accused the United States government and the drug industry of conspiring to obscure the link between childhood vaccines and autism – a link for which there is no scientific evidence.
Likewise, US Representative Paul Ryan, a Republican and former vice-presidential candidate, accused leading climatologists of conspiracy for arguing that climate change was real, and voted to undo climate-protection plans and eliminate White House climate advisers.
And, despite the absence of evidence that mobile phones pose any kind of danger, former Democratic Representative Dennis Kucinich, alleging that officials were suppressing information, introduced the “Cell Phone Right to Know Act” to require radiation warnings on the devices.
Pseudoscience and scientific illiteracy used to be the domain of astrologers, quacks, and other charlatans who lacked the influence to be a major social threat.
Today, acting against scientific evidence is politically expedient: it offers left-wing and right-wing politicians alike an opportunity to court an anti-elite, populist image.
But this approach endangers public health and the planet, and some scientists are beginning to worry about the possibility of a new “dark age of political feudalism.”
What happened to the science-based technocratic state that my humanities professors feared?
The truth is that hard facts and scientific evidence never had any special authority in shaping policy in the first place; to political leaders, a scientist’s view is just another opinion.
My humanities professors came of age in the aftermath of World War II – won with radar and ended with the atomic bomb – when the scientific perspective needed no proselytizing to guarantee its authority.
But this reflected less a rational belief in deferring to science in decision-making than an enthusiastic response to the role science had played during the war.
Such enthusiasm raised fears of what the political scientist Roger Pielke, Jr. has called the transformation of “abortion politics” into “tornado politics.”
The debate preceding a collective decision about abortion is about values – there is no shared goal, and scientific information is all but irrelevant.
In short, they are turning tornado politics into abortion politics.
Science is far from perfect.
Its practitioners are no more innately virtuous than anyone else, and their work is no less vulnerable to error and misuse.
The difference is that scientists have struggled to institutionalize a process that involves extensive observation, experimentation, and independent review that, in the long run, provides a firmer purchase on the world than intuition and political posturing.
I am glad that we do not live in a technocracy, ruled by experts who decide our social goals rather than advancing the goals that society establishes.
But I am beginning to fear that I am living in a state whose politicians are more interested in proclaiming the nobility of goals that cannot be achieved.
With no route from here to there, we are guaranteed to get lost.
The Road to Full Investment
LONDON – A specter is haunting the treasuries and central banks of the West – the specter of secular stagnation.
What if there is no sustainable recovery from the economic slump of 2008-2013?
What if the sources of economic growth have dried up – not temporarily, but permanently?
The new pessimism comes not from Marxists, who have always looked for telltale signs of capitalism’s collapse, but from the heart of the policymaking establishment: Larry Summers, former US President Bill Clinton’s Secretary of the Treasury, and chief economist of almost everything at one time or another.
Summers’s argument, in a nutshell, is that if the expected profitability of investment is falling, interest rates need to fall to the same extent.
But interest rates cannot fall below zero (in fact, they may be stuck above zero if there is a strong desire to build up cash balances).
This could result in profit expectations falling below the cost of borrowing.
Most people agree that this could happen at the depth of a slump.
It was to avert this possibility that central banks began pumping money into the economy after 2008.
The novelty of Summers’s argument is the claim that “secular stagnation” began 15-20 years before the crash.
True enough, interest rates were falling, though not as fast as the fall in expected profit on new investment.
So, even in the so-called boom years, most Western economies were kept afloat not by new investment, but by asset bubbles based on increasingly unsustainable leverage.
The generalized version of this proposition is that secular stagnation – the persistent underuse of potential resources – is the fate of all economies that rely on private investment to fill the gap between income and consumption.
As capital becomes more abundant, the expected return on new investment, allowing for risk, falls toward zero.
But this does not mean that all investment should come to an end.
If the risk can be eliminated, the investment engine can be kept going, at least temporarily.
This is where public investment comes in.
Certain classes of investment may not earn the risk-adjusted returns that private investors demand.
But, provided that the returns are positive, such investments are still worth making.
Given near-zero interest rates and idle workers, it is time for the state to undertake the rebuilding of infrastructure.
Those who know their history will recognize that Summers is reviving an argument advanced by the American economist Alvin Hansen in 1938.
Owing to a slowdown in population growth, and thus lower “demand for capital,” the world, Hansen claimed, faced a problem of “secular, or structural, unemployment…in the decades before us.”
The prolonged boom that followed World War II falsified Hansen’s projection.
But his argument was not foolish; it was the assumptions underlying it that turned out to be wrong.
Hansen did not anticipate the war’s huge capital-consuming effect, and that of many smaller wars, plus the long Cold War, in keeping capital scarce.
In the United States, military spending averaged 10% of GDP in the 1950’s and 1960’s.
Population growth was boosted by a war-induced baby boom and mass immigration into the US and Western Europe.
New export markets and private investment opportunities opened up in developing countries.
Most Western governments pursued large-scale civilian investment programs: think of the US interstate highway system built under President Dwight D. Eisenhower in the 1950’s.
This mixture of stimulating events and policies enabled Western economies to maintain high investment ratios in the post-WWII years.
But it is possible to argue that all of this merely postponed the day when the expected rate of return to capital would fall below the minimum rate of interest acceptable to savers, which would happen as capital became more abundant relative to population.
Hansen thought that new inventions would require less capital than in the past.
This has now come to pass in what the MIT economists Erik Brynjolfsson and Andrew McAfee call The Second Machine Age.
A company like Kodak needed and built vastly more infrastructure than its digital successors Instagram and Facebook – and (of course) employed many more workers.
The inventions of the future may well consume even less capital (and labor).
What follows from this?
The human race has proved very successful in the past at keeping capital scarce – mainly by engaging in destructive wars.
One cannot exclude recourse to this solution in the future.
Apart from this, it is surely premature to believe that the West has run out of investment opportunities.
Some new inventions, like self-driving car systems, will require heavy capital investment in new kinds of roads.
And one can think of many others.
It is probable, though, that most of the new investment will have to be carried out with state subsidies.
But beyond this, one should view secular stagnation as an opportunity rather than a threat.
The classical economists of the nineteenth century looked forward to what they called a “stationary state,” when, in the words of John Stuart Mill, the life of “struggling to get on…trampling, crushing, elbowing, and treading on each other’s heels” would no longer be needed.
If a point of true “full investment” – that is, a situation when the supply of capital increased to the point at which it would yield no net return above its replacement cost – were ever reached, it would signify that the human race had solved its economic problem.
The challenge then would be to convert capital abundance into more leisure and balanced consumption.
Should that happen, we would be at the threshold of a new world – some would say a heaven on earth.
We can be tolerably certain of one thing: our leaders will do their best to make sure we never get there.
Endgame for Putin in Ukraine?
LONDON – Vladimir Putin may (or may not) enjoy 80% public support in Russia for his Ukraine policy; but it has become increasingly clear that he has bitten off more than he can chew.
The question is: At what point will his position as President become untenable?
Leave to one side the moral and geopolitical background of the Ukraine imbroglio.
Russians are justified, I believe, in their view that the West took advantage of Russia’s post-communist weakness to encroach on their country’s historic space.
The Monroe Doctrine may be incompatible with contemporary international law; but all powers strong enough to enforce a strategic sphere of interest do so.
There is merit, I also believe, in Putin’s contention that a multipolar world is better than a unipolar world for advancing the cause of human flourishing.
No single power or coalition is wise or disinterested enough to claim universal sovereignty.
So it should be no surprise that Russia and other countries have started to build an institutional structure for multi-polarity.
The Shanghai Cooperation Organization, which includes Russia, China, and four ex-Soviet Central Asian states, was established in 2001.
Last month, the five BRICS countries – Brazil, Russia, India, China, and South Africa – established the New Development Bank and a contingent reserve fund to diversify sources of official lending to developing countries.
The BRICS’ “no strings” policy explicitly challenges the conditionality imposed on borrowers by the World Bank and the International Monetary Fund, though the policy remains untested.
Indeed, it is impossible to imagine China’s leaders approving a loan to a country that, say, recognizes Taiwan or accepts Tibetan claims to independence.
But the fact remains that Russia is too weak to challenge the West further, at least in the way that it did in Ukraine.
Russia’s GDP is around $2 trillion, and its population of 143 million is falling fast.
The United States and the European Union have a combined GDP of about $34 trillion and a population of 822 million, with the US population growing rapidly.
This means that the West can inflict much more damage on Russia than Russia can inflict on the West.
Even in its heyday, the Soviet Union was a one-track superpower.
With an economy about a quarter of the size of America’s, it was able to maintain rough military parity by spending four times as much of its national income on defense as the US did – to the detriment of the living standards of ordinary citizens.
Today the balance of power is even more unfavorable.
Russia’s economy is weaker, and its armaments are rusty.
It retains a formidable nuclear capacity, but it is inconceivable that Russia would use it to secure its aims in Ukraine.
So we are left with a looming endgame in which Putin can neither retain his spoils – Crimea and control of Russian-speaking parts of eastern Ukraine – nor back down.
Russia will be required to disgorge these acquisitions as a condition of normalizing its relations with the West.
But Putin will most likely try to prop up eastern Ukraine’s separatists as long as he can – perhaps with military assistance disguised as humanitarian aid – and will absolutely refuse to give up Crimea.
This will lead to a further escalation of Western sanctions: restrictions on gas exports, general export restrictions, suspension from the World Trade Organization, withdrawal of the FIFA 2018 World Cup soccer tournament, and so on.
This, in conjunction with the tightening of current sanctions, including the exclusion of Russian banks from Western capital markets, is bound to cause serious shortages, declining living standards, and major problems for Russia’s ownership class.
The Russian public’s natural reaction will be to rally to their leader.
But support for Putin, though broad, may not be deep.
It is support before, not after, the debate about the costs of Putin’s policy has taken place.
And that debate is being silenced by state control of the media and the suppression of opposition.
It is natural and right to think of possible compromises: Ukraine’s guaranteed neutrality, greater regional autonomy within a federal Ukraine, an interim international administration in Crimea to supervise a referendum on its future, and the like.
The question is not how much of this kind of package Putin would accept, but whether any of it will be offered to him.
The West no longer believes anything he says.
US President Barack Obama has publicly accused him of lying.
German Chancellor Angela Merkel, formerly Putin’s strongest backer in Europe, is reported to have described him as delusional.
(The last straw for her apparently was his attempt to blame the downing of Malaysia Airlines Flight 17 on the Ukrainian government.)
All leaders lie and dissemble to some extent; but the scale of disinformation coming from the Kremlin has been epic.
So the question must be asked: Will the West be prepared to make peace with Putin?
Leaders whose foreign-policy adventures end in defeat do not usually survive long in office.
Either formal mechanisms are used to dethrone them – as occurred, for example, in the Soviet Union, when the Central Committee forced Nikita Khrushchev out of power in 1964 – or informal mechanisms come into play.
Putin’s power elite will start fracturing – indeed, that process may have begun already.
Pressure will grow for him to step aside.
There is no need, it will be said, for his country to go down with him.
Such a scenario, unimaginable a few months ago, may already be shaping up as the Ukraine drama moves to its endgame.
The Putin era may be over sooner than we think.
Post-Crash Economics
LONDON – In last month’s European Parliament election, euroskeptic and extremist parties won 25% of the popular vote, with the biggest gains chalked up in France, the United Kingdom, and Greece.
These results were widely, and correctly, interpreted as showing the degree of disconnect between an arrogant European elite and ordinary citizens.
Less noticed, because less obviously political, are today’s intellectual rumblings, of which French economist Thomas Piketty’s Capital in the Twenty-First Century, a withering indictment of growing inequality, is the latest manifestation.
We may be witnessing the beginning of the end of the neoliberal capitalist consensus that has prevailed throughout the West since the 1980s – and that many claim led to the economic disaster of 2008-2009.
Particularly important is the growing discontent of economics students with the university curriculum.
Undergraduates’ discontent matters, because economics has long been the West’s political lodestar.
This discontent was born in the “post-autistic economics movement,” which started in Paris in 2000, and spread to the United States, Australia, and New Zealand.
Its adherents’ main complaint was that the mainstream economics taught to students had become a branch of mathematics, disconnected from reality.
The revolt made little progress in the years of the “Great Moderation” of the 2000s, but was revived following the 2008 crisis.
Two important links with the earlier network are US economist James Galbraith, the son of John Kenneth Galbraith, and British economist Ha-Joon Chang, author of the best-selling 23 Things They Don’t Tell You about Capitalism.
In a manifesto published in April, economics students at the University of Manchester advocated an approach “that begins with economic phenomena and then gives students a toolkit to evaluate how well different perspectives can explain it,” rather than with mathematical models based on unreal assumptions.
Significantly, Andrew Haldane, Executive Director for Financial Stability at the Bank of England, wrote the introduction.
The Manchester students argue that “the mainstream within the discipline (neoclassical theory) has excluded all dissenting opinion, and the crisis is arguably the ultimate price of this exclusion.
Alternative approaches such as Post-Keynesian, Marxist, and Austrian economics (as well as many others) have been marginalized.
The same can be said of the history of the discipline.”
As a result, students have little awareness of neoclassical theory’s limits, much less alternatives to it.
The aim, according to the students, should be to “bridge disciplines within and outside of economics.”
Economics should not be divorced from psychology, politics, history, philosophy, and so on.
Students are especially keen to study issues like inequality, the role of ethics and fairness in economics (as opposed to the prevailing focus on profit maximization), and the economic consequences of climate change.
The idea is that such intellectual cross-fertilization would help students understand recent economic phenomena better and improve economic theory.
From this point of view, everyone stands to benefit from curriculum reform.
The deeper message is that mainstream economics is in fact an ideology – the ideology of the free market.
Its tools and assumptions define its topics.
If we assume perfect rationality and complete markets, we are debarred from exploring the causes of large-scale economic failures.
Unfortunately, such assumptions have a profound influence on policy.
The efficient-market hypothesis – the belief that financial markets price risks correctly on average – provided the intellectual argument for extensive deregulation of banking in the 1980s and 1990s.
Similarly, the austerity policies that Europe used to fight the recession from 2010 on were based on the belief that there was no recession to fight.
These ideas were tailored to the views of the financial oligarchy.
But the tools of economics, as currently taught, provide little scope for investigating the links between economists’ ideas and the structures of power.
Today’s “post-crash” students are right.
So what is keeping the mainstream’s intellectual apparatus going?
For starters, economics teaching and research is deeply embedded in an institutional structure that, as with any ideological movement, rewards orthodoxy and penalizes heresy.
The great classics of economics, from Smith to Ricardo to Veblen, go untaught.
Research funding is allocated on the basis of publication in academic journals that espouse the neoclassical perspective.
Publication in such journals is also the basis of promotion.
Moreover, it has become an article of faith that any move toward a more open or “pluralist” approach to economics portends regression to “pre-scientific” modes of thought, just as the results of the European Parliament election threaten to revive a more primitive mode of politics.
Yet institutions and ideologies cannot survive by mere incantation or reminders of past horrors.
They have to address and account for the contemporary world of lived experience.
For now, the best that curriculum reform can do is to remind students that economics is not a science like physics, and that it has a much richer history than is to be found in the standard textbooks.
In his book Economics of Good and Evil, the Czech economist Tomáš Sedláček shows that what we call “economics” is only a formalized fragment of a much wider range of thinking about economic life, stretching from the Sumerian epic of Gilgamesh to the meta-mathematics of today.
Indeed, mainstream economics is a pitifully thin distillation of historical wisdom on the topics that it addresses.
It should be applied to whatever practical problems it can solve; but its tools and assumptions should always be in creative tension with other beliefs concerning human wellbeing and flourishing.
What students are taught today certainly does not deserve its imperial status in social thought.
Shale Gas to the Rescue?
LONDON – The developed world is slowly emerging from the Great Recession, but a question lingers: How fast and how far will the recovery go?
One big source of pessimism has been the idea that we are running out of investment opportunities – and have been since before the 2008 crash.
But is that true?
The last big surge of innovation was the Internet revolution, whose products came onstream in the 1990’s.
Following the dot-com collapse of the early 2000’s, speculation in real estate and financial assets – enabled by cheap money – kept Western economies going.
The post-2008 slump merely exposed the unsoundness of the preceding boom; the mediocrity of the recovery reflects the mediocrity of previous prospects, coolly considered.
The risk now is that a debt-fueled asset spike merely perpetuates the boom-bust cycle.
The economist Larry Summers has reintroduced the term “secular stagnation” to describe what awaits us.
By the mid-2000’s, Summers argued at a recent International Monetary Fund conference, the average prospective return on new investment in the United States had fallen below any feasible reduction in the Federal Reserve’s benchmark interest rate.
That remains true today.
We may be in a permanent liquidity trap, in which nominal interest rates cannot fall below zero, but the expected rate of return to investment remains negative.
Unconventional monetary policies like quantitative easing may inflate a new generation of asset bubbles, but the underlying problem – negative returns to new investment – will not have been solved by the time the next crash comes.
So the problem is poor investment prospects.
Why?
In the 1930’s, the economist Alvin Hansen argued that opportunities for new investment in already-rich countries were drying up.
Investment growth had depended on population growth, technological innovation, and westward expansion.
With the closing of the frontier and static populations, growth would depend on innovation; but future innovation would require smaller inputs of capital and labor than in the past.
In other words, the returns to capital were bound to fall as it became more abundant relative to population.
In this situation, full employment could be maintained only by running continuous fiscal deficits.
John Maynard Keynes held a different view.
In 1945, he wrote to T.S. Eliot: “[T]he full employment policy by means of investment is only one particular application of an intellectual theorem.
You can produce the result just as well by consuming more or working less.
Personally, I regard the investment policy as first aid.…Less work is the ultimate solution.”
Developed countries’ strong postwar investment performance dispelled fear of secular stagnation.
But this occurred after a world war that had created huge pent-up demand for new equipment, transport infrastructure, and household appliances, together with a military-industrial complex that armed the West during the Cold War.
The real rate of return to capital may have started to decline by the early 1970’s; productivity growth certainly has slowed since then.
Some crucial changes in the political economy of Western capitalism in the 1980’s can also be viewed in this light: the rise of neoliberal ideology, the growing inequality of wealth and incomes, the increase in structural unemployment, the growth of financial services, globalization, the invention of post-Cold War threats to sustain military spending, and so on.
The question today is whether a new upsurge of investment will come to our rescue.
Optimists point to the shale-energy revolution in the US.
The McKinsey Global Institute has identified shale energy as a “game changer” for the world economy, estimatingthat it could boost America’s GDP by as much as 4% ($690 billion) per year and add 1.7 million permanent jobs to the labor market by 2020.
From 2007 to 2012, North American shale-gas production grew at an average annual rate of more than 50%.
As a result, the share of shale gas in America’s overall gas production rose from just 5% in 2007 to 36% in 2012.
With the share of imports in US natural-gas consumption dropping from 16.5% in 2007 to 11% in 2010, America is on the path to energy self-sufficiency.
Likewise, a September 2013 report by IHS concludes that midstream industries like transportation and downstream industries like manufacturing and chemicals are also receiving a massive stimulus.
As a result of the shale-energy boom, “over $216 billion in total will be invested in the midstream and downstream oil and gas industries” from 2012 to 2025.
Nearly 380,000 of the 2.1 million jobs that shale-related industries generated in the US in 2012 , were created in these areas.
Beyond this, the most dramatic impact of shale oil and gas on the economy has been the fall in energy prices.
In the US, the price of natural gas has fallen to $4 per MMBtu, from $13 in 2008, boosting household purchasing power.
IHS estimates that in 2012, developments in the shale-energy industry increased households’ real disposable income by more than $1,200.
Thus the shale revolution represents a huge stimulus for America, in terms of investment, exports, and a reduction in energy costs.
I am not in a position either to judge the quantitative impact of shale energy on the US economy and, via growth there, on the rest of the world, or to comment on its geopolitical consequences or net effect on carbon emissions.
But it does seem to me that contemporary apostles of secular stagnation like Summers and Paul Krugman at least ought to be taking the shale-energy revolution into account.
Death to Machines?
LONDON – At the start of the Industrial Revolution, textile workers in the Midlands and the North of England, mainly weavers, staged a spontaneous revolt, smashing machinery and burning factories.
Their complaint was that the newfangled machines were robbing them of their wages and jobs.
The rebels took their name, and inspiration, from the apocryphal Ned Ludd, supposedly an apprentice weaver who smashed two knitting frames in 1779 in a “fit of passion.”
Robert Calvert wrote a ballad about him in 1985: “They said Ned Ludd was an idiot boy/ That all he could do was wreck and destroy,” the song begins.
And then: “He turned to his workmates and said: ‘Death to Machines’/They tread on our future and stamp on our dreams.”
The Luddites’ rampage was at its height in 1811-12.
An alarmed government sent in more troops to garrison the disturbed areas than were then available to Wellington in the Peninsular War against Napoleon.
More than a hundred Luddites were hanged or transported to Australia.
These measures restored peace.
The machines won: the Luddites are a footnote in the history of the Industrial Revolution.
Historians tell us that the Luddites were victims of a temporary conjuncture of rising prices and falling wages that threatened them with starvation in a society with minimal welfare provision.
The Luddites, however, blamed their misfortune on the machines themselves.
The new knitting frames and power looms could weave yarn into cloth much faster than the most skilled artisan weaver working in his own cottage.
Caught between fixed costs (the hire and upkeep of their domestic appliances) and falling prices for their products, tens of thousands of families were doomed to become paupers.
Their plight evoked some sympathy (Lord Byron made a brilliant speech in their defense in the House of Lords); their arguments, however, did not.
There could be no rejecting progress: the future lay with machine production, not with old-fashioned handicrafts.
Trying to regulate trade, Adam Smith taught, was like trying to “regulate the wind.”
Thomas Paine spoke for middle-class radicalism when he said, “We know that every machine for the abridgment of labor is a blessing to the great family of which we are part.”
There would, of course, be some temporary unemployment in the technologically advancing sectors; but, in the long run, machine-assisted production, by increasing the real wealth of the community, would enable full employment at higher wages.
That was the initial view of David Ricardo, the most influential economist of the nineteenth century.
But in the third edition of his Principles of Political Economy (1817), he inserted a chapter on machinery that changed tack.
He was now “convinced that the substitution of machines for human labor is often very injurious to the class of laborers,” that the “same cause which may increase the net revenue of the country, may at the same time render the population redundant.”
As a result, “the opinion entertained by the laboring class, that the employment of machinery is frequently detrimental to their interests, is not founded on prejudice and error, but is conformable to the correct principles of political economy.”
Just consider: machinery “may render the population redundant”!
A bleaker prospect is not to be found in economics.
Ricardo’s orthodox followers took no notice of it, assuming it to be a rare lapse by the Master.
But was it?
The pessimistic argument is as follows: If machines costing $5 an hour can produce the same amount as workers costing $10 an hour, employers have an incentive to substitute machines for labor up to the point that the costs are equal – that is, when the wages of the workers have fallen to $5 an hour.
As machines become ever more productive, so wages tend to fall even more, toward zero, and the population becomes redundant.
Now, it did not work out like that.
Labor’s share of GDP remained constant throughout the Industrial Age.
The pessimistic argument ignored the fact that by lowering the cost of goods, machines increased workers’ real wages – enabling them to buy more – and that the rise in labor productivity enabled employers (often under pressure from trade unions) to pay more per worker.
It also assumed that machines and workers were close substitutes, whereas more often than not workers could still do things that machines could not.
However, over the last 30 years, the share of wages in national income has been falling, owing to what MIT professors Erik Brynjolfsson and Andrew McAfee call the “second machine age.”
Computerized technology has penetrated deeply into the service sector, taking over jobs for which the human factor and “cognitive functions” were hitherto deemed indispensable.
In retail, for example, Walmart and Amazon are prime examples of new technology driving down workers’ wages.
Because computer programs and humans are close substitutes for such jobs, and given the predictable improvement in computing power, there seems to be no technical obstacle to the redundancy of workers across much of the service economy.
Yes, there will still be activities that require human skills, and these skills can be improved.
But it is broadly true that the more computers can do, the less humans need to do.
The prospect of the “abridgment of labor” should fill us with hope rather than foreboding.
But, in our kind of society, there are no mechanisms for converting redundancy into leisure.
That brings me back to the Luddites.
They claimed that because machines were cheaper than labor, their introduction would depress wages.
They argued the case for skill against cheapness.
The most thoughtful of them understood that consumption depends on real income, and that depressing real income destroys businesses.
Above all, they understood that the solution to the problems created by machines would not be found in laissez-faire nostrums.
The Luddites were wrong on many points; but perhaps they deserve more than a footnote.
Vanguard Scotland?
LONDON – Since I believe that the Scots are sensible, I think that they will vote “no” this week to independence.
Either way, nationalist politicians enjoy the huge advantage of not requiring a practical program: all good things will flow from sovereignty.
Though nationalist politics was long suppressed after World War II by economic prosperity and memories of pre-war horrors, Europe offers fertile ground for its revival.
This is not just because of Europe’s prolonged economic malaise.
It is because practically all of Europe’s existing nation-states contain geographically concentrated ethnic, religious, or linguistic minorities.
Moreover, these states’ incorporation into the European Union – a kind of voluntary empire – challenges their citizens’ allegiance.
Thus, nationalists can look either to Europe to protect them against their own states or to their states to protect them against the European empire.
That is why Britain has spawned two nationalisms simultaneously.
The United Kingdom Independence Party (UKIP), led by populist Nigel Farage, looks to London to protect British independence against the EU bureaucracy.
The Scottish National Party (SNP), led by the astute Alex Salmond, looks to Brussels to protect Scotland against the “imperial” parliament in Westminster.
Given the right conditions, nationalism will always discover an “other” against which to define itself.
Scottish nationalism was not created by the recent economic crisis, but the Scottish referendum was.
Scotland convened its first devolved parliament in 1999, giving the SNP a political platform in Edinburgh from which to campaign for independence.
The removal of the Labour government in London in 2010 was the voters’ way of punishing the Labour Party for the economic collapse of 2008-2009.
But, while Labour’s punishment delivered a Conservative government in London, it produced a majority victory for the SNP in Edinburgh in 2011.
To maintain governability in Scotland, British Prime Minister David Cameron was forced to permit a referendum on independence.
An independent Scottish government would face huge economic costs.
It would inherit its share of UK public-sector debt and future liabilities without the benefit of the substantial subsidy that it currently receives from the British Treasury.
The SNP claims that additional revenues from North Sea oil would offset the subsidy.
But these revenues are naturally time-limited, and the SNP has failed to mention the large decommissioning costs that will be incurred when the oil runs out.
So, almost certainly, Scottish taxes would have to be higher than UK taxes.
In addition, leading Scottish-based banks and many large businesses have said they would relocate some of their operations to London.
Scotland would also be threatened with the loss of British defense contracts.
According to the SNP, an independent Scotland would not cause fragmentation of the UK internal market, because it would maintain a currency union with Britain.
But the three main British political parties, and the Bank of England, have rejected this.
If the Scots want sovereignty, they will need their own currency – and their own central bank: no British lender of last resort would be available to Scotland’s banks.
Scotland might try to keep its currency at par with sterling, but this would require larger reserves than a Scottish central bank could command, at least at the outset.
And a Scottish currency that floats against the British pound would mean large transaction costs and reduced trade between the two countries.
Nor is there any easy escape, at least in the short run, by joining the EU, which may well require an independent Scotland to apply for membership.
In short, the SNP’s dream of social democracy in one country would fall afoul of the larger interdependencies that bind together the components of the UK, and that tie the UK to the EU and the EU to the rest of the globalized world.
None of this fazes the Scottish nationalists.
In nationalism’s forward march in post-crash Europe, its standard-bearers often use immigration to exploit pre-crash resentment against globalization, notably the erosion of cultures and identities, declining sense of community, wage stagnation, rising inequality, uncontrolled banks, and high unemployment.
They question whether people can enjoy the benefits of globalization while being sheltered from its costs – and what alternatives there are to the “market fundamentalism” that has defined capitalism since the late twentieth century.
In this mood, people are more willing to discount nationalism’s costs, because they have come to doubt the benefits of its liberal capitalist rival.
Ordinary Russians, for example, refuse to face the costs of their government’s Ukraine policy, not just because they underestimate them, but because they somehow seem unimportant relative to the huge psychological boost the policy brings.
Nationalism today is not nearly as virulent as it was in the 1930s, because economic distress is much less pronounced.
But its revival is a portent of what happens when a form of politics claims to satisfy every human need except the coziness of communal belonging – and then lets the people down.
Free Trade and Costly Love
LONDON – The World Trade Organization’s ministerial conference in Bali in December produced a modest package of encouragements to global trade.
More broadly, the WTO’s multilateral approach has shown its worth by preventing a massive increase in trade barriers, unlike in 1929-1930, when protectionism helped deepen and broaden the Great Depression.
But the main question – whether globalization is a good thing, and for whom – remains unanswered.
The essence of globalization – free trade – rests on the theory of comparative advantage, which views international trade as profitable even for a country that can produce every commodity more cheaply (in terms of labor or all resources) than any other country.
The textbook example given by the Nobel laureate Paul Samuelson is that of a town’s best lawyer who is also its best typist.
Provided that he is better at law than at typing, he should specialize in law and leave his secretary to do the typing.
That way, both of their earnings will be higher.
The same logic applies to countries.
Each country should specialize in producing those things that it produces most efficiently, rather than producing a bit of everything, because that way its income will be higher.
Economists regard understanding the theory of comparative advantage as a test of professional competence.
But are the incompetents – say, the average person who believes that buying cheap imports from China destroys Western jobs – always wrong?
Samuelson, who called the theory of comparative advantage the most beautiful thing in economics, changed his tune a bit at the end of his life.
Free trade, he said, works fine with unchanging technology.
Time is money: the more money you can squeeze out of an hour’s work, the better off you are.
But what about all of the things that you enjoy doing, or that you think of as valuable, that do not maximize your earnings?
The economist responds that the more efficient you are at your work, the more time you will have for those other things.
The trouble is that the more you start to think of your welfare in terms of money, the more likely you are to regard spending time with your friends or making love as an “opportunity cost” – the loss of money you would have made by working instead – rather than a benefit.
The goal of squeezing as much money as possible out of time makes a great deal of sense in poor countries, where inefficient use of time can lead to starvation.
The whole point of economic development is, surely, to reduce the cost of inefficiency.
Yet economists, not noticing that their logic is less applicable to rich countries, continue trying to extend it to more and more areas of life.
A newly luxuriant research area is “life outsourcing.”
Paying someone else to fold your socks is a way to maximize your own earnings and those of the sock folder.
Even as penniless graduate students, the economists Jon Steinsson and Emi Nakamura borrowed money to pay people to do their household chores, calculating that “spending an extra hour working on a paper was better for their lifetime expected earnings than spending that same hour vacuuming.”
Likewise, the economists Betsey Stevenson and Justin Wolfers, pioneers of “lovenomics,” cite the tax code as a reason for not marrying.
They also conducted a cost/benefit analysis before having a child.
As Wolfers explains,
“The principle of comparative advantage tells us that gains from trade are largest when your trading partner has skills and endowments that are quite different from yours.
I’m an impractical bookish Harvard-trained empirical labor economist, while Betsey is an impractical and bookish Harvard-trained empirical labor economist.
When your skills are so similar, the gains from trade aren’t so large.
Except when it comes to bringing up our baby.
There, Betsey has a pair of, um, endowments that mean that she’s better at inputs.
And that means that I’m left to deal with outputs.”
As Stevenson helpfully clarifies, “it turns out that fathers can be pretty good at dealing with diapers.”
At this point, those untutored in economics are likely to start gnashing their teeth.
“I enjoy doing lots of things that do not maximize my earning power,” they might protest.
But as soon as we accept the premise that to be rational is to seek to maximize one’s utility – defined in terms of consumption, with money the way to maximize it – the economist’s logic wins.
At that point, we must admit that it is irrational to spend time on long conversations with friends if it is time stolen from inventing, say, new software (unless the conversation helps the invention).
For Wolfers, it is a coincidence that what earns him the most money, economics, is also what he most enjoys doing.
Such reasoning crystallizes opposing views of the world, one in which time is a cost, and the other in which it is a benefit.
The first sees time spent on enjoyment as a missed opportunity; the second as part of the good life.
We should be clear about what is at stake in the choice between the two.
The Rights of Digital Man
ABU DHABI – We have created an online world whose vastness exceeds our comprehension.
As a measure of its magnitude, consider this: In 2012, the new Internet address system, IPv6, created more than 340 trillion trillion trillion (3.4 x 1038) addresses – that is, around 4.8 x 1028 addresses for every person on earth.
That should be sufficient to service the five billion devices that currently connect to the internet, and the 22 billion devices forecast to be in use by 2020.
The hard part of the connectivity explosion is not building capacity, but how it should be managed.
We must answer profound questions about the way we live.
Should everyone be permanently connected to everything?
Who owns which data, and how should information be made public?
Can and should data use be regulated, and, if so, how?
And what role should government, business, and ordinary Internet users play in addressing these issues?
Such questions can no longer be ignored.
As the virtual world expands, so, too, do breaches of trust and misuse of personal data.
Surveillance has increased public unease – and even paranoia – about state agencies.
Private companies that trade in personal data have incited the launch of a “reclaim privacy” movement.
As one delegate at a recent World Economic Forum debate, noted: “The more connected we have become, the more privacy we have given up.”
But we can shape our future cyber-world in a way that keeps our data safe, reestablishes trust online, and welcomes in billions of new participants.
Ensuring security will require that the Internet’s many stakeholders establish some kind of governance system.
Organizations such as the Internet Corporation for Assigned Names and Numbers (ICANN) will need to become much more global in scope.
At the same time, we must guard against over-regulation or government control.
This might require us to phase out the Internet Assigned Numbers Authority to prevent it from falling under the control of an inter-governmental body, as some states have demanded.
Governments certainly have an important part to play.
But too much control would almost certainly stifle innovation, increase costs, and probably exclude important anti-establishment voices.
A better approach, and one that would enhance public trust in the system, would be to establish diversified stewardship with multiple stakeholders.
One such stakeholder group is business.
Now that our personal data have become such a valuable asset, companies are coming under increasing pressure to develop online business models that protect rather than exploit users’ private information.