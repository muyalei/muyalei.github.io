In this, Putin’s arrogance is failing Russia miserably.
His monomaniacal drive to centralize power is driving out the very expertise that the country needs to flourish.
Shell and BP are being expelled from the oil industry at the very moment that Russian oil production is declining dramatically.
His embittered attempts to counter American power are equally short-sighted: helping Iran develop its nuclear program and selling high-tech weapons to China are hardly in Russia’s long-term strategic interest.
As usual, history is set on fast-forward in America.
Everyone can now see the gross and historic failures of the Bush presidency.
Indeed, the American people have preempted the historians, rebuking Bush by electing a Democratic Congress in November 2006.
Meanwhile, Russia’s troubles remain hidden behind the strong arm tactics and oil bloated coffers of Putin’s autocratic bureaucracy.
But the fact that Russia’s social and economic diseases are going unaddressed has consigned the country to the long-term decline that his presidency was supposed to reverse.
In the twentieth century, the Cold War parity between Russia and America was apparent.
For Russians, America was an evil empire, the world of capitalist exploitation and a nuclear superpower, but also a cradle of economic prosperity and individual freedom.
For America, Russia, too, was an evil empire, the world of communist expansionism and a nuclear superpower, but also a cradle of science, spirit, and soul.
A similar parity characterized the Bush-Putin era.
Unlike America, however, Russia’s people have not yet understood the price of arrogant power run amuck.
The Libertarian and the Lobbyists
WASHINGTON, DC – In the three years since the global financial crisis erupted, two dominant views of what went wrong have emerged.
It is crucial that we understand each, because their implications for policymakers – and thus for the future health and stability of the global economy – could not be greater.
The first view is that governments simply lost control of the situation, either through incompetence or because politicians were pursuing their own agendas.
This is the view heard most frequently from the political right – for example, from people who think that the main problem in the run-up to the financial meltdown of 2008 was government housing policies.
In the United States, among the candidates still competing for the Republican Party’s nomination to challenge Barack Obama in November’s presidential election, Ron Paul stands out for arguing consistently that government is the problem, not the answer, with regard to banking.
If the government were removed more fully from the financial sector (including abolishing the Federal Reserve), he argues, the economy would function better.
The second view is that the financial sector lobbied long and hard for deregulation in recent decades, and spent a great deal of time and money persuading politicians that it constituted the safe and modern approach to banking.
According to this view, government policies did not fail; on the contrary, they operated exactly as intended – and as bought and paid for.
If this view is correct, the kind of policy prescription recommended by Ron Paul is less appealing.
Unless you think that a modern financial sector really can operate with absolutely no regulation of any kind (including, presumably, the rules for banks that come with deposit insurance), the real problem is not government officials’ policy preferences, but what financial-sector lobbyists are able to persuade officials to do.
Fresh evidence supporting the second view is now available in the form of a recent study by Deniz Igan and Prachi Mishra of the International Monetary Fund.
In “Three’s Company: Wall Street, Capitol Hill, and K Street,” the authors look at the data – lots of it – on lobbying by financial-sector companies in the US.
Legislators, of course, have different preferences about what kinds of laws to support, which can make it hard to study mechanisms of political influence precisely.
But Igan and Mishra approach the problem in a clever way – they look for instances when elected officials switched their position on legislative proposals that surfaced more than once. And they devote a lot of effort to figuring out what caused this switch.
In addition to analyzing information about lobbying expenditures, the authors map out the network connections of lobbyists (known collectively as “K Street,” because so many have their Washington offices there) and legislators.
For example, lobbyists were often previously employed by legislators on their staffs.
The results are simply staggering – although surely not a surprise to professional lobbyists.
A big increase in lobbying expenditures helps to persuade legislators to switch their votes.
And “whether any of the lobbyists working on a bill also worked for a legislator in the past sways the stance on that bill in favor of deregulation.”
It is deregulation, of course, that financial firms want – fewer rules and less oversight of any kind.
And it really is all about whom you know, and how you know them.
In particular, your value as a lobbyist seems to depend very highly on whom you worked with in the past.
Igan and Mishra find “spending an extra dollar is almost twice as effective in switching a legislator’s position if the lobbyist is connected to the legislator compared to the case where the lobbyist is unconnected.”
The revolving door between Congress and lobbying firms appears to have been central to how the financial sector became deregulated, which effectively allowed excessive risk-taking in the run-up to the crisis.
In another paper, Igan and Mishra, working with Thierry Tressel, found that firms taking more risks before 2008 were also engaged in more lobbying.
Essentially, financial firms have been buying the right to take on more risk.
When things go well, executives in these firms get the upside – mostly in terms of immediate compensation, because few executives are compensated on the basis of risk-adjusted returns.
That means that when the risks materialize and the firms suffer losses, the costs fall on taxpayers.
Ron Paul is right to point to imbalances of power and massive distortions within the financial sector.
He is also correct that many government policies favor relatively few big firms – and favor them in a way that encourages excessive and dangerous risk-taking.
But Paul and others are wrong to argue that the government is the ultimate cause of all financial evil.
Executives in financial firms want to take big risks.
They like arrangements under which they win even when they lose.
Big financial firms can more readily buy the necessary political protection (in the form of deregulation), enabling them to become even bigger and more dangerous.
This incentive structure has only become more extreme since the financial crisis of 2008.
Who’s Afraid of the Big Bad Debt?
CAMBRIDGE – It has been a while since a debate among academic economists attracted so much interest from the mainstream press as has the row between Carmen Reinhart and Kenneth Rogoff, on one side, and Paul Krugman, on the other.
In fact, it has even become fodder for television comedy shows.
At issue is an influential 2010 paper by Rogoff and Reinhart that purports to show that high levels of public debt are associated with lower long-term economic growth.
A new paper by Thomas Herndon, a graduate student at the University of Massachusetts at Amherst, and two of his professors, Michael Ash and Robert Pollin, questioned this finding, and Krugman made their work famous.
Herndon, Ash, and Pollin argue that the results obtained by Reinhart and Rogoff are based on coding errors and questionable methodological choices.
But, after all their quibbles, their paper weakens but does not refute the Reinhart/Rogoff paper’s main result.
So why all the fuss?
The debate is considered important because it is supposed to have implications for the choice between cutting the deficit and stimulating the economy now.
But this is just not so.
Instead, the paper needs to be understood in the context of the debate between Keynesians and (as Krugman calls them) “Austerians” – those who propose fiscal austerity to stem spiraling government debt.
The Keynesian prescription is simple: If the economy is weak, fiscal policy should be used to stimulate it; if it is overheating, spending cuts or tax hikes should be used to cool it down.
Public-debt levels will rise and fall, but policymakers should not pay too much attention.
After all, look at the United States and the United Kingdom: despite high deficits and rising debt, inflation remains subdued and long-term interest rates are at historic lows.
Why not use this opportunity to stimulate the economy and invest in its future?
Interestingly, Reinhart and Rogoff broadly agree with this recommendation (at least for the US), and they even support heterodox policies such as writing down mortgages and targeting a higher inflation rate.
But their paper is really about a different subject.
It is about the long-term effects of high levels of public debt, which they argue are deleterious to growth.
That conclusion implies that Krugman is wrong to claim that one can be blasé about the debt level.
Krugman would argue that, if the economy remains weak, interest rates will remain low, despite high and rising public debt.
Fear of a speculative attack by so-called “bond vigilantes” is unwarranted, he would claim, as the US and the UK show.
The Reinhart/Rogoff paper provides worldwide evidence in favor of the view that high public debt can become a problem, and that countries should beware of putting themselves in a vulnerable position.
But the ensuing debate sheds no light on the question of whether policymakers should disregard debt levels when their economies are depressed, as Krugman recommends.
There really is a big bad debt wolf, and the world is full of examples in which it has emerged from its lair to create havoc.
Consider Spain.
When the 2008 crisis erupted, the G-20 convened that November to coordinate a Keynesian response.
All member countries were supposed to fight the coming recession by stimulating their economies through simultaneous fiscal expansion.
Pedro Solbes, Spain’s finance minister at the time, quickly ordered an acceleration of public investment and spending.
By the spring of 2009, however, Solbes was forced to reverse course.
With tax revenue collapsing and expenditure ballooning, the government found itself running such large deficits that the markets were spooked – government-bond prices collapsed, interest rates soared, and the country found itself unable to finance its deficit.
Where were the rock-bottom interest rates that are supposed to characterize periods of weak growth and high unemployment?
Financial history is full of similar examples: Mexico in 1994, Russia in 1998, Ecuador in 1999, Argentina in 2001, Uruguay in 2002, the Dominican Republic in 2003, and even the UK in 1976.
All were battling recession and high unemployment, only to find themselves unable to finance their deficits.
In fact, when a country is in this predicament, fiscal contraction may end up being expansionary to the extent that it reestablishes financial confidence and lowers sky-high interest rates.
As much as Krugman has made of the Reinhart/Rogoff paper, the debate between “Austerians” and Keynesians has limited relevance outside of the US.
Krugman does not mention issues that he knows are central to fiscal choices.
The level of debt does matter, and its currency composition matters even more.
The US is in the enviable position of issuing debt in its own currency.
The Federal Reserve can create as many dollars as it sees fit in order to buy government debt.
Moreover, as the world’s reserve currency, the dollar plays a very particular role in the global economy.
Japan, too, can finance its deficits, despite astronomical public debt, because it borrows in yen – and overwhelmingly from Japanese institutional investors.
By contrast, Spain’s debt is in euros, a currency that it cannot print, and is held mostly by foreigners.
And many emerging-market countries are in a similar position.
In a recent paper with Ugo Panizza of the Graduate Institute of Development Studies in Geneva, we show that in the aftermath of the 2008 crisis, emerging-market countries that could run the kind of counter-cyclical Keynesian policies espoused by Krugman had low levels of foreign-currency debt.
It is only because they were “Austerians” before the crisis that they could afford to be Keynesians afterwards.
Whatever weaknesses one finds in the Reinhart/Rogoff paper, it does not follow that countries in recession should always disregard deficits and debt levels and focus on stimulus.
That might be the right recommendation for the US today, but as a universal rule of thumb, it is just plain wrong.
China’s New Inflation Constraint
BEIJING – China’s economic-growth rate slowed in the second quarter of this year to 7.5% year on year, down from 7.7% in the January-March period, in line with Chinese economists’ forecasts in recent months.
At the start of 2013, however, economists – both at home and abroad – were much more upbeat about the prospects for Chinese growth.
So, what changed?
China’s growth has shown a cyclical pattern over the past two decades.
Immediately after the collapse of Lehman Brothers in September 2008, China unveiled a ¥4 trillion ($650 billion) stimulus package.
The economy rebounded quickly, with the annualized growth rate soaring to 12.1% in the first quarter of 2010.
To rein in a housing bubble and preempt a rise in inflation, the People’s Bank of China tightened monetary policy in January 2010.
Then, to arrest the resulting loss of economic momentum, the PBOC loosened monetary policy in November 2011.
Most people believed that rapid growth would quickly be restored once again. But the rebound did not come until the fourth quarter of 2012.
Worse, instead of establishing renewed economic momentum, the growth rate fell in the second quarter of 2013 and all major forecasters are now revising their projections of full-year growth downward.
Of course, if the Chinese government wished, China’s growth rate in 2013 could still surpass 8%.
But the country’s new leaders do not wish to pursue growth at the expense of structural adjustment, which has been delayed for too long.
It seems that the government has established a floor for growth; as long as it is not hit, there will be no more fiscal or monetary stimulus.
But the new leadership’s reluctance to intervene in order to spur growth is just part of the story of China’s current slowdown.
Something more fundamental has happened, weakening the government’s ability to stimulate the economy.
In particular, even as the annualized growth rate in the first quarter of 2013 fell far below the average growth rate over the past 30 years, the annual increase in the consumer price index rose to a ten-month high of 3.2% in February, while house prices have been rising unabatedly.
Slower growth and higher inflation in the expansionary phase of the economic cycle (compared with previous cycles) reflect an essential macroeconomic change.
For many years, China’s Phillips curve – the historical inverse relationship between inflation and unemployment – was rather flat, which meant that when the government used expansionary monetary and fiscal policies to spur growth, it did not have to worry too much about price instability.
But there is now growing evidence that the Phillips curve has started to rotate since 2010.
Today, for a given rate of GDP growth, the corresponding inflation rate is substantially higher than it was over the past two decades.
In other words, inflation – especially house-price inflation – has become an important constraint on growth.
The leftward rotation of China’s Phillips curve stems from many important structural changes.
First, as a result of demographic and social changes, the marginal wage cost of production and minimum-wage levels have increased significantly.
Second, with environmental concerns becoming more widespread, enterprises – especially those with newly installed production facilities – have been spending lavishly.
Third, the relentless exploitation of resources has caused the prices of energy and raw materials to increase rapidly.
Fourth, feverish real-estate development throughout China continues to propel land prices to new heights.
Fifth, as a result of decades of catch-up growth, China is approaching the technological frontier in many areas and the latecomer’s advantage is diminishing, which means that the marginal productivity of its capital stock is diminishing, too.
In short, the changes in China’s microeconomic foundations, together with the weaknesses in its economic structure, imply that the economy must pay a higher cost, in the form of higher inflation, for a given increase in GDP growth.
The question now is whether China’s leaders will tolerate higher inflation in order to maintain an annual growth rate of more than 8%.
The answer seems to be no.
As a result, China’s growth has reached a new plateau.
The era of growth rates above 8% is over, at least for the foreseeable future.
After three decades of breakneck growth, the Chinese economic juggernaut needs to slow down somewhat so that the machine can be fixed; only then can it return to the fast lane and accelerate anew.
But no one should bet on a Chinese crash anytime soon.
China has faced much worse on numerous occasions; each time, it muddled through.
There is still no compelling reason why this time should be different.
The Limits of Bonapartism
PARIS – After four decades, France has returned to NATO’s unified military command.
At a stroke, President Nicolas Sarkozy overturned one of the pillars of French policy – and of the legacy of Charles de Gaulle, the founder of Sarkozy’s own political party.
In effect, rather than according serious room for decision-making to his prime minister, François Fillon, or to Fillon’s cabinet, Sarkozy has arrogated almost every lever of power to himself and his advisers within the Élysée Palace.
Indeed, few informed observers doubt that Sarkozy’s chief foreign policy adviser, Jean-David Levitte, has far more influence than France’s foreign minister, Bernard Kouchner.
Likewise, on matters of domestic policy, the interior minister, Michele Alliot-Marie, has nothing close to the agenda-setting power of Claude Guéant, Sarkozy’s longtime aide and director-general of the President’s office.
For all the authoritarian habits of de Gaulle or François Mitterand, Sarkozy’s personalization of the presidency is unprecedented in the history of the Fifth Republic.
Sarkozy makes little secret of his disdain for members of his own party, luring Socialists like Kouchner and Rama Yade, the junior minister for foreign affairs, into his cabinet, and naming retired Socialist politicians like former Prime Minister Michel Rocard to head national commissions and represent France in international treaty negotiations.
Sarkozy can afford to thumb his nose at his party, given the total collapse of the opposition Socialists, who will almost certainly lose the 2012 election.
If Sarkozy governed effectively, such political and institutional departures might seem like a breath of fresh air in a society whose institutions seem increasingly ill-suited to the challenges of a multi-ethnic and post-industrial society (even though dirigiste France has conserved its industrial base better than many other rich countries).
This was how many who supported Sarkozy’s presidential bid viewed him.
Despite policy differences, Sarkozy would be for France what Margaret Thatcher was for Britain: someone who would lead the country out of its impasse, conserving the best aspects of dirigisme but finally giving entrepreneurs room to grow, cracking down on crime, and reforming education.
But Sarkozy has not governed effectively, as his party’s disenchantment with him and polling data make abundantly clear.
The manic character of his presidency – initiative spilling into initiative, each being the transformative solution to the problem at hand, all opposition denounced as lies, bad faith, and cowardice – has worn thin.
On a number of issues, notably wages, liberalization of employment rules, and reform of the judiciary and of secondary education, programs announced with tremendous fanfare have had to be delayed or withdrawn.
Almost invariably, Sarkozy has blamed the minister in question, and then moved on to the next subject to strike his interest.
In the meantime, his obsession with dominating the daily news cycle, no matter how flimsy the pretext, continues unabated.
He has even appeared at crime scenes – not urban riots, but private crimes of passion, where no reason of state could possibly warrant the presence of the President of the Republic.
Given the pathetic state of the Socialist opposition, it is difficult to see what price, if any, Sarkozy will pay for his record in office.
But this style of government – essentially an electoral campaign, not a government – virtually guarantees that almost nothing of real importance can be accomplished.
At a recent press conference, US President Barack Obama remarked that he was loathe to comment immediately on matters of great public importance before being absolutely sure that he knew – and knew what he thought about – the subject in question.
Many French wish that such self-discipline could rub off on Sarkozy.
Given his temperament, however, that hardly seems likely.
As a result, an administration in which many had placed high hopes is lapsing into demagoguery and ineffectiveness.
The Limits of Democracy
The election of the militant and hitherto extra-parliamentary group Hamas in the Palestinian territories reminds us of what democracy cannot achieve.
No one in a more established democratic state is surprised if one’s own side does not win.
Democracy is about competing parties, and, unless they form a “grand coalition,” they cannot all win.
But what if an election’s winners have no intention of abiding by the rules that are part and parcel of the democratic process?
One remembers Hitler, who, while his own party did not quite get 50% of the vote, could base his “seizure of power” on a parliamentary majority.
More recently, elections in the post-communist countries of Europe have brought groups to power whose democratic credentials are dubious, to say the least.
This is not to compare Hamas to any of these political forces.
Nevertheless, one must wonder about a winning movement with quite a few elected members in Israeli prisons and others who are not likely to get permission to enter the country in which they were elected, so that the new parliament cannot function properly.
All of this tells us three things about democracy.
First, elections rarely solve fundamental problems. In particular, they do not create a liberal order.
To be effective, elections must be preceded by an extensive period of debate and argument.
Cases have to be made and attacked or defended.
First elections, in particular, are almost inevitably of limited value as foundations of democracy, because they take place in an emotionally charged atmosphere and largely without substantive debate.
They are an invitation to assert who one is and where one belongs rather than to a competition of well-defined and comprehensive political programs.
This means, secondly, that first elections, and perhaps elections more generally, are not themselves a sufficient guarantee of liberty.
As the German constitutional court judge Ernst-Wolfgang Böckenförde famously put it, democracies cannot create the conditions of their survival and success.
What are these conditions, and who creates them?
The answer to the first question is, the rule of law.
There must be certain accepted rules of the political game that are binding on all, so that whoever does not accept or obey them is disqualified.
This is, to be sure, easier said than done.
Who sets the rules of the game?
There is an obvious logic to establishing a constitutional convention first and then holding elections under the rules agreed by it.
This is what happened in Iraq, for example.
But the constitutional convention, too, must be elected, and this election may run into the very difficulties that plague first elections to parliaments in new democracies.
Once the rules of the game are set, there still remains the question: who enforces them?
Who could say to Hamas that unless they accept certain rules, their election is not valid?
This requires a constitutional court of sorts, as well as a judiciary and institutions to enforce its rulings.
In sovereign states and territories, this is highly unlikely to come about on its own.
It is no accident that the democratic process has emerged most smoothly where there was some external power to back up the constitution.
The third lesson follows from such considerations.
Democracy in the sense of free elections within certain rules does not allow the rest of us to say that the cause of freedom has prevailed and that we can walk away.
On the contrary, democracy is a long-term task.
Some say that it is achieved only once a country has passed the “two-turnover test,” that is, two changes of government without violence.
One must add to this criterion a culture of debate that makes elections a genuine contest of a plurality of answers to the issues at stake.
For the Palestinian territories, this means that people’s expectations of the elections were probably too high.
By the same token, reducing expectations means that the significance of the results should not be exaggerated.
Who knows?
The result may yet turn out to be a stepping-stone towards an effective state that deserves international recognition.
In the meantime, the key task is to promote the rule of law, backed by the international community.
Tempering the Genetic Revolution
LEUVEN – We may not be fully aware of it, but future generations will likely consider our era truly historic.
Never before has mankind been able to understand the functioning of cells, tissues, and organs, the precise molecular mechanisms of evolution, and where and how our species originated and spread throughout the world.
The technology that allows us to unravel cellular and subcellular processes and mechanisms, identify the causes of diseases and develop more specific and effective treatments, and determine who is biologically related to us and to what degree combines knowledge from biology, computer sciences, information technology, and material sciences.
As might be expected, such a revolution in knowledge must also have a significant societal impact, requiring answers to questions that, until recently, were considered pure science fiction.
Today, it is technically possible to sequence the 2.4 meters of DNA –&#160;present in the nucleus of every cell of our body – in only a few days.
And, just as the speed of reliable sequencing continues to increase, the price of sequencing has dropped precipitously, and will soon amount to just a few hundred dollars.
Once the function of every fragment of DNA is known, nothing will stand in the way of routine sequencing.
Already, variations in the composition of about 500,000 DNA building blocks (SNPs or Single Nucleotide Polymorphisms), spread over the total length of the DNA and shown to correlate with particular physical and behavioral characteristics or susceptibility to diseases, are being analyzed routinely.
Major errors in DNA composition that are responsible for about 3,000 of the 7,000 known genetic diseases can be visualized, and efforts are underway to identify the causes of the remaining 4,000.
Meanwhile, a growing number of companies are offering a new commercial service: direct-to-consumer analysis of DNA for genealogical or medical purposes.
While their activities and clientele are steadily increasing, many of the results currently are of only limited value for determining physical and behavioral characteristics or risks of common diseases such as hypertension, cardiovascular diseases, diabetes, and depression.
Some people, however, claim the right to know all information pertaining to them, including even the slightest elevated risk for these diseases.
Some are even willing to undergo preventive measures or modify their behavior to decrease or control this risk.
Others must cope with results showing that they carry defects that significantly increase their risk of developing a hereditary form of cancer or dementia, or of transmitting a defect to their children that could, in turn, cause a serious defect in their grandchildren.
Some people – so far still a minority – are fascinated by this new knowledge, and take the results for granted.
But more research is needed before we can understand the results of sequencing correctly and apply this knowledge appropriately in risk calculations.
For example, more than 97% of our DNA contains no information for the synthesis of proteins – that is, it contains no genes – but nonetheless interacts with our genes to increase, decrease, or inhibit the production of proteins.
We also know that even if our DNA is somewhat responsible for increased risks for common diseases, and in some cases is fully responsible for inherited diseases, the environment in which this DNA functions can be as important as the composition of the DNA itself.
Indeed, from fertilization on, the environment in which the fertilized egg develops – for example, what the mother eats, whether she smokes or drinks alcohol, and whether she develops diseases or infections – places so-called epigenetic marks on the DNA or on the proteins surrounding it, affecting its function.
This conditioning effect continues and increases after birth, leading to different degrees of epigenetic marking in different organs.
Individual differences in susceptibility to diseases can be the consequence.
This is nicely illustrated in identical twins, who show as they age increasing differences in the way that their identical DNA is marked by the environment.
Nonetheless, the dangers implied by recent technological progress have become increasingly obvious.
For example, it is now possible to analyze the DNA of an unborn child from the blood of its mother and determine its risk for diseases later in life.
This opens the way to full-blown eugenics – the selection (by parents, authorities, or others) of children with characteristics considered “appropriate.”
We must take care that we do not become more fascinated by the composition of DNA and what characteristics and risks it carries than we are by the human qualities of less-than-perfect individuals, which we all are.
This does not mean that there are no applications of our knowledge that are not important, life-saving, and even necessary.
But they are more limited in number and scope than many seem to believe.
Now is a time not only to advance current research, but also to reflect and to tread cautiously.
Israel’s Missing Peace Offensive
TEL AVIV – Even before the latest cease-fire took hold, it had become clear that the dilemma facing Israel in Gaza entails more than simply developing military answers to the challenge posed by Hamas.
The real question is whether Israel’s leadership is capable of using new, non-military tools to address the anti-Israeli rage that has gained momentum across the region in the wake of the Arab Spring.
And now, in the wake of Palestine’s resoundingly successful bid for observer-state status at the United Nations, Israel’s conundrum has become particularly acute.
Israel conducted the recent showdown with Hamas in a regional context that has changed dramatically since its last incursion into Gaza, “Operation Cast Lead” in 2008.
The rise of Islamist regimes throughout the Arab world, and the subsequent shift of regional alliances, has increased the Jewish state’s isolation.
Major regional powers like Egypt, Turkey, and Qatar now support an emboldened Hamas, whose paramount objectives are now to consolidate its increased international legitimacy and sideline the West Bank-based Palestinian Authority (PA).
Indeed, Israel is now in a strategic trap, owing not only to the Arab Spring, but also to its own diplomatic blunders, particularly the disintegration of its alliance with Turkey.
No display of military muscle could help; only robust peace diplomacy could end Israel’s isolation.
Unfortunately, Israeli leaders are unable to summon the statesmanship required to manage the strategic readjustment occurring in the region.
Instead, Defense Minister Ehud Barak explained the thinking behind the recent hostilities in Gaza in typically existential terms.
He fell back on a defining speech in Israeli history, General Moshe Dayan’s eulogy for Roi Rothberg, a young soldier riddled by bullets from the Gaza Strip in 1956.
Rothberg was killed because “the yearning for peace deafened his ears, and he did not hear the voice of murder waiting in ambush.”
Dayan-Barak warned that “beyond the furrow of the (Gaza) border, a sea of hatred and desire for revenge is swelling, awaiting the day when serenity will dull our path.”
An anxious nation is counseled to be resilient: “Let us not be deterred from seeing the loathing that is inflaming and filling the lives of the hundreds of thousands of Arabs who live around us….This is the fate of our generation…to be prepared and armed, strong and determined, lest the sword be stricken from our fist and our lives cut down.”
Like Dayan before him, Barak believes that Israel, a “villa in the jungle,” is forced to go to war every few years to consolidate its deterrence in an unmerciful Middle East neighborhood, where “there is no pity for the weak, nor a second chance for the defeated.”
But Barak skipped a cruelly candid paragraph in Dayan’s speech that evoked the imposing magnitude of the Palestinian plight: “Let us not cast the blame on the murderers today….For eight years, they have been sitting in the refugee camps in Gaza, and before their eyes we have been transforming the lands and the villages where they and their fathers dwelt into our estate.
It is not among the Arabs in Gaza, but in our midst, that we must seek Roi’s blood.”
The Middle East, of course, is not a congenial neighborhood.
But audacity in the quest for peace, as demonstrated by Yitzhak Rabin and Barak himself in the past – and as Dayan demonstrated as a negotiator with Egypt– is no sign of weakness.
Like the United States, which has come to terms with the changes in the Middle East by dealing with the Muslim Brotherhood, and even with Salafists, Israel would be well advised to test Hamas on the diplomatic front.
Hamas’s military collapse would not pave the way for the moderate Fatah to return to power in Gaza; it would enthrone Islamic Jihad and Al Qaeda.
Hamas’s promise to the Palestinians, however, is a delusion.
Religious fervor and a state of permanent conflict with Israel might be a badge of identity, but they will not pave the way to victory.
Hamas is ready to expose Gaza’s civilians to Israel’s devastating retaliations as long as this serves to mobilize the region against the Zionist aggressors and to mock PA President Mahmoud Abbas’s illusions of a diplomatic solution.
Hamas understands that accommodation with the Jewish state – and attending to the tedious business of providing decent governance in Gaza, rather than accumulating a formidable arsenal with help from Iran and Sudan (for which “Palestine” is just a pretext) – would mean the end of the organization as we know it.
Yet, unlike Islamic Jihad and Al Qaeda, Hamas is susceptible to change; and this is precisely what Israeli diplomacy should strive to achieve.
This requires, first and foremost, superseding the cognitive dissonance whereby Israel dreams of engagement with the Muslim Brotherhood in Egypt but refuses that path with the Brothers’ Gazan offspring, Hamas.
Instead, Israel should acknowledge Hamas’s right to govern, which means opening the borders (including the Rafah crossing to Egypt), lifting the siege, and allowing free movement of goods and people.
Moreover, Israel should use Egypt’s vital role in brokering the recent cease-fire as an opportunity to expand the bilateral dialogue with the new Islamist regime in Cairo to include issues of peace and regional security.
President Mohamed Morsi’s government cannot be uninterested in periodic flare-ups in Gaza, which serve only to destabilize Egypt.
The current cease-fire, however, will be as short lived as many others before it – its terms are practically identical to those that ended Operation Cast Lead – if Israel does not follow up with a vigorous peace initiative on the broader Palestinian front.
Europe’s Pain without Gain
VITORIA-GASTEIZ – In a recent interview, French President François Hollande made the crucial, but often forgotten, point that there are limits to the level of sacrifice that can be demanded of the citizens of southern Europe’s financially distressed countries.
To avoid turning Greece, Portugal, and Spain into collective “correctional houses,” Hollande reasoned, people need hope beyond the ever-receding horizon of spending cuts and austerity measures.
Even the most rudimentary understanding of psychology supports Hollande’s assessment.
Negative reinforcement and delayed gratification are unlikely to achieve their goals unless there is a perceived light at the end of the tunnel – a future reward for today’s sacrifices.
Public pessimism in southern Europe is largely attributable to the absence of such a reward.
As declining consumer confidence and household purchasing power deepen the recession, projections of when the crisis will end are repeatedly pushed back, and those bearing the brunt of austerity are losing hope.
Throughout history, the concept of sacrifice has merged theology and economics.
In the ancient world, people made often-bloody offeringsto divinities, whom they believed would reward them with, say, good harvests or protection from evil.
Christianity, with its belief that God (or the Son of God) sacrificed Himself to expiate humanity’s sins, inverted the traditional economy of sacrifice.
In this case, divine suffering serves as an exemplar of the selflesshumility with which earthly misfortunes should be endured.
Despite secularization, the belief that rewards, or achievements, require sacrifice has become an integral part of European cultural consciousness.
The idea of a “social contract” – which arose during the Enlightenment in orderto address, without resort to divine right, the legitimacy of the state’s authority over its citizens – rests on the premise that individuals surrender a certain degree of personal liberty in order to secure peace and prosperity for all.
As a result, political leaders have often asked citizens to sacrifice personal freedoms and comforts in the name of secularized spiritual entities, such as the nation or the state – and citizens have eagerly obliged.
In his first speech to the House of Commons as Prime Minister of the United Kingdom, Winston Churchill inspired hope in a beleaguered nation when he famously declared that he – and thus Britain – had “nothing to offer but blood, toil, tears, and sweat.”
Given such countless precedents, it may be surprising that the rhetoric of sacrifice under the banner of austerity has proven so ineffective in Europe’s current crisis.
Some observers blame declining levels of commitment to anything that transcends the individual, including the political system.
But resistance to austerity in southern Europe is not rooted in general hostility toward sacrifice.
Rather, Europeans have come to believe that their leaders are demanding sacrifices that do not advance their interests.
Churchill gave Britons something to look forward to: victory.
Without a clear end that justifies it, sacrifice becomes meaningless.
Prosperity was supposed to legitimize the European Union.
After the period of rapid economic growth ended, Europe’s leaders came to rely, instead, on the threat of an evil that is greater than austerity: further destabilization of debtor countries, leading to default, expulsion from the eurozone, and economic, social, and political collapse.
But the rhetoric of fear is losing sway, because the “new deal” taking shape across southern Europe offers morerepression and less protection, thus violating the social contract’s fundamental tenets.
Indeed, while European citizens are being asked to sacrifice their standard of living – and even their livelihoods – for the sake of the “national economy,” transnational corporations are thriving.
The conditions imposed by the “troika” – the European Commission, the European Central Bank, and the International Monetary Fund – amount to an indefinite delay in addressing the needs of those asked to sacrifice and in repairing tattered social safety nets.
Yet national governments continue to implement policies that exacerbate injustice.
For example, Portugal’s 2013 budget reduces the number of tax brackets from eight to five – a move that will devastate the middle class.
Sacrifice used to involve ransoming the body – its pleasures, basic needs, and even vitality – for the sake of the spirit.
While the discourse of sacrifice persists, the logic that has shored it up for millennia has been abandoned.
Europe’s leaders must imbue their citizens with renewed hope.
The legitimacy of “post-national” Europe – based on the EU’s obligation, enshrined in the Lisbon Treaty, to promote “the well-being of its people” – is at stake.
The Only Game in Town
TOKYO – What should central banks do when politicians seem incapable of acting?
Thus far, they have been willing to step into the breach, finding new and increasingly unconventional ways to try to influence the direction of troubled economies.
But how can we determine when central banks overstep their limits?
When does boldness turn to foolhardiness?
Central banks can play an important role in a cyclical downturn.
Interest-rate cuts can boost borrowing – and thus spending on investment and consumption.
Central banks can also play a role when financial markets freeze up.
By offering to lend freely against collateral, they “liquify” assets and prevent banks from being forced to unload loans or securities at fire-sale prices.
Anticipating such liquidity insurance, banks can make illiquid long-term loans or hold other illiquid financial assets.
To the extent that unconventional monetary policy – including various forms of quantitative easing, as well as pronouncements about prolonging low interest rates – serves these roles, it might be justified.
For example, the US Federal Reserve’s first round of so-called quantitative easing (QE1), implemented in the midst of the crisis, was doubly effective: By purchasing mortgage-backed securities, the Fed brought down interest rates in that important market (in part, probably, by signaling its confidence in those securities), and restored it to vitality.
Similarly, with its outright monetary transaction (OMT) program, the European Central Bank has offered to buy peripheral eurozone countries’ sovereign bonds in the secondary market – provided that they sign up to agreed reforms.
The logic is that conditionality will ensure that countries are solvent, while OMTs will restore trust to a market that has broken down because investors fear that the countries concerned will exit the eurozone.
Again, its effect, thus far, has been significant.
Other unconventional policies, however, have been undertaken to stimulate the economy, rather than to deal with broken markets.
The benefits have been commensurately smaller.
QE2, in which the Fed bought long-term government bonds, did not have a discernible effect on long-term government interest rates.
Indeed, with its recent decision to pursue QE3, the Fed is focusing once again on the mortgage-backed securities market; but, given that the market is much healthier now, it is unclear how much good this will do.
Recently, the Fed expressed its intent to keep policy rates low for a long time – until employment picks up strongly.
The hope is that if investors consider this announcement credible, long-term interest rates will come down further, encouraging spending.
But the immediate effect on long-term bond rates has not been encouraging.
As central banks venture farther into uncharted territory, advocates argue that at worst they will do no harm.
In fact, no one really knows.
For example, sustained low interest rates hurt savers who traditionally prefer safe short-term investments.
Pensioners and those near retirement, facing low income from interest, may cut back further on consumption, weakening the economy.
Bolder pensioners, desperate to generate higher returns, may take undue risks – for example, investing in junk bonds – that could jeopardize their nest eggs.
And, unfortunately, such financial risk-taking may have little impact in terms of spurring corporations to assume more risk by investing.
Similarly, a potential downside to quantitative easing is that low interest rates send capital to higher-growth, high-interest-rate countries.
In theory, as capital floods in, these countries’ exchange rates will appreciate rapidly, making them look unattractive and automatically stemming the flow.
In practice though, as investors make money on their trades, they bring in yet more money, forcing further currency appreciation.
All too often, the process does not end smoothly but in a crash.
No wonder recipient countries resist inflows of hot capital.
We also know little about how smooth the exit from quantitative easing will be.
In theory, as the economy picks up and interest rates begin to climb, central banks will simply pay higher interest rates on their reserves, so that they can finance their holdings of long-term securities and shrink them slowly.
But higher interest rates also imply large capital losses for central banks’ asset holdings.
Even if some of these losses are offset for the government as a whole (as the central bank loses on its holdings of government debt, the treasury gains in equal measure, because the debt it owes is worth less), the losses on long-term private debt holdings are real.
Moreover, the argument that losses are offset is not easy to explain to the public.
Will opinion be sympathetic to the Fed when politicians like Ron Paul excoriate it for losing tens of billions of dollars monthly on its asset holdings?
Will bond markets fall sharply (and interest rates rise) as markets fear that the Fed will be pushed to sell its enormous holdings in short order?
A last defense offered by advocates of continuing on the path of adventurous monetary policy, even when the perceived benefits are small, is that, because politicians refuse to settle their differences and act, monetary policy is “the only game in town.”
In democracies, when there are no other alternatives, politicians often eventually do the right thing.
By creating the impression that something beneficial is being done, unconventional monetary policy relieves pressure on politicians.
So, when central bankers argue that they are the only game in town, they are ensuring that outcome.
Central bankers nowadays enjoy the popularity of rock stars, and deservedly so: their response to the difficult and uncertain environment during and after the financial crisis has been largely impeccable.
But they must be able to admit when they are out of bullets.
After all, the transformation from hero to zero can be swift.
The \
Since the Cold War’s end, all kinds of barriers have come down, and the world economy has fundamentally changed.
Until 1989, the global market encompassed between 800 million and one billion people.
Today, it is three times larger, and growing.
Indeed, we are witnessing one of the most dramatic revolutions in modern history, and it is occurring almost unnoticed.
From a model applicable to the minority of the world’s population, “Western consumer society” is becoming the dominant economic model of the world, one to which there is increasingly no alternative.
By mid-century, the lives of seven billion people might be governed by its laws.
The West has established the economic model of the twenty-first century, with its hitherto unheard of standard of living, and almost all nations and regions are trying to equal it, no matter what the cost.
When, in the 1970’s, the Club of Rome issued its famous report on the “Limits to Growth,” the reaction was one of concern.
Over the years, however, as the world economy continued to grow without interruption – and, in the current age of globalization, seemingly without limits – the dire predictions of the Club of Rome have become increasingly an object of ridicule.
And yet the Club of Rome’s basic insight – that we live and work in a finite global ecosystem, with exhaustible resources and capacities – has returned to challenge us again.
The world is not preoccupied today by the “limits to growth,” but awareness of the consequences of growth on the earth’s climate and ecosystem is becoming prevalent.
China, for example, needs annual growth rates of 10% to keep its huge economic, social, and ecological problems under control.
There would be nothing sensational about this if China were a country like Luxembourg or Singapore.
But China has 1.3 billion people.
So the consequences of its economic growth are much more serious.
Global demand for energy, raw materials, and food is increasingly influenced by rising demand in China and India, whose combined population is 2.5 billion.
Other large and populous emerging countries in Asia and South America are following in these giants’ footsteps.
Steadily rising prices of raw materials, agricultural products, and energy already reflect fears about future shortages.
These undesirable consequences of the expansion of world markets have assumed alarming proportions within a relatively short period of time.
China is on course, this year or next, to overtake the United States as the world’s largest CO2 emitter, even though its per capita emissions are only one-fifth or even less of the US level.
What will the world look like when China reduces this difference to one-half?
And India is following close behind China in its level of carbon emissions.
Will the global ecosystem be able to absorb these additional pollutants without considerable changes in the ecosphere?
Obviously not, as a large majority of climatologists are now warning.
These basic data have been known for a long time, and only a few deny that rapidly accelerating man-made climate change is occurring.
But one might conclude from the bizarre debates we engage in about climate change that what the world needs is a change in its political and psychological mood, rather than a profound social and economic transformation.
So, despite grand rhetoric, very little is being done.
Emerging countries continue to grow every year.
The US has almost totally backed away from the global fight against pollution, and, through uncontrolled growth, solidifies its position as the world’s leading polluter.
The same pattern holds true for Europe and Japan, albeit on a slightly smaller scale.
In view of this global challenge, the G-8 countries have made a heroic decision: the eight richest industrial countries – which are also the largest polluters – promised to “seriously examine” cutting their emissions in half by 2050.
This rhetorical heroism is enough to leave the world speechless.
Indeed, it remains to be seen if the European Union will even be able to implement its promise to cut CO2 emissions by 20-30% by 2020.
So far, the EU has not really come up with any practical ways to do this.
But the solution to the challenge of global climate change is as plain as day.
The only chance of improvement is to decouple economic growth from energy consumption and emissions.
This must happen in the emerging countries, and even more urgently in the old industrial economies.
Such decoupling can occur only if we do away with the illusion that pollution is cost-free.
We can no longer get away with subsidizing economic growth and standards of living at the expense of the global environment.
Human population has simply become too large to be able to afford it.
Doing away with this illusion requires the creation of a global emissions market – still a very distant goal.
It also requires more energy efficiency, which means a reduction of waste in both energy production and consumption.
Rising energy prices already point in this direction, but this knowledge has yet to register.
Finally, it requires a technological and politico-economic breakthrough in favor of renewable energy, rather than a return to nuclear power or coal.
In essence, then, we are confronted by a three-pronged challenge of a new “green” industrial revolution.
Coping with this global challenge also offers an enormous opportunity for future prosperity and social justice that we must seize.
Of course, there will be many powerful losers as we make these changes.
They are not about to accept their “disempowerment” without a struggle.
At the moment, they still seem to have the upper hand, as evidenced by much talk and no action.
This is precisely what needs to change.
The Lingering Shadow of Mad Cow Disease
Optimists are proclaiming that variant Creutzfeldt-Jakob disease (CJD), the human form – always fatal – of bovine spongiform encephalopathy (BSE), or “Mad Cow Disease,” is on the wane.
Obviously, given the degree of suffering and public anxiety that variant CJD has caused, the possibility that it is receding is welcome news.
But is it true?
CJD belongs to the family of what are called prion diseases, a unique group of neurodegenerative diseases that can be transmitted.
Although the precise nature of the disease’s transmission remains uncertain, a key event in these disorders is the conversion of the prion protein’s normal cells to an abnormal form that appears to be the major (if not the sole) component of the infection.
Variant CJD was first described in 1996, following intensive surveillance activities undertaken by the UK National CJD Surveillance Unit (NCJDSU) in Edinburgh.
This new form of prion disease had distinctive clinical and pathological features, and occurred in young patients within a single genetic subgroup.
My colleagues and I in NCJDSU argued that this new form of human prion disease was likely to be linked to exposure to the BSE agent, probably by eating BSE-infected meat products.
Later investigations have shown that the transmitting agent in variant CJD shares identical biological properties with BSE’s agent, supporting a causal relationship.
BSE occurred as an epidemic in the UK after its identification in 1986, and several million BSE-infected cattle are likely to have entered the human food chain between 1980 and 1996.
It is estimated that most of the UK population was exposed to BSE through diet at this time.
Subsequent epidemiological studies in the NCJDSU indicate that individuals with variant CJD are likely to have consumed more meat products than control patients, further supporting a link between these disorders.
Moreover, epidemiological studies indicated that BSE was likely to have been transmitted to cattle (and other species) by meat-and-bone-meal animal feed produced by UK rendering plants and exported to many countries.
This pattern of trade has now been mirrored in the increasing geographical spread of BSE from the UK to other countries in Europe, and more recently to Japan and the United States.
This unfortunately has been accompanied by increasing number of variant CJD cases in Canada, France, Ireland, Italy, Japan, Netherlands, Portugal, Saudi Arabia and the USA.
In the UK, however, the epidemic of variant CJD seems to have peaked in 2000 and is now in decline, with 156 cases being identified so far.
However, a retrospective study of abnormal prion protein accumulation in appendix and tonsil samples from over 12,600 people in the UK has yielded three more cases, which suggests that the level of BSE infection in the UK population is much higher than the actual number of confirmed variant CJD cases indicates.
Given the extensive exposure of the UK population to BSE in the late 1980’s and early 1990’s, what explains the low number of confirmed cases?
One clue lies in the results of studies of the transmission of BSE and variant CJD in mice, which in many cases does not result in death from clinical disease, but instead can produce an asymptomatic “carrier state,” in which the disease has not yet manifested itself.
These findings have been reinforced by an extensive control study to identify risk factors for variant CJD, which recently identified two cases of human-to-human transmission of variant CJD infection through transfusions of particular types of red blood cells.
These cases are particularly interesting, because the first case resulted in the clinical onset of variant CJD (with typical symptoms and pathology) 6.5 years after the transfusion from a donor who, although asymptomatic at the time of donation, subsequently developed and died from CJD. 
The second case involved a known recipient of such cells transfused from another asymptomatic donor who subsequently died from variant CJD, whereas the recipient showed no evidence of neurological disease and died of unrelated causes.
However, abnormal prion protein was detected in the recipient’s lymphoid tissues, indicating transmission of infection from an asymptomatic individual.
These cases have major implications for blood safety everywhere, implying additional restrictions on eligibility for blood donation and on the processing and handling of blood and blood products.
Individuals infected with BSE who remain in an asymptomatic state during their lives could represent a risk to others of potential secondary transmission of variant CJD through blood transfusion or surgery.
Further uncertainty regarding the future of variant CJD arises from the observation that the average age of the patients in the UK has not increased significantly over the past 10 years.
If the epidemic were in decline, it might be anticipated that the average age of the patients would increase in the final stages (as occurred with cattle in the UK that were infected with BSE).
But variant CJD affects patients who are much younger than sporadic CJD patients, which might be due to either age-related exposure to BSE or age-related susceptibility.
Until we know the answers to these questions, it seems premature to decide that we are witnessing the beginning of the end of variant CJD.
On the contrary, the cases identified so far may be only the tip of the iceberg, with a much larger number of asymptomatic infections posing a risk to public health through secondary transmission.
Indeed, secondary transmission by blood transfusion or surgical instruments might even result in variant CJD becoming endemic in the UK population.
This would prove impossible to eradicate in the absence of improved means of cleaning and decontaminating surgical instruments and a specific test – preferably based on a blood assay – to screen asymptomatic carriers.
Nutrition for Growth
GENEVA – This week, British Prime Minister David Cameron, whose country holds this year’s G-8 Presidency, is hosting a “Nutrition for Growth” summit in London.
The issue could not be more urgent.
We need the political will to tackle malnutrition now, with access to nutritious food recognized as a fundamental human right.
Malnutrition kills an innocent child every five seconds, and is responsible for 11% of the global burden of disease.
The summit rightly focuses on the direct links between nutrition and productivity, economic growth, and political stability.
Investment in nutrition is investment in generations of children in poor communities, and the summit must place women and mothers at the center of proposed solutions.
That is all the more important because a new baby boom is taking place – not in the United States or Europe, but in Sub-Saharan Africa and Southeast Asia.
Infants born over the next 20 years will enter adulthood at a unique time: these regions’ working populations will outnumber their non-working populations by two to one.
This provides a rare opportunity to boost economic growth, save and improve lives, and help families, communities, and countries move from poverty to prosperity.
Recent research has shown that nutrition can be a major catalyst of inclusive economic growth, with each dollar of investment yielding a return of $15-138 dollars.
Defeating malnutrition is not only an ethical duty; we also know that it can boost GDP growth in Africa and Asia by up to 11%.
We now know that giving pregnant mothers and their babies essential nutrients in the critical 1,000-day window from conception to a child’s second birthday is the best investment in their health and that of society at large.
The alternative is stunting, which currently afflicts an astronomical 165 million children.
Indeed, stunting has come to represent the true face of contemporary global poverty, causing irreparable damage to children’s cognitive development and physical growth.
Moreover, there is ample medical evidence that malnutrition in this “window of nutrition” is linked to increases in hypertension, cardiovascular disease, diabetes, and even obesity, resulting in higher health-care costs later in life.
But in India, a 2011 study of 112 rural districts across the country found that “less than 20% of mothers had heard the word for malnutrition in their local language.”
In Africa, most food is produced by women smallholder farmers.
Yet malnutrition is rife because these women own only 2% of the land and access only 10% of the available extension services.
To paraphrase what many women farmers have said to me, “We are the primary producers.
But we receive very little for our hard work, because by the time our produce reaches the market, middlemen have taken the profit.
But Africa would starve if we went on strike.”
Any solution to hunger and malnutrition must place such women at its core.
Recent development research is unambiguous: empowering women and raising their incomes results in better education, health, and nutrition for their children.
We must make markets work for them and their families.
The summit’s appeal for global unity to combat malnutrition must target heads of state, finance and health ministers, as well as business and civil-society leaders.
We have to make the food system work for all citizens, which requires stronger action from each of these actors.
In particular, governments must invest in nutrition through budgets, introduce mandatory fortification of staple foods, curb “junk food,” and improve quality control.
Similarly, civil-society organizations must build robust advocacy and education programs that work with local communities to change unhealthy eating habits, emphasize the critical importance of exclusive breast feeding in the first six months, and explain the link between lifestyle, diet, and exercise in preventing disease.
Finally, the business community should use its management expertise, marketing, technology, logistical capacity, and reach to improve the quality and affordability of nutritious foods on the market.
Moreover, large companies should use their global supply chains to empower their workforces and women smallholder farmers.
Local, large-scale solutions are emerging.
In Bangladesh, where the rate of malnutrition is among the highest in the world, an affordable vitamin and mineral supplement is now available that can be added to porridge and soup.
A partnership between BRAC, the world’s largest development NGO, and the Bangladeshi pharmaceutical company Renata produces the supplement from locally available chickpeas and lentils; tens of thousands of health-care workers then distribute it.
Similarly, in India’s Rajasthan state, high-quality complementary foods produced by decentralized women’s self-help groups are improving the nutrition of children aged 6-36 months.
In Ghana, a new instant maize-based product, enriched with vitamins and minerals, is the first of its kind on the market, owing to its affordability and natural integration with breastfeeding.
As a result, the nutrition of more than one million children will be improved during their first 1,000 days of life.
We need greater innovation in finding solutions.
We need partnerships that leverage the knowledge and solutions that come from local communities.
While we recognize the commitment of the United Kingdom in promoting the new Scaling Up Nutrition movement, coordinated by the United Nations, we also know that who sits at the table to design solutions determines who eats at the table later.
By investing now in nutrition and improved food security, by 2020 we can lift 50 million people out of poverty, prevent stunting in 20 million children under the age of five, and save 1.7 million lives.
The Liquidity Puzzle
We increasingly hear that “the world is awash with liquidity,” and that this justifies expecting asset prices to continue rising.
But what does such liquidity mean, and is there really reason to expect that it will sustain further increases in stock and real estate prices?
Liquid assets are assets that resemble cash, because they can easily be converted into cash and used to buy other assets.
The idea seems to be that there are a lot of liquid assets lying around, and that they are being used to get money to bid up the prices of stocks, housing, land, art, etc.
That theory sounds as general and fundamental as the theory that global warming is melting glaciers and raising sea levels around the world.
Rising sea levels would explain a lot of geological and economic events.
Is rising financial liquidity really a similar force?
What is this theory anyway?
Traditionally, “awash with liquidity” would suggest that the world’s central banks are expanding the money supply too much, causing too much money chasing too few goods.
But if that were the problem, one would cause all prices – including, say, clothing and haircuts – to rise.
That is what the Federal Reserve Chairman Arthur Burns meant when he said that the United States was “awash with liquidity” in 1971, a period when the concern was general inflation.
But the recent popular use of the term “awash with liquidity” dates to 2005, a time when many central banks were tightening monetary policy.
In the US, the Fed was sharply raising rates.
Central banks worldwide clearly have been behaving quite responsibly with regard to general inflation since 2005.
According to the IMF, world inflation, as measured by consumer price indices, has generally been declining since 2005, and has picked up only slightly in 2007.
So it is something of a puzzle why people started using the term so much in 2005.
It may have had something to do with the near-total lack of response of long-term interest rates to monetary tightening.
If central banks are tightening and long-term rates aren’t rising, one needs some explanation.
Liquidity is just a nice-sounding word to interpret this phenomenon.
Another interpretation is that people are saving a great deal, and that all this money is chasing investment assets, bidding up prices.
Current Fed Chairman Ben Bernanke raised this idea a few years ago, alleging a world “saving glut.”
But, once again, the data do not bear this out.
The IMF’s world saving rate has maintained a fairly consistent downward trend since the early 1970’s, and, while it has picked up since 2002, it is still well below the peak levels attained in the previous three decades.
True, savings rates in emerging markets and oil-rich countries have been increasing since 1970, and especially in the last few years, but this has been offset by declining saving rates in advanced countries.
Another interpretation is that “awash with liquidity” merely means that interest rates are low.
But interest rates have been increasing around the world since 2003.
Hardly anyone was saying the world was “awash with liquidity” in 2003.
The use of the term has grown in parallel with rising , not falling, interest rates.
Yet another theory is that changes in our ways of handling risk have reduced risk premia.
The growth of the financial markets’ sophistication has allowed risks to be sliced and diced and spread further than ever before.
Indeed, the much-vaunted market for collateralized debt obligations, which divides risks into tranches and places the different risk levels in different places according to the willingness to accept them, has plausibly played a role in boosting asset prices.
But this is really a theory about risk management for certain kinds of products, not “liquidity” per se .
Hyun Song Shin of Princeton University proposed a theory of excess liquidity in a paper with Tobias Adrian that he presented last month at the Bank for International Settlements in Brunnen, Switzerland.
He says that it merely reflects a feedback mechanism that is always present: any initial upward shock to asset prices strengthens the balance sheets of financial institutions, so in response they borrow more and bid up prices even more.
But if that is what the term “awash with liquidity” means, then its widespread use today is simply a reflection of the high asset prices that we already have.