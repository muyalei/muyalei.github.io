But her family and teachers failed to recognize the problem, so she received no support or professional help.
This lack of early treatment undermined her recovery, and she has continued to experience episodes of depression throughout her life.
In order to help ensure that more people did not have to suffer alone as Betty had, we resolved to create a mental-health first-aid training course in our local community.
Three years later, when Betty reduced her paid employment in order to develop Mental Health First Aid training, we were finally able to launch the course.
The benefits of this initiative quickly became apparent, with evaluation studies showing that participants became more accepting of the health significance of mental illnesses, more confident in their ability to help others, and motivated to apply their knowledge after completing the course.
Such positive results helped to drive the course’s expansion.
By 2005, it was operating across Australia and in Scotland and Hong Kong, and has since spread to more than 20 other countries.
Over 200,000 people in Australia alone – more than 1% of the population – have now received the training.
This rapid growth should not be surprising, given the prevalence of mental-health problems worldwide.
In Australia, roughly one in five adults is affected by a diagnosable mental-health problem each year, but many of these people receive no professional help.
The statistics are similar in other developed countries.
This means that everyone will either be personally affected by a mental-health problem or have close contact with someone who is.
Indeed, most people will have contact, whether they are aware of it or not, with someone who is suicidal.
Research shows that whether or not a person obtains professional help is strongly influenced by the encouragement and attitudes of those close to them.
People with strong support networks have a significantly better chance of recovery than those whose problems go undetected or are ignored or minimized.
Given this, ensuring awareness and acceptance in communities, while enhancing people’s ability to identify potential mental-health problems in others and to provide help, is vitally important.
This need is particularly pressing for those – such as parents, teachers, youth workers, and sports coaches – who are in regular contact with young people.
Mental-health problems tend to arise early in life, with the first episode occurring during adolescence or early adulthood – a critical phase of development, when people are completing their education, joining the work force, building key relationships, and forming health habits.
Without a strong support system, mental-health problems can disrupt these developments, damaging the future prospects of those whom they affect.
While the Mental Health First Aid course’s rapid expansion has helped to improve the situation in many communities, there is much left to do.
In the short term, all developed countries should aim to achieve 1% participation rates in mental-health first-aid courses, as Australia has.
In the longer term, countries should aim to match participation rates in conventional first-aid courses.
In the last three years, 11% of Australia’s population has completed such a course, partly owing to requirements that people in certain positions, such as child-care workers, have a first-aid certificate.
Requiring that people in particular occupations – including high-school teachers, nurses, and police officers – acquire a mental-health first-aid certificate would significantly enhance participation, thereby strengthening support for those who are struggling with mental-health problems.
Such certifications are even more important in the developing world, given the limited availability of mental-health professionals.
Pilot work in rural India shows that the mental-health first-aid approach can be successfully adapted to the needs of communities with limited resources.
In developed and developing countries alike, the scope of the problem is too large to be left exclusively to mental-health professionals.
Every member of the community must be empowered to protect and improve their own mental health, and that of those around them.
The Globalization of Protest
NEW YORK – The protest movement that began in Tunisia in January, subsequently spreading to Egypt, and then to Spain, has now become global, with the protests engulfing Wall Street and cities across America.
That slogan echoes the title of an article that I recently published, entitled “Of the 1%, for the 1%, and by the 1%,” describing the enormous increase in inequality in the United States: 1% of the population controls more than 40% of the wealth and receives more than 20% of the income.
And those in this rarefied stratum often are rewarded so richly not because they have contributed more to society – bonuses and bailouts neatly gutted that justification for inequality – but because they are, to put it bluntly, successful (and sometimes corrupt) rent-seekers.
This is not to deny that some of the 1% have contributed a great deal.
Indeed, the social benefits of many real innovations (as opposed to the novel financial “products” that ended up unleashing havoc on the world economy) typically far exceed what their innovators receive.
Worse, the bankers are now back at their desks, earning bonuses that amount to more than most workers hope to earn in a lifetime, while young people who studied hard and played by the rules see no prospects for fulfilling employment.
The rise in inequality is the product of a vicious spiral: the rich rent-seekers use their wealth to shape legislation in order to protect and increase their wealth – and their influence.
The US Supreme Court, in its notorious Citizens United decision, has given corporations free rein to use their money to influence the direction of politics.
But, while the wealthy can use their money to amplify their views, back on the street, police wouldn’t allow me to address the OWS protesters through a megaphone.
The contrast between overregulated democracy and unregulated bankers did not go unnoticed.
But the protesters are ingenious: they echoed what I said through the crowd, so that all could hear.
And, to avoid interrupting the “dialogue” by clapping, they used forceful hand signals to express their agreement.
They are right that something is wrong about our “system.”
Around the world, we have underutilized resources – people who want to work, machines that lie idle, buildings that are empty – and huge unmet needs: fighting poverty, promoting development, and retrofitting the economy for global warming, to name just a few.
In America, after more than seven million home foreclosures in recent years, we have empty homes and homeless people.
The protesters have been criticized for not having an agenda.
But this misses the point of protest movements.
They are an expression of frustration with the electoral process.
They are an alarm.
The anti-globalization protests in Seattle in 1999, at what was supposed to be the inauguration of a new round of trade talks, called attention to the failures of globalization and the international institutions and agreements that govern it.
When the press looked into the protesters’ allegations, they found that there was more than a grain of truth in them.
The trade negotiations that followed were different – at least in principle, they were supposed to be a development round, to make up for some of the deficiencies highlighted by protesters – and the International Monetary Fund subsequently undertook significant reforms.
So, too, in the US, the civil-rights protesters of the 1960’s called attention to pervasive institutionalized racism in American society.
That legacy has not yet been overcome, but the election of President Barack Obama shows how far those protests moved America.
On one level, today’s protesters are asking for little: a chance to use their skills, the right to decent work at decent pay, a fairer economy and society.
Their hope is evolutionary, not revolutionary.
But, on another level, they are asking for a great deal: a democracy where people, not dollars, matter, and a market economy that delivers on what it is supposed to do.
The two are related: as we have seen, unfettered markets lead to economic and political crises.
Markets work the way they should only when they operate within a framework of appropriate government regulations; and that framework can be erected only in a democracy that reflects the general interest – not the interests of the 1%.
The best government that money can buy is no longer good enough.
The Global Jobs Challenge
NEW YORK – Over the past three decades, hundreds of millions of new workers have entered the global economy.
They arrived with various levels of education and skill, and over time have generally gained in terms of “human capital” – and in terms of value added and income.
This has brought a tremendous, and ongoing, growth in income levels, opportunities, and the size of the global economy.
But these new workers have also brought more employment competition and significant shifts in relative wages and prices, which is having profound distributional effects.
These massive structural changes in the global economy present three great employment challenges worldwide, with different countries facing their own variants.
The first challenge is to generate enough jobs to accommodate the inflow of new entrants into the labor market.
Clearly, a wide range of advanced and developing countries is failing to do so.
Youth unemployment is high and rising.
Even in fast-growth developing countries, surplus labor is awaiting inclusion in the modern economy, and the pressure is on to sustain job creation.
The second challenge is to match skills and capabilities to the supply of jobs – an adjustment that takes time.
It is also a moving target.
Globalization and major labor-saving technologies have thrown labor markets in many countries into disequilibrium.
Skills mismatches abound.
Moreover, with continuing rapid growth in developing countries, the global economy’s structure is far from static, and it seems clear that the pace of market adjustment is lagging that of structural change.
The third challenge is distributional.
As the tradable part of the global economy (goods and services that can be produced in one country and consumed in another) expands, competition for economic activity and jobs broadens.
That affects the price of labor and the range of employment opportunities within all globally integrated economies.
Subsets of the population gain, and others lose, certainly relative to expectations – and often absolutely.
Many advanced countries – in fact, most of them – have experienced limited middle-income growth.
In some European countries, where income inequality has remained in check, this has been a component of a deliberate strategy to maintain employment growth and competitiveness in the tradable part of the economy, with wage restraint partly shared across the income distribution.
In the United States, income inequality has risen as the upper end of the income and education spectrum benefits from globalization, while the rest experience declining employment opportunities in the tradable sector.
For two decades prior to the 2008 crisis, employment levels were maintained – and downward pressure on incomes mitigated – by creating jobs in non-tradable sectors.
In some cases, this took the form of rapid growth in government; in others, like the US, a pattern of excessive, debt-fueled consumption underpinned a large shift in employment to (non-tradable) services and construction.
Indeed, government and health care (both largely non-tradable) accounted for almost 40% of net employment growth in the US between 1990 and 2008.
That pattern came to a sudden stop in the financial crisis of 2008.
Private-sector leverage declined and public-sector leverage reached – and exceeded – sustainable limits, with Greece being only the most extreme example.
But expectations created by pre-crisis growth patterns adjust slowly.
Because the dominant narrative still maintains that the pre-crisis period was normal, at least in terms of the growth pattern in the real economy, the perceived challenge is to restore growth according to the pre-crisis pattern.
Unfortunately, this narrative cannot explain why, particularly in the advanced countries, growth is faltering and the employment engines have largely shut down.
Part of the answer consists in the long, lingering impact of financial crises and deleveraging, well documented by Carmen Reinhart and Kenneth Rogoff in their book This Time is Different.
At the same time, the financial imbalances and distortions that precede a crisis delay appropriate and necessary responses to technological and global market forces in the real economy as well.
In short, economies and policies adjusted in an unsustainable fashion, to some extent obscuring the need for a more sustainable pattern of adaptation.
What does it mean – for individuals, businesses, and governments – that structural adjustment is falling further and further behind the global forces that are causing pressure for structural change?
Above all, it means that expectations are broadly inconsistent with reality, and need to adjust, in some cases downward.
But distributional effects need to be taken seriously and addressed.
The burden of weak or non-existent recoveries should not be borne by the unemployed, including the young.
In the interest of social cohesion, market outcomes need to be modified to create a more even distribution of incomes and benefits, both now and in inter-temporal terms.
After all, underinvestment now implies diminished opportunity in the future.
The imperative of structural adjustment also implies that individuals, governments, and other institutions (especially schools) need to focus on increasing the speed of adjustment to meet rapidly shifting market conditions.
Attention to both the demand and supply sides of job markets is required.
This means not only matching skills to jobs, but also expanding the range of jobs to match skills.
Finally, global economic-management institutions need to address whether the pace of globalization, and its implied structural change, is faster than the capacity of individuals, economies, and societies to adjust can withstand.
If so, the next challenge will be to find non-destructive ways to moderate the pace in order to bring capacity to adjust and the need for adjustment into closer alignment.
None of this will be easy.
We do not now have well developed frameworks for understanding structural change.
Nevertheless, the unemployed and underemployed, especially younger people, expect their leaders and institutions to try.
The Global Roots of Euro-Jitters
FLORENCE – It is too simplistic to explain the current wave of concern about the euro in terms of Greece’s problems.
Greece has massive fiscal and competitiveness problems, but Greece (2.25% of the population of the European Union) is smaller than California (12% of the population of the United States).
And California, too, is suffering massive fiscal difficulties and declining competitiveness in some of the industries in which Californians were once pioneers.
The euro’s current problems are, instead, a reflection of unresolved Europe-wide and global problems.
The common currency is the canary in the mine of the global exchange-rate system.
The euro precisely measures international tensions in that it is a bold experiment: a currency that is not linked to a state, but rather follows from international rules and treaties.
It is a creature of the intellect rather than a product of power.
It is a post-modern or post-sovereign currency.
But in the aftermath of a crisis, countries put national interests above their willingness to go along with international rules.
The creation of money is often thought to be the domain of the state: this was the prevalent doctrine of the nineteenth century, reaching its apogee in the German economist Georg Friedrich Knapp’s The State Theory of Money .
In the New Testament, Christ famously answers a question about obedience to civil authorities by examining a coin and telling the Pharisees, “Render unto Caesar what is Caesar’s.”
Unlike most banknotes and coins, there is no picture of the state or its symbols – no Caesar – on the money managed by the European Central Bank.
There has always been a close relationship between European monetary integration and global problems.
Europeans thought that their close geographic proximity and shared cultural inheritance might enable them to produce answers where global debates had become stalled.
When things did not work out globally, a regional solution might be possible.
The impetus to the first act of European monetary integration, the 1970 Werner Report, stemmed from awareness that there were major difficulties in the fixed exchange-rate system established in 1944 at the Bretton Woods conference.
Nobody outside the US could force it to restrain either its monetary policy, which was becoming increasingly expansive under President Richard Nixon, or its fiscal policy, marked by mushrooming deficits due to the costs of the Vietnam war.
Policymakers in France loved to quote a remark by the French poet Paul Valéry, who in the middle of the chaos of the Great Depression had written that “Europe visibly aspires to be governed by an American committee.”
To Europeans, the International Monetary Fund, which supervised exchange-rate arrangements in the post-Bretton Woods world, looked like a perfectly American committee, and France did not like that.
The Werner Report’s ideas were too feeble to deal with the currency turmoil of the early 1970’s, and it was almost a decade before Europe produced a new response.
The European Monetary System began as a high-level reaction to global currency chaos, and in particular to the depreciation of the dollar in 1977 and 1978, which seemed to threaten its continued role as the major international reserve currency.
The process that began with the report of the Delors Committee in 1989 and led to the Maastricht Treaty in 1992, the establishment of the euro in 1999, and the introduction of the physical currency in 2002 was rooted in an attempt to devise mechanisms that would generate a more stable global exchange-rate regime.
The critical policy innovators of the late 1980’s, in particular the highly activist French Finance Minister Edouard Balladur, took an international answer and started to advocate its realization on the European level.
At the G-7 meeting of finance ministers in Louvre in February 1987, Balladur suggested a system of currency target zones; when its realization proved problematic, he pushed on with a more definitive and tighter European version of the scheme.
What resulted was a partly flawed answer to the problem.
That was because France and Germany, the principal protagonists in the drama of monetary integration, had different visions of how the problem should be solved.
The Germans pressed for clearly defined fiscal rules, but other countries wanted more wiggle room.
The French argued for European economic governance alongside the monetary union, but that looked to others as imposing too much French planisme .
A watered-down version of the German solution was eventually adopted.
Today, as in the 1960’s or 1970’s, we face a fundamentally global problem of inconsistent monetary policies.
Back then, Europeans complained that low interest rates in America were driving global inflation; now low US interest rates are blamed for driving irresponsible asset-price booms.
Indeed, low US interest rates, though an appropriate domestic response to the financial crisis, have pushed a global carry trade in which people borrow in dollars to fund investments in the apparently less crisis-hit large emerging-market economies.
These large transactions are funneled through the international banking system.
The answers to a global problem of this kind cannot be found on a European level.
It will demand global coordination of monetary policies, and some form of global economic governance.
Europe tried this combination, and found that even in a regional setting it could not be fully realized.
Instead, an imperfect answer produced heightened vulnerability.
The result is that Europe has made itself into the primary victim of the financial crisis.
The God of Suffering?
PRINCETON – Do we live in a world that was created by a god who is all-powerful, all-knowing, and all good?
Christians think we do.
Yet a powerful reason for doubting this confronts us every day: the world contains a vast amount of pain and suffering.
If God is all-knowing, he knows how much suffering there is.
If he is all-powerful, he could have created a world without so much of it – and he would have done so if he were all good.
Christians usually respond that God bestowed on us the gift of free will, and hence is not responsible for the evil we do.
But this reply fails to deal with the suffering of those who drown in floods, are burned alive in forest fires caused by lightning, or die of hunger or thirst during a drought.
Christians sometimes attempt to explain this suffering by saying that all humans are sinners, and so deserve their fate, even if it is a horrible one.
But infants and small children are just as likely to suffer and die in natural disasters as adults, and it seems impossible that they could deserve to suffer and die.
Once again, some Christians say that we have all inherited the original sin committed by Eve, who defied God’s decree against eating from the tree of knowledge.
This is a triply repellant idea, for it implies that knowledge is bad, disobeying God’s will is the greatest sin of all, and children inherit the sins of their ancestors, and may justly be punished for them.
Even if we were to accept all this, the problem remains unresolved.
For animals also suffer from floods, fires, and droughts, and, since they are not descended from Adam and Eve, they cannot have inherited original sin.
In earlier times, when original sin was taken more seriously than it generally is today, the suffering of animals posed a particularly difficult problem for thoughtful Christians.
The seventeenth-century French philosopher René Descartes solved it by the drastic expedient of denying that animals can suffer.
Animals, he maintained, are merely ingenious mechanisms, and we should not take their cries and struggles as a sign of pain, any more than we take the sound of an alarm clock as a sign that it has consciousness.
People who live with a dog or a cat are not likely to find that persuasive.
Last month, at Biola University, a Christian college in southern California, I debated the existence of God with the conservative commentator Dinesh D’Souza.
In recent months, D’Souza has made a point of debating prominent atheists, but he, too, struggled to find a convincing answer to the problem I outlined above.
He first said that, because humans can live forever in heaven, the suffering of this world is less important than it would be if our life in this world were the only life we had.
That still fails to explain why an all-powerful and all-good god would permit it.
Relatively insignificant as this suffering may be from the perspective of eternity, the world would be better without it, or at least without most of it.
(Some say that we need to have some suffering to appreciate what it is like to be happy.
Maybe, but we surely don’t need as much as we have.) 
Next, D’Souza argued that since God gave us life, we are not in a position to complain if our life is not perfect.
He used the example of a child born with one limb missing.
If life itself is a gift, he said, we are not wronged by being given less than we might want.
In response I pointed out that we condemn mothers who cause harm to their babies by using alcohol or cocaine when pregnant.
Yet since they have given life to their children, it seems that, on D’Souza’s view, there is nothing wrong with what they have done.
Finally, D’Souza fell back, as many Christians do when pressed, on the claim that we should not expect to understand God’s reasons for creating the world as it is.
It is as if an ant should try to understand our decisions, so puny is our intelligence in comparison with the infinite wisdom of God.
(This is the answer given, in more poetic form, in The Book of Job .)
But once we abdicate our powers of reason in this way, we may as well believe anything at all.   
Moreover, the assertion that our intelligence is puny in comparison with God’s presupposes just the point that is under debate – that there is a god who is all-knowing, all-powerful, and all good.
The evidence of our own eyes makes it more plausible to believe that the world was not created by any god at all.
If, however, we insist on believing in divine creation, we are forced to admit that the god who made the world cannot be all-powerful and all good.
He must be either evil or a bungler.
The Gold Bubble and the Gold Bugs
NEW YORK – Gold prices have been rising sharply, breaching the $1,000 barrier and in recent weeks rising towards $1,200 an ounce and above.
Today’s “gold bugs” argue that the price could top $2,000.
But the recent price surge looks suspiciously like a bubble, with the increase only partly justified by economic fundamentals.
Gold prices rise sharply only in two situations: when inflation is high and rising, gold becomes a hedge against inflation; and when there is a risk of a near depression and investors fear for the security of their bank deposits, gold becomes a safe haven.
The last two years fit this pattern.
Gold prices started to rise sharply in the first half of 2008, when emerging markets were overheating, commodity prices were rising, and there was concern about rising inflation in high-growth emerging markets.
Even that rise was partly a bubble, which collapsed in the second half of 2008, when – after oil reached $145, killing global growth –the world economy fell into recession.
As concerns about deflation replaced fear of inflation, gold prices started to fall with the correction in commodity prices.
The second price spike occurred when Lehman Brothers collapsed, leaving investors scared about the safety of their financial assets – including bank deposits.
That scare was contained when the G-7 committed to increase guarantees of bank deposits and to backstop the financial system.
With panic subsiding towards the end of 2008, gold prices resumed their downward movement.
By that time, with the global economy spinning into near-depression, commercial and industrial gold use, and even luxury demand, took a further dive.
Gold rose above $1,000 again in February-March 2009, when it looked like most of the financial system in the United States and Europe might be near insolvency, and that many governments could not guarantee deposits and backstop the financial system, because banks that were too big to fail were also too big to be saved.
That panic subsided – and gold prices started to drift down again – after US banks were subjected to “stress tests,” America’s Troubled Asset Relief Program further backstopped the financial system by removing bad assets from banks’ balance sheets, and the global economy gradually bottomed out.
So, with no near-term risk of inflation or depression, why have gold prices started to rise sharply again in the last few months?
There are several reasons why gold prices are rising, but they suggest a gradual rise with significant risks of a downward correction, rather than a rapid rise towards $2,000, as today’s gold bugs claim.
First, while we are still in a world of global deflation, large, monetized fiscal deficits are fueling concerns over medium-term inflation.
Second, a massive wave of liquidity, via easy monetary policy, is chasing assets, including commodities, which may eventually stoke inflation further.
Third, dollar-funded carry trades are pushing the US dollar sharply down, and there is an inverse relation between the value of the dollar and the dollar price of commodities: the lower the dollar, the higher the dollar price of oil, energy, and other commodities – including gold.
Fourth, the global supply of gold – both existing and newly produced – is limited, and demand is rising faster than it can be met.
Some of this demand is coming from central banks, such as those of India, China, and South Korea.
And some of it is coming from private investors, who are using gold as a hedge against what remain low-probability “tail” risks (high inflation and another near-depression caused by a double-dip recession).
Indeed, investors increasingly want to hedge against such risks early on.
Given the inelastic supply of gold, even a small shift in the portfolios of central banks and private investors towards gold increases its price significantly.
Finally, sovereign risk is rising – consider the troubles faced by investors in Dubai, Greece, and other emerging markets and advanced economies.
This has revived concerns that governments may be unable to backstop a too-big-to-save financial system.
But, since gold has no intrinsic value, there are significant risks of a downward correction.
Eventually, central banks will need to exit quantitative easing and zero-interest rates, putting downward pressure on risky assets, including commodities.
Or the global recovery may turn out to be fragile and anemic, leading to a rise in bearish sentiment on commodities – and in bullishness about the US dollar.
Another downside risk is that the dollar-funded carry trade may unravel, crashing the global asset bubble that it, together with the wave of monetary liquidity, has caused.
And, since the carry trade and the wave of liquidity are causing a global asset bubble, some of gold’s recent rise is also bubble-driven, with herding behavior and “momentum trading” by investors pushing gold higher and higher.
But all bubbles eventually burst.
The bigger the bubble, the greater the collapse.
The recent rise in gold prices is only partially justified by fundamentals.
Nor is it clear why investors should stock up on gold if the global economy dips into recession again and concerns about a near depression and rampant deflation rise sharply.
If you truly fear a global economic meltdown, you should stock up on guns, canned food, and other commodities that you can actually use in your log cabin.
The Goldstone Reversal
NEW YORK – Justice Richard Goldstone was condemned by many apologists for Israel’s human-rights record for his conclusion that Israel intentionally targeted Palestinian civilians as a matter of policy during the 2008-9 Gaza war.
Goldstone’s United Nations-backed report accused both Israelis and Palestinians of war crimes, and called on both sides to investigate, prosecute, and punish their own personnel.
The Israeli government reacted furiously to Goldstone’s efforts.
Now he is being condemned by some critics of Israel’s human rights record for retracting his finding of intentionality.
The controversy illustrates the care that is required in publishing human-rights reports.
What is not in dispute about the “Goldstone Report” is the fact-finding on which its conclusions are based.
In difficult circumstances, and with no cooperation from the Israeli government, Goldstone documented in substantial detail a large number of Israeli attacks that killed many hundreds of civilians, injured thousands, and destroyed a significant part of Gaza’s civilian infrastructure.
Goldstone also documented attacks against Israeli civilians by Hamas, and did not restrict himself to a discussion of the notorious rockets indiscriminately fired from Gaza.
Goldstone included in his report a detailed discussion of Hamas’s seizure of the Israeli soldier Gilad Shalit and its refusal even to allow the International Committee of the Red Cross to see him.
It is extremely difficult to prove a policy of intentionality when conducting human rights investigations.
That is why Human Rights Watch, which covered much of the same ground as Goldstone in its own reporting on Gaza – and was also vigorously denounced by apologists for Israeli human rights abuses – did not reach such a conclusion.
But that does not make it wrong for a seasoned investigator like Goldstone, reviewing the evidence that he collected, to infer intentionality from the pattern and quantity of abuses.
In certain cases, the evidence requires a judgment on such a question.
The original Goldstone Report could have limited its conclusory judgment to an assertion that Israel did not meet its obligation under the international laws of armed conflict to take all feasible measures to minimize harm to civilians.
Yet, because Goldstone went further and found a policy of intentionality, before revising that judgment, he should have insisted on additional evidence that his finding was not warranted.
Instead, Goldstone says that his revised judgment is based on the fact that “Israel has dedicated significant resources to investigate over 400 allegations of operational misconduct in Gaza.”
That sounds impressive.
Yet, to my knowledge, none of those investigations so far has resulted in the criminal prosecution and punishment of any Israeli soldier or official for a human-rights abuse committed against a civilian in Gaza.
Only three have resulted in indictments.
Moreover, there is no indication that any of the Israeli investigations address questions of policy.
In other words, Goldstone’s retraction is either not warranted by the evidence on which he says that he now relies, or it is premature.
At the very least, it alleviates much of the pressure on the Israeli authorities to go forward with good-faith prosecutions.
It would have been better to wait for the outcome of the Israeli authorities’ investigations.
The most important part of human-rights reporting is collecting the facts of abuses accurately.
This must be done fairly, so that disproportionate focus on one side’s abuses does not create distortions.
And it must be done as quickly as is consistent with accuracy and fairness, so that the information can be used effectively to help prevent additional abuses.
In withdrawing his conclusion that there was a policy of intentional targeting of civilians by Israel, Goldstone has not said that his judgment, based on the evidence before him at the time, was wrong.
Rather, he has said that subsequent investigations by the Israeli authorities have made him change his judgment.
The evidence available to him and to us about those investigations is clearly too paltry to warrant such a shift.
In recanting on this basis, Goldstone conveys to the Israelis that they can receive absolution from a highly respected voice of the international community by making a show of investigations.
Yet his distinguished record in ensuring that human-rights abuses are reported fairly and accurately remains untarnished.
The Good Fallout from Iraq
Reconciling morals with how a society is organized - in other words, reconciling ethics with politics - is one of humanity's oldest ambitions.
Hammurabi, Raamses II, Solon, Confucius, and Pericles were among the first great figures to embark on this effort.
The emergence of the nation-state in the eighteenth century, and the extreme level of barbarism reached in the twentieth century, may have created the impression that an ethical politics was an unrealizable dream, or that it was a dream growing ever more distant as it receded into the future.
Yet, despite the rivalry of nations and the bloodiness of modern warfare, democracy is spreading.
Indeed, in but half a century, Latin Americans rid themselves of all of that continent's military and civilian dictatorships, and Africa has eliminated more than half of the despots that have blighted its era of independence.
Compared with all the other political regimes known to mankind, democracy represents ethical progress twice over: first, because it is based on respect for human rights; and secondly, because the universal suffrage that modern democracy embraces prohibits neglecting or oppressing minorities.
Of course, progress towards more democracy and morality in international public affairs remains extremely slow.
Yet the year 2004 may leave to history some of the greatest progress in this area that humanity has seen.
Signs of hope and progress abound.
A Spanish government was overthrown because it lied to its public about the origin of the terrorist bombs that ripped apart Madrid's train station last spring.
Tony Blair and George W. Bush are having huge problems with their electorates, also because they lied about the reasons they gave to justify their war in Iraq.
Democracy is alive and well in the developing world, too.
The electoral process in Indonesia is reaching a level of equity and accountability hitherto unknown in that country.
Morocco and Algeria are working to strengthen women's rights.
Turkey has committed itself to a vast legislative effort to improve human rights, freedom of thought, treatment of prisoners, and civilian control over the military.
Even China, though highly insensitive to democratic principles, is discovering, with the dangerous spread of AIDS, an obligation to listen to popular clamor, and the need for public support to justify government actions.
The US, owing to its horrific treatment and torture of prisoners in Baghdad, has had no option but to search for international legitimacy after denying and defying it for so long, in order to extricate itself from the chaos and drama of what is now Iraq.
Israel has seen both the legitimacy of its "security wall," as well as the wall's proposed path through Palestinian territory, called into question - differently, but in a parallel manner - by both its own Supreme Court and by the International Court of Justice in The Hague.
Israel will not be able to ignore completely the rulings of either court.
In replacing the Organization of African Unity with the African Union, Africa, for its part, is making a huge effort to control conflict on the continent, as well as to spread observance of human rights and pursue the struggle against poverty.
Moreover, capitalism itself is feeling pressure in every direction.
It sees ever increasing anger against bloated payments to bosses, risky speculation, and outright fraud.
The creation of the International Criminal Court strengthens all of these efforts to bring abuses of power by the powerful to book.
So, despite the Iraq war and the seeming impotence of world institutions, the beginning of the twenty-first century could well bring faster global improvement in political ethics than at any time in the past.
But for this trend to truly take hold, good politics needs something more than morals alone.
States must begin to explain their toughest actions, those deeds that the search for security and the inevitable mistrust among states make necessary.
"Reason of State" will not disappear entirely.
But for democracy to continue its march of ethical progress, reasons of state must be submitted to greater public accountability and justification.
The Gospel According to Gates
Bill Gates and Warren Buffett, the richest and second richest person in America, and perhaps the world, are often described as admirers of Andrew Carnegie’s famous 1889 essay “The Gospel of Wealth.”
Carnegie’s treatise, an American classic, provides a moral justification for the concentration of wealth that capitalism tends to create by arguing that immense wealth leads to well-spent charitable contributions and support of the arts and sciences.
In short, Carnegie thought that great personal wealth leads to great civilizations.
”The Gospel of Wealth” is based on the premise that business competition results in “survival of the fittest” – the fittest being those endowed with the most “talent for organization.”
Carnegie argued that those who thrive in business and acquire huge personal fortunes are better at judging how the world really works, and thus are better qualified to judge where resources should be directed.
Successful people, according to Carnegie, should retire from business while they still retain those talents and devote their remaining years to spending their fortunes on philanthropy.
Carnegie also advocated an inheritance tax as an incentive, arguing that it would “induce the rich man to attend to the administration of wealth during his life.”
Encouraging the rich to spend their fortunes on good causes while still alive, Carnegie maintained, is far better than leaving the disposition of their wealth to the care of their (probably untalented) children.
Last month, Bill Gates announced that he will do what Carnegie recommended: in two years, he will change his priorities so that he can work full time for the Bill and Melinda Gates Foundation, which he and his wife founded.
Even earlier than Carnegie, who quit at 65, Gates will devote his life to spending his huge fortune on philanthropy.
Warren Buffett, by contrast, is 76, so he has missed his chance to apply his talents to running a charitable foundation.
But, by leaving the bulk of his fortune, approximately $31 billion, to the Gates Foundation, he will have done the next best thing.
Bill Gates is a controversial figure, but few doubt that he is smart.
Even so, whereas Carnegie’s theory makes some sense (which is why his essay is remembered so well more than a century later), it isn’t obvious that he was right to believe that successful business people are the best administrators of charitable foundations.
Useful traits in business, like aggressiveness or political savvy, might be poorly suited to philanthropy.
Likewise, running a foundation may well require studying social problems or the arts and sciences – activities that may not accord with former capitalists’ inclinations and talents.
The deeper flaw in Carnegie’s theory may be that it is just too difficult psychologically for business people to make the mid-life career transition to philanthropy.
Having accumulated great wealth as “survivors” of the business world, will they really turn their talents to the task of giving it away?
Regardless of whether Gates lives up to his promise, are people like him the exception that proves the rule?
It is easy to be skeptical that his example will spur a new wave of early retirements to run philanthropies.
The public-spirited justification of the concentration of wealth offered in “The Gospel of Wealth” has more support in the United States than elsewhere, which reflects Americans’ relatively greater admiration of business people.
But Carnegie’s argument never became received doctrine even in America, because most people reject the view that rich business people are smarter and morally superior.
Certainly, Gates and Buffett claim nothing of the sort.
Similarly, even in America, movies and TV shows do not dramatize the lives of great tycoon philanthropists.
Americans, like everyone else, prefer portrayals of business people who are truly evil and in the end receive their just deserts.
And yet there is more charitable giving in the US than in other countries, reflecting a greater sense in America that private benevolence is an obligation.
According to the Johns Hopkins University Comparative Nonprofit Sector Project, headed by Lester Salamon, the US leads major countries in private contributions to nonprofits.
Excluding donations to churches, such contributions amount to 1% of GDP in the U.S., which is six times higher than in Germany or Japan, and 30 times higher than in Mexico.
However, 1% of GDP is still not a very big number, and the Gates Foundation, with about $60 billion after Buffett’s bequest, now accounts for a substantial share of the total.
Of course, Gates and Buffett deserve praise, and we should certainly wish them well.
But we should not yet consider their example a vindication of “The Gospel of Wealth.”
The Gospel of Growth
CANBERRA/SEOUL – Almost four years after the start of the global financial crisis, the world economy remains fragile and unemployment is unacceptably high.
There are roughly 200 million unemployed people worldwide, including nearly 75 million young people.
Growth is weakening in many countries, risks are mounting, and uncertainty has intensified, owing especially to events in Europe.
Only swift and sustained recovery can stem the rise in the human cost of economic stagnation.
When the G-20 meets in Los Cabos, Mexico, on&nbsp;June 18-19, its challenge will be to shift public perceptions from pessimism and concern about the future to an optimistic mindset of growth and stability.
We need resolute action to address the uncertainty confronting the global economy and to chart a path toward self-sustaining recovery and job creation.
We see two components to such a strategy.
First, we need a clear message from Europe – the immediate source of global economic concern – that it is taking decisive steps to stabilize and strengthen its banks, and that it is focused on restoring growth while credibly committing itself to fiscal consolidation.
A crucial element of restoring confidence in Europe is agreement on a “roadmap” for the eurozone to underpin its monetary union with a fiscal union and a banking union, including pan-European supervision and deposit insurance.
It is essential that Europe move quickly to ensure that its banks are adequately capitalized and backstopped.
In this regard, we welcome the recent decision by Spain to seek financial assistance from the European Union to recapitalize its banks as required.
Decisive steps to safeguard the banking sector’s health are necessary not only to reduce some of the risks that are preoccupying markets, but also because healthy financial institutions are vital for economic growth.
Europe must have credible fiscal-consolidation plans to restore debt sustainability, but it is also essential that it has a growth strategy that includes policies aimed at boosting investment, freeing up product and labor markets, deregulating business, promoting competition, and building skills.
These reforms, including deeper institutional integration, will be politically difficult and their benefits will take time to become fully apparent; but setting a clear pathway will underpin public confidence in Europe’s long-term growth and cooperation.
We do not underestimate the magnitude of the reforms that Europe has achieved in recent years.
Since the G-20’s meeting at Cannes last November, for example, Europe has increased its financial firewalls by €200 billion ($252 billion), restructured Greek debt, taken steps towards strengthening its banks and banking regulations, established rules for fiscal discipline, and implemented a range of labor- and product-market reforms.
But the magnitude of the challenges confronting Europe implies an urgent need for far more decisive reforms.
We are confident that Europe will act together to meet these challenges, and we will continue to support such efforts, because European stability and growth matter for us all.
Second, we need a clear message from the G-20 that all of its members are delivering policies for strong, sustainable, and balanced growth.
To be meaningful, the message must be backed up with action: G-20 members must demonstrate that their policies are clearly directed toward restoring economic growth and creating jobs, and that they will be accountable for meeting their commitments in full.
And world leaders must be unambiguous about resisting protectionism and opening trade and investment.
In particular, we believe that an international agreement on trade facilitation is the right step, as it would reduce export and import costs and restore momentum to global trade liberalization.
The G-20 must demonstrate in Los Cabos that reform of the International Monetary Fund is continuing.
That means that countries must deliver on their commitment to increase IMF resources by more than $430 billion, and that the Fund’s quota and governance structure must reflect the ongoing global shifts in economic influence.
Economic growth and new jobs are crucial to improving people’s livelihoods now and to ensuring the prosperity of future generations.
The reforms needed to secure these objectives are not easy, and change will not happen overnight.
But the world expects the G-20 to deliver.
The Great American Mirage
NEW HAVEN – In September 1998, during the depths of the Asian financial crisis, Alan Greenspan, the United States Federal Reserve’s chairman at the time, had a simple message: the US is not an oasis of prosperity in an otherwise struggling world.
Greenspan’s point is even closer to the mark today than it was back then.
Yes, the US economy has been on a weak recovery trajectory over the past three years.
But at least it’s a recovery, claim many – and therefore a source of ongoing resilience in an otherwise struggling developed world.
Unlike the Great Recession of 2008-2009, today there is widespread hope that America has the capacity to stay the course and provide a backstop for the rest of the world in the midst of the euro crisis.
Think again.
Since the first quarter of 2009, when the US economy was bottoming out after its worst postwar recession, exports have accounted for fully 41% of the subsequent rebound.
That’s right: with the American consumer on ice in the aftermath of the biggest consumption binge in history, the US economy has drawn its sustenance disproportionately from foreign markets.
With those markets now in trouble, the US could be quick to follow.
Three regions have collectively accounted for 83% of America’s export-led growth impetus over the past three years – Asia, Latin America, and Europe.
(Since regional and country trade statistics assembled by the US Department of Commerce are not seasonally adjusted, all subsequent comparisons are presented on the basis of a comparable seasonal comparison from the first quarter of 2009 to the first quarter of 2012.)
Not surprisingly, Asia led the way, accounting for 33% of the total US export surge over the past three years.
The biggest source of this increase came from the 15-percentage-point contribution of Greater China (the People’s Republic, Taiwan, and Hong Kong).&nbsp; Needless to say, China’s unfolding slowdown – even under the soft-landing scenario that I still believe is most credible – is taking a major toll on the largest source of America’s export revival.
The remainder of the Asian-led US export impetus is spread out, led by South Korea, Japan, and Taiwan – all export-led economies themselves and all heavily dependent on a slowing China.
Latin America provided the second-largest source of America’s export resurgence, accounting for another 28% of the total gains in US foreign sales over the past three years.
Brazil and Mexico collectively accounted for 19 percentage points of that increase.
Growth in both economies is now slowing significantly, especially in Brazil.
But, given the close linkages between Mexican production and US consumption (which is now sputtering again), any resilience in the Mexican economy could be short-lived.
Finally, there is the sad case of Europe, which has accounted for 21% of the cumulative growth in US exports over the past three years.
Here, the US Commerce Department statistics are not as helpful in pinpointing the source of the impetus, because only a partial country list is published.
What we do know is that the United Kingdom, Germany, and France – the so-called core economies – collectively accounted for just 3.5% of total US export growth since early 2009, with the UK grabbing the bulk of that increase.
That suggests that most of America’s European export gain was concentrated in the region’s so-called peripheral economies.
And that is clearly a serious problem.
Forecasts are always hazardous, but some “what-if” scenarios shed considerable light on what all of this means for the world’s largest economy.
Since the second quarter of 2009, US annualized real GDP growth has averaged 2.4%.
With roughly 40% of that increase attributable to exports, that means the remainder of the economy has grown at an anemic 1.4% pace.
Under a flat-line export scenario, with no rise in US exports, and if everything else remains the same (always a heroic assumption), overall real GDP growth would converge on that 1.4% bogey.
That is a weak growth trajectory by any standard – likely to result in rising unemployment and further deterioration in consumer confidence.
Alternatively, in a moderate export-downturn scenario, with real exports falling by 5% over a four-quarter period, real GDP growth could slip below the 1% “stall speed” threshold – leaving the US economy vulnerable to a recessionary relapse.
By way of reference, the assumption of a 5% export downturn pales in comparison with the precipitous 13.6% decline in real exports that occurred in 2008-2009.
As such, this “what if” is a cautiously optimistic assessment of the downside risks stemming from weak external demand.
All of this underscores one of the more obvious, yet overlooked, implications of an increasingly interdependent world: we are all in it together.
The euro crisis is a serious shock, and is now producing ripple effects around the world.
Europe is export-led China’s largest source of external demand; as China goes, so goes the rest of China-centric Asia; and, from there, the ripples reach the shores of an increasingly export-dependent US economy.
As recent weakness in employment and retail sales suggests, that may already be happening.
Greenspan’s warning in 1998 came at a time when US exports accounted for only about 10.5% of GDP.
Today, that share stands at a record-high 14%, as post-crisis America has made a big bet on an export-led revival.
The current global slowdown is not on a par with what occurred in the late 1990’s or the more wrenching shocks of 3-4 years ago – at least not yet.
But today’s global downturn can hardly be dismissed as unimportant for the US or anyone else.
In an era of globalization, there are no innocent bystanders.
There are certainly no oases of prosperity in the face of yet another major shock in the global economy.
America’s growth mirage is an important case in point.
The Great Bank Robbery
NEW YORK – For the American economy – and for many other developed economies – the elephant in the room is the amount of money paid to bankers over the last five years.
For banks that have filings with the US Securities and Exchange Commission, the sum stands at an astounding $2.2 trillion.
Extrapolating over the coming decade, the numbers would approach $5 trillion, an amount vastly larger than what both President Barack Obama’s administration and his Republican opponents seem willing to cut from further government deficits.
That $5 trillion dollars is not money invested in building roads, schools, and other long-term projects, but is directly transferred from the American economy to the personal accounts of bank executives and employees.
Such transfers represent as cunning a tax on everyone else as one can imagine.
It feels quite iniquitous that bankers, having helped cause today’s financial and economic troubles, are the only class that is not suffering from them – and in many cases are actually benefiting.
Mainstream megabanks are puzzling in many respects.
It is (now) no secret that they have operated so far as large sophisticated compensation schemes, masking probabilities of low-risk, high-impact “Black Swan” events and benefiting from the free backstop of implicit public guarantees.
Excessive leverage, rather than skills, can be seen as the source of their resulting profits, which then flow disproportionately to employees, and of their sometimes-massive losses, which are borne by shareholders and taxpayers.
In other words, banks take risks, get paid for the upside, and then transfer the downside to shareholders, taxpayers, and even retirees.
In order to rescue the banking system, the Federal Reserve, for example, put interest rates at artificially low levels; as was disclosed recently, it also has provided secret loans of $1.2 trillion to banks.
The main effect so far has been to help bankers generate bonuses (rather than attract borrowers) by hiding exposures.
Taxpayers end up paying for these exposures, as do retirees and others who rely on returns from their savings.
Moreover, low-interest-rate policies transfer inflation risk to all savers – and to future generations.
Perhaps the greatest insult to taxpayers, then, is that bankers’ compensation last year was back at its pre-crisis level.
Of course, before being bailed out by governments, banks had never made any return in their history, assuming that their assets are properly marked to market.
Nor should they produce any return in the long run, as their business model remains identical to what it was before, with only cosmetic modifications concerning trading risks.
So the facts are clear.
But, as individual taxpayers, we are helpless, because we do not control outcomes, owing to the concerted efforts of lobbyists, or, worse, economic policymakers.
Our subsidizing of bank managers and executives is completely involuntary.
But the puzzle represents an even bigger elephant.
Why does any investment manager buy the stocks of banks that pay out very large portions of their earnings to their employees?
The promise of replicating past returns cannot be the reason, given the inadequacy of those returns.
In fact, filtering out stocks in accordance with payouts would have lowered the draw-downs on investment in the financial sector by well over half over the past 20 years, with no loss in returns.
Why do portfolio and pension-fund managers hope to receive impunity from their investors?
Isn’t it obvious to investors that they are voluntarily transferring their clients’ funds to the pockets of bankers?
Aren’t fund managers violating both fiduciary responsibilities and moral rules?
Are they missing the only opportunity we have to discipline the banks and force them to compete for responsible risk-taking?
It is hard to understand why the market mechanism does not eliminate such questions. A well-functioning market would produce outcomes that favor banks with the right exposures, the right compensation schemes, the right risk-sharing, and therefore the right corporate governance.
One may wonder: If investment managers and their clients don’t receive high returns on bank stocks, as they would if they were profiting from bankers’ externalization of risk onto taxpayers, why do they hold them at all?
The answer is the so-called “beta”: banks represent a large share of the S&P 500, and managers need to be invested in them.
We don’t believe that regulation is a panacea for this state of affairs.
The largest, most sophisticated banks have become expert at remaining one step ahead of regulators – constantly creating complex financial products and derivatives that skirt the letter of the rules.
In these circumstances, more complicated regulations merely mean more billable hours for lawyers, more income for regulators switching sides, and more profits for derivatives traders.
Investment managers have a moral and professional responsibility to play their role in bringing some discipline into the banking system.
Their first step should be to separate banks according to their compensation criteria.
Investors have used ethical grounds in the past – excluding, say, tobacco companies or corporations abetting apartheid in South Africa – and have been successful in generating pressure on the underlying stocks.
Investing in banks constitutes a double breach – ethical and professional.
Investors, and the rest of us, would be much better off if these funds flowed to more productive companies, perhaps with an amount equivalent to what would be transferred to bankers’ bonuses redirected to well-managed charities.
The Great Brain Race
WASHINGTON, DC – For decades, research universities in the United States have been universally acknowledged as the world’s leaders in science and engineering, unsurpassed since World War II in the sheer volume and excellence of the scholarship and innovation that they generate.
But there are growing signs that the rest of the world is gaining ground fast – building new universities, improving existing ones, competing hard for the best students, and recruiting US-trained PhDs to return home to work in university and industry labs.
Is the international scholarly pecking order about to be overturned?
There is no question that the academic enterprise has become increasingly global, particularly in the sciences.
Nearly three million students now study outside their home countries – a 57% increase in the last decade.
At the same time, growing numbers of traditional source countries for students, from South Korea to Saudi Arabia, are trying to improve both the quantity and quality of their own degrees, engaging in a fierce – and expensive – race to recruit students and create world-class research universities of their own.
All this competition has led to considerable hand-wringing in the West.
During a 2008 campaign stop, for instance, then-candidate Barack Obama spoke in alarmed tones about the threat that such academic competition poses to US competitiveness.
“If we want to keep on building the cars of the future here in America,” he declared, “we can’t afford to see the number of PhDs in engineering climbing in China, South Korea, and Japan even as it’s dropped here in America.”
Nor are such concerns limited to the US.
In some countries, worries about educational competition and brain drains have led to outright academic protectionism.
India and China are notorious for the legal and bureaucratic obstacles they place in front of Western universities that want to set up satellite campuses catering to local students.
And sometimes students who want to leave face barriers.
Several years ago, the president of one of the prestigious Indian Institutes of Technology effectively banned undergraduates from accepting academic or business internships overseas.
There are other impediments to global mobility, too, not always explicitly protectionist, but all having the effect of limiting access to universities around the world.
In the years following the terrorist attacks of September 11, 2001, for example, legitimate security concerns led to enormous student-visa delays and bureaucratic hassles for foreigners aspiring to study in the US.
Student numbers have since rebounded, despite intermittent problems, but there remain severe limits on work and residency visas, which should serve as an enticement for the best and brightest to study in the US.
Perhaps some of the anxiety over the new global academic enterprise is understandable, particularly in a period of massive economic uncertainty.
But educational protectionism is as big a mistake as trade protectionism.
The globalization of higher education should be embraced, not feared – including in the US.
There is every reason to believe that the worldwide competition for human talent, the race to produce innovative research, the push to extend university campuses to multiple countries, and the rush to train talented graduates who can strengthen increasingly knowledge-based economies will be good for the US as well.
Above all, this is because the expansion of knowledge is not a zero-sum game.
More PhD production and burgeoning research in China, for instance, doesn’t take away from America’s store of learning; on the contrary, it enhances what we know and can accomplish.
Because knowledge is a public good, intellectual gains by one country often benefit others.
Chinese research may well provide the building blocks for innovation by US entrepreneurs – or those from other countries.
Indeed, the economic benefits of a global academic culture are significant.
Just as free trade provides the lowest-cost goods and services, benefiting both consumers and the most efficient producers, global academic competition is making free movement of people and ideas, on the basis of merit, more and more the norm, with enormously positive consequences for individuals, universities, and countries.
Today's swirling patterns of mobility and knowledge transmission constitute a new kind of free trade: free trade in minds.
The US should respond to the globalization of higher education not with angst but with a sense of possibility.
Neither a gradual erosion in the US market share of students, nor the emergence of ambitious new competitors in Asia, Europe, and the Middle East means that American universities are on an inevitable path to decline.
By resisting protectionist barriers at home and abroad, by continuing to recruit and welcome the world’s best students, by sending more students overseas, by fostering cross-national research collaboration, and by strengthening its own research universities, the US can sustain its well-established academic excellence while continuing to expand the sum total of global knowledge and prosperity.
The Great Debt Scare
NEW HAVEN – It might not seem that Europe’s sovereign-debt crisis and growing concern about the United States’ debt position should shake basic economic confidence.
But they apparently have.
And loss of confidence, by discouraging consumption and investment, can be a self-fulfilling prophecy, causing the economic weakness that is feared.
Significant drops in consumer-confidence indices in Europe and North America already reflect this perverse dynamic.
We now have a daily index for the US, the Gallup Economic Confidence Index, so we can pinpoint changes in confidence over time.
The Gallup Index dropped sharply between the first week of July and the first week of August – the period when US political leaders worried everyone that they would be unable to raise the federal government’s debt ceiling and prevent the US from defaulting on August 2.
The story played out in the news media every day.
August 2 came and went, with no default, but, three days later, a Friday, Standard &amp; Poor’s lowered its rating on long-term US debt from AAA to AA+.
The following Monday, the S&amp;P 500 dropped almost 7%.
Apparently, the specter of government deadlock causing a humiliating default suddenly made the US resemble the European countries that really are teetering on the brink.
Europe’s story became America’s story.
Changes in public confidence are built upon such narratives, because the human mind is very receptive to them, particularly human-interest stories.
The story of a possible US default is resonant in precisely this way, implicating as it does America’s sense of pride, fragile world dominance, and political upheavals.
Indeed, this is arguably a more captivating story than was the most intense moment of the financial crisis, in 2008, when Lehman Brothers collapsed.
The drop in the Gallup Economic Confidence Index was sharper in July 2011 than it was in 2008, although the index has not yet fallen to a lower level than it reached then.
Most confidence indices today are based on survey questions that ask respondents to assess the economy today or in the near future.
George Gallup, the pioneer of survey methods and creator of the Gallup poll, created a confidence index in 1938, late in the Great Depression, when he asked Americans, “Do you think business will be better or worse six months from now?”
He interpreted the answers as measuring “public optimism” and “the intangible mental attitude which is recognized as one vital element in the week-to-week fluctuations of business activity.”
But it hardly seems likely that big changes in people’s confidence (the kind of confidence that affects their willingness to spend or invest) are rooted in expectations over so short a time horizon.
When George Gallup wrote, almost nine years after the Great Depression began, a sense of ultimate futility – a belief that high unemployment would never end – was widespread.
That sentiment probably held back consumption and investment far more than any opinions about changes in the next six months.
After all, consumers’ willingness to spend depends on their general situation, not on whether business will be a little better in the short term.
Likewise, businesses’ willingness to hire people and expand operations depends on their longer-term expectations.
The Consumer Sentiment Survey of Americans, created by George Katona at the University of Michigan in the early 1950’s, and known today as the Thomson-Reuters University of Michigan Surveys of Consumers, has included a remarkable question about the reasonably long-term future, five years hence, and asks about visceral fears concerning that period:
“Looking ahead, which would you say is more likely – that in the country as a whole we’ll have continuous good times during the next five years or so, or that we will have periods of widespread unemployment or depression, or what?”
That question is usually not singled out for attention, but it appears spot-on for what we really want to know: what deep anxieties and fears do people have that might inhibit their willingness to spend for a long time.
The answers to that question might well help us forecast the future outlook much more accurately.
Those answers plunged into depression territory between July and August, and the index of optimism based on answers to this question is at its lowest level since the oil-crisis-induced “great recession” of the early 1980’s.
It stood at 135, its highest-ever level, in 2000, at the very peak of the millennium stock market bubble.
By May 2011, it had fallen to 88.
By September, just four months later, it was down to 48.
This is a much bigger downswing than was recorded in the overall consumer-confidence indices.
The decline occurred over the better part of a decade, as we began to see the end of debt-driven overexpansion, and accelerated with the latest debt crisis.
The timing and substance of these consumer-survey results suggest that our fundamental outlook about the economy, at the level of the average person, is closely bound up with stories of excessive borrowing, loss of governmental and personal responsibility, and a sense that matters are beyond control.
That kind of loss of confidence may well last for years.
That said, the economic outlook can never be fully analyzed with conventional statistical models, for it may hinge on something that such models do not include: our finding some way to replace one narrative – currently a tale of out-of-control debt – with a more inspiring story.
The Great Escapism
NEW YORK – Barack Obama, however mixed his accomplishments to date as US president, has sought to rebrand America and reclaim its former signature asset: its ability to embody universally admired values.  As popular culture is usually the way those values are transmitted, it is worth considering what it is about American cinema, music, and popular literature that makes them so compelling to many other parts of the world.
After all, much of what America once monopolized in Hollywood movies and other pop-culture exports is now being reproduced locally.
Bollywood competes with California in terms of glamorous stars and big production numbers; Japan and South Korea mint their own pop singers and fashion trends.
But consider Entourage, the American TV show that centers on a rising male film star and his posse of dudes.
Or a recent article in The New Yorker about two scruffy young chefs who have set out across the country to start the great adventure of running their own crazy restaurant, called Animal.
Or Swingers, the 1996 worldwide hit movie about a twenty-something guy in Hollywood and his band of male friends who drag him to Las Vegas to mend his broken heart.