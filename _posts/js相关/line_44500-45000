As the full extent of the cover-up was revealed, foreign investors, like GIC Private Limited (Singapore’s sovereign wealth fund), rebelled.
Singapore sold nearly all of its 2% stake almost immediately, and other foreign investors and analysts reacted similarly.
It was a turning point for Japan, as the country’s clubby investment culture came up against global transparency and accounting standards.
Things have not been the same since, either for Japan or for companies’ understanding of the expectations and influence of international investors.
International investors are in a unique position to encourage, or even enforce, global best practices in corporate governance.
If such investors show that they are willing to withdraw financing, they will gain real influence in bringing about sustainable change – to the benefit of us all.
This is especially true if investors are guided by principles that go beyond financial returns.
Global funds that uphold high ethical standards concerning labor practices and environmental protections are safeguarding the global ecosystem on which they, and the rest of us, depend.
As they establish and implement such principles, the resulting momentum has been changing corporate governance and behavior across industries and regions.
This is evident from several high-profile examples.
CalPERS (the California Public Employees’ Retirement System), a $300 billion pension fund, has published its corporate governance principles, which include boardroom diversity, fair labor practices, and environmental protection.
Norges Bank Investment Management, Norway’s $870 billion sovereign wealth fund (the largest in the world), has also pushed for changing governance rules, including separating the role of chief executive and chairman and better reporting by companies on how they are addressing climate change.
The shift in emphasis on best-practice corporate governance is real, and it is here to stay.
It comes from people finding and raising their voices, from politicians recognizing the importance of corporate governance for sustainable economic growth, and from influential investors putting genuine pressure on companies to change their behavior.
Companies and boards ignore this trend at their peril.
Redefining Business Competence
DURHAM, NORTH CAROLINA – One of the most interesting parts of my job as a business school dean is engaging in candid conversations with leaders across industries.
A few years ago, I started hearing a troubling refrain: business leaders are feeling the type of public disdain once reserved for politicians.
The problem is one of trust – or lack thereof.
The 2014 Edelman Trust Barometer reveals that less than one-fifth of the global public believes that business and government officials will tell the truth when confronted with a difficult issue.
That public sentiment is affecting business worldwide.
The Duke University CFO Magazine Global Business Outlook Survey found that nearly 60% of chief financial officers in the United States believe that a lack of public trust has harmed the business environment.
Those percentages are even higher in other parts of the world.
Given the constant stream of security and data breaches and allegations of financial manipulation involving some of the world’s most respected banks, who can blame the public for feeling this way?
Now, more than ever, we need leaders who can regain the public’s trust.
To do that, we must redefine what it means to be a competent business leader.
Traditionally, society has measured business competence by a person’s intellectual ability to examine problems broadly and deeply.
But, in order to seize global opportunities today, we need to emphasize a new dimension: the ability to create a shared set of values and foster a culture that embraces those beliefs.
Doing so requires taking three, sometimes uncomfortable, steps.
First, business leaders must overcome their fear of learning from others.
That sounds simple, but how many executives can admit that they don’t know everything or that they aren’t the smartest person in the room?
Many business leaders talk a good game about diversity, but surround themselves with people who are just like them.
Working closely with others who think differently can be scary and frustrating.
But the best leaders have the courage to encourage authenticity in both themselves and others.
Second, embrace the ambition of others.
The downfall of many business leaders in recent years has been greed and selfish ambition.
Great leaders are other-directed instead of self-focused.
They adopt a “your success is my success” mentality.
This attitude goes a long way toward developing trust among team members and helps foster strong commitment to a common vision.
It also requires leaders to trust others that they will not abuse the faith placed in them.
Finally, business leaders must value collaboration – and mean it.
Leaders who overcome fear and frustration, embrace the ambition of others, and possess a strong character and sense of purpose are likely to build diverse teams whose members share an identity and common goals but still represent themselves authentically.
Research has shown that such teams outperform others, which means that this approach can lead to a tremendous competitive advantage.
In short, collaboration not only matters; it wins.
Imagine the immense potential we would have to solve some of the world’s toughest challenges if business leaders adopted this strategy.
Consider the global threat posed by Ebola.
Efforts are underway to research, manufacture, and distribute experimental drugs that could treat the disease.
But until now drug companies had largely ignored Ebola, because there appeared to be little profit in developing a drug for populations that could not afford to pay for it.
The New York Times reported last month that United States officials are planning to scale up the production of one experimental drug, but it is still not likely to meet demand.
If some of the brightest minds in business and health care had found a way to encourage the production of an Ebola drug before the outbreak, thousands of lives might have been saved.
The type of leadership that I am advocating poses no threat to a company’s bottom line.
On the contrary, it is the starting point for scaling a business to its full potential.
As former Procter &amp; Gamble CEO and current US Secretary of Veterans Affairs Bob McDonald is fond of saying, leaders have a responsibility to make sure that their organization can “do well and do good.”
Business can be the common thread that weaves positive change throughout the world.
In order to reach that goal, we need business leaders with the vision, skills, and commitment to make a profit and a difference.
A new standard for business competence that incorporates more than the bottom line will go a long way toward winning back the public’s trust.
Corporate Short-Termism in the Fiscal Cliff’s Shadow
CAMBRIDGE – Economic trends are sometimes more closely related to one another than news reports make them seem.
For example, one regularly encounters reports of governments’ financial troubles, like the “fiscal cliff” in the United States and the debt crisis in Europe.
And much attention has been devoted, often in nearby opinion pieces, to the view that hyperactive equities markets, particularly in the US and the United Kingdom, push large corporations to focus disproportionately on short-term financial results at the expense of long-term investments in their countries’ economies.
The two are not unconnected.
And examining that connection provides a good opportunity to assess the weaknesses and ambiguities of the longstanding argument that furiously high-volume stock-market trading shortens corporate time horizons.
The conventional thinking is that as traders buy and sell corporate stocks more often, they induce corporate managers to plan for shorter and shorter horizons.
If institutional investors refuse to hold stocks for more than a few months, the thinking goes, CEOs’ time horizons for corporate planning must shrink to roughly the same timeframe.
Policymakers in Europe and the US are urged to act on this conventional thinking: Something must be done to insulate CEOs, boards, and managers from the financial markets’ ever-shortening time horizons.
The UK’s official Kay Review from last July and the European Union’s Green Paper on corporate governance, adopted by the European Parliament earlier this year, diagnose corporate short-termism as a serious problem and point policymakers toward solutions.
American commentators – and, increasingly, US judges – want to insulate CEOs and boards further from their firms’ trading shareholders.
But highlighting short-term trading in stock markets obscures other powerful sources of short-termism in corporate time horizons, such as uncertainty about long-term government fiscal policies on both sides of the Atlantic.
More important, some corporate short-termism may not be as strong as it is thought to be.
Consider, first, the lofty market capitalization of Apple and other tech companies, which belies the depiction of US financial markets as hopelessly short-term-oriented.
The ability to appreciate the long-term earnings potential of Silicon Valley and firms like Apple, Amazon, and Facebook suggests that more is going on in the US stock market than a relentless focus on short-term financial performance.
Indeed, the intermittent over-valuation of entire economic sectors – recall the dot-com bubble from a decade ago – indicates that financial markets are often excessively focused on the long term.
Many firms during the bubble had no hope of making enough money in the short run to justify their sky-high stock prices.
Moreover, there are ambiguities in the trend lines for stock-holding periods.
While the overall average length of time for holding a stock has declined, the impact on senior managers is unclear, because the holding period for core institutional investors, like Vanguard and Fidelity, has not changed in the past decade or two from its two- or three-year baseline.
Fast program trading pulls the overall holding period average down.
But it’s not as clear as many believe that the holding period for traditional shareholders has shortened greatly – or at all.
The declining average is partly due to a furiously trading fringe.
Excessive short-termism can come from the executive suite as much as from financial markets, especially from CEOs, who in the US have an average tenure of 6-7 years.
It is fully understandable – and largely supported by empirical evidence – that these CEOs would want good results to occur on their watch, rather than after their successor takes over.
Insulating CEOs and boards further from financial markets may perversely free them to focus even more narrowly on short-term results.
In any case, while concern with corporate short-termism has arrived on the US judicial agenda, judges in America (or elsewhere, for that matter) are not well positioned to weigh economic evidence that is far from clear regarding the sources, extent, and even the direction of short-term thinking in large corporations.
Other political and administrative institutions are better positioned to determine whether corporate short-termism is a serious problem and what the best solution would be.
For example, a so-called Tobin tax on financial transactions is a frequently proposed solution, but it is not a policy solution that could be implemented by corporate-law judges.
Finally, firms that become more oriented toward short-term performance may be reacting to their real environment, not to their financial environment.
They may well be adapting to new economic, political, and technological realities, not hiding from the future.
Critics of short-term thinking, like the authors of the Kay Review and the EU Green Paper, ought to consider that economic life has, in fact, become more short term.
That brings us to the link between corporate short-termism and weak public finances.
Companies on both sides of the Atlantic could be thrown off course by the US fiscal cliff and the EU sovereign-debt crisis.
If economy-defining government and regulatory policies have become unstable in the short and long term, companies must adjust to that reality.
Similarly, if technological innovation can now transform major industries in a matter of a few years, or even months, long-term investment makes less sense than it did before.
Amazon’s lofty price/earnings multiple indicates that investors are not shy about financing its long-term future.
But does Amazon’s success mean that traditional brick-and-mortar retailers are slackers for not upgrading their stores, or for not building new stores in better locations?
If investors understand that online distribution is revolutionizing the retail sector, isolating the sector’s CEOs from financial markets would just push more resources into a deteriorating, shrinking business model.
In this sense (and only this sense), short-term thinking that induces change and movement away from obsolete technology – here and throughout the economy – may well facilitate long-term prosperity.
Corrupting the Fight Against Corruption
At its recent annual meeting, World Bank officials spoke extensively about corruption.
It is an understandable concern: money that the Bank lends to developing countries that ends up in secret bank accounts or finances some contractors’ luxurious lifestyle leaves a country more indebted, not more prosperous.
James Wolfensohn, the Bank’s previous president, and I are widely credited with putting corruption on the Bank’s agenda, against opponents who regarded corruption as a political issue, not an economic one, and thus outside the Bank’s mandate.
Our research showed systematic relationships between corruption and economic growth, which allowed us to pursue this critical issue.
But the World Bank would do well to keep four things in mind as it takes up the fight.
First, corruption takes many forms, so a war on corruption has to be fought on many fronts.
You can’t fight the diversion of small amounts of money by weak and poor countries while ignoring the massive diversion of public resources into private hands of the sort that marked, say, Russia under Boris Yeltsin.
In some countries, overt corruption occurs primarily through campaign contributions that oblige politicians to repay major donors with favors.
Smaller-scale corruption is bad, but systemic corruption of political processes can have even greater costs.
Campaign contributions and lobbying that lead to rapid privatizations of utilities – before appropriate regulatory frameworks are in place, and in a manner that produces only a few bidders – can impede development, even without direct kickbacks to government officials.
Life is never black and white.
Just as there is no “one size fits all” policy for economic development, there is no such policy for fighting corruption.
The response to corruption needs to be as complex and variegated as corruption itself.
Second, it’s fine for the World Bank to deliver anti-corruption sermons.
But policies, procedures, and institutions are what matter.
In fact, the Bank’s procurement procedures are generally viewed around the world as a model to be admired.
Indeed, some countries with large dollar reserves – hardly in need of World Bank credit – borrowed from the Bank at far higher interest rates than they were getting from the United States, believing that these procedures would help ensure high-quality projects free of corruption and become standard in other areas.
But success in fighting corruption entails more than just good procurement procedures (avoiding, for instance, single-source non-competitive bidding).
Many other policies and procedures can be enacted that reduce incentives for corruption.
For example, some tax systems are more corruption-resistant than others, because they curtail the discretionary authority of tax officials.
Third, the World Bank’s primary responsibility is to fight poverty, which means that when it confronts a poor country plagued with corruption, its challenge is to figure out how to ensure that its own money is not tainted and gets to projects and people that need it.
In some cases, this may entail delivering assistance through non-governmental organizations.
But seldom will it be the case that the best response is simply to walk away.
Finally, while developing countries must take responsibility for rooting out corruption, there is much that the West can do to help.
At a minimum, Western governments and corporations should not be complicit.
Every bribe that is taken has a payer, and too often the bribe payer is a corporation from an advanced industrial country or someone acting on its behalf.
Indeed, one reason for the so called “natural resource curse” ­– the fact that resource-rich countries do not, on average, do as well as resource-poor countries – is the prevalence of corruption, too often aided and abetted by companies that would like to get the resources they sell at discount prices.
The US under President Jimmy Carter made an important contribution in passing the Foreign Corrupt Practices Act, which made bribery by American companies anywhere in the world illegal.
The OECD’s Convention on Bribery was another step in the right direction.
Making all payments to governments transparent would bring further progress, and Western governments could encourage this simply by tying this requirement to tax deductibility.
It is equally important to address bank secrecy, which facilitates corruption by providing corrupt dictators with a safe haven for their funds.
In August 2001, just before the terrorist attacks on America, the US government vetoed an OECD effort to limit secret bank accounts.
While the government has since reversed its stance on bank secrecy for terrorists, it has not done so for corrupt officials.
A strong stand by the World Bank would enhance its credibility in the war on corruption.
Those who criticize the Bank’s stance on corruption do not do so because they favor corruption.
Some critics worry about corruption in the corruption agenda itself: that the fight will be used as a “cover” for cutting aid to countries that displease the US administration.
Such concerns have found resonance in the seeming incongruity of the Bank’s tough talk on corruption and simultaneous plans to expand lending to Iraq.
No one is likely to certify that Iraq is corruption-free – or even ranks low on corruption internationally.
The most strident criticism, however, comes from those who worry that the World Bank is straying from its mandate.
Of course, the Bank must do everything that it can to ensure that its money is well spent, which means fighting both corruption and incompetence.
But money itself will not solve all problems, and a single-minded focus on fighting corruption will not bring development.
On the contrary, it might merely divert attention from other issues of no less moment for those struggling to lift themselves out of poverty.
The Impunity Trap
NEW YORK – Ours is a world of impunity.
Allegations of corruption swarmed around FIFA for decades, culminating in indictments of current and former officials last week.
Yet FIFA President Sepp Blatter was re-elected four times, including after the indictments were filed.
Yes, Blatter has finally resigned, but only after he and dozens of Federation members once again showed their scorn for honesty and the law.
We see this kind of behavior all over the world.
Consider Wall Street.
In 2013 and 2014, JPMorgan Chase paid more than $20 billion in fines for financial malfeasance; yet the CEO took home $20 million in compensation in both 2014 and 2015.
Or consider corruption scandals in Brazil, Spain, and many other countries, where governments remain in power even after high-level corruption within the ruling party has been exposed.
The ability of those who wield great public and private power to flout the law and ethical norms for personal gain is one of the more glaring manifestations of inequality.
The poor get life sentences for petty crimes, while bankers who fleece the public of billions get invitations to White House state dinners.
A famous ditty from medieval England shows that this is not a new phenomenon:
The law locks up the man or womanWho steals the goose off the commonBut leaves the greater villain looseWho steals the common from the goose.
Today’s greatest thieves are those who are stealing the modern commons – raiding government budgets, defiling the natural environment, and preying on the public trust.
When the indictments against the 14 FIFA officials were filed, the cast of characters included not only miscreants from the sports world, but also some familiar players: secret Swiss bank accounts, Cayman Islands tax havens, shell corporations – all of the financial appurtenances that are literally designed to shield the rich from scrutiny and the law.
In this case, the FBI and US Justice Department have done their jobs.
But they did so, in part, by penetrating the murky worlds of financial secrecy created and protected by the US Treasury, the Internal Revenue Service, and the US Congress (ever-protective of Caribbean tax havens).
In some societies and economic sectors, impunity is now so pervasive that it is viewed as inevitable.
When unethical behavior by political and business leaders becomes widely viewed as “normal,” it then goes unpunished by public opinion, and is reinforced as normal – creating an “impunity trap.”
For example, with politicians in the United States now so flagrantly and relentlessly on the take from wealthy donors, much of the public accepts new revelations of financial impropriety (such as the Clinton Foundation’s morally dubious financial dealings) with a cynical yawn.
The situation in the global banking sector is especially alarming.
A recent careful study of ethical attitudes in the financial-services industry in the US and the United Kingdom showed that unethical and illegal behavior is indeed now viewed as pervasive.
Some 47% of respondents said that it is “likely that their competitors have engaged in unethical and illegal activity,” and 23% believed that their fellow employees have engaged in such activities.
The younger generation has learned the lesson: 32% of respondents employed in the financial industry for less than ten years said that, “they would likely engage in insider trading to make $10 million if there was no chance of being arrested.”
The chance of being arrested for such malfeasance is, alas, probably very low.
Yet not all societies or sectors are caught in an impunity trap.
Some societies, most notably in Scandinavia, maintain the expectation that their public officials and business leaders should and will act ethically and honestly.
In these countries, ministers are forced to resign for petty infractions that would seem trivial in other countries.
Convincing American, Russian, Nigerian, or Chinese citizens that corruption can indeed be controlled might seem to be a futile task.
But the goal is certainly worth embracing, because the evidence is overwhelming: impunity is not only morally noxious; it is also economically costly and deeply corrosive to wellbeing.
Recent studies have shown that when “generalized trust” in society is high, economic performance is improved and life satisfaction is higher.
Among other reasons, commercial agreements are more easily reached and efficiently implemented.
It is no coincidence that the Scandinavian countries rank among the world’s happiest and most prosperous year after year.
So what can be done to overcome an impunity trap?
Part of the answer is of course law enforcement (such as the FIFA indictments) and protection for whistleblowers.
Yet law enforcement is not sufficient; public attitudes also play a major role.
If the public expresses contempt and revulsion for bankers who cheat their clients, oil executives who wreck the climate, FIFA officials who countenance kickbacks, and politicians who cozy up to all of them in exchange for campaign funds and bribes, illegality for the few cannot become the norm.
Public scorn might not end corruption immediately, but it can make life far less pleasant for those who are stealing the commons from the rest of us.
One candidate for US President in 2016, former Maryland Governor Martin O’Malley, recently launched his campaign by asking why not a single Wall Street CEO was convicted of a financial crime in the wake of the 2008 financial meltdown.
It is a good question, the kind that can help the US to overcome its impunity trap.
Yet we can ask an even simpler question.
Why are those same bankers still fêted by President Barack Obama, invited to glittering state dinners, and reverently interviewed by the media?
The first thing any society can and should do is deny respectability to political and business leaders who willfully abuse the public trust.
India’s LBW
NEW DELHI – A casual reader of India’s newspapers for the last several weeks would be forgiven for wondering whether the country was suddenly bereft of political controversy, sex scandals, or official corruption – normally the standard headline fare here.
The newspapers’ front pages have had space – under massive banner headlines – only for a topic normally reserved for the sports pages: cricket.
The cause is not some particularly exciting test match.
Instead, the public has been outraged by lurid accusations concerning the Indian Premier League (IPL) – bribes for bad play, owners betting on games, and players seduced by starlets and call girls.
The national captain was revealed to have a conflict of interest, and the son-in-law of Indian cricket’s most powerful official was implicated in an illegal gambling operation run by a sinister network of bookies.
The police, whose phone taps led to a wave of arrests, have filed charges alleging involvement by well-known organized crime figures.
They have even linked a player for India’s national team to the fugitive Dawood Ibrahim, widely suspected of being the architect of the 1993 Bombay bombings, who has been hiding in Pakistan.
The Indian media have not had it this good in a long time.
After years of corruption scandals, political dramas, and protest marches, this was manna from heaven – a story combining cricket, the national obsession, with vice, the national weakness.
India’s 300-plus television news channels have been no better than the print media, devoting almost all of their time to parsing every morsel of information leaked or announced by the police.
A country that traditionally grinds to a halt during an exciting cricket match has now been ground into submission by its antithesis – the slow unraveling of illusions about a game that seizes Indians’ imagination like no other.
Five years ago, I wrote a column about the phenomenal appeal of the IPL and its transformation of cricket in a manner inspired by the televised razzle-dazzle of American sport.
India not only livened up a game that was originally invented in staid and decorous Victorian England; it also brought the game into the twenty-first century, complete with rampant commercialization.
Two-and-a-half minute “strategic timeouts” now interrupt the flow of the game, allowing advertisers to hawk their wares to hundreds of millions of enthralled viewers.
The sociologist Ashis Nandy once memorably wrote that “cricket is an Indian game accidentally discovered by the British.”
Anyone watching the IPL, however, might be tempted to conclude that Twenty20 cricket, the “instant” form of the game, is actually an American game deliberately rediscovered by the Indians.
Other countries have followed suit, with tournaments modeled on the IPL springing up throughout the cricketing world.
To keen observers, the IPL represented more than a sports league; it signaled nothing less than the emergence of a new India.
In the IPL’s glitz, glamour, and excess lay an antidote to the hidebound statist mentality that had produced economic stagnation in India in the past.
Here was a venture that opened new vistas for businesses and fired the imaginations of young people to emulate the entrepreneurial energies shown by owners, promoters, players, and fans.
The IPL suggested a new departure for a country inspired by the allure of its own success.
Understandably, the exposure of the IPL as a morass of deceit, discredited by “spot-fixing” episodes engineered by unscrupulous bookies and venal players, has deflated such heady notions.
Cricket continues to hold many Indians in thrall, but many others have forsaken it in the wake of the IPL revelations.
The paroxysm of media flagellation will soon abate, but the excitement with which the public followed the IPL will not return.
Weighty minds will probably see the IPL’s tawdry underside as emblematic of post-liberalization India’s crony capitalism and business short-termism.
But it is always dangerous to find in sports large metaphors for national decline, so the temptation to view the IPL as symptomatic of everything that is wrong with today’s India must be resisted.
Having initially been seduced by the idea that the IPL showcased the alluring face of a brave new entrepreneurial India, I am reluctant to embrace the opposite view instantly.
But there is no doubt that the flaws being exposed daily in the media – cupidity on a colossal, almost suicidal scale, the quest for easy money, the turn to illegality, and the lack of ethical standards at the highest levels – reveal dangerous streaks in our national character.
The IPL can continue as sporting entertainment, good for a fun evening with the kids in front of the idiot box.
But what it has revealed to Indians about themselves is far less amusing.
The call for reform in cricket is really a call for reform in the way India goes about its business.
The character flaws laid bare in the IPL must be curbed if India is ever to fulfill its obvious promise and take its place at the front of the world stage in the twenty-first century.
The Rising Costs of US Income Inequality
BERKELEY – During the last several decades, income inequality in the United States has increased significantly – and the trend shows no sign of reversing.
The last time inequality was as high as it is now was just before the Great Depression.
Such a high level of inequality is not only incompatible with widely held norms of social justice and equality of opportunity; it poses a serious threat to America’s economy and democracy.
Underlying the country’s soaring inequality is income stagnation for the majority of Americans.
With an expanding share of the gains from economic growth flowing to a tiny fraction of high-income US households, average family income for the bottom 90% has been flat since 1980.
According to a recent report by the Council of Economic Advisers, if the share of income going to the bottom 90% was the same in 2013 as it was in 1973, median annual household income (adjusted for family size) would be 18%, or about $9,000, higher than it is now.
The disposable (after tax and transfer) incomes of poor families in the US have trailed those of their counterparts in other developed countries for decades.
Now the US middle class is also falling behind.
During the last three decades, middle-income households in most developed countries enjoyed larger increases in disposable income than comparable US households.
This year, the US lost the distinction of having the “most affluent” middle class to Canada, with several European countries not far behind.
Once the generous public benefits in education, health care, and retirement are added to estimates of disposable family income in these countries, the relative position of the US middle class slips even further.
The main culprit behind the languishing fortunes of America’s middle class is slow wage growth.
After peaking in the early 1970s, real (inflation-adjusted) median earnings of full-time workers aged 25-64 stagnated, partly owing to a slowdown in productivity growth and partly because of a yawning gap between productivity and wage growth.
Since 1980, average real hourly compensation has increased at an annual rate of 1%, or half the rate of productivity growth.
Wage gains have also become considerably more unequal, with the biggest increases claimed by the top 10% of earners.
Moreover, technological change and globalization have reduced the share of middle-skill jobs in overall employment, while the share of lower-skill jobs has increased.
These trends, along with a falling labor-force participation rate during the last decade, explain the stagnation of middle-class incomes.
For most Americans, wages are the primary source of disposable income, which in turn drives personal consumption spending – by far the largest component of aggregate demand.
Over the past several decades, as growth in disposable income slowed, middle- and lower-income households turned to debt to sustain consumption.
As these families have tightened their belts, the pace of consumption spending and economic growth has become more dependent on earners at the top of the income distribution.
Since the recession ended in 2009, real consumption spending by the top 5% has increased by 17%, compared to just 1% for the bottom 95%.
The recovery’s pattern has reinforced longer-run trends.
In 2012, the top 5% of earners accounted for 38% of personal-consumption expenditure, compared to 27% in 1995.
During that period, the consumption share for the bottom 80% of earners dropped from 47% to 39%.
Looking to the future, growing income inequality and stagnant incomes for the majority of Americans mean weaker aggregate demand and slower growth.
Even more important, income inequality constrains economic growth on the supply side through its adverse effects on educational opportunity and human-capital development.
Children born into low- and high-income families are born with similar abilities.
But they have very different educational opportunities, with children in low-income families less likely to have access to early childhood education, more likely to attend under-resourced schools that deliver inferior K-12 education, and less likely to attend or complete college.
The resulting educational-attainment gap between children born into low and high-income families emerges at an early age and grows over time.
By some estimates, the gap today is twice as large as it was two decades ago.
So the US is caught in a vicious circle: rising income inequality breeds more inequality in educational opportunity, which generates greater inequality in educational attainment.
That, in turn, translates into a waste of human talent, a less educated workforce, slower economic growth, and even greater income inequality.
Although the economic costs of income inequality are substantial, the political costs may prove to be the most damaging and dangerous. The rich have both the incentives and the ability to promote policies that maintain or enhance their position.
Given the US Supreme Court’s evisceration of campaign-finance restrictions, it has become easier than ever for concentrated economic power to exercise concentrated political power.
Though campaign contributions do not guarantee victory, they give the economic elite greater access to legislators, regulators, and other public officials, enabling them to shape the political debate in favor of their interests.
As a result, the US political system is increasingly dominated by money.
This is a clear sign that income inequality in the US has risen to levels that threaten not only the economy’s growth, but also the health of its democracy.
Countdown to Withdrawal from Iraq
How long will the United States maintain a large deployment of troops in Iraq?
That is now the central question of George W. Bush’s second term.
Until recently, the Bush administration answered with an evasive cliché: “as long as it takes and not one day longer.”
But not anymore.
The ice began to crack on November 17, when Representative John Murtha, a hawkish Democratic congressman and marine veteran, suggested pulling troops out of Iraq in six months.
Soon after, the Republican-controlled Senate voted for “a significant transition to full Iraq sovereignty in 2006.”
After initial resistance, Bush began to change his rhetoric by suggesting that a troop drawdown would occur sooner than previously expected.
The erosion in public support for Bush’s Iraq policy is stark.
Fifty-four percent of Americans now say that the US erred in sending troops, up from 24% at the start of the war in March 2003.
In part, this reflects the rising casualty rate, with more than 2,100 American soldiers killed thus far.
But it also reflects a growing belief that the war is failing.
As Duke University’s Peter Feaver, an expert on public opinion who is now serving as a White House advisor, recently pointed out, Americans will tolerate casualties when they believe that a war is just and has a reasonable prospect of success.
But citizens now doubt both these points.
The administration is paying the price for overselling the reasons for the war and bungling the post-invasion occupation.
Not surprisingly, Bush’s new rhetoric stresses that he has a “strategy for victory.”
If “victory” remains defined as stable democracy in Iraq, it is unlikely that Bush will have enough time to implement his strategy.
In September, General George Casey, the senior American military commander in Iraq, testified to Congress that modern insurgencies last about a decade, and that the Iraqi army had only one battalion capable of fighting without help from American military forces.
A month later, the influential International Institute for Strategic Studies in London estimated that US troop withdrawals next year were likely to be small, and that it would take at least five years for Iraq to build the 300,000-strong army needed to fight the insurgency on its own.
But, with Congressional elections in 2006 and a presidential election in 2008, five years is too long.
It seems more realistic that the Republican administration will have only 18 months to two years to implement its strategy.
The Democrats, meanwhile, are divided.
Some, like John Murtha and Nancy Pelosi, the minority leader in the House of Representatives, want a short timetable, while others, like Senator Joseph Biden, resists a firm timetable but predicts a withdrawal of 50,000 US troops in 2006, with many of the remaining 100,000 to follow in 2007.
Those of us who believe that invading Iraq was a mistake, and that Bush is guilty of hubris in his failure to plan adequately for the aftermath, face a dilemma: if America withdraws too precipitously, it may compound these mistakes.
Iraq is not like Vietnam, where American departure was followed by stability imposed by an authoritarian government.
In Iraq, the danger is that departure could be followed by civil war and chaos – ideal conditions for terrorists to maintain havens.
Iraq differs from Vietnam in another way as well.
Unlike the North Vietnamese, the Sunni insurgents will have a difficult time taking over a country where they represent only 20% of the population.
Indeed, with Shia Arabs and Kurds making up 80% of the country, the insurgency is focused on only four of Iraq’s 18 provinces.
America’s quandary is that it is both part of the problem and part of the solution.
So long as a large number of American troops remains as an occupying force, they serve as a recruiting tool for insurgents.
As the political scientist Robert Pape has shown in a careful study, resistance to foreign occupation is a prime motivation for suicide bombers.
But, if America leaves too soon, the elected Iraqi government may be unable to cope with the insurgency, sending Iraq the way of Lebanon in the 1980’s or Afghanistan in the 1990’s.
Similarly, if Bush sets a short timetable, he may encourage the insurgents to wait him out.
But, unless he makes it clear that American troops will leave in the near term, he will reinforce the impression of imperial occupation.
The key to resolving this dilemma will be to press for local compromises that involve Sunnis in the political process, and to step up the rate of training of Iraqis to manage their own security.
Even then, success is uncertain.
One failure is already clear: that of the neo-conservative dream of creating a military ally that could serve as a long-term base for American troops in the campaign to transform and democratize the Middle East.
Three elections have produced some degree of legitimacy for the Shia-dominated Iraqi government, but without a sense of community and effective institutions, elections merely create a tyranny of the majority.
That may be better than Saddam Hussein’s tyranny of the minority, but it is hardly modern democracy.
Bush compares his goal in Iraq to the democratization of Japan after World War II. But Japan was a totally conquered, ethnically homogeneous country with no insurgency, a large middle class, and previous experience of political openness.
Even then, success took seven years.
Instead, Bush should plan on a two-year window to give the Iraqi government as strong a chance as possible before the Americans leave, while emphasizing that Iraqis will thereafter be responsible for their own security and political salvation.
Local Innovation for Local Problems
BOSTON – As we learn more about the threat from substandard and counterfeit medicines, it is becoming clear that it is a far greater problem than previously thought.
It is also a scourge that is most acutely felt in developing countries, where fake and low-quality pharmaceuticals kill more than 500,000 people a year and affect millions more by contributing to the emergence of diseases that are resistant to existing treatments.
Compounding the problem is the approach taken by policymakers in the developing world, who are far more likely to look for solutions abroad than at home.
This shortsightedness is a grave mistake that impedes innovation and progress.
When it comes to tackling high-impact health challenges like the proliferation of fake or inferior drugs, local solutions and local innovations are not only likely to be central to any successful effort; they have the potential to provide benefits that go far beyond the scope of the original problem.
Throughout the developing world, but most evidently in Africa, two groups are interested in finding tools to combat the menace of bad drugs.
One group, comprising students, entrepreneurs, and researchers, seeks solutions that are local, original, and tailored to the needs of their societies. Its members are quick to share ideas and eager to collaborate.
While this group has produced some innovative solutions – for example, the Ghanaian entrepreneur Bright Simmons is using mobile technology to address the counterfeit-drug problem – many more passionate local inventors and entrepreneurs must get involved.
The other group is made up of government officials, including regulators.
They, too, are deeply concerned about the scourge of low-quality and fake drugs, but they are reluctant to rely on local innovation.
In their minds, the solutions already exist, in the form of high-end technology designed and developed in the world’s richest countries.
The challenge, for this group, lies in finding the financial resources to import these technologies.
For developing-country leaders, the effort needed to create an ecosystem that supports innovation simply appears too great, and the return on investment too little.
At countless conferences and symposia, ministry officials and government personnel insist that funds must be found to import solutions, à la carte.
Research and innovation, or engagement with local entrepreneurs and inventors, is, unfortunately, never on the agenda.
There simply is little interest in tapping into the enormous pool of intellect, passion, and energy at home.
Officials would be wise to reconsider.
There is mounting evidence that sustainable solutions must have local support and local partners.
Raising funds to import solutions from abroad addresses just one part of the challenge.
Many countries lack the resources to install, operate, and maintain equipment that has not been designed locally.
As misuse and neglect causes equipment to malfunction, more funds become required or the program simply dies.
Not only does this approach fail to nurture local ecosystems of innovation, which is deeply frustrating; it also fails – repeatedly – to solve the problem at hand.
While some solutions in the area of drug-quality testing have come from African entrepreneurs like Simmons, such examples are extremely rare, and many are developed in the diaspora with the support of organizations from outside the region.
For the most part, such initiatives never engage local students.
Local curricula do not focus on local challenges or promote local innovation.
And yet local talent is critical for solutions that are both original and sustainable.
Indeed, by nurturing an inclusive culture of research, local innovation has the potential to provide benefits that extend far beyond the specific problem that is being addressed.
Nurturing the participation of underrepresented groups and creating opportunities for education and learning not only creates goodwill and promotes transparency and accountability.
Building a stable foundation for future research also enables more productive public-private partnerships and stronger links between academia and domestic industry, thereby promoting economic growth.
Foreign organizations, such as aid agencies or pharmaceutical companies, do have a role to play in boosting local innovation.
They can support it financially, create new partnerships, and encourage policymakers to give it more credence.
The international community has a role to play as well.
This year, the United Nations will adopt the Sustainable Development Goals, marking the start of the next phase of global efforts to eradicate poverty and improve health.
As the example of developing countries’ ongoing fight against counterfeit and low-quality medicines shows, success will depend – far more often than not – on local innovation.
Pendidikan sebagai Penangkal Radikalisasi
DUBAI – Setiap pengunjung di Timur Tengah pasti melihat kesenjangan yang semakin besar antara aspirasi pendidikan, kewirausahaan, dan pekerjaan yang dimiliki kaum muda di kawasan ini dan kenyataan pahit yang menghalangi begitu banyak dari mereka dari terwujudnya masa depan yang positif.
Memang, di Timur Tengah, setengah dari penduduk usia 18-25 tahun tergolong penangguran (unemployed) atau setengah menganggur (underemployed).
Kondisi ini diperburuk dengan krisis pengungsi global, kini sekitar 30 juta anak-anak terlantar, 6 juta diantaranya dari Suriah saja, hanya sedikit yang mungkin bisa kembali ke rumahnya selama usia sekolah.
Tentu tidak mengejutkan ketika kelompok yang dikenal di kawasan ini sebagai Daesh (Negara Islam atau ISIS) percaya bahwa krisis ini bisa menciptakan lahan subur bagi rekrutmen mereka dengan adanya populasi besar kaum muda yang terusir dan merasa tidak puas.
Kini propagandis Daesh menyalahgunakan media sosial sama seperti pendahulu-pendahulu mereka yang ekstrimis dan para propagandis sezamannya terkadang menyalahgunakan masjid – sebagai forum radikalisasi.
Kelompok ini secara konsisten mengunggah muatan-muatan yang meragukan atau menolak kemungkinan koeksistensi antara Islam dan dunia Barat dan menyerukan pemuda untuk berjihad.
Video-video mengerikan yang mengandung kekerasan yang dibuat Daesh telah mengakibatkan kontroversi (shock appeal).
Namun satu hal yang memiliki daya tarik terbesar bagi pemuda-pemuda yang tidak puas adalah undangan untuk menjadi bagian dari sesuatu yang lebih besar dari diri mereka sendiri dan masyarakat di tempat tinggal mereka.
Shiraz Maher dari Pusat Internasional untuk Studi Radikalisasi (ICSR) di King’s College London mengidentifikasi benang merah dari sentimen diantara anggota-anggota baru: “ingin menegakkan kebenaran-keadilan Tuhan, pembangkangan, perasaan teraniaya, dan penolakan untuk menyesuaikan diri”.
Seperti yang disimpulkan dalam laporan terbaru yang disusun Quilliam Foundation, Daesh memanfaatkan hasrat pemuda menjadi bagian dari sesuatu yang berharga; itu merupakan daya tarik utopis organisasi ini yang paling memikat bagi anggota-anggota baru.
Mengingat hal ini beberapa diantaranya anda akan setuju bahwa kita tengah berada dalam pertempuran hati dan pikiran yang terus-menerus dan tidak bisa dimenangkan oleh cara-cara militer saja.
Kekuatan keras (hard power) bisa menyingkirkan pemimpin-pemimpin utama Daesh, tapi kita perlu lebih dari itu untuk meyakinkan hampir 200 juta pemuda Muslim bahwa ekstrimisme, secara harafiah, adalah jalan buntu.
Ada banyak contoh operasi diam-diam yang dijalankan untuk melawan ekstrimisme di sub-benua India dan Timur Tengah: majalah anak-anak di Pakistan, video yang ditujukan untuk remaja di Afrika Utara, stasiun radio di Timur Tengahm dan buku-buku serta publikasi yang menentang Al-Qaeda.
Mereka bisa membantu mengungkap kebenaran tentang kehidupan di Daesh – bahwa mereka itu brutal, korup, dan rentan terhadap pembersihan internal (internal purge) – melalui berbagai cara, termasuk dengan menarik perhatian untuk meninggalkan kelompoknya.
Sebagaimana termuat dalam laporan tahun 2014, “[keberadaan pembelot] menghancurkan citra akan persatuan dan tekad yang berusaha disampaikan [kelompok ini].”
Tetapi kita harus lebih ambisius jika ingin memenangkan perang pemikiran/ide (war of ideas), mempertahankan ruang budaya yang disebut Daesh sebagai “zona abu-abu”, yang kehancurannya sangat mereka dambakan.  Ini adalah ruang dimana warga Muslim dan non-Muslim bisa hidup berdampingan, menemukan nilai-nilai bersama, dan bekerja sama.
Di seluruh Lebanon, kurikulum sekolah yang seragam tentang memperjuangkan keberagaman agama – termasuk “penolakan terhadap segala bentuk radikalisme dan pengasingan agama atau sektarian” – diajarkan kepada anak-anak Sunni, Syiah, dan Nasrani sejak usia sembilan.
Lebanon juga memperkenalkan double shift (kelas pagi dan siang/sore) dalam sistem pendidikannya guna memenuhi kebutuhan 200.000 anak-anak pengungsi Suriah.
Jika negara yang bermasalah seperti Lebanon, negara yang hancur akibat kekerasan sektarian dan perpecahan agama, bisa memperjuangkan koeksistensi dan memberikan kesempatan belajar bagi pengungsi Suriah, maka tidak ada alasan bagi negara-negara lainnya di kawasan itu tidak mengikuti teladannya.
Pilihannya jelas.
Kita bisa saja berdiri dan menonton generasi baru pemuda Muslim yang melek internet (web-savvy) dibanjiri dengan klaim palsu bahwa Islam tidak bisa hidup berdampingan dengan nilai-nilai Barat.
Atau kita bisa mengakui bahwa pemuda di Timur Tengah dan di negara-negara dengan populasi Muslim memiliki aspirasi yang sama dengan kaum muda di negara manapun di dunia.
Semua bukti menunjukkan bahwa kaum muda di kawasan tersebut mendambakan pendidikan, pekerjaan, dan kesempatan untuk mengoptimalkan bakat mereka.
Resolusi kita di tahun 2016 harus berupaya mewujudkannya.
Countering the Contagious West
NEWPORT BEACH – Imagine for a moment that you are the chief policymaker in a successful emerging-market country.
You are watching with legitimate concern (and a mixture of astonishment and anger) as Europe’s crippling debt crisis spreads and America’s dysfunctional politics leave it unable to revive its moribund economy.
Would you draw comfort from your country’s impressive internal resilience and offset the deflationary winds blowing from the West; or would you play it safe and increase your country’s precautionary reserves?
That is the question facing several emerging-market economies, and its impact extends well beyond their borders.
Indeed, it is a question that also speaks to the increasingly worrisome outlook for the global economy.
The very fact that we are posing this question is novel and notable it its own right.
You can add this to the list of previously unthinkable things that we have witnessed lately.
That list includes, just in the last few weeks, America’s loss of its sacred AAA rating; its political flirtation with a debt default; mounting concern about debt restructurings in peripheral European economies and talk about a possible eurozone breakup; and Switzerland’s dramatic steps to reduce (yes, reduce) its safe-haven status.
The answer to the emerging markets’ question would have been straightforward a few years ago.
It is not today.
In the world of old, the West’s economic malaise already would have pulled the rug from beneath most emerging-market countries.
Indeed, the conventional wisdom – supported by many painful experiences – was that when the industrial countries sneezed, the emerging world caught a cold.
Today, however, several (though not all) emerging-market countries are benefiting from years of considerable efforts to reduce their financial vulnerability by accumulating huge amounts of international reserves.
They have also paid back a significant share of external debt and converted much of what remains into more manageable local-currency liabilities.
This sharp balance-sheet improvement has been instrumental in enabling emerging countries to bounce back strongly from the 2008-2009 global financial crisis, whereas the West continues to hobble along.
Indeed, until the recent renewed downturn in America and Europe, the emerging world’s major policy concern was too much growth, mounting inflationary pressure, and economic overheating.
Today’s emerging countries have considerable policy flexibility and much greater latitude to act than they had in the past.
Accordingly, faced with a weakening global economy, they confront two basic policy choices.
On the one hand, they can compensate for the global weakness by turbo-charging their own internal demand through aggressive fiscal stimulus.
This would shield their populations from the West’s problems and, at the global level, provide a counter-impetus to the deteriorating global outlook.
In the process, they would shift some of the policy emphasis from production to consumption.
They would run down their trade surpluses and, in some cases, allow their currencies to appreciate.
Their international reserves would decline and/or their debt would rise.
On the other hand, these economies can opt for greater self-insurance.
In this scenario, rather than stimulating domestic demand, they would fortify their defenses, positioning themselves for a long and stormy winter for the global economy.
Thus, they would minimize the deterioration in their trade surpluses, maintain competitive exchange rates, and safeguard their foreign reserves and net-creditor positions.
In the process, they would accentuate the pressure on the global economy from the West’s seemingly endless downturn.
I suspect that emerging-market policymakers’ hearts are advocating the former.
After all, a domestic stimulus would help maintain economic growth.
Moreover, a counter-cyclical policy would signal to the world these countries’ willingness to take on global responsibilities.
But I also suspect that their heads are cautioning against spending a lot of money in an attempt to accomplish a difficult, if not impossible, task.
After all, there is little to suggest that emerging economies could counter, effectively and sustainably, a large synchronized slowdown in the West, especially when it comes with the risk of another banking crisis.
My inclination is to believe that the head will prevail – but not completely.
Emerging-market economies will take some steps, including interest-rate cuts, to safeguard domestic growth.
They will also signal willingness to help the West financially.
But such steps, while notable, would prove insufficient to counter fully the slowdown emanating from the West; and it certainly would not materially change the outlook for the United States and Europe.
Despite their strong fundamentals, emerging countries still feel vulnerable in the face of the West’s economic weakness, policy shortfalls, and political paralysis.
Moreover, they know from experience that there are no easy and immediate solutions to the West’s debt overhang and structural impediments to growth.
And they have no illusions about the potential for effective global policy coordination.
In such circumstances, policymakers in emerging markets will eschew boldness for prudence.
They will hope for a short winter for the global economy, but they will plan and position for a long one.
Accordingly, they will show very limited appetite for risking the hard-earned policy gains of the last 10-15 years, and the resilience and self-assurance that has come with those gains.
Having put yourself in their position for a moment, can you blame them?
Counting Iraqi Casualties
In times of war, accurate figures on the civilian death toll are almost always hard to come by.
With few exceptions, demographers and epidemiologists have not applied their expertise to making rigorous, credible estimates of civilian mortality and morbidity.
Sometimes, a lack of professional freedom prevents those who may be most familiar with the data – for example, analysts whose livelihoods depend on the government(s) involved in the conflict – from using their expertise for purposes that could be politically damaging.
But there are other challenges as well.
Isolating the conflict’s impact from that of other interventions (e.g., economic sanctions) may be impossible.
Moreover, the high-quality population data needed for credible estimates may not be available due to their “sensitive nature,” or because they never have been collected (sometimes the case in developing nations), or because refugee movements have made data obsolete.
As a result, the degree of uncertainty in such estimates may be unacceptably high, making them of little real worth.
Consider the different approaches that have been used to examine the Iraq war.
The Iraq Body Count aims to tally only deaths from violence during the current war by creating a data set based on media reports.
If there is no double counting, and if the incidents included in the data were reported correctly, their tally represents a minimum number, because media reports may not be comprehensive.
Another approach estimates the total change in mortality that the war caused (including deaths due to the war’s direct and indirect effects) by calculating the change in the death rate from the pre-war period.
This requires data upon which to base the rise in mortality, usually derived by conducting a household survey on a random sample of the population.
Typically, interviewers ask the head of the household to disclose the number and demographic characteristics of pre-war household members, whether any of the people in the pre-war household had died between the pre-war period and the time of the survey, and the date of any household member’s death.
If household surveys are carried out properly, the number of excess deaths during the war can be estimated within a range of statistical uncertainty.
But, when conducted during wartime, risks abound.
Aside from the risks to interviewers collecting such data during a conflict, these include the selection bias of households in the sample, a lack of credible population data to which to apply the changed mortality rates, and mistaken or misleading accounts by participants.
The survey approach was used twice by a group of researchers based primarily at Johns Hopkins University, who published their results in the medical journal 
 The Lancet
 .
Their estimates have been lauded, but also questioned because of their misinterpretation of their own figures. 
For example, in a summary of the 2004 study, they wrote, “Making conservative assumptions we think that about 100,000 excess deaths, or more, have happened since the 2003 invasion of Iraq.”
But the first study yielded very imprecise estimates of the number of deaths, which the authors glossed over.
They should have said, “We can say with 95% certainty that between 8,000 and 194,000 excess Iraqi deaths occurred during the period.”
The group essentially repeated the study in 2006, using a larger sample size.
Again, the researchers had interviewers administer what resembled a typical survey of a random sample of households.
Appropriately, at the end of the article in 
 The Lancet
 , the authors discuss issues that may have resulted in a sample that in fact did not meet the “random” threshold.
Problems with interpretation also plagued that second effort.
The authors used crude death rates (CDR’s), which reflect the number of deaths per thousand people, in explaining the rise in mortality.
Comparing internationally, the UN reports that Iran’s CDR in the 2000-2005 period was 5.3 per thousand.
Prior to the war, most observers thought that the situation in Iraq was considerably worse than in Iran.
So the pre-war CDR that the two 
 Lancet
 studies yield seems too low.
It may not be wrong, but the authors should provide a credible explanation of why their pre-war CDR is nearly half that of the UN Population Division.
If the pre-war mortality rate was too low and/or if the population estimates were too high – because, for example, they ignored outflows of refugees from Iraq – the resulting estimates of the number of Iraqi “excess deaths” would be inflated.
More fundamentally, what purpose do these numbers serve?
Certainly, after the dust has settled, numbers play a role in evaluating the costs and benefits (if any), of a war.
But in real time, do the numbers really add to the debate?
Do they really provide us with more information than the Iraq Body Count figures provide?
Indeed, Richard Nixon’s journey to China in 1972 opened the door for China’s return to the international community.
Most of the next two decades were a honeymoon for Sino-American relations.
On the economic front, the US not only granted China most-favored-nation trade status, but also tolerated China’s mercantilist approach to international trade and finance, notably its dual-track exchange-rate regime.
In the 1990’s, bilateral economic ties continued to expand.
American support for China’s integration into the world system culminated with the country’s accession to the World Trade Organization in 2001.
Since then, China’s exports have grown five-fold.
Of course, China’s inadequate intellectual-property protection has damaged relations (a shortcoming that may be harming Chinese firms more than US firms by deterring American – and other advanced country – companies from deploying new technologies in China).
And the role of China’s state-owned enterprises and official Chinese support for technological “national champions” (privileged companies that almost certainly use government money carelessly) has also hurt relations.
In fact, China’s approach is akin to gambling against the odds.
Successful hi-tech innovations are random events that follow the law of large numbers.
When left to the market, many firms and individuals try to innovate, so the overall probability of success can increase dramatically.
The market allows the law of large numbers to work, whereas concentrated government support for a few favored firms undermines it.
But neither of these flaws, nor the exchange rate, is at the root of today’s global imbalances.
Consider the exchange rate.
The United Kingdom maintained a current-account surplus for the century before World War I, and the US did the same for about 80 years before 1980.
But neither country, apparently, did so by manipulating its exchange rate.
Moreover, the economies that managed to narrow their external gaps with the US substantially after World War II, notably Germany, Japan, South Korea, Singapore, and Taiwan, ran current-account surpluses throughout their rapid-growth periods.
This contradicts American economists’ conventional wisdom that fast-growing countries should borrow today against their larger future shares in the world economy.
One possible explanation is that the relationship between GDP growth rates and a country’s current-account position is not linear.
Compared to countries with very slow growth rates, countries with reasonably high growth rates should borrow.
But when a country’s growth rate continues to increase, its saving rate would increase faster than its investment rate, so it is more likely to run a current-account surplus.
For “catch-up” countries, like China, rapid growth is often accompanied by brisk structural change that moves factors of production, especially labor, from low-productivity activities to economic sectors with much higher productivity.
This adds to the surplus by increasing firms’ profitability.
China’s exchange-rate policy is problematic not because it promotes exports, but because it has forced the country to accumulate a huge pile of wasteful foreign reserves.
The Chinese government’s reluctance to allow faster exchange-rate appreciation may reflect its aversion to large, unforeseeable fluctuations, particularly given its determination to make the renminbi an international reserve currency.
While China’s economy is hampered by structural difficulties, the US is not free of similar challenges.
Frankly, I am always struck by US economists’ reluctance to discuss the structural problems that caused the current crisis, and that hinder America’s recovery.
Most seem to believe that the crisis result from bad monetary policy and lax financial-sector regulation; some even blame the savings accumulated by Asian countries, especially China.
That may be true of the immediate causes of the crisis.
But its eruption was far more deeply rooted in the American version of capitalism, which aims at high levels of competition, innovation, returns, and compensation.
While this model has, of course, helped the US to become the world’s leading economy, it has also delivered severe structural problems.
For example, to sustain high innovation, the US has maintained the most flexible labor market among mature economies.
But this does not come without costs.
Companies often lay off a whole department of scientists to shift to a new product, destroying not only human capital, but also human lives.
Moreover, flexible labor markets imply adversarial labor relations, particularly when compared to northern European countries.
These countries are less innovative than is the US, but their economies and societies may be more resilient.
Meanwhile, the jewel of American capitalism, the financial sector, caused the crisis and is underpinning the US current-account deficit.
Oil exporters aside, countries running current-account surpluses, such as China, Germany, and Japan, have stronger manufacturing sectors relative to their financial sectors, while the relationship is reversed for countries running external deficits, such as the US and the United Kingdom.
Finally, America’s global hegemony has proven to be a curse as well as a blessing.
The US dollar accounts for 60% of world trade, and the US has the strongest military in the world, making it a safe haven for global investors.
But, while large capital inflows reduce borrowing costs, they also tend to cause current-account deficits: lower costs of capital boost asset prices, with the wealth effect then prompting people to consume more than they earn.
The policies adopted or discussed by American policymakers and scholars nowadays – quantitative easing, fiscal-stimulus packages, government-deficit reduction – seek to cure only the symptoms of a deeper malaise.
As a first step to recovery, the US must undertake serious financial-sector reforms.
As Lenin pointed out, financial capitalism is the highest form of capitalism – that is, it is the end of capitalism.
Lenin may have gotten the underlying analysis wrong, but today we know that his conclusion may have been right for another reason: financial capitalism forces a country into unsustainable indebtedness.
Unfortunately, America’s financial reforms have been half-baked at best.
For three decades, “reform” was a word reserved for the Chinese side of the Sino-American relationship.
The US, one hopes, will grow to like the sound of it.
The End of Cross-Border Surrogacy?
LONDON – The global trade in babies born through commercial surrogacy is slowly being shut down.
India, Nepal, Thailand, and Mexico have introduced measures that would limit or ban foreigners from hiring locals as surrogate mothers.
Cambodia and Malaysia look likely to follow suit.
In an industry in which the conventional wisdom has long dismissed efforts to “buck the market,” this is a surprising – and welcome – development.
Uncritical proponents of biotechnology tend to celebrate the fact that technological breakthroughs have outpaced government regulations, arguing that this has allowed science to progress unfettered.
But the determination of countries that have historically been centers of commercial surrogacy to stop the practice underscores the naiveté of that position.
It is no coincidence that the countries cracking down on cross-border surrogacy are those in which the practice takes place.
The argument that all parties – surrogate mothers, babies, and commissioning parents – benefit from the transaction has not withstood scrutiny.
Consider India, where the surrogacy industry is valued at $400 million per year; until recently, some 3,000 fertility clinics were operating in the country.
And yet, as worries have mounted that commercial surrogacy leads to human trafficking and the exploitation of women, India’s authorities have concluded that the ethical concerns outweigh the economic benefits.